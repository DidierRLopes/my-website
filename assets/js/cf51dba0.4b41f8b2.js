"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[90506],{67539:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>g,frontMatter:()=>a,metadata:()=>c,toc:()=>d});var i=t(85893),s=t(3905),o=t(9286),r=t(34673);const a={slug:"building-an-ai-agent-from-scratch-that-can-post-on-bluesky",title:"Building an AI agent from scratch that can post on bluesky",date:new Date("2025-01-04T00:00:00.000Z"),image:"/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky",tags:["openbb","artificial intelligence","ai","agent","open source","ollama","llama","telegram","bluesky","xai","grok","perplexity"],description:"A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky.",hideSidebar:!0},l=void 0,c={permalink:"/blog/building-an-ai-agent-from-scratch-that-can-post-on-bluesky",editUrl:"https://github.com/DidierRLopes/my-website/tree/main/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.md",source:"@site/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.md",title:"Building an AI agent from scratch that can post on bluesky",description:"A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky.",date:"2025-01-04T00:00:00.000Z",tags:[{inline:!0,label:"openbb",permalink:"/blog/tags/openbb"},{inline:!0,label:"artificial intelligence",permalink:"/blog/tags/artificial-intelligence"},{inline:!0,label:"ai",permalink:"/blog/tags/ai"},{inline:!0,label:"agent",permalink:"/blog/tags/agent"},{inline:!0,label:"open source",permalink:"/blog/tags/open-source"},{inline:!0,label:"ollama",permalink:"/blog/tags/ollama"},{inline:!0,label:"llama",permalink:"/blog/tags/llama"},{inline:!0,label:"telegram",permalink:"/blog/tags/telegram"},{inline:!0,label:"bluesky",permalink:"/blog/tags/bluesky"},{inline:!0,label:"xai",permalink:"/blog/tags/xai"},{inline:!0,label:"grok",permalink:"/blog/tags/grok"},{inline:!0,label:"perplexity",permalink:"/blog/tags/perplexity"}],readingTime:10.415,hasTruncateMarker:!0,authors:[],frontMatter:{slug:"building-an-ai-agent-from-scratch-that-can-post-on-bluesky",title:"Building an AI agent from scratch that can post on bluesky",date:"2025-01-04T00:00:00.000Z",image:"/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky",tags:["openbb","artificial intelligence","ai","agent","open source","ollama","llama","telegram","bluesky","xai","grok","perplexity"],description:"A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky.",hideSidebar:!0},unlisted:!1,prevItem:{title:"Tracking my writing progress through an open source blog tracker generator",permalink:"/blog/tracking-my-writing-progress-through-an-open-source-blog-tracker-generator"},nextItem:{title:"AI chatbots won't revolutionize finance, but intelligent workspaces will",permalink:"/blog/ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will"}},h={authorsImageUrls:[]},d=[{value:"Getting Started",id:"getting-started",level:2},{value:"Environment Setup",id:"environment-setup",level:3},{value:"Main libraries",id:"main-libraries",level:3},{value:"Implementation",id:"implementation",level:2},{value:"1. Bluesky API",id:"1-bluesky-api",level:3},{value:"2. Telegram API",id:"2-telegram-api",level:3},{value:"3. Agent brain",id:"3-agent-brain",level:3},{value:"4. Tools for the agent",id:"4-tools-for-the-agent",level:3},{value:"4.1. OpenBB",id:"41-openbb",level:4},{value:"4.2. Perplexity",id:"42-perplexity",level:4},{value:"4.3. Grok",id:"43-grok",level:4},{value:"5. Put it all together",id:"5-put-it-all-together",level:3},{value:"Conclusion",id:"conclusion",level:2}];function p(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.ah)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)("p",{align:"center",children:(0,i.jsx)("img",{width:"900",src:"/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.png"})}),"\n",(0,i.jsx)(n.p,{children:"A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky."}),"\n",(0,i.jsxs)(n.p,{children:["The open source code is available ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post",children:"here"}),"."]}),"\n","\n",(0,i.jsx)("div",{style:{borderTop:"1px solid #0088CC",margin:"1.5em 0"}}),"\n",(0,i.jsx)(n.p,{children:"Over the Christmas break, I decided to explore the world of fine-tuning while assessing the quality of open-source models that can run locally. This exploration is particularly important for me, as we frequently discuss with prospects the possibility of integrating local AI agents into OpenBB to avoid reliance on third-party vendors."}),"\n",(0,i.jsx)(n.p,{children:"To make this experiment practical and engaging, I needed a well-defined use case. My objective was straightforward: to develop an agent capable of focusing on a specific topic, gathering external information, and crafting a post to share on Bluesky triggered by myself."}),"\n",(0,i.jsx)("p",{align:"center",children:(0,i.jsx)("img",{width:"600",src:"/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky_1.jpg"})}),"\n",(0,i.jsx)(n.p,{children:"This is the workflow we are looking at:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"I send a message to my Telegram bot with the idea of what I want to post on Bluesky."}),"\n",(0,i.jsx)(n.li,{children:"That message gets processed by my fine-tune agent, which runs locally."}),"\n",(0,i.jsxs)(n.li,{children:["That message is used to extract further context either from:","\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"OpenBB if financial information is needed."}),"\n",(0,i.jsx)(n.li,{children:"xAI if latest news from social media is needed."}),"\n",(0,i.jsx)(n.li,{children:"Perplexity if more information from the web is necessary."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"The agent then writes a thought on the topic."}),"\n",(0,i.jsx)(n.li,{children:"Then it pushes that post to Bluesky."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,i.jsx)(n.h3,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,i.jsxs)(n.p,{children:["You have a Bluesky account - like mine here: \xa0",(0,i.jsx)(n.a,{href:"https://bsky.app/profile/didierlopes.com",children:"https://bsky.app/profile/didierlopes.com"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["You will need ",(0,i.jsx)(n.code,{children:"BLUESKY_HANDLE"})," and ",(0,i.jsx)(n.code,{children:"BLUESKY_PASSWORD"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["You have a Telegram account and you have created a bot by following the steps highlighted here: \xa0",(0,i.jsx)(n.a,{href:"https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token",children:"https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["You will need ",(0,i.jsx)(n.code,{children:"TELEGRAM_BOT_TOKEN"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["You have installed Ollama and are running a model like ",(0,i.jsx)(n.code,{children:"Llama3.2:latest"})," locally."]}),"\n",(0,i.jsx)(n.p,{children:"Additionally, you will need the following tokens for the agent's tools:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"OPENBB_PAT"})," which you can retrieve from: ",(0,i.jsx)(n.a,{href:"https://my.openbb.co/app/platform/pat",children:"https://my.openbb.co/app/platform/pat"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"PERPLEXITY_API_KEY"})," which you can retrieve from: ",(0,i.jsx)(n.a,{href:"https://www.perplexity.ai/settings/api",children:"https://www.perplexity.ai/settings/api"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"GROK_API_KEY"})," which you can retrieve from: ",(0,i.jsx)(n.a,{href:"https://console.x.ai/",children:"https://console.x.ai/"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"main-libraries",children:"Main libraries"}),"\n",(0,i.jsx)(n.p,{children:"The bot is built using several key libraries:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ATProto Client"}),": For interacting with the Bluesky social network"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Python-Telegram-Bot"}),": For handling Telegram interactions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Asyncio"}),": For handling asynchronous operations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OpenBB"}),": To access financial data"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OpenAI"}),": to hit Perplexity and Grok OpenAI compatible endpoints"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(n.p,{children:"For this tutorial, I'm not going to write about fine-tuning my own LLM to keep it simpler. I will leave that for another post where I want to share more on what I learned about doing so."}),"\n",(0,i.jsx)(n.p,{children:"I'm also going through the step-by-step I performed in order to complete this project, so that this can serve as an inspiration for somebody starting something."}),"\n",(0,i.jsxs)(n.p,{children:['I have a folder called "experiments" ',(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/tree/main/experiments",children:"here"})," which I use to show you how I experiment each subsystem independently and only after each individually works I merge them together. Dividing and conquering here is fundamental."]}),"\n",(0,i.jsx)(n.h3,{id:"1-bluesky-api",children:"1. Bluesky API"}),"\n",(0,i.jsx)(n.p,{children:"I can't push a post to Bluesky if the API doesn't allow me to do so. Therefore, this is where I started."}),"\n",(0,i.jsx)(o.Z,{language:"python",title:(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/bluesky-api.ipynb",target:"_blank",rel:"noopener noreferrer",style:{fontWeight:"bold",color:"#0366d6"},children:"/experiments/bluesky-api.ipynb"}),showLineNumbers:!0,children:"from atproto import Client, client_utils\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = Client()\nprofile = client.login(\n    os.getenv('BLUESKY_HANDLE'),\n    os.getenv('BLUESKY_PASSWORD')\n)\nprint('Welcome,', profile.display_name)\n\ntext = client_utils.TextBuilder().text('Merry Christmas!')\npost = client.send_post(text)\nclient.like(post.uri, post.cid)\n"}),"\n",(0,i.jsx)(n.p,{children:"The code is extremely simple, this made me understand how easy Bluesky API is to interact with."}),"\n",(0,i.jsx)(n.p,{children:"The only thing I added to this was to create a thread of posts if the 300 character post limit was crossed. I didn't know the limit was 300 characters, and so had to handle that situation after when merging all the pieces together since, it turns out, AI agents like to write long posts (or my prompt didn't hint at not doing so strong enough)."}),"\n",(0,i.jsx)(n.h3,{id:"2-telegram-api",children:"2. Telegram API"}),"\n",(0,i.jsx)(n.p,{children:"In order to push a post to Bluesky, I need to have something that triggers it."}),"\n",(0,i.jsx)(n.p,{children:'I could have automated this process as in "at 9am every day post something on a topic", but I wanted the subject to vary and retain control over what my agent does research on.'}),"\n",(0,i.jsx)(n.p,{children:'Therefore, I chose Telegram to act as the "trigger". I have used Discord and Slack in the past, this allowed me to get familiar with interacting with a bot on Telegram.'}),"\n",(0,i.jsxs)(n.p,{children:["I was actually mind-blown by how simple they made the process. More on this here: ",(0,i.jsx)(n.a,{href:"https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token",children:"https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Then I tested that I could send a Telegram bot a message that I would receive on the terminal where this code was running."}),"\n",(0,i.jsx)(r.Z,{summary:"View Telegram API Code",children:(0,i.jsx)(o.Z,{language:"python",title:(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/telegram-api.py",target:"_blank",rel:"noopener noreferrer",style:{fontWeight:"bold",color:"#0366d6"},children:"/experiments/telegram-api.py"}),showLineNumbers:!0,children:'import logging\nfrom telegram import Update\nfrom telegram.ext import (\n    Application,\n    CommandHandler,\n    MessageHandler,\n    filters,\n    ContextTypes,\n)\nimport os\nfrom dotenv import load_dotenv\nimport argparse\n\n# Load token from .env file\nload_dotenv()\nTOKEN = os.getenv("TELEGRAM_BOT_TOKEN")\n\nif not TOKEN:\n    raise ValueError("No TOKEN found in .env file")\n\n# Initialize logger\nlogger = logging.getLogger(__name__)\n\n\n# Move logging setup into a function\ndef setup_logging(verbose: bool) -> None:\n    level = logging.INFO if verbose else logging.WARNING\n    logging.basicConfig(\n        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=level\n    )\n\n\nasync def start(update: Update, _context: ContextTypes.DEFAULT_TYPE) -> None:\n    """Send a message when the command /start is issued."""\n    user = update.effective_user\n    await update.message.reply_html(\n        f"Hi {user.mention_html()}! "\n        f"I\'m a bot. Send me a message and I\'ll print it on the console."\n    )\n\n\nasync def handle_message(update: Update, _context: ContextTypes.DEFAULT_TYPE) -> None:\n    """Print the user message on the console."""\n    message = update.message.text\n    user = update.effective_user\n    chat_id = update.effective_chat.id\n\n    logger.info(\n        "New message received from @%s (chat_id: %s): %s",\n        user.username,\n        chat_id,\n        message,\n    )\n\n    print(f"Message from @{user.username}: {message}")\n\n\nasync def error_handler(_update: object, context: ContextTypes.DEFAULT_TYPE) -> None:\n    """Log errors caused by Updates."""\n    logger.error("Exception while handling an update:", exc_info=context.error)\n\n\ndef main() -> None:\n    # Add argument parsing\n    parser = argparse.ArgumentParser()\n    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")\n    args = parser.parse_args()\n\n    # Setup logging based on verbose flag\n    setup_logging(args.verbose)\n\n    logger.info("Bot started. Waiting for messages...")\n\n    # Create application\n    app = Application.builder().token(TOKEN).build()\n\n    # Add handlers\n    app.add_handler(CommandHandler("start", start))\n    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n\n    # Register error handler\n    app.add_error_handler(error_handler)\n\n    # Start polling\n    app.run_polling(poll_interval=1.0)\n\n\nif __name__ == "__main__":\n    main()'})}),"\n",(0,i.jsx)(n.p,{children:"The only additional things I added afterwards for a better user experience were:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Shows processing status in text"}),"\n",(0,i.jsx)(n.li,{children:"Provides the Bluesky post URL when complete"}),"\n",(0,i.jsx)(n.li,{children:"Indicates if the post was threaded"}),"\n",(0,i.jsx)(n.li,{children:"Reports any errors"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-agent-brain",children:"3. Agent brain"}),"\n",(0,i.jsxs)(n.p,{children:["I have used Ollama and ",(0,i.jsx)(n.code,{children:"Llama3.2:latest"})," previously, and knew how easy it was to call the model. So I didn't bother spending time testing it up in advance."]}),"\n",(0,i.jsx)(o.Z,{language:"python",children:'response = requests.post(\n\t"http://localhost:11434/api/generate",\n\tjson={"model": model, "prompt": post_prompt, "stream": False},\n)'}),"\n",(0,i.jsx)(n.p,{children:"However, I wanted to give some form of flexibility in case someone found some interest in the project - so they could bring their own custom models."}),"\n",(0,i.jsxs)(n.p,{children:["So I put this code into a folder called ",(0,i.jsx)(n.code,{children:"agents"})," and each file here has a class ",(0,i.jsx)(n.code,{children:"LanguageModelWrapper"}),"and works as an agent with (potential) access to tools."]}),"\n",(0,i.jsxs)(n.p,{children:["The code for the ",(0,i.jsx)(n.code,{children:"LLama3.2:latest"})," agent can be found here: ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/llama_3_2_ollama.py",children:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/llama_3_2_ollama.py"})]}),"\n",(0,i.jsx)(n.h3,{id:"4-tools-for-the-agent",children:"4. Tools for the agent"}),"\n",(0,i.jsxs)(n.p,{children:["Finally, I wanted the agent to have access to a few tools, so I created a folder within agents called ",(0,i.jsx)(n.code,{children:"tools"})," where I added each of these. It can be found ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/tree/main/agents/tools",children:"here"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"agents/\n    llama_3_2_ollama.py\n    phi_3_mini_4k_instruct_ft_on_didier_blog.py\n    ...\n    tools/\n        grok.py\n        openbb.py\n        perplexity.py\n        ...\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The implementation for how function calling is performed can be found ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/llama_3_2_ollama.py",children:"here"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["I didn't do anything fancy, just followed the ",(0,i.jsx)(n.a,{href:"https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2",children:"documentation from Meta"})," and checked that the model would return the function in the right format."]}),"\n",(0,i.jsx)(n.p,{children:"The implementation is also very straightforward:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Check what the topic is (that I wrote on Telegram)"}),"\n",(0,i.jsxs)(n.li,{children:["Check if it needs to do research using any of the tools provided","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Currently can only use up to one of them"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Uses the topic I wrote on Telegram + the output from the function call to write a post"}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"41-openbb",children:"4.1. OpenBB"}),"\n",(0,i.jsx)(n.p,{children:"I'm biased here, but wanted to throw OpenBB in the mix for financial information."}),"\n",(0,i.jsx)(n.p,{children:"In this case there are 2 tools that the agent has access to:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"openbb_news_search"})," is used when the agent needs:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"General news articles from various sources"}),"\n",(0,i.jsx)(n.li,{children:"Latest headlines on a specific topic"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"openbb_news_on_company_search"}),"  is used when the agent needs:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Specific news articles about a particular company"}),"\n",(0,i.jsx)(n.li,{children:"Latest information on a company"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's how I tested that I could get this data easily:"}),"\n",(0,i.jsx)(o.Z,{language:"python",title:(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_openbb.py",target:"_blank",rel:"noopener noreferrer",style:{fontWeight:"bold",color:"#0366d6"},children:"/experiments/test_openbb.py"}),showLineNumbers:!0,children:'import os\nfrom openbb import obb\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Initialize the OpenBB SDK\nobb.account.login(pat=os.getenv("OPENBB_PAT"))\n\ndef openbb_news_search(query):\n    """Retrieve news results for a given query using OpenBB\'s news world endpoint."""\n\n    # Fetch news from the world endpoint\n    return obb.news.world(query=query, limit=5, provider="benzinga")\n\ndef openbb_news_on_company_search(query):\n    """Retrieve news results for a given query using OpenBB\'s news world endpoint."""\n\n    # Fetch news from the company news endpoint\n    return obb.news.company(query=query, limit=5, provider="benzinga")\n\n\nif __name__ == "__main__":\n    result = openbb_news_search("technology")\n    print(result)\n\n    result = openbb_news_on_company_search("Apple")\n    print(result)'}),"\n",(0,i.jsxs)(n.p,{children:["And the real implementation is ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/openbb.py",children:"here"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"42-perplexity",children:"4.2. Perplexity"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"perplexity_web_search"})," is used when the agent needs:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"General web information"}),"\n",(0,i.jsx)(n.li,{children:"Detailed background information"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's how I tested that the API worked:"}),"\n",(0,i.jsx)(o.Z,{language:"python",title:(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_perplexity.py",target:"_blank",rel:"noopener noreferrer",style:{fontWeight:"bold",color:"#0366d6"},children:"/experiments/test_perplexity.py"}),showLineNumbers:!0,children:'import os\nimport re\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\ndef perplexity_query(messages):\n    client = OpenAI(\n        api_key=os.getenv("PERPLEXITY_API_KEY"),\n        base_url="https://api.perplexity.ai"\n    )\n\n    response = client.chat.completions.create(\n        model="llama-3.1-sonar-small-128k-online",\n        messages=messages,\n        stream=False,\n    )\n\n    # Remove citations using regex\n    content = response.choices[0].message.content\n    cleaned_content = re.sub(r\'[d+]\', \'\', content)\n    return cleaned_content.strip()\n\nif __name__ == "__main__":\n    # Load environment variables from .env file\n    load_dotenv()\n\n    # Example message\n    example_messages = [\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": "What is the capital of France?"}\n    ]\n\n    # Run the query\n    result = perplexity_query(example_messages)\n    print("Response:", result)\n'}),"\n",(0,i.jsxs)(n.p,{children:["And the implementation is ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/perplexity.py",children:"here"}),"."]}),"\n",(0,i.jsx)(n.h4,{id:"43-grok",children:"4.3. Grok"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"grok_x_search"})," is used when the agent needs:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Recent social media discussions"}),"\n",(0,i.jsx)(n.li,{children:"Twitter/X specific content"}),"\n",(0,i.jsx)(n.li,{children:"Real-time reactions and trends"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Here's how I tested the API:"}),"\n",(0,i.jsx)(o.Z,{language:"python",title:(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_grok.py",target:"_blank",rel:"noopener noreferrer",style:{fontWeight:"bold",color:"#0366d6"},children:"/experiments/test_grok.py"}),showLineNumbers:!0,children:'import os\nimport re\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\n\ndef grok_x_search(query):\n    """Retrieve web search results for a given query using Grok."""\n    client = OpenAI(\n        api_key=os.getenv("GROK_API_KEY"),\n        base_url="https://api.x.ai/v1",\n    )\n    messages = [\n        {\n            "role": "system",\n            "content": (\n                "You are a helpful assistant with access to up-to-date information "\n                "from the web. You can provide context on various topics, especially "\n                "recent events and developments. Your task is to provide enough "\n                "content so the user can craft an informative and engaging post "\n                "based on the given query."\n            ),\n        },\n        {"role": "user", "content": query},\n    ]\n\n    response = client.chat.completions.create(\n        model="grok-beta",\n        messages=messages,\n        stream=False,\n    )\n\n    # Remove citations using regex\n    content = response.choices[0].message.content\n    cleaned_content = re.sub(r"[d+]", "", content)\n    return cleaned_content.strip()\n\nif __name__ == "__main__":\n    # Load environment variables from .env file\n    load_dotenv()\n    # Run the query\n    result = grok_x_search("What are the latest developments in AI?")\n    print("Response:", result)\n'}),"\n",(0,i.jsxs)(n.p,{children:["And the implementation is ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/grok.py",children:"here"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"5-put-it-all-together",children:"5. Put it all together"}),"\n",(0,i.jsxs)(n.p,{children:["Finally, I merged it all together in ",(0,i.jsx)(n.a,{href:"https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/bluesky-agent.py",children:"this file"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"This is what the architecture looks like:"}),"\n",(0,i.jsx)("p",{align:"center",children:(0,i.jsx)("img",{width:"900",src:"/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.png"})}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(n.p,{children:"I enjoyed working on this project. It didn't take me much time to do it, and allowed me to learn:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Utilizing Telegram API and bot convention"}),"\n",(0,i.jsx)(n.li,{children:"Posting on Bluesky"}),"\n",(0,i.jsx)(n.li,{children:"Playing with local models through Ollama"}),"\n",(0,i.jsx)(n.li,{children:"Using xAI API for the first time - made extremely easy with OpenAI compatibility"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The architecture I went with offers several advantages:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Privacy"}),": Using a local LLM means sensitive data stays on your machine"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Customization"}),": The system prompt can be easily modified to change the AI's tone"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reliability"}),": Asynchronous design prevents the bot from hanging"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalability"}),": The modular design makes it easy to add new tools or models"]}),"\n"]}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(n.p,{children:"This hasn't been heavily tested - just enough for me to test that it works end-to-end."}),"\n",(0,i.jsxs)(n.p,{children:["Over the next few days I'm going to play with ",(0,i.jsx)(n.a,{href:"https://github.com/elizaOS/eliza",children:"Eliza from ai16z"}),' which I learned about only after having this implemented. It looks like it has a similar concept but agents "live" natively on X.']}),"\n",(0,i.jsx)(n.p,{children:"Any feedback please let me know!"})]})}function g(e={}){const{wrapper:n}={...(0,s.ah)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},3905:(e,n,t)=>{t.d(n,{ah:()=>c});var i=t(67294);function s(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){s(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function a(e,n){if(null==e)return{};var t,i,s=function(e,n){if(null==e)return{};var t,i,s={},o=Object.keys(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var l=i.createContext({}),c=function(e){var n=i.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},h={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},d=i.forwardRef((function(e,n){var t=e.components,s=e.mdxType,o=e.originalType,l=e.parentName,d=a(e,["components","mdxType","originalType","parentName"]),p=c(t),g=s,m=p["".concat(l,".").concat(g)]||p[g]||h[g]||o;return t?i.createElement(m,r(r({ref:n},d),{},{components:t})):i.createElement(m,r({ref:n},d))}));d.displayName="MDXCreateElement"},34673:(e,n,t)=>{t.d(n,{Z:()=>b});var i=t(67294),s=t(36905),o=t(788),r=t(28138),a=t(72389),l=t(86043);const c={details:"details_lb9f",isBrowser:"isBrowser_bmU9",collapsibleContent:"collapsibleContent_i85q"};var h=t(85893);function d(e){return!!e&&("SUMMARY"===e.tagName||d(e.parentElement))}function p(e,n){return!!e&&(e===n||p(e.parentElement,n))}function g(e){let{summary:n,children:t,...s}=e;(0,r.Z)().collectAnchor(s.id);const g=(0,a.Z)(),m=(0,i.useRef)(null),{collapsed:u,setCollapsed:b}=(0,l.u)({initialState:!s.open}),[x,f]=(0,i.useState)(s.open),y=i.isValidElement(n)?n:(0,h.jsx)("summary",{children:n??"Details"});return(0,h.jsxs)("details",{...s,ref:m,open:x,"data-collapsed":u,className:(0,o.Z)(c.details,g&&c.isBrowser,s.className),onMouseDown:e=>{d(e.target)&&e.detail>1&&e.preventDefault()},onClick:e=>{e.stopPropagation();const n=e.target;d(n)&&p(n,m.current)&&(e.preventDefault(),u?(b(!1),f(!0)):b(!0))},children:[y,(0,h.jsx)(l.z,{lazy:!1,collapsed:u,disableSSRStyle:!0,onCollapseTransitionEnd:e=>{b(e),f(!e)},children:(0,h.jsx)("div",{className:c.collapsibleContent,children:t})})]})}const m={details:"details_b_Ee"},u="alert alert--info";function b(e){let{...n}=e;return(0,h.jsx)(g,{...n,className:(0,s.Z)(u,m.details,n.className)})}}}]);