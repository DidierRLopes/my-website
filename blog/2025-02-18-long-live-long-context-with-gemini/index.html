<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Long live long context with Gemini | Didier Lopes</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Long live long context with Gemini | Didier Lopes"><meta data-rh="true" name="description" content="A practical exploration of using Gemini&#x27;s long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts."><meta data-rh="true" property="og:description" content="A practical exploration of using Gemini&#x27;s long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts."><meta data-rh="true" property="og:image" content="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini"><meta data-rh="true" name="twitter:image" content="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-02-18T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="long context window,gemini,streamlit,rag,pdf parsing,analyst"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini"><link data-rh="true" rel="alternate" href="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini" hreflang="en"><link data-rh="true" rel="alternate" href="https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://CTGM87XQE8-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","mainEntityOfPage":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","url":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","headline":"Long live long context with Gemini","name":"Long live long context with Gemini","description":"A practical exploration of using Gemini's long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts.","datePublished":"2025-02-18T00:00:00.000Z","author":[],"image":{"@type":"ImageObject","@id":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","url":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","contentUrl":"https://didierlopes.com/blog/2025-02-18-long-live-long-context-with-gemini","caption":"title image for the blog post: Long live long context with Gemini"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://didierlopes.com/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Didier Lopes RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Didier Lopes Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="Didier Lopes JSON Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Didier Lopes" href="/opensearch.xml">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-T39XQ0VWEB"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-T39XQ0VWEB",{anonymize_ip:!0})</script>

<link rel="stylesheet" href="src/css/custom.css"><link rel="stylesheet" href="/assets/css/styles.c49f6e55.css">
<script src="/assets/js/runtime~main.9ab2aa73.js" defer="defer"></script>
<script src="/assets/js/main.bc9f9dc3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" target="_self" href="/"><div class="navbar__logo"><img src="/img/goku.png" alt="Goku NFT" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/goku.png" alt="Goku NFT" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Didier Lopes</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/projects">Projects</a><a class="navbar__item navbar__link" href="/books/to-read">Books</a><a class="navbar__item navbar__link" href="/media/news-mentions">Media</a><a class="navbar__item navbar__link" href="/resume/experience">Resume</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/newsletter">Newsletter</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article><header><h1 class="title_f1Hy">Long live long context with Gemini</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-02-18T00:00:00.000Z">February 18, 2025</time> Â· <!-- -->12 min read</div></header><div id="__blog-post-container" class="markdown"><p align="center"><img width="900" src="/blog/2025-02-18-long-live-long-context-with-gemini.png"></p>
<p>A practical exploration of using Gemini&#x27;s long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts.</p>
<p>Learn how to move beyond traditional RAG approaches for document analysis and leverage the power of large context windows for more accurate information retrieval.</p>
<p>The open source code is available <a href="https://github.com/DidierRLopes/long-live-long-context">here</a>.</p>
<!-- -->
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<h2 id="introduction">Introduction</h2>
<p>Last week, a friend of mine was mentioning an interesting challenge that they had. They had to handle multiple documents with over 200-300 pages each with text, tables and images. Their current process of doing this with RAG wasn&#x27;t leading to the best results and it was very time consuming when analyzing the results. But also there wasn&#x27;t a systematic approach being taken to improve the prompt for data retrieval (e.g. few-shot prompt).</p>
<p>Given that I had been reading about people saying that &quot;RAG is dead&quot; because of Gemini models havign 1M+ input context, I wanted to test this model myself. At the same time I wanted to help my friend in setting up a pipeline that would help them automating their data retrieval pipeline.</p>
<p>This post is going to focus on the approach I took, why and how you can set it up yourself.</p>
<p>Note: This isn&#x27;t meant to be a production ready pipeline, but enable you to &quot;vibe test&quot; your ingestion pipeline + data retrieval model + prompts. Funnily enough, this was mostly built in a day through <em>vibe coding</em> (Karpathy&#x27;s coined the term recently).</p>
<p align="center"><img width="600" src="/blog/2025-02-18-long-live-long-context-with-gemini_1.png"></p><p align="center" class="mt-1" style="font-size:0.75em"><a href="https://x.com/karpathy/status/1886192184808149383" target="_blank" rel="noopener noreferrer">Karpathy tweet</a></p><p></p>
<h2 id="starting-point">Starting point</h2>
<p>This is what my friend sent me:</p>
<ul>
<li>Complex PDFs with 200 pages comprised of text, images and tables</li>
<li>An Excel spreadsheet with rows corresponding to values that were being attempted to retrieve and columns including prompt, value returned and correct value.</li>
</ul>
<p>The Excel spreadsheet effectively served as eval, which enabled them to understand whether a better model/pipeline would lead to better results or not. However, this process was very manual.</p>
<p>The equivalent here is the following:</p>
<ul>
<li>
<p>I will be using the following documents: <a href="https://github.com/DidierRLopes/long-live-long-context/blob/main/DeepSeek_R1.pdf">DeepSeek_R1 paper</a> and <a href="https://github.com/DidierRLopes/long-live-long-context/blob/main/ME-cio-weekly-letter.pdf">Capital Market Outlook report</a>. I just had these two at hand to serve as an example.</p>
</li>
<li>
<p>I won&#x27;t be using an Excel spreadsheet, but instead will rely on files in a directory called <code>data</code> within the project.</p>
</li>
</ul>
<p>Here are the prompts that I&#x27;m going to test:</p>
<table><thead><tr><th>idx</th><th>ID</th><th>Prompt</th><th>Expected Result</th></tr></thead><tbody><tr><td>0</td><td>Consumer Discretionary vs Consumer Staples comparison cap-weighted</td><td>By how much did Consumer Discretionary outperform Consumer Staples over the last three months on cap-weighted?</td><td>+17%</td></tr><tr><td>1</td><td>Consumer Discretionary vs Consumer Staples comparison equal-weighted</td><td>By how much did Consumer Discretionary outperform Consumer Staples over the last three months on equal-weighted?</td><td>+13%</td></tr><tr><td>2</td><td>Fed funds rate Q4 2024E</td><td>What is the Fed funds rate, end period (%) for Q4 2024E?</td><td>4.38</td></tr><tr><td>3</td><td>DeepSeek-R1-Zero GPQA Diamond pass@1</td><td>What was DeepSeek-R1-Zero GPQA Diamond pass@1 benchmark?</td><td>73.3</td></tr><tr><td>4</td><td>DeepSeek V3 C-SimpleQA</td><td>What was DeepSeek V3 C-SimpleQA bemchmark?</td><td>68.0%</td></tr><tr><td>5</td><td>Number of reasoning related training samples</td><td>How many reasoning related training samples were collected?</td><td>600k</td></tr></tbody></table>
<p>Note: Prompts 0-2 can be found in Capital Market Outlook report whilst prompts 3-5 in DeepSeek R1 paper.</p>
<h2 id="setting-up-this-experiment">Setting up this experiment</h2>
<h3 id="architecture">Architecture</h3>
<p>Create a folder called data with the following structure:</p>
<pre><code class="language-bash">data/
âââ system_prompt.txt
âââ 0/
â   âââ id.txt
â   âââ prompt.txt
â   âââ expected.txt
âââ 1/
    âââ id.txt
    âââ prompt.txt
    âââ expected.txt
</code></pre>
<p>See our example <a href="https://github.com/DidierRLopes/long-live-long-context/tree/main/data">here</a>.</p>
<p>Let&#x27;s go through each of these:</p>
<h3 id="system-prompt">System prompt</h3>
<p>Contains the system prompt to be used throughout entire application in a <code>system_prompt.txt</code> file.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_2.png"></p>
<h3 id="prompt">Prompt</h3>
<p>Each prompt will have a folder with the idx in the order of it being run - e.g. 0, 1, 2, ...</p>
<p>Inside this folder you will find 3 files: <code>id.txt</code>, <code>prompt.txt</code> and <code>expected.txt</code>. Note that this follows the table that we displayed above.</p>
<h4 id="id">ID</h4>
<p>Contains an identifier that we can use to understand what prompt that is. This can be a slug of the prompt, a KPI number or anything else. It doesn&#x27;t affect anything apart from helping user to be able to distinguish more easily between prompts at a higher level.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_3.png"></p>
<h4 id="prompt-1">Prompt</h4>
<p>Contains the actual prompt to run through all the documents that have been loaded.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_4.png"></p>
<h4 id="expected">Expected</h4>
<p>Contains the expected value or information to be retrieved.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_5.png"></p>
<h2 id="running-the-streamlit-app">Running the Streamlit app</h2>
<p>Clone <a href="https://github.com/DidierRLopes/long-live-long-context">this repository</a>.</p>
<p>Install the following libraries with <code>pip install &lt;library&gt;</code>:</p>
<pre><code class="language-bash">streamlit
google-generativeai
PyMuPDF
pytesseract
pdf2image
Pillow
</code></pre>
<p>or simply do <code>pip install -r requirements.txt</code>.</p>
<p>Retrieve a Gemini API key from <a href="https://ai.google.dev/gemini-api/docs/api-key">here</a>.</p>
<p>And finally run <code>streamlit run app.py</code>.</p>
<p>Note: This application has 500 lines of code and all the logic lives in <a href="https://github.com/DidierRLopes/long-live-long-context/blob/main/app.py">app.py</a>.</p>
<h2 id="how-the-app-works">How the app works</h2>
<h3 id="1-gemini-api-key">1. Gemini API key</h3>
<p>Since the purpose of this is to test Gemini 2.0 Flash model, then we are asking for the API key to be inserted at the top of the script. It could also have been done through <code>.env</code> variable which in general is a better alternative, but I wanted to make this more easier on the people who will run this script.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_6.png"></p>
<h3 id="2-system-prompt">2. System Prompt</h3>
<p>This is the system prompt that will be used across all prompts utilized to retrieve data from context.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_7.png"></p>
<p>The EDIT button allows user to modify the content that lives in <a href="https://github.com/DidierRLopes/long-live-long-context/blob/main/data/system_prompt.txt"><code>data/system_prompt.txt</code></a> and override it.</p>
<h3 id="3-load-documents">3. Load documents</h3>
<p>This allows the user to pick any document that are next to the <code>app.py</code> file on the root of the project. You can select multiple documents and their content will be appended together.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_8.png"></p>
<p>When a document is loaded, you will be able to understand how many tokens each document utilizes when being pushed into Gemini 2.0 flash - through <code>model.count_tokens()</code>. In addition, you will understand how many tokens are being utilized with the combination of all documents uploaded.</p>
<h3 id="4-run-prompts">4. Run prompts</h3>
<p>This one is slightly more complex, let&#x27;s take it each section at a time.</p>
<p align="center"><img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_9.png"></p>
<h4 id="run-all-prompts">Run all prompts</h4>
<p>By clicking on &quot;â¶ï¸â¶ï¸â¶ï¸ Run all prompts&quot;, all prompts get run utilizing Gemini 2.0 Flash with the context provided, in the following format:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">response </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">generate_content</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">system_prompt</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    ---</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">st</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">session_state</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">document_content</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    ---</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">prompt</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    &quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    generation_config</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;temperature&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The &quot;Free Gemini tier (adds timer if running all prompts)&quot; toggle is meant for users that aren&#x27;t paying for Google API and adds a 60s delay after running each prompt. Note: Upgrading to a paid API key is recommended if you are dealing with sensitive data, so that your data is not used by Google for training.</p>
<p>Remember: &quot;If something is free, you are the product&quot; ð.</p>
<p>Now you may be wondering:</p>
<blockquote>
<p><em>&quot;Why is there a green &#x27;â Response matches expected result&#x27; box. How does the model know that the answer is accurate?&quot;</em>.</p>
</blockquote>
<br>
<p>That is because after running the prompt, I take the output and use Gemini 2.0 Flash to compare it against the compared answer. Basically doing LLM as a judge so I have a quick sense of how many prompts I got correct and which ones I didn&#x27;t and work on the failed ones.</p>
<p>This is the prompt that happens under the hood:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">comparison_response </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">generate_content</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    Compare these two texts and return only &#x27;True&#x27; if they convey the same meaning,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    or &#x27;False&#x27; if they differ in meaning.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    Don&#x27;t worry about units as long as the numerical value are the same.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="display:inline-block;color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    Do not add anything else. Just one word: &#x27;True&#x27; or &#x27;False&#x27;.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    Expected:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">expected</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    Actual:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">response</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">text</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="display:inline-block;color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    The meaning of the expected response and the actual response is the same. This statement is: </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">    &quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    generation_config</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;temperature&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;candidate_count&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 id="individual-prompts">Individual prompts</h4>
<p>The concept of running an individual prompt is very similar to the run all prompts, with the exception that it takes approximately &quot;Run all prompts time&quot;/&quot;Number of all prompts&quot; for each. So it&#x27;s better to iterate on a single prompt and the quality of its data retrieval.</p>
<p>In addition, it has a few additional features that can be helpful to iterate:</p>
<ul>
<li>You can click on &quot;EDIT&quot; to edit the <code>prompt.txt</code> directly from the interface. This enables to tweak the prompt to be better at retrieving that specific information (e.g. few shot prompt, which is something that my friend wasn&#x27;t doing and was contributing to lower accuracy).</li>
<li>You can click on &quot;EDIT&quot; to edit the <code>expected.txt</code> directly from the interface. This was particularly relevant when I saw that the LLM as a judge failed when the model retrieved 68.0% for a particular prompt and the expected string I had was 68.0. In this case, the model was actually accurate and my expected value should have been either 68.0% or 0.68.</li>
</ul>
<h2 id="final-thoughts">Final thoughts</h2>
<h3 id="data-ingestion">Data ingestion</h3>
<p>This is one of the most important parts of the workflow:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Convert PDF to images</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">images </span><span class="token operator">=</span><span class="token plain"> convert_from_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">tmp_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> dpi</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># can be increased for higher accuracy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Open PDF with fitz</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pdf_document </span><span class="token operator">=</span><span class="token plain"> fitz</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">open</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">tmp_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">file_content </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Process each page</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> page_number </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">range</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">pdf_document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    page </span><span class="token operator">=</span><span class="token plain"> pdf_document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_page</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">page_number</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> page</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_drawings</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># OCR needed for vector content</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text </span><span class="token operator">=</span><span class="token plain"> pytesseract</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">image_to_string</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            images</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">page_number</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> lang</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;eng&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Extract text directly</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        text </span><span class="token operator">=</span><span class="token plain"> page</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;text&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    file_content </span><span class="token operator">+=</span><span class="token plain"> text </span><span class="token operator">+</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;\n&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pdf_document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">close</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>From my friend results, I saw that it was consistently failing for a few prompts. The main reason for that was because the data was in a table that was an image underneat and the PDF reader didn&#x27;t parse images. That meant that it didn&#x27;t matter how good the prompt was, the model was set up for failure.</p>
<p>I don&#x27;t think the pipeline I&#x27;ve built is particularly strong but it highlights an example of how one can handle a scenario with text, tables and images going through each page individually by:</p>
<ul>
<li>Check if there is an image<!-- -->
<ul>
<li>If there is, do OCR using Tesseract to extract text</li>
<li>If there isn&#x27;t, use PyMuPDF to extract text</li>
</ul>
</li>
</ul>
<p>I believe that something that would improve results immediately is running the output of the OCR by a LLM and trying to reconstruct the table/image in markdown format if possible. I say this because I noticed that sometimes the OCR output can be a bit messy, and having an LLM focused on adding structure to each page OCR may lead to better outcomes.</p>
<h3 id="long-context-is-a-blessing">Long context is a blessing</h3>
<p>Something I noticed from the data my friend shared is that the RAG pipeline they had implemented struggled when the value that the model had to return wasn&#x27;t immediate but it had to pick values from different places to piece it together.</p>
<p>Imagine you were asking the model about the number of reasoning related training samples and the PDF mentioned that the number of reasoning related training samples was 2% of the training dataset samples. And in another page it said that the training dataset has 30 million samples. You need to get both of these in order to infer that the number of reasoning related training samples is 600k samples.</p>
<h3 id="subject-matter-experts-are-more-relevant-than-ever">Subject matter experts are more relevant than ever</h3>
<p>Despite advances in LLM capabilities, domain expertise remains crucial for effective prompt engineering. During testing, many retrieval failures stemmed not from model limitations, but from prompts that didn&#x27;t properly account for domain-specific context and terminology.</p>
<p>As a non-expert, I found it challenging to craft effective prompts because I lacked deep understanding of:</p>
<ul>
<li>How specific data points are typically represented in this type of document</li>
<li>The precise meaning and significance of domain terminology</li>
<li>Common document structures and conventions in the field</li>
<li>How small variations in wording could make it so that the metric extracted wasn&#x27;t the correct one</li>
</ul>
<h3 id="set-a-benchmark-and-work-reverse-from-there">Set a benchmark and work reverse from there</h3>
<p>Before starting this work I had a benchmark where I was working backwards from. This was super helpful as it allows me to understand how this workflow, out-of-the-box, compares with my friends&#x27; one.</p>
<p>Then we can work backwards from there and:</p>
<ul>
<li>Improve the system prompt</li>
<li>Use a different model (and get rid of RAG eheh)</li>
<li>Improve ingestion pipeline to process images</li>
<li>Automate process a bit better with a Streamlit app</li>
<li>Improve each individual prompt to retrieve information more accurately (few-shot prompt)</li>
</ul>
<h3 id="prompt-testing-and-validation">Prompt testing and validation</h3>
<p>Using LLMs as judges and being able to run prompts from the app, enabled to have a much more seamless workflow. This approach:</p>
<ul>
<li>Provides immediate feedback on prompt effectiveness</li>
<li>Helps iterate and refine prompting strategies</li>
<li>Ensures consistency in information extraction</li>
<li>Reduces the need for manual verification</li>
</ul>
<h2 id="long-live-long-context">Long live Long Context</h2>
<p>Honestly, long context is f*ing awesome.</p>
<p>Here are a few things that made me really happy:</p>
<ul>
<li>Ability to handle multiple documents at once without having to worry about chunking or managing context windows</li>
<li>No need to worry about losing context between different sections of a document</li>
<li>Reduced complexity in the overall pipeline since we don&#x27;t need complex RAG infrastructure</li>
<li>Better accuracy (in theory) since the model has access to the full context and can make connections across different parts of the document</li>
<li>Faster development time since we don&#x27;t need to spend time optimizing chunking strategies or fine-tuning retrieval mechanisms</li>
</ul>
<h2 id="next">Next</h2>
<p>I won&#x27;t be spending more time on this project, as I did it to help a friend on their specific problem. I wrote this post so that I could share this with them and any other person in the future that is getting into LLMs.</p>
<p>Feel free to fork the project and go wild.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/long-context-window">long context window</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/gemini">gemini</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/streamlit">streamlit</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/rag">rag</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/pdf-parsing">pdf parsing</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/analyst">analyst</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/DidierRLopes/my-website/tree/main/blog/2025-02-18-long-live-long-context-with-gemini.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/ui-layer-is-the-next-big-frontier"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">UI layer is the next big frontier</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/what-it-means-to-have-skin-in-the-game"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">What it means to have skin in the game</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#introduction">Introduction</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#starting-point">Starting point</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#setting-up-this-experiment">Setting up this experiment</a><ul><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#architecture">Architecture</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#system-prompt">System prompt</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#prompt">Prompt</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#running-the-streamlit-app">Running the Streamlit app</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#how-the-app-works">How the app works</a><ul><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#1-gemini-api-key">1. Gemini API key</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#2-system-prompt">2. System Prompt</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#3-load-documents">3. Load documents</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#4-run-prompts">4. Run prompts</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#final-thoughts">Final thoughts</a><ul><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#data-ingestion">Data ingestion</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#long-context-is-a-blessing">Long context is a blessing</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#subject-matter-experts-are-more-relevant-than-ever">Subject matter experts are more relevant than ever</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#set-a-benchmark-and-work-reverse-from-there">Set a benchmark and work reverse from there</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#prompt-testing-and-validation">Prompt testing and validation</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#long-live-long-context">Long live Long Context</a></li><li><a class="table-of-contents__link toc-highlight" href="/blog/2025-02-18-long-live-long-context-with-gemini#next">Next</a></li></ul></div></div></div></div></div><footer class="bg-[#f0f0f0] dark:bg-[#2c2c2c] text-[var(--ifm-footer-color)] py-8"><div class="container container-fluid"><div class="row flex justify-center items-center"><div class="col text-center"><h4 class="mb-4">Let&#x27;s stay in touch.</h4><div class="flex justify-center space-x-4"><a href="https://twitter.com/didier_lopes" target="_blank" rel="noreferrer" class="text-black dark:text-white hover:text-gray-700 dark:hover:text-gray-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" aria-label="Twitter"><title>Twitter</title><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path></svg></a><a href="https://www.linkedin.com/in/didier-lopes/" target="_blank" rel="noreferrer" class="text-black dark:text-white hover:text-gray-700 dark:hover:text-gray-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" aria-label="LinkedIn"><title>LinkedIn</title><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"></path></svg></a><a href="https://github.com/DidierRLopes" target="_blank" rel="noreferrer" class="text-[#333] dark:text-[#f5f5f5] hover:text-[#24292e] dark:hover:text-[#e6edf3]"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" aria-label="GitHub"><title>GitHub</title><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://cal.com/didierlopes/15min" target="_blank" rel="noreferrer" class="text-black dark:text-white hover:text-gray-700 dark:hover:text-gray-300" aria-label="Book a meeting"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" aria-label="Calendar"><title>Cal.com</title><path d="M19 4h-1V2h-2v2H8V2H6v2H5c-1.11 0-1.99.9-1.99 2L3 20c0 1.1.89 2 2 2h14c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 16H5V10h14v10zM9 14H7v-2h2v2zm4 0h-2v-2h2v2zm4 0h-2v-2h2v2zm-8 4H7v-2h2v2zm4 0h-2v-2h2v2zm4 0h-2v-2h2v2z"></path></svg></a></div></div></div></div></footer></div>
</body>
</html>