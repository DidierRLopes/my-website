{
    "version": "https://jsonfeed.org/version/1",
    "title": "Didier Lopes Blog",
    "home_page_url": "https://didierlopes.com/blog",
    "description": "Didier Lopes Blog",
    "items": [
        {
            "id": "https://didierlopes.com/blog/why-we-got-rid-of-pips-at-openbb",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb.png\"></p>\n<p>At OpenBB, we removed Performance Improvement Plans (PIPs) in an attempt to increase the company's talent density pool rate.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<h2 id=\"how-did-we-get-here\">How did we get here?</h2>\n<p>We are currently 16 FTE and since the company started 3 years ago, we’ve let go 15 people.</p>\n<p>This means we’re letting go of more than 1 person a quarter since the start of OpenBB.</p>\n<p>Most people had a 3-week PIP process before their departures. But out of the 15 PIPs done, only one was successful. All the others have resulted in a contract termination.</p>\n<p>That’s a success rate of less than 7%, which is extremely low.</p>\n<h3 id=\"statistics\">Statistics</h3>\n<p>If we go into the machine learning domain and have a model that predicts that a team member who gets into a PIP is let go every time - this is the classification matrix that we would have.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb_02.png\"></p>\n<p>Which has:</p>\n<ul>\n<li>\n<p>93.3% precision - answers: of all the people predicted to be let go (15), how many were let go? (14)</p>\n</li>\n<li>\n<p>100% recall - answers: of all the people that were let go (14), how many were predicted correctly (14)</p>\n</li>\n</ul>\n<p>Now, this isn’t the full story.</p>\n<p>This is the equivalent of a physics book treating an object as a point mass, considering the body as perfectly rigid or assuming the system is isolated with no external forces.</p>\n<p>So what are the other things to consider? Let’s separate these time-wise:</p>\n<ol>\n<li>\n<p>Before a PIP happens</p>\n</li>\n<li>\n<p>During the PIP</p>\n</li>\n<li>\n<p>After the PIP</p>\n</li>\n</ol>\n<h2 id=\"before-a-pip\">Before a PIP</h2>\n<p>Before someone starts a PIP, their performance has already been subpar.</p>\n<p>By definition, performance is a lagging indicator, which means you are already late when you catch this person not pulling as much value as others.</p>\n<p>Particularly when you consider that the person who would be initiating the PIP is the team lead (TL)/manager and isn’t working as closely with this person as others on a daily basis. Hence, coworkers are likely to see firsthand this suboptimal performance in advance of the team lead or manager.</p>\n<p>So, the suboptimal performance from this person over a few days or weeks is likely to go unnoticed and slow down the company.</p>\n<p>In addition, individual contributors (ICs) who work closely with this person are likely to notice this before the TL/manager, thus impacting their motivation.</p>\n<p><em><strong>\"If this person can get the same compensation as I do for average work, why am I putting in so much time and effort?\"</strong></em></p>\n<p>Honestly, if there’s one thing that I’ve learned, it’s that A players get motivated by other A players (“A players attract A players”).</p>\n<h2 id=\"during-a-pip\">During a PIP</h2>\n<p>A PIP takes time. <strong>A LOT of it.</strong></p>\n<p>And that’s the one thing that startups don’t have.</p>\n<p>Imagine that you have the following org:</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb_03.png\"></p>\n<p>If an IC is underperforming, the TL will discuss it with the IC in advance.</p>\n<p>Then the team lead may ask for feedback from other ICs who work with the IC in question.</p>\n<p>After that, the TL will talk with the Director about this before initiating the PIP.</p>\n<p>Then the Director will mention this to the CEO of the company.</p>\n<p>The CEO will likely want to talk with the team lead about this, given that in an organization of 15 people, each team member accounts for more than 5% of the org.</p>\n<p>Now, you may be thinking, “But this happens before the PIP”.</p>\n<p>This happens before and continues throughout the entire PIP. But, during the PIP, it’s even worse because there are regular meetings for a shorter feedback loop, and there needs to be documentation on the progress.</p>\n<p>So yes, this not only takes a lot of time, but it’s also a distraction to the team.</p>\n<p>And that’s the other thing that companies need: “focus”.</p>\n<p>You can’t fully focus at 100% when you know that someone is “fighting” for their job. And not being able to focus impacts each individual’s performance.</p>\n<p>So this inefficiency ends up spreading across the team.</p>\n<h2 id=\"after-the-pip\">After the PIP</h2>\n<h3 id=\"needs-to-be-let-go\">Needs to be let go</h3>\n<p>Ok, someone was underperforming and needs to be let go.</p>\n<p>The company needs to figure out:</p>\n<ul>\n<li>\n<p>How many options this person has vested and handle the paperwork if they want to buy them</p>\n</li>\n<li>\n<p>Whether they have company equipment that needs to be returned</p>\n</li>\n<li>\n<p>What the severance package will be</p>\n</li>\n<li>\n<p>How to handle the news and how the team will react</p>\n</li>\n</ul>\n<p>Again, this will be a distraction for at least an additional week and will affect other team members, who may be surprised by this.</p>\n<p>Particularly because, most of the time, they aren’t aware that the PIP is happening and from their perspective, someone they liked to work with was let go.</p>\n<h3 id=\"has-a-successful-pip\">Has a successful PIP</h3>\n<p>Let’s be honest, these cases are very rare.</p>\n<p>Not just at OpenBB. I’ve spoken with other founders, and this is the same feedback I’ve received.</p>\n<p>But let’s ignore that, we already mentioned it at the start.</p>\n<p>Someone on a PIP—almost by definition—isn’t a high performer. They could be a high performer in some parts of the job, but not as a whole. However, this is the exception, not the rule.</p>\n<p>The rule, often, is that this person has been doing just enough to be competent at the company—but not excel. Then, over a period of time, due to internal reasons, lack of motivation, etc., they fall below that threshold.</p>\n<p>This means that even after a successful PIP, you are putting all of these resources toward getting—not a high performer, but a B+ player.</p>\n<p>And ultimately, this is why we are getting rid of the PIP at OpenBB.</p>\n<p>Being <strong>“good enough”</strong> isn’t the culture we want for OpenBB and doesn’t represent our team today. If you let the bar slip, you won’t even realize it until it’s too late.</p>\n<p>Again, performance is a lagging indicator and can have both positive and negative effects on the team—so it’s important to protect the team from poor performers.</p>\n<p>There are two exceptions to this:</p>\n<p><strong>1. Imagine that this person can turn their output into 4x, imagine they had a wake-up call.</strong></p>\n<p>Several questions need to be asked:</p>\n<ul>\n<li>\n<p>If this person can perform at this level, why weren't they doing it before?</p>\n</li>\n<li>\n<p>How long will they maintain this level of performance?</p>\n</li>\n<li>\n<p>Will we need to have another serious conversation to get this person to reach this level of competency again at a later stage?</p>\n</li>\n<li>\n<p>Will they always resent the company because of the PIP?</p>\n</li>\n</ul>\n<p>It all boils down to this: if this person isn’t motivated by what we’re building, regardless of their skill set, they weren’t a good fit in the first place.</p>\n<p>We’re fortunate to have a pipeline of people applying for positions at OpenBB, not just for the money but for the product and the mission of the company.</p>\n<p><strong>2. The person is a high performer but has been performing poorly in some areas of the job (e.g. communications, testing, documentation, …)</strong></p>\n<p>This person had likely received feedback multiple times, but the PIP made it more real: <em>“This is what we are looking for in a person for your role; you have 2-3 weeks to prove that you can double down on your weaknesses and reach the level the team needs you to be at.”</em></p>\n<p>This is what happened to us, and the person improved significantly, so much so that they are now a core part of who OpenBB is today.</p>\n<p>This success story was one of the main reasons we continued doing PIPs.</p>\n<p>But the likelihood of it happening again is so low that it’s not worth keeping PIP to look for another success story like this one.</p>\n<h2 id=\"so-whats-next\">So what’s next?</h2>\n<h3 id=\"how-we-think-about-talent-level-at-openbb\">How we think about talent level at OpenBB</h3>\n<p>Let’s say you define company’s talent value as the sum of the talent of each individual divided by the total number of team members.</p>\n<p>There are two ways to increase this value:</p>\n<ul>\n<li>\n<p>Hire people who are above OpenBB’s talent level</p>\n</li>\n<li>\n<p>Let go of people who fall below the talent level</p>\n</li>\n</ul>\n<p>Or, ideally, do both.</p>\n<p>The problem is that for the first option, you often need <strong>a LOT</strong> of capital.</p>\n<p>For the second, you don’t. Not only that but letting go of low performers will accomplish two things simultaneously:</p>\n<ul>\n<li>\n<p>Increase OpenBB’s talent level immediately.</p>\n</li>\n<li>\n<p>Free up resources that can be invested in someone above OpenBB’s current talent value (assuming that companies should always seek high performers and avoid settling for underperformers).</p>\n</li>\n</ul>\n<p>And that’s why removing PIPs leads to an increase in the company’s talent level. You’re not just increasing the talent level once, but likely twice.</p>\n<p>Here’s an example:</p>\n<p>Imagine we have 5 people at OpenBB with talent scores of 2, 7, 7, 7, and 9. Then OpenBB’s talent level is:</p>\n<p>(2+7+7+7+9)/5 = 6.4</p>\n<p>If we let go of the employee with a talent score of 2, our talent level becomes 7.4. Then, if we bring in someone with a score of 8 using the same resources, that talent level increases to 7.6.</p>\n<p>You get the idea.</p>\n<h3 id=\"what-the-team-can-expect\">What the team can expect?</h3>\n<p>Full transparency.</p>\n<p>We want to build a culture where feedback is an ever-present element, and we don’t need to wait for performance reviews to give feedback that can substantially improve team performance and push the company forward.</p>\n<p>In fact, not sharing this feedback puts the company in a worse position, and it is your duty to share it. But do so with candor, in a constructive manner that keeps the team member motivated.</p>\n<p>However, each team member must care. This means you can’t rely solely on your team lead to give you feedback every day—you need to ask for it regularly. That’s the best way for you to grow.</p>\n<h2 id=\"final-notes\">Final notes</h2>\n<p>We made this decision after reading <em>No Rules Rules: Netflix and the Culture of Reinvention</em>, where they also removed PIPs.</p>\n<p>Unlike Netflix, we don’t have the resources to:</p>\n<ul>\n<li>\n<p>Pay top of the market</p>\n</li>\n<li>\n<p>Offer a generous severance</p>\n</li>\n</ul>\n<p>We still pay good salaries, just not enough to compete with public companies. This means we need to spend much more time finding diamonds in the rough.</p>\n<p>And that’s why we have a higher turnover; finding diamonds in the rough is much riskier.</p>\n<p>In any case, I think optimizing to pay top of the market is misguided—at least for startups—as it incentivizes the wrong type of talent.</p>\n<p>It incentivizes mercenaries instead of missionaries.</p>\n<p>At an early stage, you need people who want a lot of ownership and autonomy, who are excited to work with a team and on a product they believe in, and who have a chip on their shoulders.</p>\n<p>Regardless of the startup, I have yet to see someone with this mentality who doesn’t end up being successful.</p>\n<p><strong>Note</strong>: Most of the people who were let go would be considered good employees in most companies today, and they had strong referrals. But companies have different types of needs that evolve over time, and as founders, it’s our role to look at the company as a whole and understand what it needs at the moment and, more importantly, what it will need in the coming months and years.</p>",
            "url": "https://didierlopes.com/blog/why-we-got-rid-of-pips-at-openbb",
            "title": "Why we got rid of PIPs at OpenBB",
            "summary": "My thoughts on how removing PIPs can increase the company talent level",
            "date_modified": "2024-11-09T00:00:00.000Z",
            "tags": [
                "openbb",
                "management",
                "leadership",
                "talent",
                "hiring",
                "performance",
                "company-culture",
                "startups"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/implement-feedback-loops-everywhere-you-can",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-10-25-implement-feedback-loops-everywhere-you-can.jpeg\"></p>\n<p>Maximizing team transparency through focused feedback sessions.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>A couple of months ago, my co-founder came to NYC for our board meeting.</p>\n<p>During that week, we took a day to sync up with everyone on the team—literally. We had 14 conversations, each lasting up to 30 minutes. Apart from lunch, we did all these back-to-back.</p>\n<p>The goal of this exercise was 2-fold:</p>\n<ul>\n<li>\n<p>Check up on the team. Basically, a more in-depth version of:\n<a href=\"https://openbb.co/company/open/team\">https://openbb.co/company/open/team</a></p>\n</li>\n<li>\n<p>Have the team share anything they want with leadership or ask any questions openly.</p>\n</li>\n</ul>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-25-implement-feedback-loops-everywhere-you-can_2.jpeg\"></p>\n<h2 id=\"structure\">Structure</h2>\n<h3 id=\"part-1---20-minutes\">Part 1 - 20 minutes</h3>\n<p>For the first 20 minutes, we asked the following questions to each team member:</p>\n<ol>\n<li>\n<p>How do you feel working for OpenBB today?</p>\n</li>\n<li>\n<p>What do you enjoy the most about working at this company?</p>\n</li>\n<li>\n<p>Who do you get along the best? and why?</p>\n</li>\n<li>\n<p>Who do you feel like you have a not-so-close relationship with? and why?</p>\n</li>\n<li>\n<p>What does your day-to-day look like?</p>\n</li>\n<li>\n<p>How would you describe the relationship with your manager/team lead?</p>\n</li>\n<li>\n<p>It's 2028 and OpenBB didn't make it. What are potential reasons that you would bet on that lead to this?</p>\n</li>\n<li>\n<p>If you had to tell us what your biggest achievement is since being in the company, which one would you pick?</p>\n</li>\n<li>\n<p>What was your lowest moment during company time - and why? What could we have done better?</p>\n</li>\n<li>\n<p>(for managers/team leads) How do you feel about the team you have today?</p>\n</li>\n</ol>\n<h3 id=\"part-2---10-minutes\">Part 2 - 10 minutes</h3>\n<p>During the last 10 minutes, the team could ask us about anything.</p>\n<p>Funnily enough, we learned just as much (if not more) from the questions the team asked than the ones from Part 1.</p>\n<h2 id=\"results\">Results</h2>\n<p>Lack of focus is the biggest risk/challenge that we face as a company.</p>\n<h3 id=\"culture\">Culture</h3>\n<ul>\n<li>\n<p>Handbook is important (folks didn't know about personal development budget, PIP, etc…)</p>\n</li>\n<li>\n<p>The team's main reasons for being happy at OpenBB are autonomy, ownership, smart team, transparency and freedom - very aligned with our values.</p>\n</li>\n<li>\n<p>Remote work is a benefit that more people should take advantage of. Celebrate it even more.</p>\n</li>\n<li>\n<p>It's vital to set boundaries when overworking and know when to decompress to avoid burnout</p>\n</li>\n</ul>\n<h3 id=\"management\">Management</h3>\n<ul>\n<li>\n<p>It's key to consider that each person has different preferences in terms of management style - execution vs contributing to discussion.</p>\n</li>\n<li>\n<p>1:1s are essential and everyone should have them set.</p>\n</li>\n<li>\n<p>1:1s should be focused on the direct report and not necessarily on tasks at hand. Several people highlighted that they felt that their manager cared about them based on conversations about their personal life and personal development.</p>\n</li>\n<li>\n<p>Feedback should go both ways, the manager/leader appreciates when feedback is provided.</p>\n</li>\n<li>\n<p>Setting up expectations clearly for each individual is critical. People appreciate when they know exactly what is expected of them, so they understand how their value is perceived from the company's perspective.</p>\n</li>\n</ul>\n<h3 id=\"rituals\">Rituals</h3>\n<ul>\n<li>\n<p>Monthly update emails are very good. Sometimes even more details would be better.</p>\n</li>\n<li>\n<p>Some people are so focused on execution that they try to protect their time at all costs. It's important to respect this decision and default to async text-based conversations instead of setting up a meeting</p>\n</li>\n<li>\n<p>Dogfood the product from people from different backgrounds is important as it gives different points of view that we can leverage to make our product better</p>\n</li>\n</ul>\n<h3 id=\"communicatiions\">Communicatiions</h3>\n<ul>\n<li>\n<p>Be aware of different comms styles throughout org. In general, people have shared that they appreciate when others send them a DM with feedback based on a conversation in a public channel.</p>\n</li>\n<li>\n<p>Sometimes team members need to put themselves in the shoes of other people first instead of defaulting to defence.</p>\n</li>\n<li>\n<p>We shouldn't compromise on quality. We should aim to agree first on the best solution and then adapt if there's a lack of resources, but knowing what the best solution is and what is the trade-off that is being made</p>\n</li>\n<li>\n<p>When a conversation is taking a few messages back and forth, sometimes a quick huddle should be done</p>\n</li>\n<li>\n<p>Making sure that all stakeholders are involved regarding features or changes in the product before any green light is given to execute. It happened that a green light was given, mockups were created based on that context and the engineering team added the feature. Only for that to get pushed back because a stakeholder that wasn't involved in the discussion saw the final result on Slack chat.</p>\n</li>\n</ul>\n<h3 id=\"transparency\">Transparency</h3>\n<ul>\n<li>\n<p>More transparency when deals are closed - e.g. what are they interested in, how many seats, what do they do on a day-to-day basis</p>\n</li>\n<li>\n<p>When mentioning increased transparency, the vast majority of people think that our level of transparency is very high.</p>\n</li>\n<li>\n<p>A common answer: \"If I have any questions I know can just DM you and you will answer\"</p>\n</li>\n<li>\n<p>Add a Q&amp;A at the end of the status update where everyone can put questions to be answered</p>\n</li>\n<li>\n<p>A common answer: \"I don't like when someone leaves out of a sudden\". Unfortunately, we can't do anything here. We've also asked for feedback on what we could do better, but people understood that there's not much we can do. This is a conversation between the person and the manager and it's unfair for the person being let go if we share their personal information. There's a PIP and that means that before everyone leaves the company they are in 3-4 weeks PIP, where expectations are set clearly and their continuity depends on their output.</p>\n</li>\n<li>\n<p>People appreciate feedback a lot, regardless of if it's positive or not. It's the best way for them to improve.</p>\n</li>\n</ul>\n<h3 id=\"thoughts\">Thoughts</h3>\n<p>I think, at an early stage, everyone should do this. And maybe even at a later stage but in each subset of the org.</p>\n<p>One of the reasons I think this worked so well is that for the first 20 minutes, you are asking the exact same questions to everyone and so that allows you to get answers that you can compare across the board.</p>\n<p>Then, once those 20 minutes are over, the team member feels that they have already been so transparent that they openly ask questions that they are curious about.</p>\n<p>The final result was a presentation with all the combined learnings and actionable.</p>\n<p><strong>What do you think?</strong></p>",
            "url": "https://didierlopes.com/blog/implement-feedback-loops-everywhere-you-can",
            "title": "Implement feedback loops EVERYWHERE you can",
            "summary": "Maximizing team transparency through focused feedback sessions.",
            "date_modified": "2024-10-25T00:00:00.000Z",
            "tags": [
                "openbb",
                "management",
                "leadership",
                "feedback",
                "transparency",
                "culture",
                "remote-work"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/openbb-mobile-app-coming-soon",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon.png\"></p>\n<p>How we built a mobile app, in 1 evening, with 1 engineer.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>Let’s start with a bit of background to this story. 📖</p>\n<p>Back in September 2021, our first full-time team member was <a href=\"https://x.com/josedonato__?utm_source=didierlopes.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=openbb-mobile-app-coming-soon\">Jose Donato</a>. He started full-time, even before I did (due to my 3 months notice period in Europe, yikes).</p>\n<p>We met through Reddit, only to discover that we are both Portuguese and our hometowns aren’t far from each other.</p>\n<p>I’ve learned more from him about web development than from any YouTube, tutorial or book - combined.</p>\n<p>One of the topics he was very passionate about, was the concept of Progressive Web Apps (PWAs). So much so, that he talked about it in his thesis (<a href=\"https://jose-donato.deno.dev/master_thesis.pdf?utm_source=didierlopes.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=openbb-mobile-app-coming-soon\">2.2 native applications</a>).</p>\n<p>I had never heard of it before, but the concept intrigued me. Why wouldn’t more companies do that?</p>\n<p>Jose is currently writing a post about it, you can subscribe to the <a href=\"https://openbb.co/newsletter?utm_source=didierlopes.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=openbb-mobile-app-coming-soon\">company newsletter</a> to keep an eye out for it.</p>\n<h2 id=\"mobile-compatibility\">Mobile compatibility</h2>\n<p>Fast forward to September 3rd, 2024. 🏃‍♂️</p>\n<p>We are 1 week away from one of the biggest launches in the company. Earlier surprise for my subscribers, but we are about to announce a free version of our enterprise product.</p>\n<p>A web app that allows users to bring any type of data and have access to an agent to interact with all these different datasets to extract patterns, trends and insights.</p>\n<p>This web app has been built over 2 years and all workflows, tests, and iterations have been done for desktop usage.</p>\n<p>Jose sent me a video of a mobile version somewhat polished. It had the same UX as the terminal, but it rendered nicely on mobile.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_2.png\"></p>\n<p>Given that we were aiming at adoption, he believed it was important for users to be able to access the terminal through their phones on the web.</p>\n<p>And so over 2 weeks, he spent no more than 3h polishing the mobile version.</p>\n<h2 id=\"mobile-ux\">Mobile UX</h2>\n<p>On the 23rd of September, I pinged <a href=\"https://www.linkedin.com/in/ana-rita-soares-48b247152/?utm_source=didierlopes.beehiiv.com&amp;utm_medium=referral&amp;utm_campaign=openbb-mobile-app-coming-soon\">Rita Soares</a> - our lead UI/UX.</p>\n<p>I had been thinking about mobile user experience and wasn’t happy that we just adapted the interface to work with mobile. But, mobile represents a completely different paradigm on how we use a product. The screen space, the speed at which you can type, not necessarily used for work, more distractions, etc…</p>\n<p>So, I asked Rita to create a few mobile mockups for me - the idea was to improve the UX to make the copilot shine. I.e. more front and center and have the data visualization pushed more to the background.</p>\n<p>That same evening, she shared these mockups with me:</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_3.png\"></p>\n<p>I promptly shared in a group with her and Jose - this was 7:35 pm my time, which would be 0:35 am their time.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_4.png\"></p>\n<p>In less than 24 hours the bulk of the mockups had been implemented.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_5.png\"></p>\n<h3 id=\"progressive-web-apps-pwas\">Progressive Web Apps (PWAs)</h3>\n<p>On that same day, after Jose shared the bulk of mockups implemented.</p>\n<p>I sent him this message at 8:55 pm EST (1:55 am Portugal time for Jose).</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_7.png\"></p>\n<p>To which he replied:</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_8.png\"></p>\n<p>I was right, it didn’t take him 30s. But it didn’t take him much longer (15 minutes).</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_9.png\"></p>\n<p>15 minutes to have OpenBB as an application on my phone.</p>\n<p>I was mind-blown.</p>\n<p>We iterated on it for an additional 1h30m together, until we had something we would be proud to share with the team the following day.</p>\n<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-10-05-openbb-mobile-app-coming-soon_10.png\"></p>\n<p>We still had to iterate on a few more areas and involve more people from the team. But the bulk of the mobile app was done.</p>\n<p>In pretty much 1 evening.</p>\n<p>With 1 person.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>I could tell you that this doesn’t happen often, but it does.</p>\n<p>Small, highly motivated teams (or individuals like Jose) with a strong initiative and a drive to make a difference, can have a tremendous impact on the company.</p>\n<p>I hope this post inspires more builders to share behind the scenes on how great products/features are built and how serendipity can play a role in it.</p>",
            "url": "https://didierlopes.com/blog/openbb-mobile-app-coming-soon",
            "title": "OpenBB Mobile App - Coming soon!",
            "summary": "How we built a mobile app, in 1 evening, with 1 engineer.",
            "date_modified": "2024-10-05T00:00:00.000Z",
            "tags": [
                "openbb",
                "mobile",
                "pwa",
                "web-development",
                "ux",
                "engineering"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/chatgpt-and-the-future-of-ai-in-finance",
            "content_html": "<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance.jpg\"></p>\n<p>I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT &amp; The Future of AI in Finance.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>Last week, I participated in a panel at the Cornell Financial Engineering Manhattan Conference. The topic of the panel was ‘ChatGPT &amp; The Future of AI in Finance.’</p>\n<p>The other panelists were:</p>\n<ul>\n<li><strong>Yu Yu</strong>, Director of Data Science - BlackRock</li>\n<li><strong>Tony Berkman</strong>, Managing Director - Two Sigma</li>\n<li><strong>Samson Qian</strong>, Trader - Citadel</li>\n</ul>\n<p>After the discussion, several people reached out, mentioning it was one of their favorite panels of the day.</p>\n<p>Since this wasn't recorded, I took the opportunity to write down some of the topics discussed, along with a few additional thoughts that I believe in.</p>\n<p>I will organize the following sections based on the topics discussed at the event:</p>\n<ol>\n<li>Hallucinations</li>\n<li>Agents are the future</li>\n<li>When does it make sense to fine-tune?</li>\n<li>Compliance and Data security</li>\n</ol>\n<h2 id=\"1-hallucinations\">1. Hallucinations</h2>\n<p>When talking about the topic of hallucinations, I have a <a href=\"https://x.com/didier_lopes/status/1675630822093918209\">quote</a> that I love from Marc Andreesen:</p>\n<blockquote>\n<p>“Hallucination is what we call when we don't like it. Creativity is what we call it when we do like it.”</p>\n</blockquote>\n<h3 id=\"confident-hallucinations\">Confident hallucinations</h3>\n<p>The fundamental issue with hallucinations is the fact that the model hallucinates with confidence.</p>\n<p>Imagine asking two different friends: “Do you know where location X is?”</p>\n<p><strong>Friend A</strong>: It’s there.</p>\n<p><strong>Friend B</strong>: Hmm, I’m not really sure. If I had to guess, I’d say there, but I’m not 100% certain.</p>\n<p>If both gave wrong directions, you would consider <strong>Friend A</strong> a liar, but not Friend B. This is because <strong>Friend B</strong> lacked confidence in their answer, they were trying to help but highlighted that they weren’t sure about it.</p>\n<p>The problem with current LLMs is that they are, for the most part, like <strong>Friend A</strong>. They say wrong things with certainty.</p>\n<p>Hallucinations would be less problematic if the default behavior were more like the answer on the right, when the LLM is not 100% confident.</p>\n<div class=\"flex justify-center items-center\"><img width=\"350\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_1.png\" style=\"margin-right:10px\"><img width=\"350\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_2.png\"></div>\n<br>\n<p>The problem with confident hallucinations is that, similar to why everyone dislikes liars, it leads to a lack of trust. So users begin to put everything that is output by an LLM under a microscope - even if what the model says is accurate.</p>\n<h3 id=\"how-to-avoid-hallucinations\">How to avoid hallucinations</h3>\n<p>There are ways to address this and one of the key approaches we are extremely strong about at OpenBB is always tapping into information that is available.</p>\n<p>When a user asks a question that requires financial data, the OpenBB Copilot always searches for that data on OpenBB (either through data we make available or through private data that customers bring).</p>\n<p>The Copilot will only answer the question if that data exists. This allows the model to cite the data used in its response, so the user can double-check.</p>\n<p>This is how it looks.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_3.png\"></p>\n<p>While I've heard a few vendors promising 100% accuracy, this is simply not true.</p>\n<p>We are at a stage where technology is not even yet at the ‘trust but verify’ level.</p>\n<p>So instead of hallucinating with confidence, when data is unavailable, we prompt the model to return that there was no real-time information accessible to answer the query.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_4.png\"></p>\n<h3 id=\"function-calling-to-increase-accuracy\">Function calling to increase accuracy</h3>\n<p>One thing we found that significantly reduces hallucinations is enabling our agent, OpenBB Copilot, to have access to all the API backends that users have through OpenBB or those they've added themselves.</p>\n<p>Here’s the sequence of actions that happen:</p>\n<ol>\n<li>The user asks the OpenBB Copilot a question.</li>\n<li>The prompt is converted into embeddings.</li>\n<li>We compare that embedding with all the ones that we have on an OpenBB vector store which contains widget signatures - name, description, category, subcategory and source.</li>\n<li>We retrieve the widgets with the highest similarity.</li>\n<li>The Copilot then decides which widget to use based on the prompt.</li>\n<li>Then Copilot also decides what parameters to use when calling that API</li>\n</ol>\n<br>\n<p>This leads to less hallucination because the LLM isn't outputting tokens based on a prompt and its internal weights. Instead, it's using its internal weights, the prompt, and a function call.</p>\n<p>Assuming the function call succeeds - with correct widget retrieval and parameters - the data becomes available for the Copilot to use, which leads to higher accuracy.</p>\n<p>Note: This still means that Copilot needs to use the correct widget and the correct parameter, but there's a <strong>higher likelihood of success</strong> because if it isn't, the API call will fail, prompting the LLM to try again.</p>\n<p>Here's how it works behind the scenes, the OpenBB Copilot highlights its step-by-step reasoning so users can understand its thought process. Transparency is key.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_5.png\"></p>\n<h3 id=\"workflows-to-avoid-hallucinations\">Workflows to avoid hallucinations</h3>\n<p>In order to reduce the number of hallucinations, there are two things that can be done.</p>\n<h4 id=\"enable-users-to-quickly-detect-whether-a-hallucination-has-occurred\">Enable users to quickly detect whether a hallucination has occurred</h4>\n<p>For instance, if a user utilizes the following prompt on the OpenBB Copilot:</p>\n<blockquote>\n<p><em>Using&nbsp;the&nbsp;earnings&nbsp;transcript,&nbsp;create&nbsp;a&nbsp;table&nbsp;with&nbsp;columns:&nbsp;financial&nbsp;metric,&nbsp;value,&nbsp;sentence&nbsp;in&nbsp;the&nbsp;earnings&nbsp;where&nbsp;it&nbsp;was&nbsp;extracted&nbsp;from.&nbsp;Double&nbsp;check&nbsp;whether&nbsp;the&nbsp;information&nbsp;you&nbsp;are&nbsp;using&nbsp;is&nbsp;correct.</em></p>\n</blockquote>\n<br>\n<p>They get the \"<em>Sentence Extracted From</em>\" column, which they can copy and paste into a search field added at the top of the Earnings Transcript widget. This enable users to quickly validate the numbers that have been found.</p>\n<p>See example below,</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_6.png\"></p>\n<h4 id=\"add-deterministic-processes-to-check-for-hallucinations\">Add deterministic processes to check for hallucinations</h4>\n<p>For example, let’s say the user prompt involves a data retrieval task.</p>\n<p>We can run a deterministic process to check whether the retrieved values exist or not. Sure this won't be 100% accurate because the numbers could be flagged by referring to another thing, BUT it's all about improving the overall accuracy of Copilot.</p>\n<p>Ultimately, whatever can be done to improve the Copilot’s accuracy should be done.</p>\n<h2 id=\"2-agents-are-the-future\">2. Agents are the future</h2>\n<p>When we think about how humans operate, we recognize that the brain coordinates all the actions of our body and our thought processes. This is similar to how agents work.</p>\n<p>If I'm playing soccer, the muscles I use are different from those I would use if I were boxing. If I'm programming, the parts of my brain I use differ from those I would use when listening to music.</p>\n<p>However, it's not as simple as \"activity A requires legs\". Most of your body and mind are always involved, but at different times and in different capacities. And what dictates that are external factors.</p>\n<p>For instance, if I am playing soccer as a winger and my team is attacking, I will likely be using both legs to run forward and a lot of mental energy to decide where to position myself on the field.</p>\n<p>And that will change a lot based on where the ball is. If the ball is on the opposite side, I'll likely run less and stay more in the middle to be ready for a counterattack. If the ball is in the middle, I'll probably be running at full speed to create space. If the ball is close to me I have to worry more about controlling it and understand what I can do with it next.</p>\n<p>The environment affects my plan to carry out an action where I want to have a successful outcome.</p>\n<p><strong>This is how agents work.</strong></p>\n<p>Agents aren't just about a single LLM performing well, but about a full workflow that interacts with multiple language models, function calls, or any other process to carry an action.</p>\n<p>At the core, the biggest advantage of an agent over a LLM is that an agent has a full feedback loop. It understands the impact of the LLM output and can use that data in the next step of the process. Whereas a single LLM API call returns its best output but won't know how that affected the external environment.</p>\n<p>This is why, at OpenBB, we believe in compound AI systems.</p>\n<p>And apparently, <a href=\"https://finance.yahoo.com/news/sequoia-sees-bigger-money-ai-203655254.html?guccounter=1\">so does Sequoia</a>.</p>\n<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_7.png\"></p>\n<h3 id=\"the-strawberry-issue-will-be-solved\">The “Strawberry” issue will be solved</h3>\n<p>A panelist commented on stage that LLMs can’t even count how many R's are in the word \"Strawberry\".</p>\n<p>This <a href=\"https://x.com/MwangoCapital/status/1828857579860095428\">tweet</a> offers a good explanation of why this happens — it turns out it's due to the tokenizer, and it can be solved. In fact, it's solved by simply ensuring that the model takes each letter as a token. See below,</p>\n<div class=\"flex justify-center items-center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_8.png\" style=\"margin-right:10px\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_9.png\"></div>\n<br>\n<p>This means that the model's output can be improved by doing extra work at the input level.</p>\n<p>Data cleaning and pre-processing strikes again? 😃</p>\n<p>Interestingly, a few days ago, <a href=\"https://openai.com/o1/\">OpenAI announced OpenAI o1</a>. Which is basically GPT-4o with Chain-of-Thought (COT). This means that this model is a \"wannabe agent\".</p>\n<p>It takes in a prompt from the user and decomposes it in natural steps to solve it. Then at each step, it takes the output of the model from the previous step and predicts the next token. It turns out that this improves accuracy substantially.</p>\n<p>However, it still doesn’t have access to external data. And that is why I call it a \"wannabe agent\".</p>\n<p>I love how Jeremiah put it in this <a href=\"https://x.com/jlowin/status/1834722014839418962\">tweet</a>:</p>\n<blockquote>\n<p>(...) Agents are also characterized by iterative behavior. But there's a key difference: while models like o1 iterate internally to refine their reasoning, agents engage in iterative interactions with the external world. They perceive the environment, take actions, observe the outcomes (or side effects) and adjust accordingly. This recursive process enables agents to handle tasks that require adaptability and responsiveness to real-world changes. (...)</p>\n</blockquote>\n<br>\n<p>So, o1's model isn't an agent - but it can solve this problem. The reason is that it applies its own data cleaning/pre-processing step on its own, and doesn't rely on external factors.</p>\n<h3 id=\"small-language-models\">Small Language Models</h3>\n<p>Once agents work, Small Language Models (SLM) will be much more viable for very specific use cases.</p>\n<p>In logical terms, a Large Language Model is a model with weights.</p>\n<p>Large means that it has a lot of them. But what tends to happen is LLMs need to be very big because they want these models to be really good at everything. The problem is that if you want the exact same model to be good at discussing soccer, programming, and speaking Portuguese, its weights are updated using these drastically different datasets. Now the premise is that the more weights there are, the less each weight will be affected by data from completely different domains.</p>\n<p>What a big LLM like GPT-4o is doing is trying to build a single Jarvis that knows about everything. Whereas we could have an SLM that does something extremely well and just focus on that, e.g. translating from English to Portuguese. The benefit of an SLM is that inference is likely faster, can be hosted on devices, and, in theory, it's better on a topic because it's been less \"contaminated\" during training by data that doesn't relate to the task at hand.</p>\n<p>Imagine that a firm decides to use an SLM trained to retrieve data from SEC filings quickly and at scale. Or, we could train our own SLM to understand user intent and interact directly with the OpenBB Terminal interface.</p>\n<h3 id=\"large-language-models-as-orchestrator\">Large Language Models as orchestrator</h3>\n<p>In my opinion, the best LLM in each category will win. And the second and third won't matter. It's a winner-takes-all kind of market. Unless in specific verticals such as inference time or open weights (e.g. for data security; more on this later).</p>\n<p>The best example of this is OpenAI vs Anthropic.</p>\n<p>I had been using OpenAI's GPT-4 for coding for several months. After trying Anthropic's Sonnet 3.5 for coding, I never went back to OpenAI.</p>\n<p align=\"center\"><img width=\"400\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_10.png\"></p>\n<p>The market share for the best LLM will be gigantic. That’s why <a href=\"https://www.bloomberg.com/news/articles/2024-09-11/openai-fundraising-set-to-vault-startup-s-value-to-150-billion\">OpenAI is looking to raise at a $150 billion valuation</a>. While the valuation reflects the market size, the amount that will be raised represents the capital needed to reach that valuation. This is why only a few players will be able to compete at that level.</p>\n<p>In an \"agentic future\", I believe the best LLM will serve as the core \"brain\" - the main LLM that routes all prompts and decides what happens next.</p>\n<p>And who wouldn't want the smartest model controlling the actions with a list of models, functions and data at its disposal?</p>\n<p>I know I would.</p>\n<p>That's also why, when discussing OpenBB Copilot, we don’t rely on a single foundational model. Instead, we use the models that are best suited for each specific task.</p>\n<p>For instance, OpenAI o1 can be the brains, but when a user uses @web it triggers the Perplexity model, and when they upload an image, we have Anthropic's Haiku. Or maybe if they want to do intraday trading, we use Llama 3.1 through Groq for fast inference.</p>\n<p>You get the idea.</p>\n<h2 id=\"3-when-does-it-make-sense-to-fine-tune\">3. When does it make sense to fine-tune</h2>\n<p>A good comment was made on the panel: \"<em>it’s expensive to spend time fine-tuning a new model, just for that entire work to be 'eradicated' by a new model that has a higher performance in that specific domain than the model has been fine-tuned</em>\".</p>\n<p>In my opinion, this happens because the timing isn't right yet. We are still unlocking remarkable achievements through each new model release. Although there is a massive bump in terms of capability between these releases, I wouldn't recommend that a firm fine-tune its own models at this stage.</p>\n<p>However, at some point, whether due to a lack of data to train or architecture needing to be reinvented, improvements in LLM performance won't be substantial - they may not even be noticeable. This is when the fine-tuning technique becomes relevant because at this stage you are trying to repurpose everything the model has towards a specific vertical / use-case - and at that vertical/use-case that model will be better than the following one.</p>\n<p>Then after some new models come out, you may consider reapplying fine-tuning to that model, but this would likely be years later, not weeks or months. So, the ROI can be quite high. Particularly when you are trying to win in your specific market.</p>\n<p>This is how I see it working in my head:</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_11.png\"></p>\n<h2 id=\"4-compliance-and-data-security\">4. Compliance and Data security</h2>\n<p>Another question I received was about compliance and data security.</p>\n<p>Recently, during a discussion with one of the largest hedge funds in the world, we were asked about the entire workflow of the data when our AI Copilot has access to it.</p>\n<p>Their main concern was ensuring that no data was being shared with third-party vendors like OpenAI. For such firms, their data is their alpha, and keeping it within their network is paramount.</p>\n<p>Crypto enthusiasts often say, \"Not your keys, not your coins\" to emphasize the importance of storing assets in a cold wallet rather than leaving them on an exchange that might implode (looking at you, FTX). The same principle applies here: \"Not your weights, not your data\".</p>\n<p>When you send information to a large foundation model provider like OpenAI, your data enters their ecosystem, and you have to trust they’ll honor the terms of your contract.</p>\n<p>A more secure approach is to host an open-source model locally within your firm, ensuring that sensitive data remains entirely within your infrastructure and network.</p>\n<p>Although open-source models aren’t yet as powerful as closed-source ones, they are catching up quickly. If you think that GPT-4o can already do a lot for you, think about how at some point there will be an open-source model that is GPT-4o equivalent. Sure, at that time closed-source models will be better, but the question is: How much better?</p>\n<p>Or better, the question is: <strong>\"How much are you willing to sacrifice in terms of data security for performance?”</strong>.</p>\n<p>At OpenBB, we take this very seriously and have taken measures to allow enterprise customers to fully control their data.</p>\n<h3 id=\"bring-your-own-copilot\">Bring your own copilot</h3>\n<p>Enable firms to bring their own LLMs to access data within OpenBB. This means that we provide an interface for research, but also allow them to integrate their internal LLMs and interact directly with it from OpenBB.</p>\n<div class=\"flex justify-center items-center\"><img width=\"350\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_12.png\" style=\"margin-right:10px\"><img width=\"350\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_13.png\"></div>\n<br>\n<p>We believe in this idea so much, that we have open-source the architecture for firms to bring their own Copilot to OpenBB. More information is available <a href=\"https://github.com/OpenBB-finance/copilot-for-terminal-pro/\">here</a>.</p>\n<h3 id=\"turn-off-ai-workflows\">Turn off AI workflows</h3>\n<p>We have incorporated workflows that make users' lives MUCH better. But they come at a cost: sharing data with an LLM provider.</p>\n<p>These are the features:</p>\n<ul>\n<li><strong>Widget title/description suggestion from Copilot</strong>: This sends the content of the table or note output by Copilot to an LLM provider to receive suggestions of a title and description.</li>\n</ul>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_14.png\"></p>\n<ul>\n<li><strong>Widget title/description suggestion upon upload</strong>: It sends the content of the file that has been uploaded to an LLM provider to receive suggestions of title and description.</li>\n</ul>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_15.png\"></p>\n<ul>\n<li><strong>Copilot chat title generation</strong>: Upon the first user prompt, the content is sent to an LLM provider to update the chat title, reflecting the nature of the conversation.</li>\n</ul>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_16.png\"></p>\n<ul>\n<li><strong>Dashboard name generation</strong>: When renaming the dashboard, we send the title and descriptions of all widgets on that dashboard to an LLM provider, to ensure that the suggested name is relevant.</li>\n</ul>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_17.png\"></p>\n<p>To allow firms to keep their data within their network, one of our enterprise features is the option to disable these AI workflows.</p>\n<p align=\"center\"><img width=\"900\" src=\"https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_18.png\"></p>\n<p>In the future, we could direct these AI workflows to use an LLM that our customers are running locally.</p>\n<h2 id=\"so-in-a-nutshell-what-can-you-expect-from-openbb\">So, in a nutshell, what can you expect from OpenBB?</h2>\n<p>We are building an AI-powered research workspace.</p>\n<p>At the core it is an AI compound system, where users can bring their own data (structured, unstructured, API, custom backend, database, data warehouse, etc..) and have our (or their own copilot) access all this data seamlessly - in an interface that is customizable, flexible and enables teams to work together.</p>\n<p>If you want to learn more, e-mail me directly at <a href=\"mailto:didier.lopes@openbb.finance\">didier.lopes@openbb.finance</a></p>",
            "url": "https://didierlopes.com/blog/chatgpt-and-the-future-of-ai-in-finance",
            "title": "ChatGPT and The Future of AI in Finance",
            "summary": "I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT & The Future of AI in Finance.",
            "date_modified": "2024-09-21T00:00:00.000Z",
            "tags": [
                "finance",
                "ai",
                "agents",
                "chatgpt",
                "quant",
                "cornell",
                "twosigma",
                "blackrock",
                "citadel"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/why-i-love-boxing",
            "content_html": "<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing.jpeg\"></p>\n<p>Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>Recently, I finished reading “The Art of Learning” - a really good book that I’ve recommend to everyone (btw, <a href=\"https://x.com/didier_lopes/status/1742748040220328189?s=20\">here</a> is a page of all the books I’ve read in the past few years).</p>\n<p>In it, the author Josh Waitzkin, reflects on his journey from chess champion to martial arts practicioner - and how anyone can master the art of learning.</p>\n<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_1.png\"></p>\n<p>It made me wonder, why at 29 years old did I decide to step into a ring with boxers who have been fighting for 10+ years? 🥊</p>\n<p>As my friend Max says, “You don’t play boxing”. So why am I doing it?</p>\n<p>Similar to setting up a startup, this isn’t something that’s easy to explain. The most rationale thing to do would be to go for a run outside or just go to the gym.</p>\n<p>Yet, I hop in a ring to fight.</p>\n<p>Why?</p>\n<p>For starters, there’s something thrilling about stepping into the ring and knowing that you are going to get punched.</p>\n<p>You need to get comfortable with something that - by definition - it’s uncomfortable.</p>\n<h2 id=\"boxing-is-the-physical-to-what-startups-are-for-the-mind\">Boxing is the physical to what startups are for the mind</h2>\n<p>Think about it. Most activities that people do in their spare time have a “controlled” level of intensity. You get progressively more tired but “know” it’s coming - e.g. gym, swimming, tennis, running, etc.</p>\n<p>Contact sports are in general like this too, although every now and then you can get injured. Although this rate is small, and sports in general equip athletes to be protected against injuries.</p>\n<p>Boxing (and martial arts) don’t work this way. You step in the ring and within the first few seconds, you may get a hook that gives you a bruise next to your eye or a uppercut that makes you stop breathing for a few seconds.</p>\n<p>My point is that with boxing, you don’t know when you are going to get hurt, but you learn to be comfortable with it and over time your body gets used to that level of pain - so it will take even more to make you uncomfortable.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_2.png\"></p>\n<h2 id=\"first-sparring-session\">First sparring session</h2>\n<p>I still remember my first sparring session, I got hit on the nose and had tears coming out of my eyes from it. My nose hurt for 3 days in a row. It doesn’t matter how many times the coach told me to keep my hands up, nothing taught me quicker than that cross on my nose.</p>\n<p>For the remainder of the fight, I was mostly protecting myself and keeping my distance. I was “humbled” by the other fighter, and was pushed to outside my comfort zone.</p>\n<p>This is not so much different from startup life where mentally you have to be in uncomfortable places - for me this is the equivalent to speaking on a stage. For an introvert like myself, that was something that was hard to overcome. Although I am still not comfortable on a stage, I am much more comfortable than I used to be.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_3.png\"></p><p style=\"font-size:0.8em\">Presenting at CIBC a few weeks ago at New York AI meetup</p><p></p>\n<h2 id=\"next-sparring-sessions\">Next sparring sessions</h2>\n<p>Currently when I step in a ring I have mixed feelings, I’m somewhat anxious but also excited about it.</p>\n<p>It’s weird.</p>\n<p>I mean, I know full well that I’m going against folks who’ve been in a ring since they were young - and I also know full well that I’m going to get hit much more than I will hit.</p>\n<p><strong>However</strong>, there’s something exciting (poetic maybe?) about knowing that each time I step into the ring again, I will be able to land more punches, avoid more hits and be better mentally.</p>\n<p>Learning is the nature of the game.</p>\n<p>And the only failure is to not take any lessons from each fight.</p>\n<p>This is the same for startups. I like what Bezos has to say on the topic, about <a href=\"https://www.youtube.com/shorts/HmYj-UDT8jM\">pushing Amazon to embrace failure</a>.</p>\n<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_4.JPG\"></p><p style=\"font-size:0.8em\">This picture was what convinced me to buy my own head gear</p><p></p>\n<h2 id=\"so-why-do-i-love-boxing\">So, why do I love boxing?</h2>\n<p>I think ultimately, the reason why I love boxing is the same as why I love startups.</p>\n<p>Startups push me everyday to be the best that I can be in so many different areas, there isn’t a role that - for me - is as stimulating mentally as being a startup founder.</p>\n<p>There are 100 different initiatives ongoing at all times, you have a team of composed of human beings (by nature, highly complex with different backgrounds and life experiences), you have startups trying to disrupt your business, you have well established incumbents, etc..</p>\n<p>Boxing is the same... but at the physical level.</p>\n<p>I step in the ring and need to be the best I can in multiple verticals - it isn’t enough to be the best in one.</p>\n<p>I need to have a faster reaction to avoid punches, be light on my feet to surprise an opponent, land the combos where I put most of my energy in, trade-off balance between combos and stamina, and obviously all the mental side that comes from it too - which turns out is quite a lot.</p>\n<p>Ultimately, as cheesy as it sounds, being a startup founder and doing boxing make me feel alive.</p>\n<p align=\"center\"><img width=\"300\" src=\"https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_5.jpeg\"></p><p style=\"font-size:0.8em\">Taking my father-in-law for a class</p><p></p>",
            "url": "https://didierlopes.com/blog/why-i-love-boxing",
            "title": "Why I love boxing",
            "summary": "Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.",
            "date_modified": "2024-09-09T00:00:00.000Z",
            "tags": [
                "boxing",
                "startups",
                "learning",
                "growth"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/what-i-learned-in-3-years-at-openb",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-20-what-i-learned-in-3-years-at-openb.jpeg\"></p>\n<p>The OpenBB journey started officially 3 years ago.</p>\n<p>So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>The OpenBB journey started officially 3 years ago.</p>\n<p>So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.</p>\n<ol>\n<li>\n<p>Be curious.</p>\n</li>\n<li>\n<p>Talk to users.</p>\n</li>\n<li>\n<p>Protect your time.</p>\n</li>\n<li>\n<p>Do the right thing.</p>\n</li>\n<li>\n<p>Culture is everything.</p>\n</li>\n<li>\n<p>Energy is contagious.</p>\n</li>\n<li>\n<p>Hire slow and fire fast.</p>\n</li>\n<li>\n<p>Write everything down.</p>\n</li>\n<li>\n<p>Reward people who care.</p>\n</li>\n<li>\n<p>Celebrate every little win.</p>\n</li>\n<li>\n<p>Work on your storytelling.</p>\n</li>\n<li>\n<p>Ship often and iterate fast.</p>\n</li>\n<li>\n<p>Listen more than you speak.</p>\n</li>\n<li>\n<p>Be comfortable with saying no.</p>\n</li>\n<li>\n<p>When in doubt, there's no doubt.</p>\n</li>\n<li>\n<p>Over communicate with the team.</p>\n</li>\n<li>\n<p>Have an inherent sense of urgency.</p>\n</li>\n<li>\n<p>Don't overthink, estimate and iterate.</p>\n</li>\n<li>\n<p>Failing is ok, not learning from it isn't.</p>\n</li>\n<li>\n<p>Measure success by impact, not effort.</p>\n</li>\n<li>\n<p>Do not run away from hard conversations.</p>\n</li>\n<li>\n<p>Having common sense is a very powerful skill.</p>\n</li>\n<li>\n<p>How you do anything is how you do everything.</p>\n</li>\n<li>\n<p>It's not because you can build it that you should.</p>\n</li>\n<li>\n<p>Seeing your vision materialize gives goosebumps.</p>\n</li>\n<li>\n<p>Be so excited in your product that users can feel it.</p>\n</li>\n<li>\n<p>Lack of focus is likely the biggest risk you face as a company.</p>\n</li>\n<li>\n<p>It turns out that there's a ton of data in your gut feeling.</p>\n</li>\n<li>\n<p>Make people accountable for both successes and failures.</p>\n</li>\n<li>\n<p>Hiring is the most important thing you will do at your company.</p>\n</li>\n<li>\n<p>Create a culture where feedback is not only welcome but expected.</p>\n</li>\n<li>\n<p>Work side-by-side with the team on things that are considered \"boring\".</p>\n</li>\n<li>\n<p>Be there for your team when they need you, they will repay you with loyalty.</p>\n</li>\n<li>\n<p>One of the worst things you can do is optimizing something that shouldn't exist.</p>\n</li>\n<li>\n<p>Vast majority of decisions are 2-way door decisions. Make a decision and move on.</p>\n</li>\n<li>\n<p>Startups are hard and fun. Working with people you like makes it less hard and more fun.</p>\n</li>\n</ol>\n<br>\n<p>In the past 3 years, we have:</p>\n<ul>\n<li>The <a href=\"https://github.com/OpenBB-finance/OpenBB\">open source repo</a> has been starred over 28,000 times and 220 contributors</li>\n<li>The OG OpenBB Terminal installer was downloaded over 150k times</li>\n<li>Refactored that application to a platform that could be pip installable</li>\n<li>Enabled users to fully <a href=\"https://youtu.be/cgeN3Ep2nEw?si=8e5en_xunWcBdKMM\">automate their research workflow in a script</a></li>\n<li>Open-sourced an <a href=\"https://github.com/OpenBB-finance/openbb-agents\">LLM-powered financial analyst agent built on top of the OpenBB platform</a></li>\n<li>Made an <a href=\"https://openbb.co/products/bot\">OpenBB Bot</a> that run over 4M commands in 20k+ servers with 50k+ users</li>\n<li>Developed an <a href=\"https://openbb.co/products/excel\">Add-in for Excel</a></li>\n<li>Grew to a team of 16</li>\n<li>Built a community of over 100k people</li>\n<li>And finally, we built the foundation of the <a href=\"https://openbb.co/products/pro\">first AI-powered financial terminal</a> - more on this very very soon.</li>\n</ul>\n<br>\n<p>Personally, during that timeline:</p>\n<ul>\n<li>I got a second dog</li>\n<li>Visited US for the first time</li>\n<li>Got married on that first visit</li>\n<li>Left London to move to the Bay area a couple weeks after</li>\n<li>Moved to NYC</li>\n<li>Started boxing regularly</li>\n</ul>\n<p>We are more locked in than ever before.</p>\n<p>Can’t wait for the next 3 years. 🥂</p>",
            "url": "https://didierlopes.com/blog/what-i-learned-in-3-years-at-openb",
            "title": "What I Learned in 3 Years at OpenBB",
            "summary": "The OpenBB journey started officially 3 years ago. So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.",
            "date_modified": "2024-08-20T00:00:00.000Z",
            "tags": [
                "career development",
                "technology",
                "OpenBB",
                "learning",
                "leadership"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png\"></p>\n<p>It's not a matter of if, but a matter of when. AI will replace analysts' jobs, and we actually believe that's a good thing. In this blog post, we explain why and how you can prepare for this revolutionary change in the world of finance.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<h2 id=\"introduction\">Introduction</h2>\n<p>This is the current state of Quant/Finance/Investing conferences in 2024</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_1.png\"></p>\n<p>I’ve heard panels defending both sides: Yes and No.</p>\n<p>I think that people who say “No” don’t understand how AI fundamentally works, and most people who say “Yes” are understating the impact it will have.</p>\n<p>Personally, a much better question is “When will AI replace financial analysts?” or “How can I prepare for the shift?”.</p>\n<h2 id=\"history\">History</h2>\n<p>If we look back at the automotive industry, 100 years ago - this is what a Ford factory looked like:</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png\"></p>\n<p>How many of these blue-collar workers would have said that their jobs would be extinct in less than 100 years? And for the most part, they are.</p>\n<p>This is where we are today in terms of AI.</p>\n<p>Some tooling (read: AI) can help humans do their job, but it still needs to be supervised.</p>\n<p>But with enough time (for the automotive industry that was 100 years), AI will take over.</p>\n<p>This is what Tesla’s Giga Berlin factory looks like today.</p>\n<div class=\"flex place-items-center justify-center items-center rounded-sm mx-auto\"><iframe src=\"https://www.youtube.com/embed/7-4yOx1CnXE?si=k-adJ_cOlXS6Ldlv\" width=\"800\" height=\"400\"></iframe></div>\n<h2 id=\"when-will-ai-replace-financial-analysts\">When will AI replace financial analysts?</h2>\n<p>Bill Gates famously said: “Most people overestimate what they can achieve in a year and underestimate what they can achieve in ten years”.</p>\n<p>I’ve found this to be mostly true for everything tech.</p>\n<p>EXCEPT AI.</p>\n<p>This is why I’m so bullish on the category as a whole.</p>\n<p>I subscribe to a few newsletters that share daily AI updates, and it’s crazy that every single day there’s something big happening. Either a new model is released and open source, a new framework to do RAG or fine-tune, a new company announces they are working on foundational models, a new paper that pushes the field forward, or a new investment from a big corporation.</p>\n<p>I mean, even enterprises are rushing to jump into the AI train. Either releasing AI features to millions of users before proper testing (e.g. Gemini overview on Google and the whole Reddit answers), adding AI where it isn’t really necessary (e.g. Meta AI on WhatsApp), exploring new monetization opportunities (e.g. Amazon Bedrock for fine-tuning) or risking on their values to not be left behind (e.g. Apple partnering with OpenAI — risking the security brand they worked so hard for).</p>\n<p>So, I think this will happen soon.</p>\n<p>And it’s with that in mind that we have been building OpenBB.</p>\n<h2 id=\"how-can-i-prepare-for-the-shift\">How can I prepare for the shift?</h2>\n<p>I think that the most important question that financial analysts should ask themselves is not ‘<strong>when</strong>’ but ‘<strong>what can I do to prepare myself for when AI starts taking over</strong>’.</p>\n<p>There’s going to be multiple stages before AI fully takes over. Here’s how I envision it playing out:</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_2.png\"></p>\n<p>(For what it’s worth, I think this is equivalent to what will happen to developers in general).</p>\n<h3 id=\"short-term\">Short term</h3>\n<p>We are starting to enter this timeline.</p>\n<p>A timeline where analysts will use AI to augment their output.</p>\n<p>A good analyst using AI will be able to perform at a better level than a great analyst who doesn’t use AI.</p>\n<p>Interestingly, a mediocre analyst will be able to increase their output but nowhere as much as a good or great analyst. This is because the AI usage will supervised and still “driven” by the analyst (through prompts). So mediocre analysts will not benefit as much because they will either trust too much the AI (without being able to discern its validity), not use the best prompts because they don’t know what to use the AI for, or not use the output because they won’t comprehend the insights that the AI is generating.</p>\n<p>During this period, the gap between mediocre and great analysts will be at an all-time high. This will expose more who is pushing their weight and who isn’t.</p>\n<p>Another thing is that firms that will be hiring high-talented juniors/interns will start adding AI experience as a requirement (e.g. OpenBB experience) since they understand that they will have a higher leverage and their output will be much better. Potentially even replacing a current analyst with many years of experience that doesn’t leverage AI in the day-to-day.</p>\n<p>I think there are 2 reasons for this:</p>\n<ol>\n<li>\n<p><strong>AI will allow financial analysts to have much broader mandates</strong> as they will be able to automate the process of research and screen the best companies. Instead of analyzing 20 companies per quarter, they will do 500.</p>\n</li>\n<li>\n<p><strong>AI will be able to extract trends and patterns that humans simply can’t due to the amount of data necessary to process</strong>. The amount of data that financial firms use to invest is constantly on the rise, that’s where they get their alpha from. Given that an analyst has a limited amount of resources, they will either have to narrow down the companies in their mandate or process less data for each.</p>\n</li>\n</ol>\n<h3 id=\"long-term\">Long term</h3>\n<p>In the long term, AI will start taking the reigns.</p>\n<p>This is the equivalent of self-driving cars becoming fully autonomous.</p>\n<p>The gap between mediocre and great analysts will narrow over time because AI is doing all the heavy work.</p>\n<p>At that time, it will be very hard to distinguish the competency of mediocre and great analysts — the main indicator will be how they interpret/understand the AI model, i.e. how they can explain what led to the AI “deciding” to invest in companies based on hundreds of different datasets.</p>\n<p>This is why we spend hours obsessing over the UX of the <a href=\"https://openbb.co/products/pro\">OpenBB Terminal Pro</a>. We want to make sure analysts know at all times what the AI Copilot is doing and thinking. Because interpretability will be a big topic in the future.</p>\n<p>It’s important to note that the best analysts will be the ones who have their jobs more secure over time. That is because provided the AI is taking the reigns, when it fully takes the reigns, the output of all analysts will be more or less the same. However, in the period before, the great analyst will have an edge because their skill is still in use and so the leverage lever is bigger.</p>\n<p>I think that when AI fully takes over analysts' jobs, the best ones will move towards opening their investment firms and focus on the human part of the job: communication.</p>\n<p>Communicating to their investors why they made their decisions, e.g. “We have access to this dataset which others don’t, and our AI model correlated that data with x, y, and z which enabled us to invest ahead of the rest of the market”. This is the “interpretability” of the AI that I mentioned earlier.</p>\n<h2 id=\"what-can-you-do\">What can you do?</h2>\n<p>You should still pursue a career in the space.</p>\n<p>But you should do so with AI in mind.</p>\n<p>Experiment with products out there that leverage AI to make you more efficient (you can try OpenBB for free at pro.openbb.co). You will soon realize that your output can compete with someone who is neglecting AI in their day-to-day.</p>\n<p>Being a top financial analyst is still something you should strive for since these are going to be the last to be replaced. And when they are, you will still have an edge because your role is likely to evolve into a communication/management role that explains what the AI is doing to investors. And that would be much easier if you’re a top analyst in the first place - because you would understand the insights extracted from an AI copilot.</p>\n<p>What is your opinion on this topic?</p>",
            "url": "https://didierlopes.com/blog/why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare",
            "title": "Why AI Will Replace Jobs in Finance and How You Should Prepare",
            "summary": "As AI continues to advance, many jobs in finance are at risk. Learn why this shift is happening and how to prepare for the future.",
            "date_modified": "2024-08-06T00:00:00.000Z",
            "tags": [
                "artificial intelligence",
                "finance",
                "career development",
                "technology",
                "future of work"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG\"></p>\n<p>In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>This cause could not have been a personal one, but it is.</p>\n<p>As a young kid from a small town in Portugal, people who die from cancer are on TV and I don't know them personally.\n&nbsp;\nMy friends &amp; family are “protected” by an imaginary shield that I created in my head.</p>\n<p>Until they aren’t.</p>\n<p>Let me go back down memory lane and talk about Beatriz.</p>\n<p>Bia was in my class in high school.</p>\n<p>We started talking here and there.</p>\n<p>Before I knew it, she was my best friend.</p>\n<p>We would talk for hours about everything and nothing - always laughing.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG\"></p>\n<p>We would sit next to each other and professors would have a hard time with us because we liked to chit chat.</p>\n<p>So we created a new communication medium to not get caught.</p>\n<p>We would rip the side of those pages and write in very small font notes to each other.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_1.jpg\"></p>\n<p>We would go through multiple of these in each class.</p>\n<p>It was our thing.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_2.JPG\"></p>\n<p>A few months later, we had a sports class and she felt weak from her wrist.</p>\n<p>She didn't really like sports. So I remember making fun of her for trying to find an excuse to skip sports class.</p>\n<p>That would be the last time I made fun of that.</p>\n<p>She went to the hospital the day after, and to another one soon for a second opinion.</p>\n<p>She had cancer. On her back.</p>\n<p>Her floor was pulled from under her.</p>\n<p>She was 16 and while kids her age were worrying about boys and school grades, she had to fight for her life.</p>\n<p>At fucking 16.</p>\n<p>The crazy part is that the attitude she had with others was the same.</p>\n<p>She would not display any weakness throughout none of it.</p>\n<p>She was so strong. At 16.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_3.png\"></p>\n<p>One day I visited her and she had no hair because of chemotherapy.</p>\n<p>She was still the same beautiful and happy girl that I loved.</p>\n<p>Underneath it all, I don't know where she got the strength to go through it.</p>\n<p>The school adapted the classes to be livestream so that she could attend from home.</p>\n<p>Not only she wasn't gonna lose this battle but she didn't want to lose 1 year of school either.</p>\n<p>She was incredibly smart for her age. So losing a year wasn't an option for her.</p>\n<p>At the graduation she wrote me a message. She didn't have strength in her hand to write so she used her wrist to be able to write it in an iPad.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_4.JPG\"></p>\n<p>The translation doesn’t make it justice, but it reads as:</p>\n<blockquote><p>Didier</p><br><p>It was in the middle of laughter, in the middle of playfulness.</p><br><p>It was in the middle of tantrums and misunderstandings.</p><br><p>It was in the middle of sheets of paper fallen on the floor and of pieces of paper so efficiently utilized.</p><br><p>It was like this that our friendship grew!</p><br><p>Beatriz ❤️</p></blockquote>\n<br>\n<p>Saturday morning I got a call. A common friend let me know that she passed away unexpectedly.</p>\n<p>I was still in bed. I cried for hours. I didn't want to wake up. Maybe some part of me never did.</p>\n<p>She had her entire life ahead of her.</p>\n<p>She was kind, curious and loving. She would have accomplished so much.</p>\n<p>Yet she was gone.</p>\n<p>No one deserves to lose their best friend at 17. Not like that. It wasn't fair.</p>\n<p>But that's cancer for you.</p>\n<p>Cancer doesn't care.</p>\n<p>It never did.</p>\n<p>From that moment onwards I changed my attitude towards life.</p>\n<p>I stopped doing things for the sake of doing them and always put 120%.</p>\n<p>I went from spending most of my time as a gamer and doing just enough to have good grades in high school to being the best student of my year in my BSc in Electrical and Computer Engineering, moving to London to have a distinction at Imperial College London (top 2 uni in the world) and now moving to NYC to increase chances of success for my startup.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_5.jpeg\"></p>\n<p>I have a tattoo that says “All her would-haves are our opportunities\" (which is from Anne Frank's house in Amsterdam) to remind me that every day I have opportunities that she didn't get to experience.</p>\n<p>But I hope that in some way, shape or form, she is.</p>\n<p>And that I make her proud.</p>\n<p>Stories like this are not as uncommon as you may think they are.</p>\n<p>It took me over 10 years to talk about how cancer took my best friend’s life away.</p>\n<p>Imagine the number of people who never write about how it impacted their lives.</p>\n<p>If anything, my objective with this post is to highlight that cancer is real.</p>\n<p>In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day...</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p><a href=\"https://haymakersforhope.org/\">Haymakers for Hope</a> is an organization dedicated to raising funds for cancer research and care. They organize unique events that combine athleticism with philanthropy, making a significant impact in the fight against cancer.</p>\n<p>On March 16, 2025, I will be running the NYC Half Marathon as part of the Haymakers for Hope team.</p>\n<p>Join me in this fight against cancer, for Bia and for all those whose lives have been touched by this disease.</p>\n<p>I've created a <a href=\"https://haymakersforhope.org/events/running/nyc-half-marathon-2025/runners/Didier-Lopes\">fundraising page</a> where you can support this cause.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_6.png\"></p>\n<p class=\"text-center\"><a href=\"https://haymakersforhope.org/events/running/nyc-half-marathon-2025/runners/Didier-Lopes\" class=\"inline-block px-5 py-2.5 bg-[#0088CC] text-white rounded font-bold hover:bg-[#006699] transition-colors duration-300\">Donate here</a></p>\n<p>Every donation matters. ❤️</p>",
            "url": "https://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life",
            "title": "Inspired by Bia - How Her Fight Against Cancer Changed My Life",
            "summary": "In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.",
            "date_modified": "2024-08-01T00:00:00.000Z",
            "tags": [
                "cancer",
                "development",
                "disease",
                "charity",
                "personal"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt.png\"></p>\n<p>AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.</p>\n<p>The open source code is available <a href=\"https://github.com/DidierRLopes/supervised-learning\">here</a>.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>Recently I was invited to teach a course in Big Data and Data Analytics at Europeia University. I gave 4 hours of classes, divided into:</p>\n<ul>\n<li>Supervised Learning - Theory</li>\n<li>Supervised Learning - Practice</li>\n</ul>\n<p>And then evaluated the students coursework.</p>\n<h2 id=\"creating-a-new-syllabus\">Creating a new syllabus</h2>\n<p>My past experience as a teacher happened during my BSc., back in 2016, where I was a TA for the course of Signal Theory and had to help students in their coursework through Matlab/Octave.</p>\n<p>Things were different at the time because I had a syllabus to follow and most of my time was spent helping students if they were blocked coding-wise or had some questions regarding the theory.</p>\n<p>And of course - there was no AI. At least not in the sense that we speak about today - i.e. there were no LLMs.</p>\n<p>This time was different - I had the flexibility to choose what I was going to cover about Supervised Learning.</p>\n<p>I’ve never worked as a Data Scientist per se, but have been passionate about data for a while and spent a lot of time reading books and learning about the topic. In my previous company, I started playing with IMU data in my spare time which lead me to publish a paper at ICMLA where I used <a href=\"https://ieeexplore.ieee.org/document/9680024\">Support Vector Machine (SVM) for Step Detection using Nurvv trackers</a> and even open sourced the code <a href=\"https://github.com/DidierRLopes/step-detection-ML/tree/main\">here</a>.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_svm_paper.png\"></p>\n<p>I've wrote about this and how I managed to write the entire code in my spare time in a single week, and missing the yearly team event in order to pull this off. You can read more about it <a href=\"https://didierlopes.com/blog/how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla\">here</a>.</p>\n<p>But so the question is:</p>\n<p><em>\"Where do I start?\"</em></p>\n<p>My first intuition was to gather some of my favorite books and courses on the topic and understand how they presented the overall subject. I wouldn’t have the same time, so I would need to touch on most topics briefly - enough for students to know about it and explore further if curious.</p>\n<p>However, given my time constraints with running OpenBB, I would have had a hard time since I would need to:</p>\n<ol>\n<li>Consume the content of these books and courses</li>\n<li>Mix and match them</li>\n<li>Cut to fit the time constraints</li>\n<li>Produce a final syllabus that I’m confident about</li>\n</ol>\n<br>\n<p>This was not a trivial task, and definitely not a weekend job.</p>\n<p>Except that <strong>IT WAS</strong>.</p>\n<h3 id=\"perplexity-enters-the-chat\">Perplexity enters the chat</h3>\n<p>Since Perplexity’s main value proposition is being better at Google than Google - I popped the following prompt into it.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_perplexity.png\"></p>\n<p>BAM.💥</p>\n<p>This was exactly what I was looking for.</p>\n<p>Did it give me the content end-to-end that I was expecting?</p>\n<p>No.</p>\n<p>Was it a perfect starting point?</p>\n<p>Yes.</p>\n<p>I didn’t literally copy-paste it. I took the parts I liked, re-iterated on the ones I didn't until I eventually did. Plus, use my experience to prioritize parts that I felt should be more relevant vs others.</p>\n<p>Were there some hallucinations?</p>\n<p>Yes, it’s not a silver bullet.</p>\n<p>But it saved me DAYS of work.</p>\n<p>I was dreading having to write the syllabus and like this, it was actually fun. It was fun because I felt like Perplexity was acting as my assistant and I was engaging in a conversation of what should be contained within the course and what shouldn’t.</p>\n<p>After having all the content ready, I asked my wife to help me with some images to make it easier for students to understand concepts.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_assets.png\"></p>\n<p>I was happy with the results - but wanted a second opinion. So I asked a friend of mine who’s been a DS for over 6 years what his thoughts were on the materials I worked on - and he was impressed about the speed.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_ai_friend_message.jpeg\"></p>\n<p>Being a fan of open source, I have open sourced all the theory and practice of the course and you can access it here: <a href=\"https://github.com/DidierRLopes/supervised-learning\">https://github.com/DidierRLopes/supervised-learning</a></p>\n<p>For the practice exercises I made it so that users can run it with colab directly on the browser to focus on the learning and not on the installation of libraries - highly recommend doing this.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_colab.jpeg\"></p>\n<h2 id=\"assessing-students-grades\">Assessing students grades</h2>\n<p>After presenting the classes to the students, they had to work on a final project that involved supervised learning - and I had to grade their work on it. The grade was from 0 to 5 and I was given freedom in terms of what criteria to use.</p>\n<p>So I did what someone else in my shoes would do.</p>\n<h2 id=\"chatgpt-to-define-grading-criteria\">ChatGPT to define grading criteria</h2>\n<p>I typed <a href=\"http://chat.openai.com/\">chat.openai.com</a> and had a conversation with ChatGPT about the best way to grade the coursework. I wanted it to be as fair as possible, but also evaluate students based on criteria outside of coding, such as problem formulation and documentation/clarity.</p>\n<p>Note: Story for another day but with the raise of LLMs, I have a very strong opinion that documentation and clarity will be as important as the code itself.</p>\n<p>This is the outcome of that conversation:</p>\n<blockquote>\n<p><strong>PART I - Problem Formulation</strong></p>\n<ul>\n<li>\n<p>1.a. <strong>Clarity and Definition:</strong> Is the problem clearly defined and well-formulated? Are the project's objectives explicitly mentioned?</p>\n</li>\n<li>\n<p>1.b. <strong>Relevance and Context:</strong> Is the relevance of the problem within the application domain explained? Does the problem justify the use of supervised learning?</p>\n</li>\n</ul>\n</blockquote>\n<br>\n<blockquote>\n<p><strong>PART II - Documentation and Quality</strong></p>\n<ul>\n<li>\n<p><strong>2.a. Code Quality and Readability:</strong> Clarity and Structure: Is the code well-organized with clear and consistent formatting? Are comments used effectively to explain complex logic? Best Practices: Does the code follow standard coding practices (e.g., naming conventions, modularization)? Are functions and classes used appropriately?</p>\n</li>\n<li>\n<p><strong>2.b. Documentation and Explanation in Comments or Notebook Markdown</strong>: Clarity: Are the results and methodology clearly documented? Is there a detailed explanation of the steps taken and the reasons behind them? Visualization: Are visual aids (e.g., graphs, plots) used to illustrate key points and results? Are these visualizations clear and informative?</p>\n</li>\n</ul>\n</blockquote>\n<br>\n<blockquote>\n<p><strong>PART III - Code</strong></p>\n<ul>\n<li>\n<p><strong>3.a. Data Preprocessing and Cleaning</strong>: Completeness: Are all necessary steps for data preprocessing included (e.g., handling missing values, encoding categorical variables, scaling features)? Justification: Are the preprocessing steps justified and explained? Is there a clear reason for the choices made?</p>\n</li>\n<li>\n<p><strong>3.b. Data Exploration</strong>: Initial Analysis: Is there an exploratory data analysis? Are descriptive statistics used to better understand the data? Visualization: Are visualizations (e.g., graphs, plots) used to illustrate data distribution, correlations, and important patterns? Are these visualizations clear and informative?</p>\n</li>\n<li>\n<p><strong>3.c. Model Implementation and Training</strong>: Correctness: Is the model implemented correctly according to the chosen algorithm? Are appropriate libraries and functions used? Parameter Tuning: Is there evidence of parameter tuning or optimization? Are the chosen parameters explained and justified?</p>\n</li>\n<li>\n<p><strong>3.d. Evaluation and Validation</strong>: Metrics: Are appropriate evaluation metrics chosen and calculated? Are these metrics relevant to the problem at hand? Validation Techniques: Are appropriate validation techniques used (e.g., cross-validation, train-test split)? Is there an analysis of the model's performance on both training and testing data?</p>\n</li>\n</ul>\n</blockquote>\n<br>\n<p>This was it.</p>\n<p>Exactly what I was looking for.</p>\n<p>Now I could grade a student on each of these criteria, then select a final grade weight for each criteria (e.g. 5-15%), create a spreadsheet with such a table and call it a day.</p>\n<p>However, the most time-consuming task was coming - the grading itself.</p>\n<p>There were 10 groups in total. So 10 notebooks that I had to look into, exploring completely different datasets with a different ML model being used, different ways to do exploratory data analysis, different ways to assess the model, different objectives, …</p>\n<h3 id=\"cursor-helping-with-grading\">Cursor helping with grading</h3>\n<p>I opened <a href=\"https://www.cursor.com/\">cursor</a> (which is basically VSCode + ChatGPT) and probably the software I’ve recommended the most to developers in 2024.</p>\n<p>And opened my first notebook.</p>\n<p>Then I thought, what if I had GPT-4o on my side - helping me to assess this coursework.</p>\n<p>It didn’t need to be perfect because I was doing it myself, but it could help me understand if there was any critical thing that I missed OR if it completely had a different grade than the one I was going to provide - which would enable me to spend more time on that criteria and iterate.</p>\n<p>It gave me confidence that I was being fair to the students.</p>\n<p>And made me realize how hard it is for professors when they have 100s of students and have a subjective answer to grade. It’s impossible to get it right. They try their best, but as soon as the answer is not binary (0 or 1), they are doomed to fail.</p>\n<p>So how did I do it?</p>\n<p>Given that I just wanted GPT-4o to quickly review each of the criterias based on the code, I created a prompt that I could use for all of notebooks that the students sent.</p>\n<p>This is what my setup looked like</p>\n<p align=\"center\"><img width=\"1000\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor.png\"></p>\n<p>Having the code on the left side and the copilot on the right side that I could use to chat really enabled me to grade more confidently.</p>\n<p>Here’s an example of a section of a response I got to one of the student’s notebooks</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor_output.png\"></p>\n<p>One thing I did to have the copilot produce better outputs was to push it to do chain-of-thought (CoT). Meaning that I prompted the model to explain the reasoning behind a decision before providing a grade. This has been proved to yield to less hallucinations and more accurate responses - which is what I was looking for.</p>\n<p><strong>What if I wanted to do this at scale?</strong></p>\n<p>I would have put more effort into the prompt and focused on evaluating 1 criteria at a time. I would have done few-shot prompting where I put examples of what grades 1,2,3,4,5 look like for such criteria so the model has those references and can check for similarity of issues committed or successful tasks performed.</p>\n<p>Note: the model was able to interpret comments written in Portuguese which is another benefit.</p>\n<h2 id=\"democratizing-access-to-tutors\">Democratizing access to tutors</h2>\n<p>While I was working on my prompts to get some feedback from AI in terms of student’s coursework I realized that I only need $20/mo to access them.</p>\n<p>But then I realized - so do the students.</p>\n<p>This means that the students have no reason to NOT run their entire coursework by a LLM that can act as a critic of their work.</p>\n<p>They can keep iterating until the model doesn’t find anything - hence making students feel more confident about the work they are putting forward.</p>\n<p>My initial thought was: “this feels like cheating” (right after the - “I wish I had this a few years ago”).</p>\n<p>But it actually isn’t.</p>\n<p>Tutors have existed for a long time.</p>\n<p>Students pay tutors to spend time with them to learn outside of classes - whether it’s explaining the theory or helping with coursework.</p>\n<p>However, tutors are a vitamin and not a painkiller (they are a nice-to-have and not a must-have). And because they aren’t a requirement, it’s not a typical choice among lower-income families.</p>\n<p>On the other hand, kids from wealthy families often have multiple tutors. Not for students who are almost failing their class, but who want to bump their grades from A- to an A+.</p>\n<p>But this is about to change.</p>\n<p>For the most part, GPT-3.5 is accessible for free.</p>\n<p>This means that everyone can have access to a tutor that they can work with to have better grades but also produce better coursework.</p>\n<p>This means that the concept of a tutor will be democratized and the playing field between students who come from different wealth backgrounds will be leveled and fair.</p>\n<h2 id=\"a-final-thought-on-open-source\">A final thought on open source</h2>\n<p>Another class that I had to give to students was \"Data Analytics in Financial Markets\".</p>\n<p>The goal here was to have a more real-life application of data analytics, particularly in financial markets - and even feature OpenBB which has partnered with this university.</p>\n<p>But when I started working on the content from scratch, I wondered.</p>\n<p>Can't I find a repository on GitHub that suits my needs?</p>\n<p>And I did.</p>\n<p>The GitHub repository I found was the GitHub repository that contains the code for the case studies in the O'Reilly book \"Machine Learning and Data Science Blueprints for Finance\" written by my friend <a href=\"https://www.linkedin.com/in/hariomtatsat/\">Hariom Tatsat</a>: <a href=\"https://github.com/tatsath/fin-ml\">https://github.com/tatsath/fin-ml</a>.</p>\n<p>So why would I spend the time re-inventing the wheel when I could just walk students through a few of these case studies?</p>\n<p>This is what I did.</p>\n<p>Which then made me think that all of this data has been already fed into foundational models, and so even if I were to apply the same approach I did earlier with Perplexity or ChatGPT - it is likely that with a good prompt some of the main examples would have been derived from this repository.</p>\n<p>But in this case, this repository already had the perfect case-study format I was looking for, and so I can more easily credit the author.</p>\n<p>which made me wonder:</p>\n<p><em>How will open source authors be able to get credit for their work when all of it is being translated into weights in a big neural network architecture?</em></p>",
            "url": "https://didierlopes.com/blog/my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt",
            "title": "My first-hand experience on AI impacting education through Perplexity, Cursor and ChatGPT",
            "summary": "AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.",
            "date_modified": "2024-06-30T00:00:00.000Z",
            "tags": [
                "education",
                "ai",
                "perplexity",
                "chatgpt",
                "cursor",
                "students",
                "big data",
                "analytics",
                "supervised learning",
                "machine learning"
            ]
        },
        {
            "id": "https://didierlopes.com/blog/why-chat-only-AI-Financial-Assistants-are-not-the-future",
            "content_html": "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future.png\"></p>\n<p>Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research. They are limited by their one-dimensional approach, which hinders efficient data retrieval and long-term usability. Read on to discover how OpenBB Terminal Pro addresses these issues with a three-dimensional solution.</p>\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\n<p>This is a spicy take but bear with me.</p>\n<p>The more I think about “ChatGPT for Finance” products, the more I think this is not the answer.</p>\n<p>They are extremely good knowledge retrieval engines because you can ask what you want to know and get the answer immediately.</p>\n<p>My problem with their approach is what happens after.</p>\n<p>However, very little thought is given to the real-world investment workflow. That's why I strongly believe that a chat-only financial platform will never be successful on its own.</p>\n<p>Sure, they can win in the categories of “search” or “screening”, but they won’t be able to compete in the category of “investment research platform”.</p>\n<p>To do that, they would need to evolve.</p>\n<p>Let me explain why and how OpenBB differs from them.</p>\n<h2 id=\"1-dimensional-vs-n-dimensional\">1-Dimensional vs N-Dimensional</h2>\n<p>Financial assistants are, in general, 1-dimensional. By that, I mean that all you have on a screen is a “dashboard” with an unlimited y-axis (1 single dimension).</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_1.png\"></p>\n<p>This means that whatever information they output will always be in the same position, which is great for the short term.</p>\n<p>But for the long term? Not so much. If the user wants to find specific information, they will need to keep scrolling up the text to find it.</p>\n<p>When financial assistants allow multiple conversations, then we start having 2 dimensions, where each conversation introduces a new axis.</p>\n<p>The problem with this approach is that you can’t easily find data within one of those past conversations since the assistant focuses on answering your question and not on data retrieval from the previous outputs.</p>\n<h2 id=\"our-3-dimensional-solution-on-terminal-pro\">Our 3-dimensional solution on Terminal Pro</h2>\n<p>How do we handle those issues? We have 3 dimensions.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_2.png\"></p>\n<p>Our Terminal Pro has a Copilot on the side, similar to other financial assistants.</p>\n<p>However, its big advantage is that when you want to save Copilot’s output for later, you can convert it into a text widget. And when you do so, you can place it wherever you want in this space — with the axis being infinite vertical scroll, tabs, dashboards, and folders.</p>\n<video controls=\"\"><source src=\"https://openbb-cms.directus.app/assets/ebdda68a-95f7-425b-aebe-5c98936c9189\"></video>\n<h2 id=\"storage-based-solutions-are-not-optimized-for-investment-research\">Storage-based solutions are not optimized for investment research</h2>\n<p>Again, financial assistants are optimized for search rather than information storage.</p>\n<p>This means that, by nature, chat-only financial assistants assume that their output will not matter in the future, so they answer your queries similarly to how a text conversation works. It's literally called ChatGPT for that reason.</p>\n<p>However, that’s not ideal for investment research.</p>\n<p>If analysts and researchers need to access these financial assistants' output at some point in the future, they won’t be able to do it quickly. Instead, they’ll have to go through a long chat history.</p>\n<p>This is why, in our Terminal Pro, we allow users to create a markdown-based text widget from the Copilot’s output, as shown above, so that you can have that information quickly accessible, but also editable.</p>\n<h2 id=\"theres-no-simple-way-to-know-where-the-data-comes-from\">There’s no simple way to know where the data comes from</h2>\n<p>Financial assistants are great, and they are improving every day. But if there’s something I’ve learned from talking with financial firms for over three years, it's that this is a very slow-moving industry, and adopting new technologies takes time.</p>\n<p>But with AI, it seems different. It’s so revolutionary that people are willing to incorporate it into their workflow faster because they immediately understand the benefits it can bring to their business.</p>\n<p>However, hallucinations are still a big problem — so it’s essential for these firms to be able to verify the raw data and sources.</p>\n<p>The current level of AI is equivalent to having a smart intern that you would need to double-check their work or trust but verify.</p>\n<p>This is why our Copilot always answers based on data that is readily available on the dashboard — and (due to our “Bring Your Own Data” technology) that data can be brought by your firm rather than being limited to what we offer out of the box.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_3.png\"></p>\n<h2 id=\"financial-chats-are-not-collaborative\">Financial chats are not collaborative</h2>\n<p>Financial assistants are not collaborative by default.</p>\n<p>When someone opens a tool like ChatGPT, they are interested in getting an answer to their question. Can you imagine what would happen if more people had access to that conversation and asked ChatGPT a different question? That would translate into a horrible user experience.</p>\n<p>The interesting thing is that investment research starts as an individual process but ends up being a collaborative effort where the findings are shared and discussed within a team.</p>\n<p>So, financial assistants have a challenging task: multiple people on a team should be able to access all the conversations without being able to interact with these chats.</p>\n<p>But what if you go through a colleague’s chat where they were asking questions about a company’s earnings, and you want to do a follow-up question?</p>\n<p>That’s a complex problem.</p>\n<p>At OpenBB, we are in a very good position to solve this for our users.</p>\n<p>Since we allow them to create a widget from their conversation with the Copilot, users can effectively create the ideal dashboard to share with their team. On their turn, other team members will then be able to use the Copilot on that same dashboard to make their questions.</p>\n<p>And guess what?</p>\n<p>This can be considered yet another dimension that we allow users to explore.</p>\n<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_4.png\"></p>\n<h2 id=\"wrap-up\">Wrap up</h2>\n<p>In a nutshell,</p>\n<ul>\n<li>\n<p>Most AI financial assistant products are 1-dimensional. Great at retrieving an answer quickly but poor at the overall task of doing investment research.</p>\n</li>\n<li>\n<p>OpenBB Terminal Pro is positioning itself as a flexible and customizable investment research platform with N-dimensions that an AI copilot can control to produce a full investment dashboard as if it were an analyst.</p>\n</li>\n</ul>\n<p>I'm biased, but once we provide the OpenBB Copilot with the capability to interact with the interface (create widgets, dashboards and folders) we might be the company that gets closest to replace an analyst's job.</p>",
            "url": "https://didierlopes.com/blog/why-chat-only-AI-Financial-Assistants-are-not-the-future",
            "title": "Why chat-only AI Financial Assistants are not the future",
            "summary": "Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research.",
            "date_modified": "2024-06-15T00:00:00.000Z",
            "tags": [
                "finance",
                "ai",
                "openbb",
                "chat",
                "finance assistant",
                "chatgpt",
                "perplexity",
                "investment research"
            ]
        }
    ]
}