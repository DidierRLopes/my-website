---
slug: gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal
title: Gamestonk Terminal - The next best thing after Bloomberg Terminal
date: 2021-03-14
image: /blog/2021-03-14-gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal.png
tags: ['Gamestonk Terminal', 'Finance', 'Stock Market', 'Programming', 'Open Source']
description: In this blogpost, I introduce Gamestonk Terminal, an open-source project that aims to be a comprehensive tool for financial analysis and stock market research. It includes functionalities for discovering stocks, market sentiment analysis, fundamental and technical analysis, due diligence, prediction techniques, and more.
---

<p align="center">
    <img width="600" src="/blog/2021-03-14-gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal_1.png"/>
</p>

<br />

In this blogpost, I introduce Gamestonk Terminal, an open-source project that aims to be a comprehensive tool for financial analysis and stock market research. It includes functionalities for discovering stocks, market sentiment analysis, fundamental and technical analysis, due diligence, prediction techniques, and more.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

If you like stocks and are careful with the way you spend your money, (me saying it seems counter-intuitive given that I bought GME at the peak, I know) you know how much time goes into buying shares of a stock.

You need to: Find stocks that are somehow undervalued; Research on the company, and its competitors; Check that the financials are healthy; Look into different technical indicators; Investigate SEC fillings and Insider activity; Look up for next earnings date and analysts estimates; Estimate market’s sentiment through Reddit, Twitter, Stocktwits; Read news;. … the list goes on.

It’s tedious and I don’t have 24k for a Bloomberg terminal. Which led me to the idea during xmas break to spend the time creating my own terminal. I introduce you to “Gamestonk Terminal” (probably should’ve sent 1 tweet everyday to Elon Musk for copyrights permission eheh).

As someone mentioned, this is meant to be like a swiss army knife for finance.

It contains the following functionalities:

- **Discover Stocks**: Some features are: Top gainers; Sectors performance; upcoming earnings releases; top high shorted interest stocks; top stocks with low float; top orders on fidelity; and some SPAC websites with news/calendars.

- **Market Sentiment**: Main features are: Scrolling through Reddit main posts, and most tickers mentions; Extracting trending symbols on stocktwits, or even stocktwit sentiment based on bull/bear flags; Twitter in-depth sentiment prediction using AI; Google mentions over time.

- **Research Web pages**: List of good pages to do research on a stock, e.g. macroaxis, zacks, macrotrends, ..

- **Fundamental Analysis**: Read financials from a company from Market Watch, Yahoo Finance, Alpha Vantage, and Financial Modeling Prep API. Since I only rely on free data, I added the information from all of these, so that the user can get it from the source it trusts the most. Also exports management team behind stock, along with their pages on Google, to speed up research process.

- **Technical Analysis**: The usual technical indicators: sma, rsi, macd, adx, bbands, and more.

- **Due Diligence**: It has several features that I found to be really useful. Some of them are: Latest news of the company; Analyst prices and ratings; Price target from several analysts plot over time vs stock price; Insider activity, and these timestamps marked on the stock price historical data; Latest SEC fillings; Short interest over time; A check for financial warnings based on Sean Seah book.

- **Prediction Techniques**: The one I had more fun with. It tries to predict the stock price, from simple models like sma and arima to complex neural network models, like LSTM. The additional capability here is that all of these are easy to configure. Either through command line arguments, or even in form of a configuration file to define your NN. It also allows backtesting.

- **Reports**: Allows you to run several jobs functionalities and write daily notes on a stock, so that you can assess what you thought about the stock in the past, to perform better decisions.

- **Comparison Analysis**: Allows to compare different stocks.

- **On the ROADMAP**: Cryptocurrencies, Portfolio Analysis, Credit Analysis. Feel free to add the features you’d like and we would happily work on it.

This project will always remain open-source, and the idea is that it can grow substantially over-time so that more and more people start taking advantage of it.

Feel free to contribute towards the project.

Feedback is extremely welcome!


---

---
slug: momentum-football-bets
title: Momentum Football Bets
date: 2021-04-07
image: /blog/2021-04-07-momentum-football-bets.png
tags: ['Football', 'Betting', 'Momentum', 'Web Scraping', 'Beautiful Soup', 'Python']
description: In this blogpost, I share how I developed an automated task to estimate the momentum of football teams for betting purposes using Beautiful Soup and Python.
---

<p align="center">
    <img width="600" src="/blog/2021-04-07-momentum-football-bets.png"/>
</p>

<br />

In this blogpost, I share how I developed an automated task to estimate the momentum of football teams for betting purposes using Beautiful Soup and Python.

The open source code is available [here](https://github.com/DidierRLopes/momentum-football-bets).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This Easter, I spoke with my girlfriend’s father and there were several football matches happening that weekend, he started talking about betting on some of those matches.

He carried on to explain me his betting routine, which consisted of:

1. Checking the next fixtures for a specific competition: https://www.skysports.com/premier-league-fixtures
2. Checking the last results of each of the team and “estimate” their momentum (e.g. https://www.skysports.com/football/wolverhampton-wanderers-vs-liverpool/stats/429116)

<br />

Then, iterate these 2 steps for all the fixtures happening, from Premier League, Championship, League One, and League Two.

Since I recently learned how to use Beautiful Soup to scrap data from web pages (see [GamestonkTerminal](https://dro-lopes.medium.com/gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal-a263c001a61f)), I thought that I could create an automated task that would do all of these steps with a simple double click executable. After checking that I could extract such data from SkySports, I let him know that by the next day I would have something working.

After dinner, I started working on the project, and before I went to sleep I had the first prototype working, which you can see in [here](https://github.com/DidierRLopes/momentum-football-bets).

On top of “his” automated task, I created a “momentum score” which tries to estimate the momentum score based on what my girlfriend’s father told me that he does. He looks into the last games of the team and see if they have a positive momentum by looking to see if they come from a winning series.

So, I thought it would be good to attribute a weight to each of the last matches where the most recent match would have the biggest weight, and last one from the 6 provided from SkySports stats would have the lowest weight. Together with this weight, I thought we could use the sum of the weight to the score in case of a win, subtract in case of loss, and don’t do anything in case of a draw.

So, in simple terms, if score is positive the team is likely to have been winning their last matches, if score is negative the team is likely to have loss their last matches.

But then, I thought:

_“Ok, this is nice. But when you bet, you don’t bet on a single team, but on the result between the 2 teams that are playing each other.”_ I.e. if team A has an amazing momentum, and so has team B, the bet will — in theory — be risky.

Hence, the next step was to address this concern. This was done by checking the momentum score difference between the teams, the bigger the momentum score, the less risky — in theory — a bet would be. What we want to see is a team that has been doing amazing for the past 6 games, and one that has been performing consistently bad.

Lastly, I added a confidence filter so that the terminal would only output the games that shown at least a certain X confidence. And also, an argument that would select the number of days in the future that we could look for fixtures.

After having this implemented, the day after was about polishing the code, adding some colouring and emojis, creating a repository for it, a README, discussing the binning of the momentum score and bet confidence terms, creating a logo for it, and creating an executable + adding the logo which my girlfriend did.

![image](/blog/2021-04-07-momentum-football-bets_1.png)

After this, we were quite excited to backtest the app. We filtered the next features with a big confidence bet score (to have less risk), and put 20 pounds on 3 different accumulators. [And it’s gone.](https://www.youtube.com/watch?v=-DT7bX-B1Mg)

Hope you had a good read. Feedback is always appreciated.


---

---
slug: move-over-bloomberg-terminal-here-comes-gamestonk-terminal
title: Move over Bloomberg Terminal, here comes Gamestonk Terminal
date: 2021-04-23
image: /blog/2021-04-23-move-over-bloomberg-terminal-here-comes-gamestonk-terminal.png
tags: ['Gamestonk Terminal', 'Finance', 'Stock Market', 'Programming', 'Open Source']
description: In this blogpost, we introduce Gamestonk Terminal, an open-source project that aims to be a comprehensive tool for financial analysis and stock market research. It includes functionalities for discovering stocks, market sentiment analysis, fundamental and technical analysis, due diligence, prediction techniques, and more.
---

<p align="center">
    <img width="600" src="/blog/2021-04-23-move-over-bloomberg-terminal-here-comes-gamestonk-terminal.png"/>
</p>

<br />

In this blogpost, we introduce Gamestonk Terminal, an open-source project that aims to be a comprehensive tool for financial analysis and stock market research. It includes functionalities for discovering stocks, market sentiment analysis, fundamental and technical analysis, due diligence, prediction techniques, and more.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Hey all,

2 months ago I made a terminal that I had been working on my spare time, to help me on my stock research, open-source. See [here](/blog/gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal).

## The motto

Gamestonk Terminal provides a modern Python-based integrated environment for investment research, that allows the average joe retail trader to leverage state-of-the-art Data Science and Machine Learning technologies.

As a modern Python-based environment, Gamestonk Terminal opens access to numerous Python data libraries in Data Science (Pandas, Numpy, Scipy, Jupyter), Machine Learning (Pytorch, Tensorflow, Sklearn, Flair), and Data Acquisition (Beautiful Soup, and numerous third-party APIs).

As of today, and thanks to all your help and the traction created around it, the terminal is looking better than ever. Now it’s no longer only me taking care of the repo, but also 2 other experienced devs, who are adding features on a daily basis and increasing the robustness of the codebase. Feel free to wander through the FEATURES page to see what you would get out of this tool!

If some of you thought it was amazing 2 months ago, you won’t believe what it looks like now. You can check out the ROADMAP for all the features that have been added since, but let me list some of them:

- **New** Screener for stocks, which allows users to save their presets and share them
- **New** Options menu
- **New** Comparison Analysis to compare several tickers in their historical price, sentiment, or fundamental analysis
- **New** Portfolio Optimisation that assigns stocks weights based on risk level specified by the user
- **New** Exploratory Data Analysis menu that looks at historical data from a statistic point of view
- **New** Residual Analysis after using a statistical model for prediction
- **New** menu to provide access to your portfolio (supports Robinhood, Ally invest, Alpaca, and Degiro)
- **New** Cryptocurrency, Forex, and FRED menus
- Prediction with backtesting
- Technical analysis that includes a score and a summary
- Due Diligence menu with data from Dark Pools, and also Failure to Deliver
- Sentiment analysis from news provided from collaboration with a company that provides this feature paid. Free for us!

As always feedback is appreciated, and contributions even more so!

Let’s try to reduce the gap between the amount of information that the Hedge Funds have access to in comparison with the usual retail trader.

Bloomberg Terminal, we’re coming for you.

Feel free to join our discord at https://discord.gg/Up2QGbMKHY.


---

---
slug: neistpoint-project
title: NeistPoint Project
date: 2021-05-23
image: /blog/2021-05-23-neistpoint-project.png
tags: ['NeistPoint', 'Clothing Brand', 'Sustainability', 'Project Management', 'C++', 'Stock Management']
description: In this blogpost, I share my journey of starting a sustainable clothing brand, managing the project, and developing a stock management tool in C++.
---

<p align="center">
    <img width="600" src="/blog/2021-05-23-neistpoint-project.png"/>
</p>

<br />

In this blogpost, I share my journey of starting a sustainable clothing brand, managing the project, and developing a stock management tool in C++.

The open source code is available [here](https://github.com/DidierRLopes/NeistpointCLI).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Context

More than 2 years ago, me and some friends started a clothing brand - **NeistPoint**. The logo and name is inspired by the Neist Point Lighthouse in the Isle of Skye. The motto was “**For a greener future and a bluer ocean**”, and the goal was to raise awareness to contribute for a sustainable environment.

At **Neist**, we tried to not be yet another clothing brand, but actually to fill the current gap in the retail industry by producing high-quality, eco-friendly clothes at affordable prices. And we achieved that. For instance, our t-shirts are made of 100% organic ring-spun combed cotton, and they last longer than my Lacoste t-shirts — seriously.

The problem is that to be profitable, you need to either increase the prices of your products, or decrease the quality, which were not things we wanted to do since they didn’t represent the value of our brand. Due to that, and the fact that the team behind our brand no longer has time/resources, we’re dropping our **last ever** season now.

Anyway, no regrets from my side, it has been a great learning experience to understand what is involved around the creation of a brand, being a project manager internally, and doing something other than coding in my spare time. _Also, most importantly, ending up with a full new wardrobe of pieces that I love and that will probably last for my kids._

Sorry for this rambling, just wanted to share this context with everyone.

## Implementation

Given that our team had no experience in clothing whatsoever, and based on our needs, our steps to make this a high-quality product were:

1. Get the best (environmentaly friendly) clothing material
2. Send it to the best embroidery store in Portugal
3. Package it and forward it onto the customer

<br />

![image](/blog/2021-05-23-neistpoint-project_1.png)

This process was **far from being optimised**. In fact, pretty much everything was manual. Apart from the creation of the clothes. Therefore, we needed a Software to keep track of the products at each of it’s stages: _material to request, material shipping, material in stock, product to create, product creating, product in stock, and product sent_.

Since I didn’t find anything that I liked online, and I knew how to code, I thought the best solution was to develop something myself. This way it could be adapted to perfectly fit my own requirements (advantages of being your own product owner eheh). In addition, I wanted to improve my C++ skills, so I thought, **why not?**

![image](/blog/2021-05-23-neistpoint-project_2.png)

For 1 week or so, during my commute I worked on the [NeistPoint Stock Managemen](https://github.com/DidierRLopes/NeistpointCLI) tool. To be honest, I think it took longer to devise the architecture behind it than to actually write the code, as there were lots of things that I wanted to be taken into account. Also, the fact that the “database” is a .csv file, was intentional. This way, we could share this file between the team members.

Hope someone finds this tool interesting, and gets inspired to develop their own software to meet their own project requirements. In the meantime, feel free to check us one last time on [our website](https://neistclothing.com/) or [instagram](https://www.instagram.com/neistclothing/). You may even spot me in some of the pictures!

The repository for the code can be found here: https://github.com/DidierRLopes/NeistpointCLI

Thanks for reading, as always!


---

---
slug: customizable-meme-filter
title: Customizable Meme Filter
date: 2021-06-12
image: /blog/2021-06-12-customizable-meme-filter.png
tags: ['Python', 'Meme Filter', 'Image Processing', 'Face Recognition']
description: In this blogpost, I share my journey of creating a customizable meme filter using Python. This filter selects a random meme based on the number of people on the screen and assigns each person to a character in the meme.
---

<p align="center">
    <img width="600" src="/blog/2021-06-12-customizable-meme-filter.png"/>
</p>

<br />

In this blogpost, I share my journey of creating a customizable meme filter using Python. This filter selects a random meme based on the number of people on the screen and assigns each person to a character in the meme.

The open source code is available [here](https://github.com/DidierRLopes/meme-filter).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

For the people who know me, they know how much I enjoy memes. I’ve got to admit, whenever I go to museums I have a lot of fun captioning artwork as memes. **As I like to say, I go for the art, and I stay for the memes.**

One day while commuting to work (you can still see the [first commit](https://github.com/DidierRLopes/meme-filter/commit/59be427571c96350d9652922b3ab2ba52ddf18af) which dates back to 10 February of 2020 and has only notes of the sketch of this idea in Portuguese) I thought:

> “It would be funny if there was a snapchat kind of filter where given the number of people on the screen, a random meme was selected and each person would be one of its characters”.

<br />

Since I was still improving my Python skills, I thought why not do it in Python. After 1 month, I already had the working code, however, since I was switching jobs at the time my commute time reduced drastically and so did my time to work on this. It took around 1 more month to finish the cleaning up of the script (324 lines) to be more readable, and at the same time Covid happened. **The latter explains why my hair is blonde on the demo below** :)

Usage:

```console
./didifilter.py — location=memes — caption=’Which meme am I?’ — initial=30 — final=50 -b — max=3
```

![hair_1](/blog/2021-06-12-customizable-meme-filter_1.png)

**To sum up:** This program is meant to be an advanced version of the known snapchat filter where there are random images spinning on top of people’s heads. The main improvement is that you can not only select the images you want to choose from and the caption, but you can also play it with friends (recognizing more than 1 face at the same time).

The best part of the script is that it is meant to be easily customizable. Any person is able to create their own filter by creating a folder with the images they want within a folder with 1, 2, … based on the number of people they are meant to be used (apart from when backwardCompatible flag is enabled), and select/specify different types of flags/parameters, e.g.:

```console
./didifilter.py — locationFolder=celebrities — caption=’What celeb am I?’ — max=2 -v — video=”exampleVideo”
```

```console
./didifilter.py --locationFolder=pokemons --caption="Who's this pokemon?" --width=250 --height=150 --max=1 -p
```

**AND**, you can also quickly tweak the code to adapt it to do something else. Here’s me **pranking** my girlfriend with a psyduck when the query was: “_Who do I look like?_”

![hair_2](/blog/2021-06-12-customizable-meme-filter_2.png)

Hope you have a nice read and enjoy the filter. You can find the code [here](https://github.com/DidierRLopes/meme-filter).

Feel free to provide feedback, as always!


---

---
slug: my-journey-of-memorising-a-deck-of-52-shuffled-cards
title: My journey of memorising a deck of 52 shuffled cards
date: 2021-06-26
image: /blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards.png
tags: ['Memory Training', 'PAO System', 'Memory Palace', 'Card Memorisation']
description: In this blogpost, I share my journey of memorising a deck of 52 shuffled cards using the PAO system and Memory Palace technique.
---

<p align="center">
    <img width="600" src="/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards.png"/>
</p>

<br />

In this blogpost, I share my journey of memorising a deck of 52 shuffled cards using the PAO system and Memory Palace technique.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

A few years back, I wanted to read a book about memory and found the best-selling book **“Moonwalking with Einstein: The Art and Science of Remembering Everything”** an ideal choice. I won’t go into too much detail about the book which is a great read, if you don’t trust me, trust Bill Gates, who called the book “_absolutely phenomenal_”. But let me give you a brief sequence of events from the author and journalist of the book, Joshua Foer:

- It starts by observing the extraordinary accomplishments of mental athletes at a memory championship.
- Foer meets Tony Buzan, the trim 67-year-old English self-help guru who founded the [World Memory Championships](http://www.worldmemorychampionships.com/) in 1991 and who insists the brain is “like a muscle”: exercise it and it gets stronger.
- Foer learns the art of memory training.
- He practices his memory muscles for 1 year with help of a shambling 24-year-old from Oxford who becomes his mentor.
- He then finds himself in the finals of the US Memory Championships, alongside ‘mental athletes’ who could memorise the precise order of ten shuffled decks of cards in under an hour.

If you’re interested, here’s a [nice review](https://www.theguardian.com/science/2012/nov/21/moonwalking-einstein-joshua-foer-review) on the book.

## My thoughts after reading book

After finishing this book, more than anything I was curious. Unlike Joshua Foer, I didn’t want to dedicate a full year to the cause, but I still wanted to give it a go so I could look back and think: “Here’s something pretty useless for the day-to-day. Yet, how cool is that I can memorise 52 random cards?”.

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_1.png)

For people who know me, they know how much I hate to leave things unfinished. Whether that’s a task that I set myself, or ‘just’ not leaving any pizza leftover. Therefore, I knew that if I really wanted to do this, I’d have to set aside time for it, and so I did. The text under is my journey to memorise a shuffled deck of 52 cards.

## Technique (PAO + Memory Palace)

The mnemonic “**Memory Palace**” technique that I was about to use was referred to on the aforementioned book. The ancient mnemonic technique was first practiced by Simonides of Ceos over 2,500 years ago. When googling the term, the definition is:

_A Memory Palace is an imaginary location in your mind where you can store mnemonic images. The most common type of memory palace involves making a journey through a place you know well, like a building or town. Along that journey there are specific locations that you always visit in the same order._

The mnemonic images would be conceived using the famous PAO system. This term means:

_The Person-Action-Object System (or “PAO” System) is a popular method for memorising long random numbers and decks of playing cards. … Some people assign arbitrary images to the numbers without any phonetic conversion. The digits are usually chunked in 2 or 3 digits and then placed into loci in a Memory Palace._

The idea is to take advantage of what we humans are best at, photographic memory.

## The journey of memorising a shuffled deck of 52 cards

### 1. Create your own personal PAO system.

For each card of the deck you have to have an associated _Person_, _Action_ and _Object_. It’s useful to have the least possible rules, and have these intersecting simultaneous cards, so that there’s less to memorise. Here’s how I did it:

- Define a **category** for each **suit** (e.g. Hearts represents friends)
- Define **something** for each **type**.
    - From 1 to 10 I’ve defined the starting letter of the person (e.g. Card 7 represents a person with name starting with letter K or C).
    - For the court (Queen, Jack, King) I’ve defined them as a powerful male/female. (e.g. King is the GOAT of the category).

Below you can see what the table looks like:

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_2.png)

**Note:** The Person is the main existing link, hence it needs to be something that you think of immediately when the category and the type of the card is known.

I had to change my cards several times as some of the PAO’s I had weren’t memorable enough, either because the name was too common, or because I didn’t relate that much to this person.

### 2. Memorise each card with it’s PAO system

Once the table above is filled in, the next step is to associate each card with it’s **Person-Action-Object**. I find that as long as you can remember the person name of the card by doing the cross between category and type, the action-object comes easily.

For instance:

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_3.png)

**Jack ♦: Einstein — Writing Equations — Blackboard**

- When I see a **Diamond**, I know we are in the **Celebrities** category. Since this is a **Jack** I know it’s an **important person**. I’ve selected Musk to be my GOAT, so this has to be **Einstein**. The **writing equations** and **blackboard** comes trivially when thinking about Einstein.

**8 ♣: Floyd Mayweather — Skipping — Rope**

- When a **Club** appears, I know we are in the **Athletes** category. Since this is an **8** I know the name starts with an **F or V**. This promptly reminds me of **Floyd**. The **skipping** and **rope** come immediately, due to my own personal experiences from improving my skipping skills and looking at videos of Mayweather. I find that the more the personal and creative you get with this, the easier it is to remember.

**King ♠: Goku — Powering up — Blonde Hair**

- If I see a **Spade**, I know we are in the **Cartoon** category. Since this is a King I know that this character is the **GOAT**. Which immediately triggers my brain to Goku, since it used to be my favourite cartoon as a kid. Trivially, comes the powering up as action, and the blonde hair as object.

In order to remember all the cards, my trick was to have a deck of cards where on the back of each card I wrote its own PAO. So that if I didn’t remember, instead of looking at the table, I could look at the back of the card. However, I find it important to sometimes not quit trying to remember immediately, as when you initially struggle to remember a card, when you eventually do, your brain retains this information so much better.

**Note: At this step you may realise that you keep forgetting the same PAO card. I recommend you going back to step 1 and re-defining it.** Once I did this to the cards I kept forgetting, I was in a much better position.

### 3. Create your own memory palace

This is the easiest step. I used the house I grew up in in Portugal, and decided to place 4 PAO instruments (i.e. 12 cards) per house division. Meaning that by the time I was in the first room upstairs, I was already 36 cards down the deck.

Since I’m not living in Portugal, let me show you what I mean by using a picture of my current living room in London. The spots I would select in here would have been: 1. Top of table with candles; 2. Top of side table; 3. Inside my gecko’s vivarium; 4. As a program on the TV.

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_4.png)

**Note: Make sure you always remember your memory palace spots, otherwise you may overlook them once looking for the next 3 set of cards.** The way I think about this is imagining that I lost my keys, and mentally going back in time to try to understand where they could be.

### 4. Practice memorising each set of 3 cards PAO

This is where the creativity comes in. **When picking 3 cards from the deck, you picture the Person of the 1st card, the Action of the 2nd one, and the Object of the 3rd one.**

Let’s imagine we’ve got the cards aforementioned.

**- Card 1: Jack ♦**
  * Einstein — Writing Equations — Blackboard

**- Card 2: 8 ♣**
  * Floyd Mayweather — Skipping — Rope

**- Card 3: King ♠**
  * Goku — Powering up — Blonde Hair

In my brain, this would lead to

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_5.png)

**Note: At this point you may realise that some combos of cards don’t work well together. **If this is bad enough to not make you remember the 3 card PAO, I recommend updating your PAO system to something that’s easier to generalise.

### 5. Place each 3 cards PAO onto the memory palace

For instance, if I were to place the **Einstein Skipping with Blonde Hair** on the **3rd spot of my living room (my gecko’s vivarium)**, in my head, I would picture something like this:

![image](/blog/2021-06-26-my-journey-of-memorising-a-deck-of-52-shuffled-cards_6.png)

**Note: I recommend trying to have the 3 card PAO interacting with the environment to improve memory.** In this case, I would have thought about the Blonde Skipping Einstein having to do skipping so fast that the gecko coudn’t come close because the rope was going too fast. The more original/different, the more chances you have to remember this scenario.

### 6. Re-iterate the memory palace with new 3 card PAO every time

Instead of memorising a new 3 card PAO in a memory palace location and then moving on, I always go back to the start and think about all the previous 3 card PAO’s from start. This will ensure you don’t forget the oldest 3 card PAO. In fact, it will make it so that the oldest 3 card PAO are repeated more times than the newer ones, so it’s all balanced out.

### 7. Practice and Practice

I found out that after memorising my PAO system (which took a long time) and the memory palace, it was fairly easy to memorise the shuffled 52 deck of cards. However, it was taking me way too long to memorise it AND say it out loud.

Once I started practicing more and more time started decreasing. The last time I tried, I managed to do it under 10 minutes, which is not great but I’ll take it. As I mentioned, I just wanted to be able to do it, I didn’t care much about the time.

Also, I still needed to think about the category + type of the card every-time, I think the time to memorise the deck of cards decreases exponentially once you actually associate each card image to it’s PAO. But for that you need to practice more, which for me was getting boring.

...

This is a different post than the ones I usually do, but I find it extremely interesting. Hence why I was keen on sharing it.

Let me know if you’ve heard about it, or want to give this a go.

Thanks for reading!


---

---
slug: household-bills-program
title: Household bills Program
date: 2021-07-17
image: /blog/2021-07-17-household-bills-program.png
tags: ['Java', 'Programming', 'GUI', 'Software Development', 'Side Project']
description: In this blogpost, I share my journey of creating a program to split household bills. This was my first side project where I used Java to create a GUI application.
---

<p align="center">
    <img width="600" src="/blog/2021-07-17-household-bills-program.png"/>
</p>

<br />

In this blogpost, I share my journey of creating a program to split household bills. This was my first side project where I used Java to create a GUI application.

The open source code is available [here](https://github.com/DidierRLopes/HouseholdBills).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

**My first side project.**

Before University, I spent most of my spare time playing counter-strike (my steam account had **more than 1000 hours played**, that’s more than 41 entire days playing in a row). I was a decent player I’d say, you can see a compilation of “almosts” I’ve done [here](https://www.youtube.com/watch?v=ocsJzNJJB50).

However, I knew this wasn’t the way. I realised that if I used the amount of time I was spending on online games for learning, I would have a much bigger satisfaction return. And, in the long term, my life would be better.

**So I started studying hard.** I started valuing my time more, and declined most of the parties I was invited to because I was busy working late hours. Don’t get me wrong, I’m an easy person. I like to think I make friends easily. However, I just had different priorities, and partying just wasn’t one of them. As my parents say: _“Everything has its own time”_.

In my 2nd year of University, I was getting really good grades, which means that I started having discussions with the other best students in the course. **That’s how I met one of the smartest people I know to this day**. This guy was a proper hands-on person, he didn’t study half the time I did, but he was always busy with something.

He had a band, developed his own personalised guitar pedals and amplifiers, and developed some apps for fun. He did this all while having excellent results at University, which is insane. That’s when I realised that he was not only giving more priority to these hobbies in relation to partying or meeting people, **BUT also in relation to doing courseworks or studying for exams**. He’d never fail a coursework/exam, but that further study could have bumped a grade from 17 to a 19 out of 20.

One day, we were meant to meet at his place to work on a coursework together, and he shown me an app that he had developed for him and his girlfriend. The app was a simple command line interface that was able to split their usual household bills (rent, water bill, food shop, cat food, etc). **I found that fascinating.**

I told him I would create one for myself. Since I had read about how to use Java to make a pretty GUI, I thought why not give this a go (although I had no idea about OOP). In addition, I didn’t want my program to look the same as his, so I thought my version could be as if it was an upgrade.

...

After that, I was on a mission. Little did I know that after this, I never really stopped having an interest in working on new side projects.

The planning steps were:

**1. Decide main features.**
  Add new household bills to split, Give money, and See bills.

**2.Sketch what the GUI should look like**

**3. Devise data structure associated with a new Household bill split.**
  This was important for both coding, and also database management.

**4. Work out the math associated with the splitting and giving**

The development process was to **“divide to conquer”**. I split the tasks into several sub-tasks, and after every new little code change I was testing the code to make sure that nothing was broken. I re-iterate through design and code several times, until I was happy with my solution. Then I did some clean-up/improvements, such as: Adding pictures of the users, Login password, Frenchies as icons.

**On a funny side note:** As I didn’t know how to work with DBs at that time, I used text files to save and load all the information. Meaning that if my brother ever opened one of those text files (which weren’t properly hidden…), I could have passed from him owing me 100 euros to me owing him 10 million. The software was on his laptop, and I had an hardcoded password, so in theory he couldn’t manually add any bill without my presence — I guess that was enough for him to think that the product was bullet-proof.

See images below of the program:

<div className="flex justify-center gap-2">
  <img src="/blog/2021-07-17-household-bills-program_1.png" width="50%" />
  <img src="/blog/2021-07-17-household-bills-program_2.png" width="50%" /> 
</div>

<br />

<div className="flex justify-center gap-2">
  <img src="/blog/2021-07-17-household-bills-program_3.png" width="50%" />
  <img src="/blog/2021-07-17-household-bills-program_4.png" width="50%" /> 
</div>

<br />

You can find more information about this on my GitHub, [here](https://github.com/DidierRLopes/HouseholdBills).

**The program ended up being used for more than 3 years.** Since I lived with other people other than my brother, I had to update the name/image on the program to represent that. Since I was new to coding, I didn’t think about the future. Therefore, when that time came, I had to manually replace the names one by one in the code. I also had friends requesting to use the program, which lead to me adapting this to their names/figures.

It was a fun project and I definitely learned loads from it. The most important thing was that I was able to do whatever **I wanted software-wise as long as I dedicated enough time for it.**

Hope you had a fun read. Thanks!


---

---
slug: minion-recipes-program
title: Minion Recipes Program
date: 2021-07-23
image: /blog/2021-07-23-minion-recipes-program.png
tags: ['Python', 'Programming', 'Recipes', 'Software Development']
description: In this blogpost, I share how I developed a program to help my mum manage her recipes. The program allows for adding, editing, and removing recipes, and even includes fun minion icons.
---

<p align="center">
    <img width="600" src="/blog/2021-07-23-minion-recipes-program.png"/>
</p>

<br />

In this blogpost, I share how I developed a program to help my mum manage her recipes. The program allows for adding, editing, and removing recipes, and even includes fun minion icons.

The open source code is available [here](https://github.com/DidierRLopes/RecipesProgram).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Once I developed the [Housebills program](/blog/household-bills-program), I really enjoyed the feeling of being able to create usable software from scratch. Therefore, that year during Christmas, I wanted to challenge myself to see if I could find any interesting project to do in only 1 week.

I started by nagging my dad and brother for them to tell me something that would be useful to them in their daily lives. Sadly, none of them had any idea. Then, I went to the kitchen to ask my mum the same. She was busy searching recipes for xmas on her messy notebook, so she also said no.

I sat there next to her thinking about what I could do, while she kept on going back and forth in her notebook searching. I don’t know if she had been reading about the binary search algorithm, or if she was just opening pages randomly. What I know is that 1 week later I did a program for her to keep her recipes. Safe to say that I saved Christmas, I guess.

Note: Before the end of that year, I still upgraded the software for its version 2.0, which included more than 20 minion icons. To this day, I think she opens the program to see the minion icons more than the recipes themselves.

Below it displays the interfaces used, and these correspond to: Red-Visualize; Add; Blue-Add; Green-Edit; and Yellow-Remove recipes.

![image](/blog/2021-07-23-minion-recipes-program_1.png)

PS: Any resemblance with the Microsoft colour scheme is pure coincidence eheh.

When adding a recipe, the following window will be displayed.

![image](/blog/2021-07-23-minion-recipes-program_2.png)

This allows you to add both a recipe, and a category (i.e. the “Tiramisu” recipe would be within “Desserts” category).

The recipe content would include:

- Name of the recipe
- Ingredients
- Preparation
- Comment

When visualising a recipe, the following window will be displayed.

![image](/blog/2021-07-23-minion-recipes-program_3.png)

Where the recipe dialog box would prompt the recipes based on the category chosen on its left. Then, after selecting a recipe, the ingredients, preparation and comment would be filled out.

When editing a recipe, the following window will be displayed. This is similar to the visualisation window, with the difference that the text boxes are editable, and therefore, the recipe can be improved.

![image](/blog/2021-07-23-minion-recipes-program_4.png)

Note: throughout the program there are Message Dialog boxes (as shown above) that tell the user whether the recipe has been successfully (or not) edited, added or removed.

Finally, in order to remove a recipe, the following window would be displayed. Where you can either delete a single recipe, or the entire category.

![image](/blog/2021-07-23-minion-recipes-program_5.png)

The recipe database is handled in the most robust way: **with plain text files**, obviously.

As always, hope you had a nice read.


---

---
slug: k-means-clustering-to-visit-a-new-city
title: K-means algorithm to visit a new city
date: 2021-08-01
image: /blog/2021-08-01-k-means-clustering-to-visit-a-new-city.png
tags: ['K-means', 'Algorithm', 'Travel', 'Efficiency', 'London', 'GPS', 'Clustering']
description: In this blogpost, I share how I used the K-means algorithm to plan a visit to London. The algorithm helps to decide which attractions to visit based on the number of days of the visit and the GPS coordinates of the attractions.
---

<p align="center">
    <img width="600" src="/blog/2021-08-01-k-means-clustering-to-visit-a-new-city.png"/>
</p>

<br />

In this blogpost, I share how I used the K-means algorithm to plan a visit to London. The algorithm helps to decide which attractions to visit based on the number of days of the visit and the GPS coordinates of the attractions.

The open source code is available [here](https://github.com/DidierRLopes/LondonVisit).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Usually when I book a weekend getaway, I spend quite some time doing 2 things:

- Writing down the main attractions I want to see
- Depicting the travel path to maximise efficiency and see the most in less time (I’m a bit of an efficiency freak myself, sorry)

**This repository aims to decide which attractions to visit in London as a function of the number of days that you will be visiting, by applying K-means algorithm.**

As input you need to give the GPS coordinates of the main attractions you want to visit during your stay, and the number of days you are planning to visit. Notice that attractions that are not within the map screenshot boundaries will be discarded. See disclaimer below.

The K-means algorithm will interpret: List of GPS coordinates of the main attractions that you want to visit as 2D samples, after converting to UTM. Number of days of the visit as Number of clusters.

Of course, this is rather unrealistic because of several reasons, such as:

- Not taking into account if they want to just pass by the London Eye, or have a ride on it;
- Assumes that we are in a no man’s land since it completely bypasses the existence of other buildings, roads, …;
- Does not consider altitude, even though London is rather plane;
- Does not consider the number of attractions that one can possibly do per day;
- Plus, if there was to be an attraction really far from the centre, it may happen that the algorithm considers an entire day for it (this would depend upon kernel initialisation)

Nonetheless, I think this is a funny exercise, and if I were to select the areas to visit by myself, **it would most likely be a similar choice to the one taken by K-means**.

**Disclaimer**: I did not know how to use Google API (neither wanted to pay for a key to be fair) hence I just took a screenshot of google maps and wrote down the coordinate of the lower left corner, so that I could use it as my origin. I also took the right top corner coordinate so that I could give the map with an “accurate” scaling.

**Note**: GPS coordinates (latitude, longitude) have degrees has units, thus, explaining why the conversion to UTM coordinates, which uses meters.

Immediately below you can see the result of a visit to London for 2, 3 and 4 days.

![image](/blog/2021-08-01-k-means-clustering-to-visit-a-new-city_1.png)

<div className="flex justify-center gap-2">
  <img src="/blog/2021-08-01-k-means-clustering-to-visit-a-new-city_2.png" width="50%" />
  <img src="/blog/2021-08-01-k-means-clustering-to-visit-a-new-city_3.png" width="50%" /> 
</div>

<br />

This project was done for fun. However, I believe that by creating a tuple per location with coordinates and estimate of time taken on each attraction, something nice could come out of this.

Hope you find this interesting. Let me know your thoughts.


---

---
slug: ranking-99-mind-f-ck-movies
title: Ranking 99 Mind f*ck movies
date: 2021-08-15
image: /blog/2021-08-15-ranking-99-mind-f-ck-movies.png
tags: ['Movies', 'Thrillers', 'IMDbPy', 'Python', 'Sorting Algorithm']
description: Ranking and sorting a list of 99 mind-bending thriller movies using IMDbPy API in Python.
---

<p align="center">
    <img width="600" src="/blog/2021-08-15-ranking-99-mind-f-ck-movies.png"/>
</p>

<br />

Ranking and sorting a list of 99 mind-bending thriller movies using IMDbPy API in Python.

The open source code is available [here](https://github.com/DidierRLopes/SortMoviesPerRating).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

During the Christmas holidays, me and my girlfriend, after watching The Office [US] twice in a row, and knowing most of Dwight’s pranks off by heart, decided that it was time to find something worth watching.

Although there’s lots of tempting series out there, we didn’t want to follow that path as we don’t like the “addiction” effect that a series has. Also, we have the same taste regarding movies, where **we both enjoy complex thriller plots**, that leave your mind to resonate about them long after being done with it. Personally, I consider a movie great when it still crosses my mind when trying to sleep or the day after. So, thriller movies it was.

After doing a little research work I came across this list of movies on Reddit: [99 mind f*ck movies](https://www.reddit.com/r/coolguides/comments/geipee/99_mindfck_movies/). I knew this list was good because most of my favourite movies were there, e.g. _The Prestige, Inception, The Usual Suspects, Primal Fear_, and _Ex Machina_.

So, the movie list was decided, and with that, also our new year’s resolution.

However, this list had 2 issues:

**1. The list didn’t have any particular order.** We would like to have the list ranked from best to worst, so that watching the best ones first will keep our motivation levels up to finish the list.

**2. The movie title didn’t have the released year.** Although we don’t particularly mind old movies, sometimes we’re just not in the mood to watch a B&W screen, or poor image resolution.

Therefore, while Meg was busy, I was on a role to hack something that would both sort the list based on IMDB ranking, and add the release years to the titles.

In a couple of minutes, I was already playing with [IMDbPy API](https://imdbpy.github.io/). This allowed me to have the sorting algorithm running in the background pretty quick. Within the hour, we already had our sorted movie list. Which I have attached below for future reference.

![image](/blog/2021-08-15-ranking-99-mind-f-ck-movies_1.png)

The first movie of the list that none of us had already watched was the movie [Incendies](https://www.imdb.com/title/tt1255953/). After having watched this movie, I can already tell you that sorting out this list was worth it. Definitely mind blowing, and a great watch.

As usual, you can find the source code on my github: [SortMoviesPerRating](https://github.com/DidierRLopes/SortMoviesPerRating).

Hope you enjoyed this read!


---

---
slug: time-series-crossvalidation-for-nn
title: Time-Series CrossValidation for NN
date: 2021-09-04
image: /blog/2021-09-04-time-series-crossvalidation-for-nn.png
tags: ['Python', 'Data Science', 'Deep Learning', 'Time Series', 'Cross Validation', 'Neural Networks']
description: This blog post discusses the creation of a Python module for splitting univariate time-series data using cross-validation techniques. The module is designed to prepare data for training, validation, and testing in a Deep Neural Network (DNN).
---

<p align="center">
    <img width="600" src="/blog/2021-09-04-time-series-crossvalidation-for-nn.png"/>
</p>

<br />

This blog post discusses the creation of a Python module for splitting univariate time-series data using cross-validation techniques. The module is designed to prepare data for training, validation, and testing in a Deep Neural Network (DNN).

The open source code is available [here](https://github.com/DidierRLopes/timeseries-cv).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

2 years ago, [Filipe Ramos](https://www.linkedin.com/in/ACoAACK9n24BrpxWf0HMa9bL7MSHleu2YVXpI5E) my previous maths and probability teacher, knowing that I had a special interest in Data Science, challenged me to help him in his PhD thesis “_Data Science na Modelação e Previsão de Séries Económico-financeiras: das Metodologias Clássicas ao Deep Learning_”.

Although we have been discussing theory, analysis and results, my main contribution was to write the Python code behind the thesis.

As a result, I have written a python module that splits a given univariate time-series based on cross-validation techniques so that these can be fed to a Deep Neural Network (DNN) to extract training/validation/test errors.

I know that there are examples of these online, but this was made from scratch so that we could personalise it according to the thesis’ needs, and grasp better what was at stake when performing different cross-validation techniques.

**The idea is given a training dataset, the package will split it into Train, Validation and Test sets, by means of either Forward Chaining, K-Fold or Group K-Fold.**

As parameters the user can not only select the number of inputs (`n_steps_input`) and outputs (`n_steps_forecast`), but also the number of samples (`n_steps_jump`) to jump in the data to train.

The best way to install the package is as follows: `pip install timeseries-cv` and then use it with `import tsxv`. See the module developed [here](https://pypi.org/project/timeseries-cv/).

This can be seen more intuitively using the jupyter notebook: “_example.ipynb_” Below you can find an example of the usage of each function for the following Time-Series:

```python
timeSeries = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26])
```

## Split Train

```python
from tsxv.splitTrain import 
split_train, 
split_train_variableInput
X, y = split_train(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
X, y = split_train_variableInput(timeSeries, minSamplesTrain=10, n_steps_forecast=3, n_steps_jump=3)
```

<div className="flex justify-center gap-2">
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_1.png" width="50%" />
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_2.png" width="50%" /> 
</div>

## Split Train Val

```python
from tsxv.splitTrainVal import 
split_train_val_forwardChaining, 
split_train_val_kFold, 
split_train_val_groupKFold
X, y, Xcv, ycv = split_train_val_forwardChaining(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
X, y, Xcv, ycv = split_train_val_kFold(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
X, y, Xcv, ycv = split_train_val_groupKFold(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
```

<div className="flex justify-center gap-2">
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_3.png" width="50%" />
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_4.png" width="50%" /> 
</div>

<br />

![image](/blog/2021-09-04-time-series-crossvalidation-for-nn_5.png)

## Split Train Val Test

```python
from tsxv.splitTrainValTest import split_train_val_test_forwardChaining, 
split_train_val_test_kFold,
split_train_val_test_groupKFold
X, y, Xcv, ycv, Xtest, ytest = split_train_val_test_forwardChaining(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
X, y, Xcv, ycv, Xtest, ytest = split_train_val_test_kFold(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
X, y, Xcv, ycv, Xtest, ytest = split_train_val_test_groupKFold(timeSeries, n_steps_input=4, n_steps_forecast=3, n_steps_jump=2)
```

<div className="flex justify-center gap-2">
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_6.png" width="50%" />
  <img src="/blog/2021-09-04-time-series-crossvalidation-for-nn_7.png" width="50%" /> 
</div>

<br />

![image](/blog/2021-09-04-time-series-crossvalidation-for-nn_8.png)

This module has not only been used for my friends’ thesis but also for a Data Science company and [Gamestonk Terminal](/blog/gamestonk-terminal-the-next-best-thing-after-bloomberg-terminal), that I know of :)

You can check the stats of the module [here](https://pypistats.org/packages/timeseries-cv).


---

---
slug: gamestonk-terminal-cant-stop-won-t-stop
title: Gamestonk Terminal — Can’t Stop, Won’t Stop
date: 2021-09-16
image: /blog/2021-09-16-gamestonk-terminal-cant-stop-won-t-stop.png
tags: ['Gamestonk Terminal', 'Open Source', 'Docker', 'Jupyter Lab', 'Hugo Website', 'Python', 'Finance', 'Trading']
description: Gamestonk Terminal's latest updates including Docker integration, Jupyter Lab integration, a new Hugo website, and new features. A summary of the recent developments and future plans for the open-source financial tool.
---

<p align="center">
    <img width="600" src="/blog/2021-09-16-gamestonk-terminal-cant-stop-won-t-stop_1.png"/>
</p>

<br />

Gamestonk Terminal's latest updates including Docker integration, Jupyter Lab integration, a new Hugo website, and new features. A summary of the recent developments and future plans for the open-source financial tool.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Hey all,

Do any of you know what **Docker, Jupyter Lab integration, features website and new features** have in common? Well this is what has been happening in [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) world since last month, and **MORE**!

### Docker

- This has been a highly requested feature from our more experienced dev users, as it allows you to run our code in a container, pull the image and then get going with a smooth installation process. You will also be able to run Jupyer Lab from our Docker container.

### Jupyter Lab Integration

- Jupyter is on course to take over the world (see [here](https://netflixtechblog.com/notebook-innovation-591ee3221233)).
- Big investment banks like JP Morgan use Jupyter too, see [this](https://github.com/jpmorganchase/jupyterlab_templates).
- Professionals in the industry such as Data Scientists, Data Analysts and Machine Learning engineers are familiar with the combo dockers+notebooks. Therefore, it makes our terminal an attractive Open-Source project to devote time to.
- Academia students and universities will be able to use terminal data through a notebook for their projects and coursework. We’re on track to be able to achieve something on this soon!

### Hugo Website

- Link [here](https://gamestonkterminal.github.io/GamestonkTerminal/).
- This will not only simplify a contributor’s documentation process, but it will also let non-Gamestonkers now see the vast number of features we offer and yes, when you read “offer” this is actually an offer since the tool is **completely free** to use.

### Main New features

- New Dark Pool Shorts menu
- Refactored and improved Crypto menu!!!
- Dark Pool and Crypto report generation
- Excel Discounted Cash Flow created by a MBA student
- Big code refactoring to allow for contributors to easily get started with our codebase
- Contributing document (click here).

### Tier 2 features
- [Sentiment Investor](https://sentimentinvestor.com/) data features implemented by the SI team themselves
- Feature/fraud indicators implemented by a MBA student
- Multiple plotting for economy data for more insight extraction
- Screener presets to not miss out on promising tickers
- Several new Technical Analysis indicators, e.g. Fibonacci, Fisher transform, Centre of gravity, zlma, Donchian channels…
- Unusual options activity
- Hot penny stocks in discovery menu
- A contributor implementation of a realtime earnings expected move, from [The Geek of Wallstreet](https://thegeekofwallstreet.com/2021/08/03/realtime-earnings-data/)
- Several new YahooFinance commands to discover promising tickers
- Refactor Exploratory Data Analysis and Residual Analysis menus into a Quantitative Analysis one

As if this wasn’t enough, we’re also working towards a [Discord bot](https://github.com/GamestonkTerminal/DiscordBot) so you can make best use of our terminal when discussing trading strategies with your friends. This was an initiative from a contributor, which just goes to show how much **we rely on our community to drive our project**.

If you appreciate what we’re doing and want a better free and Open-Source financial tool, you should definitely star the project on our github [here](https://github.com/GamestonkTerminal/GamestonkTerminal), join [our Discord channel](https://discord.gg/Up2QGbMKHY), and follow our [twitter account](https://twitter.com/gamestonkt?lang=en). Not necessarily in that order! :)

Have you been following our project and want to join our growing community? Here are a few tips on how to get started:
- Join our Discord and tell us about your experience so far
- Let us know what else you would like to see in the terminal
- You can help to improve our crypto terminal, which is 99% taken care of from our contributors!
- Help us add any features! You don’t know python? This may be your cue to learn with our team!

Much love!
GST Team & Community


---

---
slug: how-i-created-a-bot-in-python-to-participate-in-nft-giveaways
title: How I created a bot in python to participate in NFT giveaways
date: 2021-09-30
image: /blog/2021-09-30-how-i-created-a-bot-in-python-to-participate-in-nft-giveaways.png
tags: ['Python', 'Bot', 'NFT', 'Giveaways', 'Reddit', 'Automation']
description: In this blogpost, I share how I created a bot in Python to automate participation in NFT giveaways on Reddit. The bot simplifies tasks such as upvoting posts, commenting, and opening Opensea links to favourite artwork.
---

<p align="center">
    <img width="600" src="/blog/2021-09-30-how-i-created-a-bot-in-python-to-participate-in-nft-giveaways.png"/>
</p>

<br />

In this blogpost, I share how I created a bot in Python to automate participation in NFT giveaways on Reddit. The bot simplifies tasks such as upvoting posts, commenting, and opening Opensea links to favourite artwork.

The open source code is available [here](https://github.com/DidierRLopes/GiveawayNFTbot).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Lately I’ve been looking into NFTs. I’ve observed that more and more people are trying to innovate and create their own pieces of art. Some of them are impressive, some of them aren’t. But,

> _Beauty is in the eye of the beholder — Margaret Wolfe Hungerford_

<br />

However, in my humble opinion, what distinguishes some art from others, is most of the time not the art itself but the community around it. For example, when everyone starts talking about the ‘new best thing’ you feel more pressure to get involved.

Because of this dynamic, creators are investing in ways to increase their collectibles popularity by building their community. A great example is [ParallelNFT](https://parallel.life/) and the dystopic story that is being created around their cards — in their case, it’s fairly easy to understand that once a big community is formed around such cards, video games, movies and even series are on the table. For the first time ever, we would go from selling collectibles to creating some form of entertainment. A whole new industry in the making.

However, not every digital creator has the resources to create a full concept around their cards. Does this mean that they can’t create a community around it? No. But they must find other ways. One of the most popular ways I’ve seen is through giveaways. Similar to what small clothing brands do to increase their popularity. This is a great tactic in my opinion, since giveaway not only give you a bigger audience (people that participate and re-share content) but it makes the cards have multiple owners. This, as a result, makes the collection more attractive for NFT collectors.

_When demand exceeds supply_, **prices tend to rise.**

And these creators are using Reddit as the platform of their giveaways.

![image](/blog/2021-09-30-how-i-created-a-bot-in-python-to-participate-in-nft-giveaways_1.png)

When scrolling through reddit you will notice that all these posts have certain things in common:
- They ask for an up-vote on the post
- A comment with your wallet address
- To favourite their artwork
- They may also ask to you to join their Discord
- For a follow on their Twitter or Instagram
- If you can retweet or share a story

These are things that take time, and a bot can perfectly do this. Therefore, I wrote a [giveaway NFT bot](https://github.com/DidierRLopes/GiveawayNFTbot) to simplify my work. Now I just sit down and read robot vacuum reviews while the bot: upvotes, comments and opens their Opensea link for me to favourite their artwork.

I’ve already won multiple NFTs with this, which is exciting— you never know where the next [CryptoPunks](https://twitter.com/cryptopunksbot) are at.

There’s actually 1 collection that I particularly like and believe has a lot of potential, it’s called [CryptoCartoonEaters](https://opensea.io/collection/crypto-cartooneaters) and due to the uniqueness of each collectible (only 100 made), I really think it has a great potential. I acquired my favourite cartoon as a kid: Goku Eating a Burger.

![image](/blog/2021-09-30-how-i-created-a-bot-in-python-to-participate-in-nft-giveaways_2.png)

Let me know if you find this article interesting, and if you used the bot as well!


---

---
slug: an-unusual-journey-learning-about-nns-for-a-phd-thesis
title: An unusual journey learning about NNs for a PhD thesis
date: 2021-10-22
image: /blog/2021-10-22-an-unusual-journey-learning-about-nns-for-a-phd-thesis.png
tags: ['PhD Thesis', 'Neural Networks', 'Python', 'Time Series Forecasting']
---

<p align="center">
    <img width="600" src="/blog/2021-10-22-an-unusual-journey-learning-about-nns-for-a-phd-thesis.png"/>
</p>

<br />

An unusual journey of learning about Neural Networks for a PhD thesis. This blog post details the author's experience of assisting in the programming aspect of a PhD thesis, focusing on the study of various models and their forecasting performance.

The open source code is available [here](https://github.com/DidierRLopes/UnivariateTimeSeriesForecast).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

On 14th February of 2019, my previous Maths and Statistics teacher — [Filipe](https://www.linkedin.com/in/filipe-r-ramos-a66242143/) - sent me a messaged because of a Linkedin post I shared about work I was doing in python.

It turns out that Filipe was looking for someone to help him with his PhD thesis, in specific, with the programming side of it. The challenge was to study diverse models (from classical to neural networks) and assess their forecasting performance. Since time series prediction was always a topic that I found fascinating and hadn’t had time to study, I thought this would be the perfect timing to do so.

So from February 2019 onwards, this exciting journey started. I was working full-time so in order to be able to take part in this, I was only sleeping 4/5h a day. I started reading a lot of books and practicing my python coding skills in order to be more helpful. Then around June, we started working together on the code. We had around 2–3h discussions a couple times a week where we would discuss the point of the situation code-wise and where we wanted to be, we kept in touch about this every day.

From the repo, which is open source [here](https://github.com/DidierRLopes/UnivariateTimeSeriesForecast), you can see that we explored: Exploratory Data Analysis; ARIMA and SARIMA; Exponential Smoothing; Deep Neural Network. The final part of this work consisted in an innovative approach to tackle an univariate time series, which you can find [here](https://github.com/DidierRLopes/UnivariateTimeSeriesForecast/blob/master/DNN_ourApproach.ipynb). On top of that, a library of cross-validation for Neural Networks was developed, which is now being used in real data science applications, see [here](https://github.com/DidierRLopes/timeseries-cv).

The work, which took around 1 year to complete, can be divided into 3 distinct phases:

- The **coding** phase lasted around 3 months. I would write the code, test the code and then touch base with Filipe to ensure we were going in the right direction.
- The **tweaking and analysis phase** took around another 3 months. Here, Filipe took the code I had completed and analysed multiple time series with different trends and seasonalities; tweaked different models; trained and validated these; and started interpreting results. In this phase, me and Filipe would discuss the code from a pragmatic point of view, and improve it based on what Filipe wanted to see/analyse. This phase was so intense that Filipe flew out to London twice to meet me, almost over a period of 1 month.
- The **writing of the thesis phase** took an additional 6 months. Here Filipe basically translated the results and analysis seen on the notebook of the thesis, wrote a full theoretical background on the models used and interpreted the applicability of these.

The full work, _“Data Science in the Modeling and Forecasting of Financial timeseries: from Classic methodologies to Deep Learning”_, can be found in [here](https://ciencia.iscte-iul.pt/publications/data-science-na-modelacao-e-previsao-de-series-economico-financeiras-das-metodologias-classicas-ao/82703) or stored in [here](https://repositorio.iscte-iul.pt/handle/10071/22964).

During this time, Filipe was also working full-time as he was a teaching assistant in three different universities. In spite of the adversities, Filipe achieved an impressive approved with “_unanimous distinction_” (maximum classification) from ISCTE Business School, Lisbon, Portugal.

My character waiting for people to join my chatroom to discuss our poster.

![image](/blog/2021-10-22-an-unusual-journey-learning-about-nns-for-a-phd-thesis_1.png)

Last week, at XXV Congress of the Portuguese Statistical Society (SPE 2021), we presented:

- A poster that you can find [here](https://www.researchgate.net/publication/355360806_Forecasting_models_for_time-series_a_comparative_study_between_classical_methodologies_and_Deep_Learning), titled: _“Forecasting models for time-series: a comparative study between classical methodologies and Deep Learning”_
- A presentation that you can find [here](https://www.researchgate.net/publication/355360897_Explorando_o_poder_da_memoria_das_redes_neuronais_LSTM_na_modelacao_e_previsao_do_PSI_20), titled: _“Explorando o poder da memória das redes neuronais LSTM na modelação e previsão do PSI 20”_

![image](/blog/2021-10-22-an-unusual-journey-learning-about-nns-for-a-phd-thesis_2.png)

The poster above was presented at XXV Congress of the Portuguese Statistical Society (SPE 2021).

I started this journey with my previous maths teacher and ended it with a close friend! Excited to see what other articles/publications we’ll be working on together in the future.

PS: The ARIMA/ETS/MLP/RNN/LSTM models learned from this work, consisted the basis of the prediction menu on [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal).

As always, feel free to provide feedback!


---

---
slug: the-start-of-my-machine-learning-journey
title: The Start of my Machine Learning journey
date: 2021-11-07
image: /blog/2021-11-07-the-start-of-my-machine-learning-journey.png
tags: ['Machine Learning', 'Python', 'Data Science', 'Education', 'Self-Learning']
description: The start of my journey into the world of Machine Learning, from learning Python to understanding the underlying mathematics of ML algorithms.
---

<p align="center">
    <img width="600" src="/blog/2021-11-07-the-start-of-my-machine-learning-journey.png"/>
</p>

<br />

The start of my journey into the world of Machine Learning, from learning Python to understanding the underlying mathematics of ML algorithms.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

During my studies at [Imperial College London](https://www.imperial.ac.uk/) - 3ish years ago - I was introduced to the topic of Machine Learning, an area that I had always been interested about.

At that time, not only I didn't know python, as `from sklearn.decomposition import PCA` wasn’t allowed. Therefore, we had to write the PCA (and other) algorithms in Matlab from scratch, which was great because it exposed us to the maths behind each algorithm.

![image](/blog/2021-11-07-the-start-of-my-machine-learning-journey_1.png)

The gif above is from my graduation at Royal Albert Hall with a MSc. in Control Systems with Distinction.

After concluding my thesis (and paper): "[Energy savings from an Ecological Cooperative Adaptive Cruise Control: a Battery Electric Vehicle platoon investigation](https://ieeexplore.ieee.org/abstract/document/8796226)", which was presented at the 2019 European Control Conference in Napoli, I had finally time to focus on Machine Learning topics during my spare time through late hours and into weekends.

I started by doing the famous MOOC **“Machine Learning - Andrew Ng”**. Saying that the course was good is an understatement. I ended up spending a long time on the course as I was taking notes and revising daily; I was still behaving like a university student even without the exam at the end! Not only the theory is really detailed, but the coursework in Matlab allowed me to understand what’s going on under the hood. Given that I was already a heavy Matlab user, due to its usage throughout my entire academic journey, I could focus on the ML section.

After this course, I knew that I had learnt a lot, but I also knew that if I wanted to use ML for real-applications, I’d have to learn Python. Given that I knew Matlab, I choose to start reading a python book that had Data Science application in mind. Hence, I started reading **“Python Data Science Handbook”**. This, along with several hours of practicing on available datasets, has taught me pretty much all I know about Numpy, Pandas and Matplotlib. Although this book also contains a last chapter with ML algorithms, these are rather brief.

> _In my previous job at Nurvv, where I worked as Sensor Fusion Engineer, I developed a python analysis tool that parsed all the raw data from a running session and conveyed that information into meaningful plots. This allowed us to analyse whether a run was successful from the Firmware side of things, and this was critical for our development. This tool was created mainly from the knowledged gathered from the book mentioned above._

<br />

Following this, I was rather confident with my Python skills. Therefore, I wanted to crack-on learning how to use ML algorithms with Python through the beauty of imports. It comes without saying that I had to start from the best-seller **“Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow”**. This book was what I was expecting and more. From time to time, when I’m working on personal projects, I still flick through it. This book also allowed me to develop many more personal projects (most of them public in [my GitHub](https://github.com/DidierRLopes), as I’m a big Open-Source fan — you should know that as I made [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) repository public).

![image](/blog/2021-11-07-the-start-of-my-machine-learning-journey_2.png)

The project that has been my biggest challenge was working with a friend on his PhD thesis entitled _“Modelling and Forecasting of Time-Series: A data science approach that compares classic methodologies with deep learning methodologies”_. Not only interpreting and discussing results but writing the code behind it. S/O to the resources: **“Forecasting: Principles and Practice”** and **“https://machinelearningmastery.com”**. Without these, this work would have been much harder.

Throughout my short journey, I followed many people related with DS. People that I thought that in some shape or form added value through their posts. One of these, was Andriy Burkov. I remember when he started talking about creating the **“The Hundred-Page Machine Learning Book”** and specifically, I remember his Linkedin's poll to select the colour of one of the bubbles for his books' cover. I voted purple; the result was yellow. So, I took the freedom to fix the cover of his book, as you can see below.

![image](/blog/2021-11-07-the-start-of-my-machine-learning-journey_3.png)

My gecko Reidid on “The Hundred-Page Machine Learning Book”​, in order to keep industry standards of ML books with reptiles.

I really enjoyed his book since it can explain everything, while keeping it simple and short. As I learned at University, _Keep It Simple, Stupid_. Also, his book is distributed in a “read first, buy later” principle. This meant that I was able to flick through the content of the book before buying it. Personally, I think this should be adopted more often, at least for technical books.

Finally, last summer, while on holiday in Portugal, I read **“Approaching (almost) any machine learning”**, which I found to be great for people that have read about the theory but were wondering where/how to apply it.

The next ML books in my list are:
- **Deep Learning** — Aaron Courville, Ian Goodfellow, and Yoshua Bengio
- **The Elements of Statistical Learning** — Jerome H. Friedman, Robert Tibshirani e Trevor Hastie
- **Pattern Recognition and Machine Learning** — Christopher Bishop
- **Understanding Machine Learning: From Theory to Algorithms** — Shai Ben-David and Shai Shalev-Shwartz

Let me know if you think these are good books, or if there are others that you’d recommend.


---

---
slug: handing-your-twitter-account-to-your-most-avid-community-member
title: Handing your twitter account to your most avid community member
date: 2021-11-17
image: /blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member.png
tags: ['Community Building', 'Twitter', 'Open Source', 'Gamestonk Terminal']
description: Handing over the Twitter account of Gamestonk Terminal to an active community member and the impact it had on the project's growth and engagement.
---

<p align="center">
    <img width="600" src="/blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member.png"/>
</p>

<br />

Handing over the Twitter account of Gamestonk Terminal to an active community member and the impact it had on the project's growth and engagement.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

When I started [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) I had no idea of the reach and impact it would have. From getting **over 3.5k stars on GitHub on the first single day alone**, to trending [on Reddit](https://www.reddit.com/r/algotrading/comments/lrndzi/cant_afford_the_bloomberg_terminal_no_worries_i/) and receiving overwhelming feedback, to receiving a message from an ex-colleague based in Switzerland about my name being [top 1 on Hackernews](https://news.ycombinator.com/item?id=26258773). As if this wasn’t enough, a couple of days later the project got featured by [VICE Magazine](https://www.vice.com/en/article/qjp9vp/gamestonk-terminal-is-a-diy-meme-stock-version-of-bloomberg-terminal) and [Daily Fintech](https://dailyfintech.com/2021/02/25/never-underestimate-bloomberg-but-here-are-5-reasons-why-the-gamestonk-terminal-is-a-contender/).

As a result, my social life was impacted and had little time to even cuddle my puppy, due to the amount of feature requests, issues… the usual somehow ungrateful life of an open-source maintainer… I’m not complaining though, as I live for this.

![image](/blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member_1.png)

Moving forward a couple of weeks, it became clear to myself that I was building a strong community around what can/will/should be a leading product in the emerging fintech industry and Internet 3.0. Therefore, I knew that github issues and discussions wouldn’t be enough to interact with all members of the community, so Discord turned out to be the best option going forward (let’s be honest: mostly because of the convenience that Discord offers to share memes, feel free to check my creations on [our Discord](https://discord.gg/2KnVnkDTxM), you can thank me later).

My next rookie mistake was thinking I could use Discord announcements and @ everyone, as a means for updating the community on new features. Being the #1 investment research free and open-source project on github gets you several PRs a day being merged, so in all the fairness the announcements were recurrent with constant several new features. You can check my [one hour live programming stream](https://www.youtube.com/watch?v=9BMI9cleTTg) of adding a feature to the terminal.

![image](/blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member_2.png)

This is when I realized that Discord wasn’t the best place for this type of communication. I needed a platform where I could share these features ad-hoc and that only alerted users who wanted to be up-to-date with our latest features. And this is when I created our [Twitter account](https://twitter.com/gamestonkt), @gamestonkt.

Reviewing the history of our Twitter feed, you can see that this is exclusively what our handle was used for. It just shared new features every day. It felt like I was always playing catchup to the growing number of features piling up in the queue waiting to be announced on Twitter. With the project already having **over 500 features** in less 1 year, this inevitable outcome would be a surprise to no one. (**yup, I repeat, over 500**).

![image](/blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member_3.png)

However, I felt like **it missed personality**... With time being a limiting factor — time was more efficiently used improving the terminal — the public facing demonstrations were a lower priority. When you believe this much in a product, the product ends up speaking for itself.

> _“If you build it, they will come” — Field of Dreams_

<br />

It then occurred to me, why am I handling our Twitter? Why not leave this up to one of our most avid and vocal users that has been with project since beginning?

As Jim from “The Office” would do, let’s do a PROS & CONS table.

### Pros

- The user represents the community that the twitter content is targeted at.
- The user is an active daily user and will help to demonstrate features in the terminal.
- The user is keen on learning the ins and outs of the product.
- This user is not only a user anymore but a friend given his interaction with the maintainers.
- Lastly, I get to spend time doing what I enjoy: coding and meme content on our Discord.

### Cons

- The user finds out my mother’s maiden name and the name of my first pet.

This is really a no brainer the more you think about it. I think it depends a lot on the type of people you have in your community and how confident you are on this individual .

We were lucky, because we had the **perfect fit**: an active Discord user **@Danglewood**, who had built an engaged audience, generating over 130K+ in Reddit karma over Q2 2021. It was clear that **@Danglewood** was having an impact on driving traffic and user engagement by posting data and his personal research with screenshots of Gamestonk Terminal.

In the future, **our report feature will allow easy sharing of this information**, I already can’t wait for this. Through a combination of humour and truths, he was engaging the audience’s curiosity by providing them with ways to filter out the ever-present noise within stock market information.

It made sense to bring this approach to [our Twitter](https://twitter.com/gamestonkt) feed which has since transformed and now offers insights, educational nuggets, and data as well as presenting new features. The end result speaks for itself!

![image](/blog/2021-11-17-handing-your-twitter-account-to-your-most-avid-community-member_4.png)

On your end, what is your opinion? And why do you 100% agree that this was the best decision?


---

---
slug: sector-and-industry-analysis-gamestonk-terminal
title: Sector and Industry Analysis — Gamestonk Terminal
date: 2021-12-02
image: /blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal.png
tags: ['Gamestonk Terminal', 'Sector Analysis', 'Industry Analysis', 'FinanceDatabase', 'Open Source']
description: The development journey of a new Sector and Industry Analysis feature for Gamestonk Terminal, integrating the FinanceDatabase package.
---

<p align="center">
    <img width="600" src="/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal.png"/>
</p>

<br />

The development journey of a new Sector and Industry Analysis feature for Gamestonk Terminal, integrating the FinanceDatabase package.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The end-to-end story of developing a new **Sector and Industry Analysis** for [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) from scratch.

On the 13th of October, [Jeroen Bouma](https://github.com/JerBouma) (a ALM advisor and python enthusiast) reached out in order to integrate his [FinanceDatabase package](https://github.com/JerBouma/FinanceDatabase) into [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal).

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_1.png)

After having a call with Jeroen to bounce ideas, it was clear that our terminal needed such capability to be even more powerful (as if **over 500 features** already and counting didn’t already do the trick eheh). However, at the time I was too busy to work on the concept so I asked Jeroen if he could sketch something up on a jupyter notebook.

Within the following week, Jeroen sent a Jupyter notebook explaining the FinanceDatabase module and what we could have in a Sector and Industry analysis.

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_2.png)

In addition, he also mentioned his [PassiveInvestor package](https://github.com/JerBouma/ThePassiveInvestor), and ended up [implementing it on his own in Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal/pull/857)! This was a great addition, as it strengthened our **ETF context** and provided a slick Excel report for the Excel fans out there! See his [LinkedIn post](https://www.linkedin.com/feed/update/urn:li:activity:6859887432532291584/) on the experience.

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_3.png)

...

Forward to last weekend (1.5 months later), I had a free Sunday afternoon so started working on the development of this menu. I started by thinking about what would make this menu more flexible and powerful.

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_4.png)

These were my thoughts about what it needs:

- **Several filtering parameters** as the number of companies in the database is pretty huge with 155.705 tickers, 16 sectors, 242 industries, 111 countries and 82 exchanges. These were the filters selected: Country, Sector, Industry, Market Cap and Flag to include/exclude international exchanges.
- **To be able to do some statistics on the sector**, industries and countries (e.g. companies per sector/industry with a specified country and market cap) which allows users to better understand companies landscape of a sector and industry.
- **To get the financials of the companies that fall under that filter subset** (e.g. return on assets, quick ratio, debt to equity), and then compare these in order to get the best performers.
- Since one of the previous financials isn’t enough to understand which company would be best to invest in, I wanted the filtered companies to have the capability to jump onto the comparison analysis menu so you could get all the capabilities of comparing historical price data, volume data, income/balance/cash flow, sentiment, or even technical indicators.
- If in the stocks context I had Tesla loaded, I wanted to go into this sia menu and get all the filtering parameters to be ready to filter for companies similar to Tesla in terms of (Sector, Industry, Country and Market Cap).

By Sunday night, I created the [pull request for this](https://github.com/GamestonkTerminal/GamestonkTerminal/pull/995). Due to the due diligent reviews performed by the main contributors of the project, the menu got a lot of improvements. Some of them were:
- Do not display companies that account for under a certain threshold (1%) and therefore sum them in an “Others” slice.
- Allow to export all the data as a table.
- After filtering and getting financials, save the data for faster data retrieval if the same filters are used.
- Minor bug fixes.

After a lot of comments and feedback from the main maintainers, and everyone being happy with this first iteration, the PR got merged. In fact, one of the main maintainers found a hidden gem while testing it.

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_5.png)

In the meantime, I’ve been in contact with Jeroen about adding some more capabilities to his FinanceDatabase package so that everyone could benefit from them. Some examples are:
- When an industry is selected, the corresponding sector should be automatically filled.
- If I select a country and a market cap for filtering, my sector choices should be bounded by what exists within those.
- I should be able to query about companies landscape in terms of a country. E.g. I want to understand what countries have the most large cap companies within the Financial Services sector.

This would not only make the FinanceDatabase a more powerful Package, which would in turn benefit Gamestonk Terminal sia menu, and ultimately our thousands of users!

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_6.png)

This is an example of how the Sector and Industry Analysis menu looks (as a bonus I show how you can go into the Comparison Analysis menu):

![image](/blog/2021-12-02-sector-and-industry-analysis-gamestonk-terminal_7.png)

Next time you know, it all starts with an e-mail. At Gamestonk Terminal we are on a role to have the best investment research terminal, and hope this story reflects it.

Try it now, it’s free. ❤️


---

---
slug: gamestonk-terminal-ux-features
title: UX/UI is better than features
date: 2022-01-06
image: /blog/2022-01-06-gamestonk-terminal-ux-features.png
tags: ['Gamestonk Terminal', 'UX/UI', 'Software Development', 'Teamwork']
description: Gamestonk Terminal's UX/UI features and the teamwork behind their implementation.
---

<p align="center">
    <img width="600" src="/blog/2022-01-06-gamestonk-terminal-ux-features.png"/>
</p>

<br />

Gamestonk Terminal's UX/UI features and the teamwork behind their implementation.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

**Features attract users, UX/UI conquers them ⚔️**

Throughout month of December, me and 3 of the most active maintainers of [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) had a meeting where we discussed shifting our focus from adding features, to improving the terminal UX/UI to make it even more attractive. The main outcomes of these meeting were:

1. Relative and Absolute menu jumping, e.g. if i’m in crypto/ta and want to go to stocks/ta I can do:

   a. Absolute: `/stocks/load tsla/ta`

   b. Relative: `../../stocks/load tsla/ta`

3. Scripting feature. You can now interact with the terminal through a sequence of commands, e.g.: `stocks/disc/ugs -l 3/gtech/active`.

4. `reset` command everywhere to allow for faster development as it exits from the terminal and comes to the same menu running new terminal code and its API keys.

5. Auto-completion in commands with choices.

6. When misspelling a command name, if it’s similar enough that the terminal recognises the right command, it will replace it, to speed up interaction.

<br />

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_1.png)

6. Running a `.gst` job, like `python terminal.py scripts/test_stocks_disc.gst` which allows to run a sequence of commands of the terminal. In the future we can take advantage of this for integration tests. The user can build their own daily routines to speed up the investment process.

<br />

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_2.png)

Now, I know what you’re thinking. This is a massive improvement over the terminal usage up until now, and that’s a **LOT** of code changes. Which is very much true, to be specific, this engineering effort resulted in:

> **370 files changed with 44,875 additions and 18,463 deletions**

<br />

And you may be wondering how long did this take us to do. Nope, it wasn’t months but…

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_3.png)

**1 week. Yup, a single f*king week.** You can see that it was finalised with these PRs ([#1049](https://github.com/GamestonkTerminal/GamestonkTerminal/pull/1049), [#1041](https://github.com/GamestonkTerminal/GamestonkTerminal/pull/1041), [#1048](https://medium.com/@dro-lopes/gamestonk-terminal-ux-features-f9754b484919#1048)).

In that week we split work, did pair programming, we called each other to discuss better implementation practices, we changed the architecture 2/3 more times… On top of that, I was feeling overwhelmed with the stocks menu, I clearly underestimated how many features we have (how naive…), so the 3 other maintainers jumped on it and helped me out. In 3 or so years of software engineering, this was** teamwork like I’ve not felt before**.

That weekend I was so happy as we accomplished this task that I think I didn’t even work on the terminal that Sunday! Doesn’t happen often these days!

However, as a good friend of mine told me:

> _**“The entertainment industry hasn’t found yet something more appealing than developing code towards a product I believe in and with people I like”**_

<br />

I still think about this often, and this is what I tell my girlfriend, to explain why I’m coding and not playing Mario Kart 8 Deluxe with her. (the fact she always beats me at it also may be considered as a factor 🤣).

You may be thinking this is a one off, the reality is that **it isn’t**. Another example can be seen in [this blog post](https://dev.to/northern64bit/aspiring-16-year-old-quant-developer-contributing-to-open-source-application-16k4). This goes over the story of the development of our discord bot where it all started from a message from a **16yo contributor that wants to become a quant**. He wanted to not only improve his python skills with us but also bring the terminal features to a bigger audience. Working with us in an open-source project is helping him towards achieving his life-goal dream.

While I write this post another contributor, finishing his CPA, is working on [improving the code resulting from that UX effort by creating a base class](https://github.com/OpenBB-finance/OpenBBTerminal/pull/1141) so that new developers can add controllers much easily (he estimates a reduction of 11% of codebase size based on “napkin maths” as he puts it).

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_4.png)

While user experience is critical, so is user interface. And that is why our next engineering effort will be around it. We already have something in the works in [this PR](https://github.com/GamestonkTerminal/GamestonkTerminal/pull/1140), where we can draw lines and write text! Almost like TradingView (almost… 😬).

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_5.png)

So, keep on the lookout because 2022 is gonna be a big year for us!! 🦋 🚀

Ohh, before I say thanks for the read and all that, it’s also worth mentioning that there’s a PR in the queue for a new context called “**alternative data**”, which already has a **COVID menu** to factor that data into account on your investments.

![image](/blog/2022-01-06-gamestonk-terminal-ux-features_6.png)

_PS: The blue text is because we are transitioning towards [rich package](https://github.com/Textualize/rich) which gives a lot more freedom when it comes to improving our user interface._

<br />

Thanks for your read, and if you enjoy Gamestonk Terminal, please reach out to [our discord](https://discord.gg/ptYabd8w) to say thank you, or ideally: for **@terp340** to change date format to dd/MM/YYYY — **the only correct one**!

Happy 2022 with lots of love ❤️


---

---
slug: meet-the-most-advanced-investment-research-platform
title: Meet the most advanced investment research platform
date: 2022-03-21
image: /blog/2022-03-21-meet-the-most-advanced-investment-research-platform.png
tags: ['Investment Research', 'Gamestonk Terminal', 'Automation', 'Routines']
description: Meet the most advanced investment research platform. This blog post introduces Gamestonk Terminal, an advanced investment research platform, and discusses its features and automation capabilities.
---

<p align="center">
    <img width="600" src="/blog/2022-03-21-meet-the-most-advanced-investment-research-platform.png"/>
</p>

<br />

Meet the most advanced investment research platform. This blog post introduces Gamestonk Terminal, an advanced investment research platform, and discusses its features and automation capabilities.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Several people have asked me why [Gamestonk Terminal](https://github.com/GamestonkTerminal/GamestonkTerminal) doesn’t have release versions, and the main reason is because at the pace the team codes and the rate that new features / bug fixes appear it doesn’t yet makes sense to do so.

To give you an example, recently I shared the first **DEMO of what the terminal can do**, and I mention about our “routines” automation concept.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/fqGPK8OVHLk?si=Xu7rtb-0iHmTDdjj"
        width="800"
        height="400"
    />
</div>

<br />

One week later, using the latest version of the terminal, on top of that simplistic routine type you are able to:

1. Provide variable input variables when calling the routine using $ARGV[i] (I used Perl convention here eheh)
2. Execute routines from within the terminal directly
3. Add comments to the routines so the process is more clear
4. Exporting data to a folder of choice is now possible
5. Exporting a file with a pre-defined name is now possible
6. Allow for the first line of the routines to be selecting a folder to export ALL the data

<br />

See below a 1 minute video of what these routine automated scripts look like!

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/pH0srojpv8Q?si=778fQVB-YqNdxDL3"
        width="800"
        height="400"
    />
</div>

<br />

Reach out if you have any question to the team, there’s very little we can’t do!

This is the way!


---

---
slug: how-i-created-the-best-discord-meme-bot
title: How I created the best discord meme bot
date: 2022-04-09
image: /blog/2022-04-09-how-i-created-the-best-discord-meme-bot.png
tags: ['Discord', 'Meme Bot', 'Open Source', 'Community Building']
description: In this blog post, I share my journey of creating a Discord meme bot, the role it played in building a vibrant community around our open source project, and how you can add your own memes to the bot.
---

<p align="center">
    <img width="600" src="/blog/2022-04-09-how-i-created-the-best-discord-meme-bot.png"/>
</p>

<br />

In this blog post, I share my journey of creating a Discord meme bot, the role it played in building a vibrant community around our open source project, and how you can add your own memes to the bot.

The open source code is available [here](https://github.com/DidierRLopes/discord-memes).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Background

Over the past few weeks, life has been very chaotic on my end, mostly due to the announcement of [OpenBB](http://www.openbb.co/) last week which you can read the full story on [here](https://openbb.co/blog/gme-didnt-take-me-to-the-moon-but-gamestonk-terminal-did).

When I started [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal), all my focus was on building, building and building. Once I made the project open source and contributors started to appear, I slowly saw my time shifting **from building a product to building a community**. This community ultimately would end up building the product, but from my end, I need to be able to pass on my passion to the project and vision.

Developing features for the terminal only took me a couple of minutes, whereas the connection with the community is a long-time game. You don’t become close with someone you’ve never met within couple of minutes. Instead you need to put effort into the relationship and **consistency is key**.

The community on our Discord was growing day by day. And so was my relationship with the people in it. The truth is, we were not only sharing insights about the platform, but were laughing and bonding together whilst building it. **And memes/gifs are a big part of these interactions.**

For people who know me, they know how much I love memes and how I can always create memes for every situation (honestly, all the time I spent on Instagram is finally paying off).

Although I believe that we have one of the most exciting open source projects going on, I also strongly believe that our fun culture (i.e. memes) is what makes contributors want to work in this particualr environment. **Building the future of investment research can be fun and this is what we’re proving.**

At this stage, I think I’ve spent more time interacting with people than I have working on the platform. The funny thing is that **the platform is 10x better than what it would be if I was working on my own**. Creating a strong community pays off and this is why since the start I was having calls with literally everyone to help them install our platform. Today, most of the team at OpenBB was met on Discord whilst working on the platform. **I didn’t need any interviews, they weren’t candidates anymore but people that I enjoyed to work with** and wanted on the team.

Sorry for the background story, but it was important to me to explain why I worked on this. **The interesting part of the article starts now.**

## Development

**The idea of Discord Memes is to avoid to open [imgflip](https://imgflip.com/) everytime I wanted to add text to a meme.** Personally, I love the gifs available through Discord but I think a meme with text is much more powerful (and funny).

When I started coding this here and there, I wanted the code to be super straightforward so it was very simple and fast to add a new meme to the pool. And so I did.

The process to add new memes is incredibly easy. Go to the [project](https://github.com/DidierRLopes/discord-memes) and star it for starters (also [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) since you’re at it). Then,

1. Add the meme you want to the `memes/` folder, e.g. `spongebob.jpg`

2. Then create a function with the same name of the image (e.g. `spongebob`) with the following format

<br />

```python
@create_and_send_meme()
def spongebob(inter, text: str = None, _=None):
    if text:
        _.text(
            0.5,
            0.2,
            "\n".join(wrap(''.join(choice((str.upper, str.lower))(c) for c in text), 40)),
            fontsize=20,
            color="white",
            alpha=0.9,
            horizontalalignment="center",
            path_effects=[pe.withStroke(linewidth=4, foreground="black")]
        )
    return _
```

3. That’s it.

<br />

**Note:** I created a python decorator `@create_and_send_meme()` that basically abstracts all the memes created and picks up the image on memes with the same name of the function. This way, the person adding a meme just needs to focus on the text on the image, i.e. it's location, size, where it wraps, colours and alignment.

I used a playground.ipynb notebook, which is also on the repo, to increase the speed of the text placement on each of the memes I added.

This is how it looks,

![image](/blog/2022-04-09-how-i-created-the-best-discord-meme-bot_1.png)

OR

![image](/blog/2022-04-09-how-i-created-the-best-discord-meme-bot_2.png)

As you can see, our Discord server just stepped up. [Join us](https://openbb.co/discord) to try out the meme bot, build the future of investment research or just to say hi.

We’ll be waiting for you. 🦋


---

---
slug: looking-for-a-new-tattoo-openbb-has-you-covered-literally
title: Looking for a new tattoo? OpenBB has you covered… literally.
date: 2022-04-21
image: /blog/2022-04-21-looking-for-a-new-tattoo-openbb-has-you-covered-literally.png
tags: ['OpenBB', 'Marketing', 'Tattoo', 'Brand Awareness']
description: Exploring unconventional ways to increase brand visibility, OpenBB's co-founder gets a tattoo of the company logo. This blog post discusses the thought process behind this unique marketing strategy.
---

<p align="center">
    <img width="600" src="/blog/2022-04-21-looking-for-a-new-tattoo-openbb-has-you-covered-literally.png"/>
</p>

<br />

Exploring unconventional ways to increase brand visibility, OpenBB's co-founder gets a tattoo of the company logo. This blog post discusses the thought process behind this unique marketing strategy.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

When [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) started last year, I went from having your typical career as a Software Engineer to becoming a co-founder & CEO of a C-Corporation overnight. One thing that I’ve really learnt from this change, is I can no longer code for 12–16 hours a day straight as my role now involves so much more than this… and most interestingly, one of those things is marketing.

During Easter in Lisbon, I was thinking about how to increase the visability of [OpenBB](https://openbb.co/). _An investment research platform for everyone, anywhere_. Seems self-explanatory and something most of us would relate to, but the problem is reaching a bigger audience.

Due to [our $8.5M funding](https://openbb.co/blog/gme-didnt-take-me-to-the-moon-but-gamestonk-terminal-did) we have money in the bank, which means we can afford to do some ads campaigns. However, I very much dislike the traditional type of ads, whether that is with Google, Instagram, Twitter or YouTube. Particularly YouTube ones, when I see an ad there I immediately think less of the product being advertised due to how intrusive these are.

That’s why I started thinking of ways to share our OpenBB brand in a non-intrusive way. In fact, I went one step further and started thinking when I personally would welcome ads.

Funnily enough, the first thing that came to my mind was when I go to the bathroom without my phone. Although there’s no ads on the back of shampoos/shower gel/soap/spray, I would very much welcome them.

![image](/blog/2022-04-21-looking-for-a-new-tattoo-openbb-has-you-covered-literally_1.png)

It’s not like knowing the %s of ingredients that makes up cleaning products has a lot of use cases…

This brought me to the conclusion that I would only welcome ads if I was bored and didn’t have anything keeping me “too busy”. This immediately made me think of London underground ads (the most effective type of DOOH imho). I always read those ads. The main reason being that I don’t have WiFi underground and the noise is too loud to listen to a podcast. Hence, I imagined the underground looking like:

![image](/blog/2022-04-21-looking-for-a-new-tattoo-openbb-has-you-covered-literally_2.png)

When I checked for the prices, I was looking at a marketing campaign for a couple of days in a couple of stations costing over 5 digits, which is quite expensive for the short time-span.

Therefore, I started to think of cheaper alternatives that yielded a better ROI. The next thing that passed through my mind was wearing OpenBB swag (yet to be revealed, [subscribe to our newsletter](https://openbb.co/newsletter) to know more). However, I feel like nowadays everyone has a t-shirt with a different logo and these aren’t as noticeable as before — at least that’s my perspective.

This lead me to think: **What about a tattoo?** It’s a similar concept than OpenBB clothes but more powerful. In addition, when wearing OpenBB clothes with a visible tattoo, this will create a “curiosity” effect since the symbol is repeated (clothes and tattoo). In addition, I’ve not come across anyone using their body to express their brand.

Later that day I booked a tattoo slot, paid 100 euros, and got the OpenBB logo on the back of my arm as shown below,

![image](/blog/2022-04-21-looking-for-a-new-tattoo-openbb-has-you-covered-literally_3.png)

I will let you know on my socials how many people ask about this tattoo over the course of my life.

And if you like [our logo](https://www.openbb.design/9242dc28c/p/809a44-logo) and [our values](https://www.openbb.design/9242dc28c/p/91bbcc-our-values), OpenBB will pay you for the tattoo.

**One things for sure, now I can definitely put the gym membership as a company expense since I’m a walking billboard 😄**

The first walking/running/coding/eating/drinking OpenBB billboard.


---

---
slug: remote-flexible-work-salary
title: Remote + Flexible work >> Salary
date: 2022-05-03
image: /blog/2022-05-03-remote-flexible-work-salary.png
tags: ['Remote Work', 'Flexible Hours', 'Work Life Balance', 'Productivity']
description: This blog post discusses the importance of remote and flexible work hours, and how it can significantly improve work-life balance and productivity.
---

<p align="center">
    <img width="600" src="/blog/2022-05-03-remote-flexible-work-salary.png"/>
</p>

<br />

This blog post discusses the importance of remote and flexible work hours, and how it can significantly improve work-life balance and productivity.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I was thinking about remote + flexible hours, and I don’t think I would ever work for a company without these. At least by choice 🙃

I mean, who would tell Morty and Sum Sum that I wouldn’t be at home to play?

**I’m a strong believer that work should wrap around your lifestyle and not vice-versa.**

On average, a person works 40 hours a week and sleeps 8 hours a day. This means that out of 168h per week you have 72h for personal time. In terms of percentage we have: 24% for work, 33% for sleep, and 43% for personal time.

So how come most people have almost 2x as much personal time compared to work time and they still feel like they are in this 9–5 rat race and their life revolves around work?

Well, here’s the 4 scenarios as I see it…

**1. The work is not remote (and not flexible).**

  - If we account for the commute and stress associated with, personal time gets directly transferred into work time.
  - E.g. with a daily 2 hour commute Mon-Fri, which is very typical, this means that your personal time is divided into 30% for work and 37% for personal. This isn’t event including the part where you have to prepare to leave the house, and the tiredness resultant from the commute.

**2. The work is remote but not flexible.**

  - This is much better than the previous. But it’s still not good enough. The argument here is not due to absolute time but performance and state of mind.
  - Life is not straightforward. We, as individuals, are very different between ourselves. Our bodies, mind, brain, relationships, … work very differently. By not being flexible on the working hours you are basically ignoring all of that diversity and grouping everyone into a single 9–5 + Mon-Fri category.
  - _The “ironic” part is that most companies promote diversity and don’t think about this. Which just shows that the diversity topic has become very much a marketing vehicle._
  - In my case, I’m a night owl, I don’t usually wake up too early, because I am much more productive when I stay awake until 3/4 am. If I have to wake up early because someone decided that 8:30am was the time that everyone needed to “check in” you are basically not getting the most out of me.
  - One may wonder, well, this is a company problem because they are paying for an employee that is not performing as much as they could. Unfortunately, that’s not true, it’s a much bigger problem to the employee. This is because when an employee excels at a job they tend to have a much happier life which in turn increases performance, which increases happiness, and so on and so forth.

**3. There is no mention for not remote but flexible because, in my opinion, that makes very little sense.**

**4. Now, let’s imagine the scenario where the work is remote and flexible.**

  - This is where it gets interesting. When we fall on this scenario your job perspective changes drastically. This is because at this point you put yourself first and can define your own priorities while having a pool of time to get a job done at your own time.
  - E.g. you can plan activities with friends, do exercise, meditate, … whatever suits your lifestyle. Which will give you a boost of energy to perform even better at your job. On top of this, you don’t need to squash the work within Mon-Fri, once you are in this flexible regime you may use the weekend to your advantage. Flights at 20 Euros on Tuesday to come back Thursday? Fine, I’ll work during weekend to make up for this time
  - There are people that love a 9–5 Mon-Fri schedule and that is fine. For those it means that the 9–5 Mon-Fri system implemented got it right. In fact, I would argue, that they are still wrapping work around lifestyle, it’s just that their lifestyle is working 9–5 Mon-Fri and enjoying time outside these hours.

The downsides of this fully flexible work are:

- Interaction with coworkers and communication. But with us going global due to remote work, it doesn’t really matter, since the 9–5 hours of different countries would already lead to this problem
- Tracking employee timesheet. I think that a company shouldn’t track an employee timesheet because results are far more important than working hours, and can be just as measurable.

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

All of this to say that at OpenBB we have:

- **REMOTE WORK:** As long as you are in a location with internet access, we are not worried. This allows us to build a strong diverse team with different backgrounds and ideas.
- **FLEXIBLE HOURS:** We believe that your work should wrap around your lifestyle and not vice-versa. As long as you excel, you will not be asked why you woke up at noon.
- **UNLIMITED HOLIDAYS:** Who has time to track holidays when building such an exciting project? We trust in our people to manage their own PTO and keep performing at the highest level.

AND this is how I sleep at night having no idea at what time John logged in and out:

![image](/blog/2022-05-03-remote-flexible-work-salary_1.png)

Ohhh, and we’re hiring!

If you provide a referral to someone that ends up joining OpenBB, I will transfer you $100 as a token of appreciation 🦋


---

---
slug: web3-symbols-and-community
title: Web3, symbols and community
date: 2022-06-28
image: /blog/2022-06-28-web3-symbols-and-community.png
tags: ['Web3', 'Community', 'Decentralization', 'Blockchain', 'Smart Contracts']
description: This blog post discusses the importance of strong communities in the Web 3.0 space, the role of decentralization, and how voting frameworks based on smart contracts can empower users.
---

<p align="center">
    <img width="600" src="/blog/2022-06-28-web3-symbols-and-community.png"/>
</p>

<br />

This blog post discusses the importance of strong communities in the Web 3.0 space, the role of decentralization, and how voting frameworks based on smart contracts can empower users.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

If you have been paying attention to the Web 3.0 space, you should have realized that most of the projects in the space rely on strong communities.

### Why on Web 3.0?

On a centralized concept (Web 2), there is usually a regulatory entity that decides whether something is True or False on a project/product. This means that there’s a single centralized company responsible for making a decision and users must trust that this entity is acting on their best interests.

Furthermore, the users do not stand to win anything whether the decision is True or False. They may identify more with one of the outcomes, but there is no personal incentive to the user. Even if a user can relate with the outcomes they never feel a sense of belonging, as deep down they are aware that their opinion is not being taken into account.

On a decentralized concept (Web 3), the story is the very different. A decentralized community is responsible for deciding the True or False, based on a voting framework defined a-priori. This means that the group of users, based on smart contracts executed on the blockchain, can vote on a particular decision. **This is where the importance of a strong community kicks in.**

On Web 2 the users must trust that such entity is acting on user’s best interests. That trust, on Web 3, occurs in form of a strong community. The best way for a user to trust the decisions of a group of people is to know that a group shares the same values and has incentives towards the success of the same project/product.

**In fact, I believe that in general when these votes occur, the more unanimous the decisions are, the stronger the community is.**

> **NOTE:** Although Web 3 communities are stronger than Web 2 ones, I believe that when something goes wrong the Web 3 communities break faster as they don’t have a common enemy due to the decentralized concept (e.g. LUNA debacle). On the other hand, Web 2 communities can “hold” onto the fact that their common enemy is now the entity that they trusted to act on their best interests (e.g. Robinhood vs wallstreetbets).

### Why build strong communities?

_The Web 3.0 concept doesn’t only benefit from strong communities but is built on top of it._ For worldwide adoption in products/projects/companies the space need strong communities.

Why does money have value? Because people believe that they will be able to exchange it for goods/services in the future. Why do people believe that? Because they trust the entity that is managing such currency.

Analogously, for a digital asset to have value, people need to believe that they will be able to exchange it for goods/services in the future. Since there is no entity to trust, people need to believe that the community will believe that a certain digital asset has value. This belief exists because there are incentives (usually financial or status) for its members.

Once this happens we enter into the law of supply and demand where the value of digital asset goes up as there is either less supply or more demand.

These communities can easily be found on CT or Discord/Telegram servers.

![image](/blog/2022-06-28-web3-symbols-and-community_1.png)

### How are strong communities created?

If we learn from history, we see that the most loyal and bigger communities **always recurred at symbology** to achieve such, some examples: sports clubs, religion, countries, clans, societies, …

The truth is that we humans constantly seek this sense of belonging (or are afraid of being alone). When we see multiple people on social media utilizing the same symbols to represent their beliefs, we want to be part of that group, of that community.

This can be seen over and over again on Web3, particularly in CT:

- Changing the eyes’ color of your twitter’s pfp which represents being bullish on crypto (usually red for BTC and blue for ETH)
- Emojis after the username
- Utilizing the NFT you acquired from a collection that you believe in
- Adding a “.eth” at the end of the username

![image](/blog/2022-06-28-web3-symbols-and-community_2.png)

### Why does this matter?

Companies outside of the Web 3.0 space will start picking up on this to build stronger communities and have a stronger identity (e.g. Notion and their employees pfp on social media). This is even more relevant for open source companies (Web 2.5 if you will), which rely on their communities to build a successful company (e.g. Hugging Face 🤗 ).

> _I believe that companies will start thinking about the emojis that their community can use while coming up with the name of the brand and logo._

<br />

As for OpenBB, we are a fintech open source company that focuses on providing better investment research for everyone, anywhere. The finance sector we are in is composed of multiple players that have been on the top of the industry for decades. We come in with a radical different approach, bottom-up.

> _Being open source for us is not a choice but a need if we are to disrupt traditional investment research platforms with years of head start._

<br />

Once we knew that we wanted the logo to be extracted from the “BB”, it was immediate that the butterfly emoji (🦋) would be used. Furthermore, a butterfly is a metaphor for transformation, which in our context, represents OpenBB Terminal allowing each investor to evolve and finally fly (i.e. achieve financial freedom).

In order for our users to start relating to the butterfly emoji (🦋) with our brand we have several cues:

- On the landing page

![image](/blog/2022-06-28-web3-symbols-and-community_3.png)

- Official social media channels
- Our team members use it in their socials

![image](/blog/2022-06-28-web3-symbols-and-community_4.png)

- On the OpenBB Terminal as the default flair,

![image](/blog/2022-06-28-web3-symbols-and-community_5.png)

And even to replace the asterisk (*) when inserting the password to enter our OpenBB Bot platform, **because details matter.**

![image](/blog/2022-06-28-web3-symbols-and-community_6.png)

And that is what we are doing at OpenBB to build a stronger community? Do you have any other tips/tricks? Feel free to share them!

Hope you enjoyed this post and as always, am looking to hear feedback!

_PS: I’d like to take this chance to say that our OpenBB Bot launch will occur in the coming weeks, you won’t have to wait much longer 🦋_


---

---
slug: how-i-became-ceo-of-openbb
title: How I became CEO of OpenBB
date: 2022-08-14
image: /blog/2022-08-14-how-i-became-ceo-of-openbb.png
tags: ['python', 'publishing', 'package', 'pypi']
description: This post talks about my story of becoming the CEO of OpenBB, the company behind the fastest growing open source project in finance.
---

<p align="center">
    <img width="600" src="/blog/2022-08-14-how-i-became-ceo-of-openbb.png"/>
</p>

<br />

This post talks about my story of becoming the CEO of OpenBB, the company behind the fastest growing open source project in finance.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Both my parents are Portuguese and emigrated to Switzerland for better conditions. This is where my brother and I were born. We moved back to our small hometown in Portugal when I was 8 years old.

When I was 21 years old I moved to London to pursue my MSc in control systems at the Imperial College. I also joined a semiconductor company as a Software Design Engineer.

![ezgif com-optimize (5)](/blog/2022-08-14-how-i-became-ceo-of-openbb_1.png)

In my spare time I learned Python so I could become more proficient in machine learning and artificial intelligence. When my mathematics professor learned of my interest in Python he challenged me to write the [code behind his PhD thesis](https://github.com/DidierRLopes/UnivariateTimeSeriesForecast) on "_Data Science in the Modeling and Forecasting of Financial Time Series: from Classic methodologies to Deep Learning_" which combined open source, ML/AI and finance. This was when I first started to realize my passion for financial data.

![image](/blog/2022-08-14-how-i-became-ceo-of-openbb_2.png)

I was inspired by books like "_Rich dad Poor dad_" which allowed me to understand that the only way to build true generational wealth is through investing. Now that I started to accumulate more savings through my professional pursuits, and with my finance interest increasing from my thesis work, I wanted to invest my own capital.

What I learned was that investing was a highly cumbersome process. Unlike coding where the tooling (e.g. VSCode) is optimized for efficiency and allows us to automate a lot of processes, investing was highly inefficient and impossible to automate.

I was spending hours doing my own investment research (multiple tabs open researching several different sources on a ticker, screenshot the data to put on a document or share with friends, write my thoughts, and repeat), and this had to be done for every single ticker at different instances of time otherwise the data would become irrelevant.

I learned from Reddit users how they gained insights and performed due diligence. I quickly realized their "workflow" was just as inefficient as mine. I concluded that the only aspect of research that should require user input is the interpretation. As far as I was concerned, all data gathering should be automated.

I began investigating potential investment research tools that allowed automation and couldn't find any, not even the mythical $24k/year Bloomberg terminal. I looked for platforms on GitHub where I could build on top of with no success.

During Covid Christmas break, the flight to visit my parents was cancelled, so I ended up staying at home and sketching/building what would become my own investment research platform. I noticed that there were hundreds of data providers offering free data tiers where the data provided didn't correlate with each other. If I wanted access to paid datasets or more requests per minute it would be as simple as to upgrade my API key to a paid plan.

![image](/blog/2022-08-14-how-i-became-ceo-of-openbb_3.png)

Over the next two months I built a python based command line interface in my spare time for and released the first lines of code as Open Source under the name "Gamestonk Terminal" since I was an investor in Gamestop and Elon Musk had recently tweeted his now infamous ["Gamestonk" tweet](https://twitter.com/elonmusk/status/1354174279894642703?s=20).

The project went viral in a couple of minutes on [Reddit](https://www.reddit.com/r/Python/comments/m515yk/gamestonk_terminal_the_equivalent_to_an/) and [HackerNews](https://news.ycombinator.com/item?id=26258773). In under 24h we had over 4,000 stars on [GitHub](https://github.com/OpenBB-finance/OpenBBTerminal), and hundreds of messages requesting features, thanking me for the tool, or reporting bugs.

The number of issues and feature requests was overwhelming for a single person working part-time, so I created a [Discord group](https://openbb.co/discord) and started building a community of users. Many of those same first users went on to become core maintainers of the project. The community started adding new data sources, new features and even new asset classes to the project - soon after we were supporting crypto, ETFs, options, forex, and macro economy.

My goal was never to build a business/company with this product. My motivation was to create a better investment research platform that was unavailable until then. When we got approached by JJ (from OSS Capital), it was a no-brainer to create OpenBB, as this would allow me to accelerate the product vision and build the world's leading investment research platform.

---

---
slug: why-you-should-drop-yfinance-api-and-adopt-openbb-sdk
title: Why you should drop yfinance API and adopt OpenBB SDK
date: 2022-10-01
image: /blog/2022-10-01-why-you-should-drop-yfinance-api-and-adopt-openbb-sdk.png
tags: ['OpenBB SDK', 'yfinance API', 'Financial Data', 'APIs', 'Open Source']
description: Why you should consider switching from yfinance API to OpenBB SDK for financial data retrieval. OpenBB SDK offers access to multiple data sources, potential for unlimited data, and incentives for data source partners.
---

<p align="center">
    <img width="600" src="/blog/2022-10-01-why-you-should-drop-yfinance-api-and-adopt-openbb-sdk.png"/>
</p>

<br />

Why you should consider switching from yfinance API to OpenBB SDK for financial data retrieval. OpenBB SDK offers access to multiple data sources, potential for unlimited data, and incentives for data source partners.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

OpenBB SDK will be released later this month 👀.

[yfinance API](https://github.com/ranaroussi/yfinance) is an unofficial (not affiliated) API around [Yahoo Finance website](https://finance.yahoo.com/).

Although it is used in over 12,600 projects on GitHub and is downloaded on average 90,000 per week. This is still an unofficial wrapper. As you can see from Yahoo Finance website, it uses an ad revenue business model. This means that Yahoo Finance doesn’t has any incentive from having users utilizing it through Yfinance API.

If one day Yahoo Finance website adds a paywall through an API key, then Yahoo Finance would:

1. Either become obsolete
2. Or adopt the same architecture of OpenBB where an API key from a data source is necessary

<br />

Regardless, Yfinance API retrieves data that exists on a third-party website: Yahoo Finance website. This means that this API is limited by the data Yahoo Finance is currently paying for redistribution. And thus, users get only what data is supported through the website.

On the other hand, OpenBB SDK allows you to retrieve data from over 50 different APIs (and growing). With yfinance being one of these APIs.

Since OpenBB SDK requires API keys from most of the data sources, these have incentives to partner with OpenBB. Because:

1. Marketing opportunity due to significant larger pool of users
2. New revenue stream

<br />

In essence, Yfinance API:

- Not officially supported by Yahoo Finance
- No incentive for Yahoo Finance
- Limited data by what Yahoo Finance displays
- May become obsolete

On the other hand, OpenBB SDK:

- Marketing for new data sources
- New revenue stream for partners through premium API keys
- (Almost) unlimited data - open source project that keeps on adding new data sources
- Multiple data sources for same data (user has choices)

As counter-intuitive as it sounds:

The shutting down of yfinance API (which is one of the data sources that OpenBB SDK has access to) would be beneficial to OpenBB adoption. This is because users would need to migrate to OpenBB SDK as that’s the most mature and maintained open source financial API.

If you have any questions, feel free to drop me a message!


---

---
slug: stop-doing-your-cv-in-word-or-latex
title: Stop doing your CV in Word or LaTeX
date: 2022-10-15
image: /blog/2022-10-15-stop-doing-your-cv-in-word-or-latex.png
tags: ['GitHub', 'CV', 'Career', 'Open Source', 'Developer']
description: The future of CVs for engineers and developers lies within GitHub. This post discusses why GitHub profiles are becoming the new CVs and how they can provide a more comprehensive view of a candidate's skills and contributions.
---

<p align="center">
    <img width="600" src="/blog/2022-10-15-stop-doing-your-cv-in-word-or-latex.png"/>
</p>

<br />

The future of CVs for engineers and developers lies within GitHub. This post discusses why GitHub profiles are becoming the new CVs and how they can provide a more comprehensive view of a candidate's skills and contributions.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The purpose of a CV is to summarize someone’s career, qualifications and education. **As an engineer or developer, I strongly believe that the future of CVs lies within GitHub.**

In fact, GitHub has realized this and they now allow you to create your own “_profile page_” by creating a repository with the same name as your GitHub username. E.g. https://github.com/DidierRLopes

In my humble opinion, this isn’t being talked enough. Previously, you needed a CV document to talk about your background, education, previous jobs and could rely on your GitHub profile to show your projects. With this update, CVs have become obsolete. When hiring for [OpenBB](https://openbb.co/), I put a lot of weight into the public GitHub of each engineer.

This is my current [GitHub profile page](https://github.com/DidierRLopes).

![image](/blog/2022-10-15-stop-doing-your-cv-in-word-or-latex_1.png)

My profile page is now much simpler since I’ve worked on my [own personal website](https://didierrlopes.github.io/personal-website/), but you can see [here](https://github.com/DidierRLopes/DidierRLopes/tree/98c27cfb087fc8ce6986f4ea8136e76ca14f145b) what my GitHub profile page looked like before. Creating your own personalized website for me is the next step after GitHub, as you can be as creative as you want while showing off your coding skills.

My repository is my way of showing the world what I can do on my own. From a blank sheet to a finalized project. **Sometimes useful, sometimes for fun, but always with the intention to learn more and challenge myself.**

The reason I think that GitHub profile’s are the CVs of the future for engineers/developers, is not only because you can now both talk about yourself in it and display your portfolio, but because of its open source nature.

With products like: https://ossinsight.io/analyze/DidierRLopes, you will be able to dive deeper on engineering skills than ever before.

![image](/blog/2022-10-15-stop-doing-your-cv-in-word-or-latex_2.png)

Companies will be able to assess a candidate based on their open source work:

- How do they interact with the community? What are their communication skills?
- Do they practice teamwork? And mentor more junior developers?
- Are they leaving comments in the code? Is their code readable in the first place?
- What about testing? Are they following good practices?
- What’s their time to reply to issues? Or to review PRs from peers?
- Activity? What are their working hour patterns like?
- …

Imagine a world where everyone develops in the wild. You can see everything and be part of any project. You have your own profile, you talk with others through issues or PRs, you build together. There is no gender, no race, no nationality,.. people are conneced through projects they believe in. **In essence, this is the developer metaverse, and I’m all here for it.**

![image](/blog/2022-10-15-stop-doing-your-cv-in-word-or-latex_3.png)

**EDIT:** The reader should be aware that nowadays a properly formatted resume is still critical when added to a job board. This is because automated resume readers expect a certain format in order to recommend candidates to companies and vice-versa.

Hope you enjoyed this post. As always, any feedback welcome! 🙏


---

---
slug: how-i-would-do-due-diligence-on-amt-using-openbb-terminal
title: How I would do due diligence on $AMT using OpenBB Terminal
date: 2022-10-20
image: /blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal.png
tags: ['OpenBB Terminal', 'Investment Research', 'Stocks', 'Due Diligence']
description: This blog post provides a detailed walkthrough on how to conduct due diligence on $AMT using the OpenBB Terminal, a free and open source platform for financial data analysis.
---

<p align="center">
    <img width="600" src="/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal.png"/>
</p>

<br />

This blog post provides a detailed walkthrough on how to conduct due diligence on $AMT using the OpenBB Terminal, a free and open source platform for financial data analysis.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Last month someone on Twitter asked me to do a thread on how I would do due diligence on $AMT using the free and open source [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal).

Below I demonstrate what you can expect from using that platform.

We could go much deeper, but this shows examples of output that you can expect. With over 800 commands and over 100 data sources, this is a very small subset of what you can achieve through this platform.

In addition, this will only be in relation with stocks data, but the terminal also has access to options, crypto, ETFs, mutual funds, NFTs, macro economy, futures and even alternative data!

More information on the platform and how to install it [here](https://my.openbb.co/app/terminal/download).

Strap in.

```console
$ /stocks/load AMT/candle
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_1.png)

```console
$ /stocks/fa/mktcap
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_2.png)

```console
$ /stocks/fa/mgmt
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_3.png)

```console
$ /stocks/fa/income/balance/cash
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_4.png)

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_5.png)

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_6.png)

```console
$ /stocks/fa/shrs
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_7.png)

```console
$ /stocks/fa/sust
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_8.png)

```console
$ /stocks/fa/divs
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_9.png)

```console
$ /stocks/fa/dcf
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_10.png)

```console
$ /stocks/ins/stats
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_11.png)

```console
$ /stocks/dps/psi
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_12.png)

```console
$ /stocks/gov/histcont
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_13.png)

```console
$ /stocks/dd/rating
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_14.png)

```console
$ /stocks/dd/pt
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_15.png)

```console
$ /stocks/dd/est
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_16.png)

```console
$ /stocks/ta/sma
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_17.png)

```console
$ /stocks/ta/recom/summary
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_18.png)

```console
$ /stocks/ba/sentiment
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_19.png)

```console
$ /stocks/sia/metric tc
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_20.png)

```console
$ /stocks/sia/metric fcf
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_21.png)

```console
$ /stocks/sia/vis oi
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_22.png)

```console
$ /stocks/ca/historical/hcorr
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_23.png)

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_24.png)

```console
$ /stocks/ca/cashflow/income/balance
```

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_25.png)

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_26.png)

![image](/blog/2022-10-20-how-i-would-do-due-diligence-on-amt-using-openbb-terminal_27.png)

I know this can be overwhelming information and it takes some time to run all these commands.

Hence I created a [script](https://github.com/OpenBB-finance/OpenBBTerminal/blob/main/openbb_terminal/miscellaneous/routines/due_diligence_stock.openbb). So now you can run all of these commands in one go, with:

```console
$ /exe due_diligence_stock.openbb -i AMT
```

Any feedback is welcome!

And if you want to ask questions about the product before installing it, feel free to join us on Discord here: https://openbb.co/discord


---

---
slug: how-to-convert-a-twitter-thread-into-a-linkedin-carousel-in-seconds
title: Twitter thread to LinkedIn carousel in python
date: 2022-10-23
image: /blog/2022-10-23-how-to-convert-a-twitter-thread-into-a-linkedin-carousel-in-seconds.png
tags: ['Python', 'LinkedIn', 'Twitter', 'Carousel', 'Content Creation']
---

<p align="center">
    <img width="600" src="/blog/2022-10-23-how-to-convert-a-twitter-thread-into-a-linkedin-carousel-in-seconds.png"/>
</p>

<br />

In this blog post, I share how I built a Python tool that converts a Twitter thread into a LinkedIn carousel in seconds. This tool is open source and contributions for improvements are welcome.

The open source code is available [here](https://github.com/DidierRLopes/thread-to-carousel/tree/master).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

As content creators, it would be good if the same content could be utilised across every platform easily. Sometimes you need some tweaks based on audience, but often the same content is used across all platforms.

I noticed recently that LinkedIn carousels have been picking a lot of traction, and given I have some nice Twitter threads ([example](https://twitter.com/didier_lopes/status/1570731358204600323?s=20&t=SAO9fD7FR7jeTE-6kem6Mg)) I thought that it would be great if I could convert them into a LinkedIn carousel.

So, I looked for free tools and didn’t find anything good enough. I ended up using [canvas](https://canvas.apps.chrome/) to re-create the thread — which you can find [here](https://www.linkedin.com/posts/didier-lopes_due-diligence-on-amt-using-openbb-terminal-activity-6977569279395176448-TFMn?utm_source=share&utm_medium=member_desktop). It worked well, but it was time consuming and for most cases, I don’t want to be messing around with the design side of things.

![image](/blog/2022-10-23-how-to-convert-a-twitter-thread-into-a-linkedin-carousel-in-seconds_1.png)

As a true software engineer and pythonist, I obtained the Twitter API keys and built a tool that would convert a Twitter thread into a LinkedIn carousel in a matter of seconds.

And as usual, I open sourced it: https://github.com/DidierRLopes/thread-to-carousel.

This tool is far from perfect, and a lot can be improved on the design side of things to: Recognize emojis; Highlight mentions; Change the size of the box based on the text; Better text placement when images attached; Better URL link display.

The goal for me wasn’t to build a perfect tool, but something easy enough that did the job. And, as the project is open source, I expect to have users contributing to the script so that it can be improved over time.

Today I run it using:

```console
python convert2carousel.py https://twitter.com/didier_lopes/status/1581247044228100096
```

And the result can be found [here](https://www.linkedin.com/posts/didier-lopes_football-momentum-indicator-carousel-activity-6989972573782482944-nM9s?utm_source=share&utm_medium=member_desktop).

![image](/blog/2022-10-23-how-to-convert-a-twitter-thread-into-a-linkedin-carousel-in-seconds_2.png)

Feel free to check the project here and I look forward to having contributors helping me improve it!

As always, any feedback welcome 🙏🏽


---

---
slug: how-to-learn-10x-faster-than-average
title: How to learn 10x faster than average
date: 2022-10-27
image: /blog/2022-10-27-how-to-learn-10x-faster-than-average.png
tags: ['learning', 'self-improvement', 'skills', 'education']
description: Learn how to accelerate your learning process and become 10x faster than average. This blog post provides practical steps to enhance your self-learning abilities and master new skills effectively.
---

<p align="center">
    <img width="600" src="/blog/2022-10-27-how-to-learn-10x-faster-than-average.png"/>
</p>

<br />

Learn how to accelerate your learning process and become 10x faster than average. This blog post provides practical steps to enhance your self-learning abilities and master new skills effectively.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Everyone is a self learner. But people’s rhythm of self learning can be vastly different.

### Have a good reason to learn this new skill

What is the main fundamental reason why you want to learn this skill? If you don’t have a one sentence answer, you probably don’t need to learn it.

University teaches you hundreds of topics that you end up not being good at because you have no interest in it.

Avoid spending your precious time on developing a skill that you have no interest or purpose in. Avoid trends too for this reason.

### Research and read about the best way to learn the basics

This should take no longer than one afternoon. Avoid promoted content.

Usually, you’re able to find a course/book/video that is acclaimed by the community to be the best to get started with.

So we are looking for the equivalent of “Machine Learning from Andrew Ng” for the skill you want to master.

### Consume the basics like your life depends on it

This will be the foundation of all your subsequent learning in this new area. Put your phone away, and take notes.

Revisit those notes, and if necessary go back in time to understand the basics.

It took me above average time to finish Machine Learning from Andrew Ng.

However, since this, whenever I learn or even think about AI problems this is now easier because of that laid out work.

### Test your knowledge with a real problem (aka get your hands dirty)

And no, I don’t mean do an exercise that you find online.

Define a problem that you can solve with the skills you acquired and work on it.

Don’t ask for the answer. Don’t Google for the solution, but Google for something that is a current impediment on your solution.

If you are struggling on formulating the Google prompt, revisit your first notes on the skill.

### Keep learning about the topic

The getting started foundation will only get you so far. It’s likely that soon you will grow out of that and need to expand your knowledge.

Don’t jump on this step too early. Make sure your basics are covered before you move on.

Go back to the real problem you worked on, and see how the new learned skills could be applied for that same problem.

If those skills aren’t necessarily in that first problem, it’s also a good sign. It’s a sign that you learned not only the skill but when it is and it isn’t used.

### Iterate

Keep iterating between using this new skill to solve a real problem and learning from courses/videos/books.

There isn’t a “you made it” badge. But you know you did, once you’re able to look for a specific piece of information on a video/book to fill in the gap for something you needed for your real problem.

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

TL;DR on how to learn 10x faster than average

1. Have a good reason to learn this new skill.
2. Research and read about the best way to learn the basics.
3. Consume the basics like your life depended on it.
4. Test your knowledge with a real problem.
5. Keep learning about the topic.
6. Iterate.


---

---
slug: how-to-grow-your-open-source-community-from-scratch.md
title: How to grow your open source community from scratch
date: 2022-11-10
image: /blog/2022-11-10-how-to-grow-your-open-source-community-from-scratch.png
tags: ['Open Source', 'Community Building', 'Project Management', 'OpenBB Terminal']
description: Growing an open source community from scratch is a challenging task. This blogpost shares insights and strategies on how to effectively build and manage an open source community, using the example of the OpenBB Terminal project.
---

<p align="center">
    <img width="600" src="/blog/2022-11-10-how-to-grow-your-open-source-community-from-scratch_1.png"/>
</p>

<br />

Growing an open source community from scratch is a challenging task. This blogpost shares insights and strategies on how to effectively build and manage an open source community, using the example of the OpenBB Terminal project.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

### Project naming

The name should be short, memorable, unique and related with the project.

When I started what we call OpenBB Terminal today, the name of the project was “Stock Market Bot” or something silly like that. I knew that wouldn’t be the last name, but I didn’t have any inspiration and in the meantime I was focused on building the platform.

I am an Elon Musk fan, and was a GameStop investor. This meant that once I saw [this tweet](https://twitter.com/elonmusk/status/1354174279894642703) — I didn’t blink twice and knew this was the name I was waiting for.

![image](/blog/2022-11-10-how-to-grow-your-open-source-community-from-scratch.png)

That’s when Gamestonk Terminal (now OpenBB Terminal) was born.

### Keep the project private until MVP

- There will be less pressure than building in public, and you will be able to iterate much faster.
- No users asking for features or reporting bugs when MVP is still under development.
- Most importantly, this guarantees that when the users see the MVP they know where you are heading with the project.

I worked on Gamestonk Terminal for 2 months on my own. The code architecture changed several times as I was in this experimental phase. And if you look into the source code I even committed API keys accidentally. But I had no pressure, so I was able to ship extremely fast.

### Prepare to onboard the community

- Make the documentation standout (not only “getting started” but also “contributing”).
- Create “quick win” tickets that the community can address quickly.
- Start a group channel on Discord or Slack, which allows you to interact with contributors and discuss features / roadmap and keep them engaged.
- Mention “starring” the project. As simple as this sounds, this helps with growth as its easy to forget to star the project, even though you were interested in what you saw.

Some people from our current team told me recently that they fell in love with the README of the project the first time they saw it. In particular with this quote:

> _“Gamestonk Terminal is an awesome stock and crypto market terminal that has been developed for fun, while I saw my GME shares tanking. But hey, I like the stock.”_

<br />

This allowed me to gain not only contributors, but maintainers. And nowadays, team members.

### Change the project visibility to public

- This allows everyone to have a first look into the project, it’s the “Hello World” moment.
- When sharing the project, describe the problem you are trying to solve and make sure your audience relates with that problem.
- Share your project on relevant channels (e.g. Reddit, HackerNews, ProductHunt) — where your audience is.

I have been building in open source for a while, without much success. Until Gamestonk Terminal.

The difference? I shared Gamestonk Terminal on:

- Reddit r/SuperStonk — where the retail traders with the same issue as me were gathered
- Reddit r/python — where the community shares projects built in python
- HackerNews — where I leveraged the name of a known brand in the same industry and insinuated that my tool was similar but affordable. The title was: “[Can’t afford Bloomberg Terminal? No prob, I built the next best thing](https://news.ycombinator.com/item?id=26258773)”.

### Keep developing in public

- Keep the community updated on the roadmap and progress. You can do this by doing demos of what you have accomplished as you add new features (e.g. [on YouTube](https://www.youtube.com/watch?v=fqGPK8OVHLk) or [on Twitter](https://twitter.com/didier_lopes/status/1567117888590340098)) which allows the community to understand what sort of tasks you are working on, and what they would learn if they were to contribute. It basically gives the community a hindsight into what a contributor will be able to work on / achieve.
- Get early feedback and prioritise accordingly.
- Occasionally go back to the same channels (e.g. Reddit, Hackernews) to report progress. This guarantees that they know the project is not dead and helps your project staying relevant and on their minds.
- Develop in public through livestreams (e.g. [live Coding](https://www.youtube.com/watch?v=9BMI9cleTTg)) or by sharing what you are working on through social media (e.g. [adding a futures menu](https://twitter.com/didier_lopes/status/1579414220256387072)).

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

TL;DR: On how to grow your open source project:

- Project naming
- Keep project private until MVP
- Prepare to onboard the community
- Change the project visibility to public
- Keep developing in public


---

---
slug: 5-steps-i-used-to-change-my-job-title-in-less-than-1-year
title: 5 steps I used to change my job title in less than 1 year
date: 2022-11-14
image: /blog/2022-11-14-5-steps-i-used-to-change-my-job-title-in-less-than-1-year.png
tags: ['career', 'job change', 'sensor fusion engineer', 'roadmap', 'hard work']
description: This blog post outlines the five steps I took to change my job title from an Embedded Firmware Engineer to a Sensor Fusion Engineer in less than a year. It provides a roadmap for others who may be looking to make a similar career transition.
---

<p align="center">
    <img width="600" src="/blog/2022-11-14-5-steps-i-used-to-change-my-job-title-in-less-than-1-year_1.png"/>
</p>

<br />

This blog post outlines the five steps I took to change my job title from an Embedded Firmware Engineer to a Sensor Fusion Engineer in less than a year. It provides a roadmap for others who may be looking to make a similar career transition.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

In March 2020, I joined a startup as an Embedded Firmware Engineer. The startup’s product focuses on smart running insoles with lightweight trackers that fit any running shoes.

The company was small, and the firmware team was myself and 2 Senior Embedded Firmware Engineers.

What I liked the most about this team was that our interests complemented each other very well. One of the Senior Embedded Firmware Engineers was very strong at wireless communications (BLE, ANT) while the other was great at communication protocols (SPI, I2C). On my end, my strength was from my MSc in Control Systems and my past experience with GNSS. In addition, I had a very high interest in learning about Inertial Navigation System (INS). My goal was to become a Sensor Fusion Engineer.

So what did I do to become a Sensor Fusion Engineer?

## Declare your intent

Since day 1 in the company, my team lead knew that my goal was to become a Sensor Fusion Engineer.

This is very important, as your manager can keep this in the back of their mind when assigning tasks to you. For instance, my team lead was giving me a lot of material around the way our product processed external samples as this was critical to the INS.

## Define a roadmap

I asked my manager: “_What do I need to do to be recognized as a Sensor Fusion Engineer_”.

Knowing about the matter is not enough, you want to have the credentials so that you can jump faster in your career.

My team lead was not aware of the capabilities I would need to have to become a Sensor Fusion Engineer, so he spent quite some time doing due diligence on this. Good managers will go out of their way to help you grow.

After some time, we discussed what I would need to do at the company to be recognized as Sensor Fusion Engineer and built a roadmap in order to get there.

## Work hard

Work extremely hard towards that roadmap.

I was not only working towards that roadmap, but I was also working towards it at 2.5x the average speed. I was working 80h — 100h / weeks during that time.

I was being pulled into all meetings that discussed sensor fusion, I was reading old documentation to understand the decisions that I made, I was reading codebase and questioning all code (which allowed me to find some issues) and I was taking online courses on top of this.

More importantly, I was experimenting with the product. Theory will only help you so much, you need to get your hands dirty or you will never be able to fully master a skill.

## Frequently revise your roadmap

Throughout all my 1:1 with my manager, we always revisited the roadmap — even if briefly. This made sure that he knew how serious I was about this topic, and allowed me to demonstrate my progress.

This also allowed myself to look back and realize my own progress. I would spend time educating him on what I had learned and how we could apply that in our product, including some simulations I had done in Python.

## Prove yourself

Don’t miss an opportunity to prove yourself.

This is the most critical point, you need to prove that you are capable of delivering by actually demonstrating a real example.

This is the egg or chicken first problem. When you don’t have the initial experience, your company won’t trust you to apply your knowledge. But if your company doesn’t give you the chance you will never get the experience.

In our case, users started getting weird jumps in altitude reported by the trackers. And we needed to figure out the issue fast as this was increasing the churn. I immediately knew I was able to solve this, and knew I had to grab this opportunity.

Our trackers were not taking the GPS location in the estimation of user altitude, and I knew that considering that would substantially improve the estimation as the altitude has less chances to change drastically over a small distance.

Finally, my degree and hundreds of hours of work were paying off. That day, I wrote our C/C++ altitude estimation algorithm in Python and provided with an input that had a spurious jump in pressure readings — i.e. I recreated how the issue was happening.

I proceeded to implement a Kalman Filter solution to consider GPS readings as well, and the result was a massive improvement. The jump in altitude was non-existant now.

In the daily standup the next day, I had accomplished most of my tasks for the sprint and asked the product owner if I could take a shot at fixing the altitude issue. He was a bit hesitant, but I had a notebook ready to show the problem recreated and my proposed solution in Python.

He accepted and gave me the next 3 days to work on it and to present results on Monday. I didn’t sleep until that Monday. Implementing from Python to C++ was the easy part. The hard part was debugging + optimizing the weights of the Kalman Filter.

I was touching the code. Performing an over the air upgrade. Going outside for a run in a track with a bridge where I knew the altitude. Analyzing results at home. Iterate.

Monday arrived and I presented results, and they looked so much better. The proposed solution was accepted. Our INS algorithm hadn’t changed in a long time, so a lot of testing was needed.

After that, the company accepted to offer me the title of Sensor Fusion engineer. Without a pay rise, but that was fine as for me it was about speeding up my career.

## Conclusion

- Declare intent
- Define roadmap
- Work towards that roadmap
- Frequently revise roadmap
- Don’t miss an opportunity to prove yourself

**Note:** If the company doesn’t give you a chance to prove yourself, you should interview for that position with other companies. And if another company offers you that job, you will have the leverage that another company perceives you as that.

I like [this video](https://youtube.com/shorts/x71Rm0MWVHY?si=BvtmjrE31d6U1bpV) about understanding your market value. And I think it can be extended in terms of your skillset if you want to change your role.

Feedback as always is welcome :)


---

---
slug: sweepstake-world-cup-2022-for-your-startup-team
title: Sweepstake World Cup 2022 for your startup team
date: 2022-11-26
image: /blog/2022-11-26-sweepstake-world-cup-2022-for-your-startup-team.png
tags: ['World Cup 2022', 'Startup Team', 'Sweepstake', 'Team Building', 'Slack Bot']
description: In this blogpost, we share how we organized a World Cup 2022 sweepstake for our startup team as a team building activity, and how we built a slack bot to facilitate discussions around the event.
---

<p align="center">
    <img width="600" src="/blog/2022-11-26-sweepstake-world-cup-2022-for-your-startup-team.png"/>
</p>

<br />

In this blogpost, we share how we organized a World Cup 2022 sweepstake for our startup team as a team building activity, and how we built a slack bot to facilitate discussions around the event.

The open source code is available [here](https://github.com/DidierRLopes/worldcup2022-sweepstake-slackbot).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

At [OpenBB](https://openbb.co/), the team puts in so much hard work for [our product](https://github.com/OpenBB-finance/OpenBBTerminal) that doing a team event is like a breath of fresh air. With the World Cup 2022 now taking place and more than half of the team being from Europe (where football is the main sport), we thought that it would be nice to run an OpenBB sweepstake.

We decided to offer a prize to the teams that end up on the podium. 1st place gets X, 2nd place gets Y and 3rd place gets Z - with $ X > $ Y > $Z.

The next step was to assign teams to each employee, so at the end of our all hands meeting we did just that. For that we used this free website: https://spinnerwheel.com/fifa-world-cup-sweepstake-generator.

This allowed us to spin the wheel of team members and then spin wheel of countries, and get a 1:1 match — it was quite funny to have everyone involved and see the reactions as the wheel was slowing down.

![image](/blog/2022-11-26-sweepstake-world-cup-2022-for-your-startup-team_1.png)

**Most companies stop here.**

...

The best part about the sweepstake for me, is that the team members that don’t usually interact with each other on a day to day basis have the opportunity to talk amongst themselves for this.

So, to encourage these team interactions, the first step was to create a slack channel #worldcup-2022 that we could use to discuss each game.

**But that isn’t enough**, because sometimes you require a trigger to start a discussion about the results and the next fixtures.

I looked for a slack bot that achieved this, but **I didn’t find one**.

So I built one using Python which you can find [here](https://github.com/DidierRLopes/worldcup2022-sweepstake-slackbot).

This is the notification that the #worldcup-2022 receives everyday after all the matches have been played.

![image](/blog/2022-11-26-sweepstake-world-cup-2022-for-your-startup-team_2.png)

The outcome has been great so far! Our team engagement is even higher than usual and we see team members that don’t work directly with each other having the opportunity to get to know others better.

If you want to do the same for your team, follow the instructions highlighted [here](https://github.com/DidierRLopes/worldcup2022-sweepstake-slackbot).

Any feedback is appreciated!


---

---
slug: bloomberg-terminal-is-no-more-openbb-terminal-2-0-has-just-been-released
title: Bloomberg Terminal is no more. OpenBB Terminal 2.0 has just been released.
date: 2022-11-29
image: /blog/2022-11-29-bloomberg-terminal-is-no-more-openbb-terminal-2-0-has-just-been-released.png
tags: ['OpenBB Terminal 2.0', 'Investment Research', 'Financial Data', 'AI', 'ML', 'SDK']
description: OpenBB Terminal 2.0 has been released. This blog post discusses the new features and improvements, including the release of OpenBB SDK, a state-of-the-art AI/ML toolkit for the financial industry, and the vision for a community-driven investment research platform.
---

<p align="center">
    <img width="600" src="/blog/2022-11-29-bloomberg-terminal-is-no-more-openbb-terminal-2-0-has-just-been-released.png"/>
</p>

<br />

OpenBB Terminal 2.0 has been released. This blog post discusses the new features and improvements, including the release of OpenBB SDK, a state-of-the-art AI/ML toolkit for the financial industry, and the vision for a community-driven investment research platform.

The open source code is available [here](https://github.com/DidierRLopes/GamestonkTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Almost 2 years ago, I started building my own investment research platform. 2 months later I named it Gamestonk Terminal, made it open source and shared it on Reddit. The rest is history.

Since then, we surpassed [17,800 stars on Github](https://github.com/OpenBB-finance/OpenBBTerminal). Raised $ 8.8 million in our seed round. Build a very competitive team and our OpenBB brand is now recognized by most in the financial space. You can read more about our story [here](https://openbb.co/blog/gme-didnt-take-me-to-the-moon-but-gamestonk-terminal-did).

**Our mission to democratize investment research has not changed.** Over the past few months we have been heads down and building and today I’m excited to share with you the announcement of OpenBB Terminal 2.0.

The headline is:

> _OpenBB Terminal 2.0 is more than an application, it’s a platform._

<br />

A summary:
- We are releasing OpenBB SDK which allows developers to use a single API to access the world’s raw financial data in order to build their own products / dashboards.

The SDK will allow users to create report templates in a matter of minutes and run them for custom tickers at any time in a matter of seconds; Instead of spending hours and starting a report from scratch every single time. We envision a world where the community can share these and help each other at becoming better investors.

![image](/blog/2022-11-29-bloomberg-terminal-is-no-more-openbb-terminal-2-0-has-just-been-released_1.png)

- We are also bringing a state-of-the-art AI / ML toolkit to the financial industry, to be used alongside all the data sources our platform has access to (stocks, crypto, NFTs, options, forex, ETFs, mutual funds, macro economic data and even alternative data).

![image](/blog/2022-11-29-bloomberg-terminal-is-no-more-openbb-terminal-2-0-has-just-been-released_2.png)

For more information, you can read our announcement here: https://openbb.co/blog/openbb-terminal-2-acai

Or even better, watch the announcement [here](https://openbb.co/blog/openbb-terminal-2-event)!


---

---
slug: the-future-of-finance-with-open-source-and-ai
title: The future of finance with open source and AI
date: 2022-12-04
image: /blog/2022-12-04-the-future-of-finance-with-open-source-and-ai.png
tags: ['Open Source', 'AI', 'Finance', 'Future']
description: The future of finance is being reshaped by open source and AI. This post discusses the potential of these technologies in disrupting the financial industry, the advantages of open source, and the role of AI in user interface.
---

<p align="center">
    <img width="600" src="/blog/2022-12-04-the-future-of-finance-with-open-source-and-ai.png"/>
</p>

<br />

The future of finance is being reshaped by open source and AI. This post discusses the potential of these technologies in disrupting the financial industry, the advantages of open source, and the role of AI in user interface.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This post will talk about my (very) u̶n̶biased opinion about the future of finance built on top of open source and AI.

## Open Source platform

![image](/blog/2022-12-04-the-future-of-finance-with-open-source-and-ai_1.png)

### Data licensing vs Marketplace

Current monopolies spend an enormous amount of cash on financial data licensing. There are dozens of different asset classes (stocks, options, crypto, NFTs, currencies, bonds, ETFs, mutual funds, …) and these often vary based on geography. **That makes the overall investment research industry a very tough market to compete.** Startups cannot disrupt the space without a massive capital injection. This is also why startups usually focus on a certain asset class in a certain geography.

**In my opinion, the only shot we have to disrupt incumbents is by not owning the data but becoming the infra layer between data sources and users.** _This is no different than Uber not owning cars, Airbnb not owning apartments or Deliveroo not owning restaurants._

**This also has a great advantage which is being able to integrate new data sources very fast and easily.** Plus, owing to open source, anyone can add it. On the other hand, it’s very unlikely that an incumbent will add data that you require. Plus, if they do, they will need to license the data and therefore decrease their margins — unless they increase the price to users.

### Full-price bundle

Current incumbents pricing is usually a complete bundled offering. **This means that regardless of what you are utilizing in terms of both breadth and depth, you pay the full price tag.** A good analogy is like a restaurant ONLY having a buffet when all you want is a bottle of water, or some chips. What happens is that a user ends up paying for data that they are not using.

In 2022, this is a very outdated take. Companies are looking to get leaner, and it doesn’t make sense to pay for data that you aren’t going to leverage. **Being the infrastructure between users and data sources allows you to create value to both**; Since users will have access to all the data they want and pay for the ones they use, and data sources will have access to a big pool of users and may not need to create a dashboard product to monetize their offerings.

### Transparency & Customization

Current incumbents have built several in-house financial models. **Although these are often customizable, their customization is typically limited.** That is because what is usually customizable are the values/weights, but not necessarily the formulas — that is kept hidden in their source code. This is an issue because that code cannot be validated and users cannot modify it.

With open source, the story is completely different. **Users can see every single line of code, and therefore not only audit the code quality but adapt the models/formulas to their own needs.** At the end of the day, there is no point in re-inventing the wheel for financial theory that has been around for decades.

By having the code open source, users can rely on the fact that these formulas have been validated/tested by thousands or millions of users and, therefore, there’s a very low chance that these are wrong. **In addition, users are more secure because they can investigate the code and check/fix any vulnerabilities.**

### Community

One of the best parts of open source is the integrated community that it creates. This attracts people from every background, gender or ethnicity. Such a pool of diversity tends to allow for better ideas and pushes a project further. With people from the community being able to contribute, this also drives innovation.

[OpenBB](http://my.openbb.co/app/terminal/community-routines) has been driven a lot by the community so far. What started as a terminal mostly focused on stocks, soon evolved into including a broad range of datasets and considering several geographies. E.g. A contributor from Sweeden integrated Avanza API to the mutual funds menu that would only appear if users were looking into mutual funds from Sweden. This shows the power of community.

Having the platform be _open source_ is key.

## GPT as the interface

**One of the hedges that incumbents have is the fact that they have been around for a very long time and spent a lot on educating users about their product.** As a result, users are used to their platform. This makes them harder to switch to an unknown product. This is also why a product needs to be 10x better than competition for users to switch.

**However, what if there was no learning curve?** What if you could use a product for the first time and knew how to access all the data without spending any time reading the documentation. **In essence, the educational incumbent advantage would become obsolete.**

With the new LLM advancements, such as [ChatGPT](https://chat.openai.com/chat). We are not far from this reality.

![cool1](/blog/2022-12-04-the-future-of-finance-with-open-source-and-ai_2.png)

Plus, if this is built on top of an open source project it means that the **community can help in improving the model** by providing more training data (e.g. provide a text as input and the corresponding command as output) or even confirm whether or not the chart that pops up was accurate. In addition, along with data sources you can imagine that the community could start contributing with new languages for the GPT model.

You can easily imagine that such interface would work well with a speech recognition model (something like [whisper](https://github.com/openai/whisper) but that allowed real-time).

**This makes using a new investment research platform easy, but more importantly makes retrieving information much faster and efficient.**

## GPT to build investment research reports

One of the new features that were announced with [OpenBB Terminal 2.0](https://openbb.co/blog/openbb-terminal-2-acai) was the automated reports generation that utilizes [papermill](https://github.com/nteract/papermill) to leverage jupyter notebook templates.

![cool2](/blog/2022-12-04-the-future-of-finance-with-open-source-and-ai_3.png)

As it stands creating one of these notebook templates requires some coding skills and reading [OpenBB documentation](https://docs.openbb.co/) to understand how to retrieve the data of interest providing the correct function and necessary arguments.

**But, for a second, imagine if you could build these notebook templates with almost no-code?**

The proof-of-concept below in combination with the automated report generation should allow you to further understand the breakthrough that we may accomplish in the following few months.

![image](/blog/2022-12-04-the-future-of-finance-with-open-source-and-ai_4.png)

**My prediction is that open source + AI will disrupt the financial sector in the upcoming years.**

[OpenBB](https://openbb.co/) will be leading that wave.

Thanks for reading!


---

---
slug: how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla
title: How I wrote a machine learning paper in 1 week that got accepted to International Conference in Machine Learning Applications
date: 2022-12-07
image: /blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla.png
tags: ['Machine Learning', 'Data Science', 'Academia', 'ICMLA', 'NURVV Run', 'Open Source']
description: How I wrote a machine learning paper in 1 week that got accepted to ICMLA while working full time and raised $8.8 million for OpenBB Terminal.
---

<p align="center">
    <img width="600" src="/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla.png"/>
</p>

<br />

How I wrote a machine learning paper in 1 week that got accepted to ICMLA while working full time and raised $8.8 million for OpenBB Terminal.

The open source code is available [here](https://github.com/DidierRLopes/step-detection-ML).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

One year ago, I raised $ 8.8 millions to build [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) full time. But since I was working at a startup in the UK, I had a 3 month notice period.

During that time I worked on documenting pretty much everything I had been working on, BUT that felt short. I felt like the data that came out of our [NURVV Run](http://www.nurvv.com/) product could be used with a machine learning algorithm in order to detect a foot strike quite efficiently.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_1.png)

So I asked my company:

> _If I use my spare time to work on this paper will you sponsor me if I get accepted?_

<br />

**My goal was to increase the visibility of our product in academia.** And given I spent some time reading papers in the area, I knew that what I had in mind had a shot at working.

**My background is not data science, and this was my first time “officially” working on machine learning.** I wasn’t 100% sure that my idea would work, but after spending more than 1 year at the company, I knew how the data behaved. I thought I could build an algorithm robust enough to be able to detect a foot strike more efficiently than what others had.

After some time, the company accepted my proposal, and between the time to decide to apply to [International Conference on Machine Learning and Applications (ICMLA)](https://www.icmla-conference.org/icmla21/) and getting ready to start working on the paper, there was 1 week left.

I thought that this window was rather tight given that I had to clean the data, work on the entire code behind the paper from idea to implementation, and write the damn paper. **I knew this was gonna be tight, but oh boy.** I had one of the harshest weeks of my life. I barely slept for 7 straight days, and skipped the company team event in order to make it through the deadline.

Because of that, I will go into what happened at each step along the way with images. I will skip the cleaning data and boring parts, don’t worry. If you just want to read the final paper, you can find it here: [”Step Detection using SVM on NURVV Trackers”](https://ieeexplore.ieee.org/abstract/document/9680024).

Also, if you’ve been following me, you know how much I love open source. Owing to that I open source the code behind the project [here](https://github.com/DidierRLopes/step-detection-ML).

## Exploratory Data Analysis

The Nurvv trackers have an **Inertial Measurement Unit (IMU) tracks linear acceleration (accelerometer) and rotational rate (gyroscope)**. Sometimes it also contains a magnetometer. And Nurvv gave me access to 6 runs from 6 different runners.

My first step was to look into how this data looked. On the left you can see the acceleration (m/s²) and the angular velocity (rad/s).

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_2.png)

I knew that our **IMU had a sampling rate of 1125 Hz** (which means that each data point gets sampled at approximately every 888.89μs) and **this was critical in order to detect the oscillations that occur when a foot strike occurs** (i.e. impact of the foot on the floor makes the IMU oscillate). Thus I zoomed in the zone of impact and used a scatter plot to understand if we were “missing” information.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_3.png)

I found it interesting that **the distance between the samples were larger at the time of the impact**. So I plotted the IMU accelerometer data and the IMU gyroscope data in a 3D plot interactively as a function of time (below you can see a snapshot).

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_4.png)

From here it was interesting to note that when the foot is in the air, the samples are somehow concentrated (darker blue), whereas when a step occurs (more sparse) they behave erratically. The plot above was snapshotted with 3 steps that occurred.

From that 3D plot I had the intuition that by utilizing a **principal component analysis (PCA**)**, I could reduce the dimensionality without losing much information. The result is shown below,

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_5.png)

This made me think that I could use a **support vector machine (SVM)** in order to detect whether a foot strike has occurred or not. And what I was most excited about it was:

- **This model isn’t time-dependant.** Meaning that it would be fascinating to be able to predict whether a step occurred or not without the notion of time, but the current IMU data.
- We can develop an SVM model for each runner style. Then create an **ensemble model with hard voting** which allowed for the model that has seen more similar data, to be more confident in the classification of foot strike vs not foot strike.

But this was all a theory, I needed to prove it.

The first issue I had was: **SVM is a supervised learning model**. This meant that for the sampling data I was providing the model, I would have to classify whether those samples corresponded to a foot strike or not.

**The issue?** Although the product had **force sensitive resistors (FSR)** in the insoles, I didn’t have access to the samples that corresponded with these IMU samples.

So I knew that I would have to classify the data myself. Manually would have been a nightmare and not reliable enough, so I needed to build an algorithm that could classify the data quite reliably. **Signal processing theory, here I go.**

### Labelling data for a supervised learning problem

1. Get the raw IMU samples (accelerometer and gyroscope)
2. Do the difference in magnitude between the accelerometers samples and then the gyroscope samples
3. Apply root sum squared to the magnitude difference of accelerometer data, and then similarly to gyroscope data
4. Standardize the accelerometer data and the gyroscope data. This is so the data can be somehow compared with each other since the magnitude varies as one represents linear acceleration and the other angular rate.
5. Do the average between these 2 signals. This makes the data more robust.
6. Finally, apply a convolution to the resulting signal with a rectangular pulse. This allows to remove “drops” from the signal and ensures a smoother signal.

<br />

Below you can see the formulas and signal changes that were made in order to obtain the final result:

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_6.png)

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_7.png)

After this, I selected a sensible value of 0.3 to be used as a threshold on the resulting signal to classify step vs no-step.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_8.png)

I applied the difference between each first foot strike detected in order to make sure that there was no missed step. As you can see above the stride time is around 700ms which is what is expected of a runner jogging.

Someone might be wondering; If this gives such a great result, why did I need machine learning in the first place? **The reason is because standardization and convolution (steps 4 and steps 6) are a post-processing signal technique.** Therefore, it cannot be deployed in running time, and relies on data that happens in the future.

For illustration purposes, here is how the initial raw IMU data behaves against the labelling from signal processing approach (red background means no step, while green background means step).

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_9.png)

## Support Vector Machine for classification

For the model, SVM was selected because:

- It works well with high dimensional data (6 IMU samples) because it only uses a few of these points (called support vectors) to create this hyperplane (decision boundary) between classes.
- SVM is ideal for binary classification problems.
- RBF kernel allows to handle non-linear data.

This is the type of classification that SVM is capable of (this is the raw acceleration data with a PCA applied, and the SVM classification on the background for a model that was trained using that same data).

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_10.png)

### C and gamma hyperparameters

- Given each dataset is rather large to perform **grid search optimization** on C and gamma, a subset of each of the datasets is used to extract these parameters.
- Each dataset subset is now split: 80% for training data and 20% for validation.
- Thus, 80% of the data subset is used to apply SVM with different combinations of C and gamma over a 2D grid. The remaining 20% is used to test the logistic loss and assess optimal hyperparameters.

### Training and testing

- 80% of data is used for training and 20% is used for testing.
- Although the testing is done **out-of-sample**, given the nature of the data (where it comes from the same distribution) it is almost as if it was an **in-sample**.
- In our case this is ideal as we want each model to perform very well on its own dataset. We want each model to generalize well for that very specific type of data (runner style, speed and terrain).
- A 5-sample moving average is applied before assessing the classification of our model, this is to remove spurious samples. A small window needs to be selected to not introduce a delay in the recognition of a step.
- Since our data set is imbalanced (i.e. there are more samples being no-step than step samples) we’ll use **Geometric Mean (G-Mean) evaluation score**, since this measure tries to maximize the accuracy on each of the classes while keeping their accuracies balanced.

### Result

In the same dataset where we trained our SVM, we were able to achieve a G-Mean of 0.9645. This is rather expected since this is a powerful model and it was trained on that same data.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_11.png)

From the graph above this result is very positive given that the mislabelling always occurs at the boundary of a step / no-step detection. And since the sampling occurs very fast, we have some margin of error.

## Ensemble SVM model architecture

This model as expected had a poor performance in an unseen dataset. This is normal as the data came from a different runner, running at a different speed in a different terrain. Thus, in order to create a more robust model, we built this ensemble SVM model architecture.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_12.png)

Each dataset has the signal processing technique applied in order to obtain the labelling. With this labels, an SVM model can be trained.

Then, an **unseen dataset** (not used for training) will be used as input for all the trained SVM models. I.e. each input (3 accelerometer samples and 3 gyroscope samples) will be given to each SVM model which will output 0 or 1 to denote no-step or step, respectively.

My rationale there was: _I could do a major voting approach, BUT because of how I trained the data. It could happen that one of the models had the sample being very inside the boundary, whereas 2 others had it just outside, and the later would win. This is not what I was looking for._

Because of this boundary approach associated with SVMs, I knew that although SVM doesn’t provide probability estimates directly, these could be calculated. So I took advantage of that. And used that probability estimate to select whether the input was considered a stop or not. My rationale was: the model that has seen more similar IMU samples is likely to have a higher confidence in their output and as output they will have what I provided as a label in advance.

Finally, I applied a **5-sample moving average** to the step (1) / no-step (0) output and round the value to be classified as step and no-step. This allowed to remove spurious samples.

### Results

The prediction for a single SVM was extremely accurate because the model was trained on data samples from that same run (i.e. distribution). On the other hand, the ensemble prediction didn’t run on data from that distribution, hence, making this problem much more complex. However, even with that constraint, a G-Mean of 0.8756 was still achieved.

![image](/blog/2022-12-07-how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla_13.png)

## Future work

- Employ the data coming from the ”smart” insoles as an alternative ground-truth for determining step versus no-step conditions.
- The diversity of the data set can also be expanded to account for more surfaces, running speeds and styles.
- Explore whether the characteristics of the PCA plot of IMU data can be used to categorize different running styles.
- The exploration of different classification algorithms for the step detection problem, e.g. applying a long-short term memory (LTSM) neural network algorithm to exploit the time-dependency between samples.
- Implement this proof-of-concept code on the production NURVV Run system, to test the prediction technique in a real-life scenario and consider computational time.

## Final remarks

This was my first most technical blogpost where I went into details in how I wrote a ML paper that was accepted in a major conference in 1 week. Would love to know your thoughts on it.

Feel free to check the full paper version here: https://ieeexplore.ieee.org/abstract/document/9680024


---

---
slug: how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster
title: How ChatGPT allowed me to leverage Twitter API 10x faster
date: 2022-12-11
image: /blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster.png
tags: ['ChatGPT', 'Twitter API', 'Tweepy', 'Python', 'Programming']
description: Leveraging the power of ChatGPT to interact with Twitter API for real-time financial news updates.
---

<p align="center">
    <img width="600" src="/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster.png"/>
</p>

<br />

Leveraging the power of ChatGPT to interact with Twitter API for real-time financial news updates.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

For a while now, users have been asking for adding real-time financial news on [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal).

Since OpenBB Terminal is a command line interface for the world’s financial data, and there is no threading going on — there was never a very straightforward way to do this.

**Until today.**

After recalling [this tweet](https://twitter.com/elonmusk/status/1591121142961799168?s=20&t=j-cjTu-XA9SNcY8PBrbUnQ) from Elon earlier in November, I realized that I’ve been using Twitter for news substantially more than MSM.

![image](/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster_1.png)

So, my next train of thought was; What if I was able to somehow display the latest tweets from Twitter accounts that I trust. In particular, accounts that have up-to-date information and usually mention the words “JUST IN” or “BREAKING”. E.g. [@WatcherGuru](https://twitter.com/WatcherGuru) or [@unusual_whales](https://twitter.com/unusual_whales).

By doing this, I could then use the bottom of the OpenBB Terminal to highlight the news. An example of this is below:

![image](/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster_2.png)

## Coding and ChatGPT

The next step for me was to implement the code!

First, I needed to understand how I could have access to the last tweet of a specific user account. I already had a Twitter API account created, which meant I already had the key, token and secrets, therefore, I just needed to read documentation to understand how to use the Twitter API. Hence, I started reading [Twitter’s developer documentation](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent).

The day before I had been playing around with ChatGPT. And like everyone else, I was very impressed. One of the things that surprised me the most was how good it was at outputting working code with an explanation along the lines.

So, while I was reading the documentation, I was thinking “I wish there was a way for me to just be able to get the last N tweets of an account without needing to dig in the developer documentation”. Could ChatGPT be the answer?

So I tried…

![image](/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster_3.png)

This was already amazing. But I’m lazy and didn’t want to copy all the cells individually to put it into a Jupyter notebook, so asked ChatGPT to provide the code output as a single block. I wasn’t convinced it was going to work. **But it did**.

![image](/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster_4.png)

… it just worked. 🤯

After that, I needed the timestamp associated with the tweet, to see how old it was. As usual, I started looking into [Tweepy documentation](https://docs.tweepy.org/en/latest/authentication.html#twitter-api-v2).

**Ups, what was I doing again?**

After a couple of seconds, I went onto ChatGPT and asked how I could get the timestamp of a tweet using Tweepy library.

**And 🪄, it worked again!!!**

![image](/blog/2022-12-11-how-chatgpt-allowed-me-to-leverage-twitter-api-10x-faster_5.png)

One thing that is for sure: ChatGPT is going to truly disrupt many industries. And I will be here for it.

PS: The PR with this addition is in development [here](https://github.com/OpenBB-finance/OpenBBTerminal/pull/3757).


---

---
slug: firing-sucks-how-to-avoid-doing-so-by-hiring-a-players
title: Firing sucks. How to avoid doing so by hiring A players.
date: 2023-01-02
image: /blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players.png
tags: ['Hiring', 'Management', 'A Players', 'OpenBB', 'Career Advice']
description: Firing is tough. This blogpost discusses how to avoid it by hiring A players, improving the hiring process, and understanding the importance of a scorecard in recruitment.
---

<p align="center">
    <img width="600" src="/blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players.png"/>
</p>

<br />

Firing is tough. This blogpost discusses how to avoid it by hiring A players, improving the hiring process, and understanding the importance of a scorecard in recruitment.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

In 2022, [OpenBB](http://openbb.co/) grew to 20 people. But amongst all of our hiring, we also had to let some people go.

Before 2022, I had never fired anyone in my life but in my new role, I had to learn how to do it. If you’re a manager, you know that this is the hardest part of the job.

Having that said, I wanted to use my Christmas holidays to understand how we can avoid letting people go. For this, I needed to start from the beginning and improve our overall hiring process.

This blogpost will be highly based on the book **“Who: The A Method for Hiring” by Geoff Smart and Randy Street**, which I highly recommend.

## A method for hiring

What is an A player? _A candidate who has at least a 90 percent chance of achieving a set of outcomes that only the top 10 percent of possible candidates could achieve.

In this post, I will go over the steps to get an A team.

![image](/blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players_1.png)

## Scorecard

This is a document that describes the mission for the position, outcomes that must be accomplished, and competencies that fit with both the company culture and the role.

This is an example of what a scorecard should look like:

![image](/blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players_2.png)

Let’s go through each of the sections in this document.

### Mission

The mission is an executive summary of the job’s core purpose. It boils the job down to its essence so everybody understands why you need to hire someone in this role.

The book talks about how you should avoid hiring a generalist. In my opinion, it depends on the stage of the company. At OpenBB, we are able to ship fast with a small team because we have a lot of generalists that are A players. However, finding a generalist A player is a much harder task than finding an A player specialist. Here, we benefit from having an open source project, since we get to build with candidates before we hire them.

**How to:** _Develop a short statement of one to five sentences that describe why a role exists._

### Outcomes

Describes what a person needs to accomplish in a role.

> _“While typical job descriptions break down because they focus on activities, or a list of things a person will be doing, scorecards succeed because they focus on outcomes, or what a person must get done.”_

<br />

**How to:** _Develop 3 to 8 specific objective outcomes that a person must accomplish to achieve an A performance, ranked by order of importance._

### Competencies

Define how you expect a new hire to operate in the fulfilment of the job and how they can achieve their objectives. What competencies really count?

#### Ensure behavioural fit

Critical competencies for A players are: Efficiency, honesty/integrity, organization, aggressiveness, follow-through, intelligence, analytical skills, attention to detail, persistence, proactivity.

Others may include: Ability to hire A players, ability to develop people, flexibility/adaptability, calm under pressure, strategic thinking/visioning, creativity/innovation, enthusiasm, work ethic, high standards, listening skills, openness. to criticism and ideas, communications, team work and persuasion.

#### Ensure organizational fit

Evaluating cultural fit begins with evaluating your company’s values against the ones of the candidate.

Recently, at OpenBB, I asked everyone to share with me a list of values that we currently had and they were proud of, and/or values that they would like to use instead. In a startup, where the pace is incredibly fast and the team is in constant change, I strongly believe values change over time. So I looked at everyone’s inputs, and summarized them into the following OpenBB values: **Autonomy and Ownership, Innovation and Excellence, Transparent and Trustworthy, Diversity and Inclusion, Purpose and Passion, User Focused and Community Oriented.**

**How to:** _Identify as many role-based competencies that you think are appropriate to describe the behaviors that someone must demonstrate to achieve the outcomes. Next, identify 5 to 8 competencies that describe your culture and place those on every scorecard._

### From scorecard to strategy
The beauty of a document like this is that they become the blueprint that links the theory of strategy to the reality of execution. They translate your business plans into role-by-role outcomes, create alignment among your team, unify your culture and ensure people understand your expectations.

In addition, they allow you to monitor employee progress over time in your annual review system and to rate your team as part of their talent review progress.

**How to:** _Pressure-test your scorecard by comparing it with the business plan and scorecards of the people who will interface with the role. Ensure that there is consistency and alignment. Then share the scorecard with relevant parties, including peers and recruiters._

## Source

Systematic sourcing before you have slots to fill ensures you have high-quality candidates waiting when you need them.

### Referrals from your professional and personal networks

Create a list of the ten most talented people you know and commit to speaking with at least one of them per week for the next ten weeks. At the end of each conversation ask “Who are the most talented people you know?”. Continue to build your list and continue to talk with at least one person per week. “_Of all the ways to source candidates, the number one method is to ask for referrals from your personal and professional networks_”.

### Referrals from your employees

Add sourcing as an outcome on every scorecard for your team. Encourage employees to ask people in their networks. Offer a referral bonus. In-house referrals often provide better-targeted sourcing, this is because employees already know our needs and culture.

### Deputizing friends of the firm

Consider offering a referral bounty to select friends of the firm. It could be as inexpensive as merchandise or as expensive as a significant cash bonus. When talking with someone new at a party or a VC, always ask “_who do you know who might be a good fit for my company?_”

### Sourcing system

Create a system that (1) captures the names and the contact information on everybody you source and (2) schedules weekly time on your calendar to follow up. Try to spend 30 minute every week sending messages or having calls with candidates from this database of A players.

### Hiring external recruiters or hiring recruiting researchers

The book speaks about both, but from my experience of having an open company with an exciting mission that builds in public, these have not been relevant to us yet.

## Select

Create a series of structured interviews which build on each other so you can rate your scorecard.

### Screening Interview

Short, phone-based interview designed to clear out B and C players from your roster of candidates.

1. **What are your career goals?** If no goals echo your own website goals, screen them out. Ideally candidate will speak with passion and energy about their goals which are aligned with the role.

2. **What are you really good at professionally?** Make sure that with the list of strengths, there are always examples to backup the claim. Ensure that those strengths are relevant to the competencies required in the scorecard, if not, screen them out.

3. **What are you not good at or not interested in doing professionally?** Ignore strengths disguised as weakness. Ask again “what are you really not good at or not interested in doing?”, talented people will catch the hint. If you’re still struggling to get a proper answer, put the fear of a reference check into the person — “if you advance to the next step in our process, we will ask for your help in setting up some references. (…) What would these references say are something things you are not good at or not interested in?”

4. **Who were your last five bosses, and what would they each rate your performance on a scale of 1–10 WHEN we talk to them?** The word ‘when’ is the key to unlock the truth. A rating of 7 is neutral, we are looking for 8 and above. After the rating answer always press for details.

<br />

If you are happy with the interview so far, conclude the call by offering the candidate an opportunity to ask questions. Otherwise just thank them for their time.

**Tips:**

- Always compare the person’s strengths with the ones on the scorecard.
- When in doubt, there’s no doubt. You need to have the feeling that you have found the one.
- Get curious: What, How, Tell me more. Keep using this framework until you are clear about what the person is really saying.
- Hit the gong fast. If an answer automatically rules out a candidate, just end up the interview earlier and use your precious time to focus on A players.

### Who to Interview

Chronological walk-through of a person’s career.

You can begin by asking about the highs and lows of a person’s educational experience to gain insight into their background. After this, ask them 5 simple questions for each job they had in the past.

#### What were you hired to do?

You are trying to discover what their scorecard might have been if they had one for that role. Ask them “how was your success measured in the role? What was the mission and key outcomes? What competencies mattered?”.

#### What accomplishments are you most proud of?

Ideally, candidates will tell you about accomplishments that match the job outcomes they just described to you. Even better if they match the ones of the scorecard for the position you are trying to fill.

Note: _A players tend to talk about outcomes linked to expectations, B and C players talk generally about events, people they met, or aspects of the job they liked without ever getting into results._

#### What were some of the low points during that job?

People can be hesitant to share their lows at first. Keep reframing the question over and over until the candidate gets the message. E.g. “_What went really wrong? Biggest mistake? done differently? parts you didn’t like? peers stronger than you?_”

#### Who were the people you worked with?

- **What was your boss’s name and how do you spell that?**

Forcing candidates to spell the name out no matter how common it might be sends a powerful message: you are going to call, so they should tell the truth. This is referred as the “threat of reference check (TORC)”.

- **What was it like working with them?**

Ideally, you expect high praise for their bosses and how they received mentoring and coaching from them over the years. A neutral answer will sound somewhat more reserved — not positive nor negative.

- **What WILL they tell me about your biggest strengths and areas to improve?**

Use “will” instead of “would” so candidates know you mean business, and are therefore, more likely to tell you the truth since you will learn it from reference calls anyways. Dig in as much as you can.

- **How would you rate the team you inherited on an A, B, C scale? What changes did you make? Did you hire anybody? Fire anybody? How would you rate the team when you left it on A,B,C scale.**

This is applicable to managers. And allows you to understand how they approach building a strong team. Do they accept the hand they have been dealt with or do they make changes to make a better hand? What changes do they make? How long does it take?

Apply TORC here too: _“When we speak with team members of your team, what will they say were your biggest strengths and weaknesses as manager?”_

#### Why did you leave that job?

Was the candidate promoted, recruited or fired from each job? How did they feel about it? How did their boss react to the news? E.g. A players are highly valued by their bosses.

Get curious. Find out why and stick with it until you have a clear picture of what actually happened.

**Conducting an effective who interview**

- The hiring manager should conduct this interview. They own the hire, and are the ones who will suffer the consequences of making a mistake. Their career and job happiness depend on finding A players.
- Conduct an interview with a colleague (e.g. someone from HR, another manager or member of your team), this allows you to focus on questions and someone else to take notes.
- Kick off the interview by setting expectations, e.g. _“We are going to walk through each job you have held, for each job I am going to ask you five core questions. At the end we will discuss your career goals and aspirations and you will have a chance to ask me questions. If we mutually decide to continue, we will conduct reference calls to complete the process”._

**Master tactics**

1. **Interrupting.** You have to interrupt the candidate, there is no avoiding it. At least once every 3/4 minutes. Smile broadly, match their enthusiasm level, and use reflective listening to get them to stop talking without demoralizing them.
2. **The three P’s.** This helps you understand how valuable an accomplishment was in any context. (1) How did the performance compare to the previous year’s performance; (2) How did your performance compare to the plan?; (3) How did your performance compare to that of peers?
3. **Push versus Pull.** People who perform are generally pulled to greater opportunities. People who perform poorly are often pushed out of their jobs.
4. **Painting a picture.** You’ll only understand what a candidate is saying when you can literally see a picture of it in your mind. Always try to put yourself in their shoes.
5. **Stopping at the Stop signs.** Look for shifts in body language and other inconsistencies. “We did great in that role” while shifting in their chair, looking down and covering their mouth may be a stop sign. When that happens, get curious and understand how “great” they actually did. What was actually their contribution?

### Focused Interview

Getting to know more. This is NOT another Who interview. It provides the chance to invite other team member to get their opinion, but the script should be followed. Think of this interview as the “odds enhancer” to truly focus on the outcomes and/or competencies on the scorecard.

1. The purpose of this interview is to talk about [specific outcome or competency]
2. What are your biggest accomplishments in this area during your career
3. What are your insights into your biggest mistakes and lessons learned in this area?

<br />

Don’t be scared to use the “What? How? Tell me more” framework until you understand what the person did and how they did it.

Feel free to have multiple shorter focused interviews to understand particular outcome/competencies.

**Double-check the cultural fit.** Final gauge on the cultural fit — **critical!** Include competencies and outcomes that go beyond the specifics of the job to embrace the larger values of your company.

### Reference Interview

Testing what you learned. Don’t skip the references!

1. Pick the right references. Review your notes from the Who interview and pick the bosses, peers, and subordinates with whom you would like to speak. Don’t just use the reference list the candidate gives you.
2. Ask the candidate to contact the references to set up the calls. Some companies have a policy that prevents employees from serving as references, so you can increase your chances of talking with a reference if the candidate sets this up.
3. Conduct the right number of reference interviews. The book recommends 3 past bosses, 2 peers/customers and 2 subordinates.

<br />

**Reference interview guide:**

1. **In what context did you work with the person?** Conversation starter and memory jogger.
2. **What were the person’s biggest strengths?** Ask for multiple examples to put strengths and development areas into context. Don’t forget to get curious by using “What? How? Tell me more” framework to clarify responses.
3. **What were the person’s biggest areas for improvement back then?** The wording ‘back then’ liberates the reference to talk about weaknesses that existed in the past. “In truth, we believe, people don’t change that much. People aren’t mutual funds. Past performance really is an indicator of future performance.”
4. **How would you rate their overall performance in that job on a 1–10 scale?** What about their performance causes you to give that rating? Remember that 6 is really a 2. How does this rating compare with what the candidate said in advance? Wide discrepancy is alarming.
5. **The person mentioned that they struggled with ____ on that job. Can you talk more about that?** Test something the candidate told you by framing it as a question for the reference. E.g. “the person mentioned that you MIGHT SAY he was disorganized. Can you tell me more about that?” the wording is again very important as ‘might say’ suggests to the reference that they have permission to talk about the subject because the candidate raised it.

<br />

These questions follow the same pattern as the other interviews. This makes it very easy to merge what you hear with what you have already learned about a candidate.

**Tips:**

- **Avoid accepting a candidate’s reference list at face value.** E.g. either use your own network for gathering objective unbiased data or try to reach out to subordinates or people two levels below who interacted with the candidate to get a more honest answer.
- **Hearing or understanding the code for risky candidates.** Be able to read between lines. People don’t like to give negative reference, so your best defense is to pay close attention to what people say and how they say it. Examples of bad signs: If they just confirm dates of employment, um’s and er’s is hesitation, absence of enthusiasm (faint praise).

### Decide who to hire

**Skill-Will Bull’s Eye**

Does somebody’s skill (what they can do) and will (what they want to do) match your scorecard? This is a person’s skill-will profile.

![image](/blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players_3.png)

You should have plenty of data at this stage to make this assessment.

- **Skill has to do with a candidate’s ability to achieve the individual outcomes on your scorecard.** If you believe a candidate has a 90% or better chance to achieve a certain outcome based on the data gathered, rate them an A, otherwise a B or a C. Repeat for each outcome.
- **Will has to do with the motivations and competencies a candidate brings to the table.** For each competency, does the data suggest there is a 90% or better chance that the candidate will display that competency? If so rate them an A, otherwise a B or C. Repeat for each competency.

An A player is someone whose skill and will match your scorecard. Anything less is a B or C, no matter the experience or seeming talent level.

**Red Flags: When to dive beneath the surface**

These flags may not be deal killers, but they are likely to signal that there is something worth exploring beneath the surface:

- Does not mention past failures
- Exaggerates their answers
- Takes credit for the work of others
- Speaks poorly of past bosses
- Cannot explain job moves
- People most important to the candidate are unsupportive of a change
- For managerial hires, never had to hire or fire anybody
- Seems more interested in compensation and benefits than in the job itself
- Tries too hard to look like an expert
- Self-absorbed

More behavioral warning signs:

- Winning too much
- Adding too much value
- Starting a sentence with ‘no’, ‘but’, or ‘however’
- Telling the world how smart we are
- Making destructive comments about previous colleagues
- Blaming others
- Making excuses
- The excessive need to ‘be me’

**How to decide:**

1. Take out your scorecards that you have completed on each candidate
2. Make sure you have rated all of the candidates on the scorecard. If you have not given each candidate an overall A, B or C grade, do so now. Make any updates you need to based on the reference interviews. Look at the data, consider the opinions and observations of the interview team, and give a final grade.
3. If you have no A’s, then restart your process and the second step: source.
4. If you have one A, decide to hire that person.
5. If you have multiple A’s, then rank them and decide to hire the best A among them.

## Sell

Once candidates pass the selection, persuade them to join. The key to successfully selling your candidate to your company is putting yourself in their shoes.

### Five F’s of selling

There are 5 areas that candidates tend to care about, make sure to address each of these 5 areas until you get the person onboard.

1. **Selling Fit:** This ties together the company’s vision, needs and culture with the candidate’s goals, strengths and values.
2. **Selling Family:** Takes into account the broader trauma of changing jobs.
3. **Selling Freedom:** The autonomy the candidate will have to make their own decisions.
4. **Selling Fortune:** Reflects the stability of your company and the overall financial upside.
5. **Selling Fun:** Describes the work environment and personal relationships the candidate will make.

### Five waves of selling

Selling should be something that happens throughout the entire hiring process. In particular, there are five distinct phases that merit increased selling effort:

1. When you source
2. When you interview
3. The time between your offer and the candidate acceptance
4. The time between the candidate’s acceptance and their first day
5. The new hire’s first one hundred days on the job

### Persistent pays off

Once you have identified the right candidate, you must be persistent and do whatever you can to sign the deal.

### How to: sell A Players

1. Identify which of the five F’s really matter to the candidate.
2. Create and execute a plan to address the relevant F’s during the five waves of selling.
3. Be persistent. Don’t give up until you have your A player on board.

## Conclusion

In a more simplistic image, this is what the A method boils down too.

![image](/blog/2023-01-02-firing-sucks-how-to-avoid-doing-so-by-hiring-a-players_4.png)

I really enjoyed reading this book and I am taking a lot of these learnings to improve the hiring processes at OpenBB.


---

---
slug: financial-chat-bots-are-underrated-and-heres-why
title: Financial chat bots are underrated, and here’s why.
date: 2023-01-05
image: /blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why.png
tags: ['chatbots', 'finance', 'AI', 'Discord', 'OpenBB', 'OptionsFamBot']
description: In this blog post, we discuss the underrated potential of financial chat bots, our collaboration with OptionsFamBot, and why chat bots are becoming increasingly popular.
---

<p align="center">
    <img width="600" src="/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why.png"/>
</p>

<br />

In this blog post, we discuss the underrated potential of financial chat bots, our collaboration with OptionsFamBot, and why chat bots are becoming increasingly popular.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

At OpenBB, earlier this year we [joined forces with OptionsFamBot](https://openbb.co/products/bot). This was a bot that had a reach of over 1 Million users on Discord.

Today, [OpenBB Bot](https://openbb.co/products/bot) is one of our more powerful products and I still think a lot of people are sleeping on it.

### What is a chatting bot platform?

According to [ChatGPT](https://chat.openai.com/chat):

> _“A chatbot platform is a software service or tool that enables the creation, management, and deployment of chatbots. These platforms typically provide a variety of tools and features for building, testing, and deploying chatbots, as well as options for integrating chatbots with other systems or services. Some chatbot platforms are designed to support the development of chatbots for specific industries or use cases, such as customer service, e-commerce, or marketing. Others are more general purpose, and can be used to build chatbots for a wide range of applications.”_

<br />

### Why are chat bots not engaging?

I believe that one of the reasons for this is because people usually associate chatbots with customer service or marketing. Not as a finalized product but as a feature.

If I ask ChatGPT about this, the main reasons are: Lack of personalized conversation, limited capabilities, poor design and high error rate.

![image](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_1.png)

But wait.. ChatGPT is **LITERALLY** a chat bot. Everything happens through a chat interface, which shows that you can build a successful product as a bot, as long as it adds enough value to the user.

One could argue that ChatGPT is not done in an established chatting platform, and that is **partially true**. The reason I say partially is because ChatGPT has an API, so developers can use it to develop their own chatting bots and deploy it in whatever chatting app they are interested in.

## Examples of good chatting platforms

I believe that Discord is in the forefront here due to: Free, easy to use, allows customizing servers with roles/channels/permissions, high-quality voice chat, strong communities.

A testament to this is the fact that [midjourney](https://midjourney.com/) has built a successful chat bot that generates images from text prompts using AI, **SOLELY** relying on Discord. If you go into their website, the button “**Join the Beta**” takes you to their Discord server which has over **7 million users**!

As far as I know, this is the only example of a company that distributes their product solely through a chatting platform in a successful way.

![image](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_2.png)

## Why are chat bots getting more popular?

In my opinion, there are a few factors why chat bots are becoming more popular:

### Interactivity

The bots are becoming more interactive, almost working like an application within a chatting platform.

![interactivity](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_3.png)

### Speed

The speed of interaction is increasing over time, making the experience more seamless.

![speed](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_4.png)

### Customization

The level of customization allowed for these bots keeps on increasing.

![customization](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_5.png)

### Automation

You are starting to be able to create automated workflows. Not only for you, but for entire communities.

![automation](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_6.png)

### Notifications

It has notification features that can ping you similarly as if a friend sent you a message.

![notifications](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_7.png)

### Monetization

You are going to start to be able to monetize products through it.

![monetization](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_8.png)

### Community

You can use it within a server with friends/colleagues, and unlock a better user experience.

![community](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_9.png)

### Standardization

The product can work similarly on multiple chatting platforms. By keeping the same method of interaction / commands, the user is allowed to pick their favourite chatting platform or even use it in more than 1.

![standardization](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_10.png)

### Accessibility

These chatting platforms are developed for all devices and operating systems, making it a very powerful distribution system.

![last](/blog/2023-01-05-financial-chat-bots-are-underrated-and-heres-why_11.png)

## Why Finance?

I’ve spoke with over 100 people in the financial world in 2022. Over 50 are Bloomberg users. From those, 90% agree that their chatting feature is the most attractive feature — some of them going further and saying that that is the reason why they pay for it.

But what if you didn’t need to pay $26 k / year for such feature. What if you could pay to have access to servers with big names in the industry? Or what if you could create your own servers? What if while you were talking with Cathie Wood about ARK performance, you could also access financial data from ARK to back up your arguments? All this while not leaving the chat.

This is the reason why I believe that financial chatting bots will become popular in 2023. And [OpenBB Bot](https://openbb.co/products/bot) will be leading that wave.

Try it out for free on [OpenBB Discord server](https://openbb.co/discord) by using a command such as `/chart TSLA` and let me know what you think.

---

---
slug: how-to-get-hired-by-an-exciting-tech-startup-in-2023
title: How to get hired by an exciting tech startup in 2023
date: 2023-01-22
image: /blog/2023-01-22-how-to-get-hired-by-an-exciting-tech-startup-in-2023.png
tags: ['Career Advice', 'Tech Startups', 'Open Source', 'Job Hunting', 'Software Engineering']
description: The future is a strange place. We’re not entirely sure what it will look like, but we do know that it will be shaped by the choices we make today. And while I can’t tell you exactly how to get a job in 2023, I can help you set yourself up for success by showing you some of the best ways to build your career today.
---

<p align="center">
    <img width="600" src="/blog/2023-01-22-how-to-get-hired-by-an-exciting-tech-startup-in-2023.png"/>
</p>

<br />

The future is a strange place. We’re not entirely sure what it will look like, but we do know that it will be shaped by the choices we make today. And while I can’t tell you exactly how to get a job in 2023, I can help you set yourself up for success by showing you some of the best ways to build your career today.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Everyone is doing the same hacker tests. Being good at interviews will no longer suffice to get a job in top tech company. Conventional CVs are too boring. Recruiters may like what they read, but this doesn’t make them think any further about a person and think “wow, we really need someone like them”.

Ultimately, a CV cannot demonstrate creativity and in my opinion, to be a top engineer you need to be creative. Often there isn’t an easy straightforward solution and being creative is what distinguishes top tier engineers from medium. I wrote a post about this [here](/blog/stop-doing-your-cv-in-word-or-latex).

Below I will let you know my views on what I would do to get a job at an exciting tech startup.

## Work on open source projects

Open source is a great way to build your skills and get your name out there. It’s also a great way to make connections with other developers, which can lead to referrals and job opportunities. If you want to show that you’re a good engineer, open source is an excellent opportunity. This is because it allows you to demonstrate your problem-solving abilities, while also improving the codebase of a project that is potentially used by thousands of users — and because the project is open source, it never dies.

**But which open source projects should you choose?**

I’d say that there are two routes that you can take here. You can select the project based on your **own use case** or you can **be strategic** about it.

### Own use case

Don’t overthink it. The world of software is built on top of open source. If it weren’t for open source, we would be living in the year 2000 or less. This means that your favorite apps are relying on open source projects, which you can be a part of!

This means that you can:

- Contribute to an open source library that is used by a project that you like. E.g. someone from our team is a [cpython](https://github.com/python/cpython) contributor.
- Contribute to a product that you use that is Open Source. The advantage here is that you are able to literally customize the product that you are using.

With Red Hat in the 90s this open source movement is starting to be a very hot topic. [Joseph Jacks](https://twitter.com/JosephJacks_) from OSS Capital is one of the best investors (if not the best) in this space. The chart below that he put together illustrates well the growth of open source (shared in [this tweet](https://twitter.com/JosephJacks_/status/1494840009882361859?s=20))

![image](/blog/2023-01-22-how-to-get-hired-by-an-exciting-tech-startup-in-2023_1.png)

### Strategic

If you’re reading this, there’s a good chance that you want to make a positive impact on the future of technology. If so, it can be helpful to consider how your work will affect the lives of others. Take some time and think about what kind of role you would like to play in shaping those futures — are you someone who wants to improve people’s physical well-being through health innovations? Or maybe achieve more efficient energy use through new technologies? This will help determine which companies or projects might be best suited for any given career path.

Once you figure out what motivates you, select an industry where you wish to find a job.

Then there are multiple paths that you can take:

- Look into the signals provided by top venture capital firms in that selected industry. I.e. see what open source companies are being backed in that space.
- Look into the developer engagement around the open source projects in that industry. You can not only use GitHub stars and forks, but you can use tools such as [https://analyzemyrepo.com](https://analyzemyrepo.com/analyze/OpenBB-finance/OpenBBTerminal) or [https://ossinsight.io/](https://ossinsight.io/)
- Cold email VCs to ask them about which open source products they are excited about. I say VCs because often their job is to find these startups early, so usually they have more recent information. But talking with devs or listening to people that you respect in the industry is equally valid.

Note: By being an early contributor of a promising open source startup, you can become a core maintainer of a project and even make it to the founding team. This is how I met James, OpenBB’s co-founder. He was an active developer in my own open source project, and I invited him to be part of the main maintainers of the project. When we built a company, he became a founding member.

## Develop your own open source project

I strongly believe that being able to successfully build your own open source project is severely underrated. There are so many components that you need to get right from so many departments that it shows a lot about your strengths as an individual and a preview of the value you could add to the team.

You may think that the only thing that you are demonstrating is your ability to write high-quality code since it will be open to the public. Well that’s wrong. Here is a non-exhaustive list of skills that you show off

- Solution to a real-world problem
- Design around the product
- User experience
- How you prioritize task and how fast you can ship high-quality code
- Interaction with others
- Marketing
- Listening to feedback from users

This is what I did with OpenBB Terminal: [https://github.com/OpenBB-finance/OpenBBTerminal](https://github.com/OpenBB-finance/OpenBBTerminal) and it has single handedly changed my life.

## Conclusion

If you’re looking for a job in 2023, the best thing you can do is to contribute to/develop open source projects.

You should be aware that you can also add value to an open source project by reporting bugs. You can even do more than just report a bug, but suggest a solution or workaround for the problem — this shows that not only are you paying attention to what’s going on around you, but also that you have some ideas about how things could be improved — a combination that any hiring manager would love!

I hope you found this post insightful.

Any feedback is welcome.


---

---
slug: how-i-used-openai-api-to-improve-our-product-documentation
title: How I Used OpenAI API to improve our product documentation
date: 2023-04-01
image: /blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation.png
tags: ['OpenAI', 'API', 'Product Documentation', 'ChatGPT', 'Discord', 'OpenBB Bot']
description: In this blog post, I share how I used the OpenAI API to improve our product documentation. I used ChatGPT to generate more detailed descriptions for our OpenBB Bot Discord commands, making them more understandable for new users.
---

<p align="center">
    <img width="600" src="/blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation.png"/>
</p>

<br />

In this blog post, I share how I used the OpenAI API to improve our product documentation. I used ChatGPT to generate more detailed descriptions for our OpenBB Bot Discord commands, making them more understandable for new users.

The open source code is available [here](https://github.com/DidierRLopes/improve-documentation-using-openai).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The [documentation](https://docs.openbb.co/bot/reference/discord) of our free OpenBB Bot was pretty simplistic for most of the commands.

For instance, the description for the command `/dp alldp` was: "Last 15 Darkpool Trades", as seen below:

![image](/blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation_1.png)

For more experienced traders, this may be enough. But for new users, these 4 words may not mean much.

For context, this is the output that a user would get if running `/dp alldp` on our [Discord server](https://openbb.co/discord).

![image](/blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation_2.png)

So I talked with someone in our team about improving the documentation. Not only for the new users that wanted to utilize our free product but also so that we could train our own LLM on this better dataset.

Over the weekend I had the idea: What if I provided ChatGPT with the current description and an example of how to use the command and asked it to provide a more detailed description?

So the next step was to try whether ChatGPT would indeed improve the current documentation.

After a bit of prompt tweaking, I got a much better description than the one we currently had. See below:

![image](/blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation_3.png)

The next step was rather straightforward. I created a script that iterated [through all our OpenBB Bot Discord documentation](https://github.com/OpenBB-finance/OpenBBTerminal) files and updated the old description with a more detailed one.

This is the template prompt that I used:

> _Context: You are a developer writing a detailed documentation for a function that allows the user to retrieve desc utilizing the command example how would you explain what this command does in a single paragraph”_

Where **desc** and **example** corresponds to the current description and example that each of our commands have, respectively.

The results can be seen below (done on [this PR](https://github.com/OpenBB-finance/OpenBBTerminal/pull/4657)),

![image](/blog/2023-04-01-how-i-used-openai-api-to-improve-our-product-documentation_4.png)

As usual, I open source the script [here](https://github.com/DidierRLopes/improve-documentation-using-openai).

The funny thing is that I used an LLM output to improve our documentation. And we may use this data to train our own LLM.

LLM-ception?


---

---
slug: the-role-of-ai-and-openbb-in-the-future-of-investment-research
title: The role of AI and OpenBB in the future of investment research
date: 2023-04-03
image: /blog/2023-04-03-the-role-of-ai-and-openbb-in-the-future-of-investment-research.png
tags: ['OpenAI', 'future', 'ChatGPT', 'Discord']
description: How OpenBB can lead the future of finance using AI on top of an open source investment research platform.
---

<p align="center">
    <img width="600" src="/blog/2023-04-03-the-role-of-ai-and-openbb-in-the-future-of-investment-research.png"/>
</p>

<br />

How OpenBB can lead the future of finance using AI on top of an open source investment research platform.

The open source code is available [here](https://github.com/openbb-finance/OpenBBTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Introduction

This blogpost won't speak about what the OpenBB Terminal can offer today. Instead, we are going to share where we think AI can play a role in the future of investment research, and how through an open source platform, we can lead that wave.

A lot of this blog is based on the fact that the OpenBB Terminal is an open source investment research platform, and therefore it's very relevant to read [our blogpost about why we are open source](/blog/why-the-need-for-an-open-source-investment-research-platform).

Note: This blogpost will share several proof-of-concepts that are still within R&D and are not yet ready for production. Also, this blogpost will assume that you are aware of LLMs such as ChatGPT and WhisperAI.

## ChatGPT as the interface

An edge that incumbents have is the fact that they have been around for a very long time and spent a lot on educating users about their product. As a result, users are used to their platform. This makes it harder for users to switch to an unknown product, meaning they need to be 10x better than the competition for them to do so.

However, what if there was no learning curve? What if you could use a product for the first time and know how to access all the information you wanted without spending any time reading the documentation? In essence, the educational incumbent advantage would become obsolete.

With the new LLM advancements, such as ChatGPT. We are not far from this reality. Below is a proof-of-concept of what this could look like:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/FeYgQxnF_VY?si=3ZuXnyrWdW4UkqQy"
        width="800"
        height="400"
    />
</div>

Plus, if this is built on top of an open source project it means that the community can help in improving the model by providing more training data (e.g. provide a text as input and the corresponding command as output) or even confirm whether or not the chart that pops up was accurate.

In addition, along with data sources you can imagine that the community could start contributing with new languages for the GPT model. This makes using a new investment research platform easy, but more importantly makes retrieving information much faster and efficient.

The screenshot below shows that ChatGPT can accurately return the right OpenBB command when the user requests a certain type of data, as long as the model can be trained on our documentation:

![image](https://cdn-images-1.medium.com/max/1600/1*IWnSMNhHDyiulxri_hEB0g.png)

EDIT: Bloomberg introduced [BloombergGPT](https://openai.com/research/whisper) last week, and the following screenshot is taken from their research paper which validates the argument above.

![image](/blog/2023-04-03-the-role-of-ai-and-openbb-in-the-future-of-investment-research_1.png)

## WhisperAI as the interface

If we go one step further, instead of relying on text as input, the platform could rely on voice. With models such as [WhisperAI](https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance) we will be able to speak with the platform in order to retrieve financial data.

Below is a proof-of-concept showing how you can retrieve this data through voice.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/1CHti3nmWGY?si=yLF5AFHe91JFVgaS"
        width="800"
        height="400"
    />
</div>

One of the advantages of an automatic speech recognition (ASR) system is the fact that it doesn't rely solely on english and therefore, it would welcome people from all over the world to interact with the platform. Note: WhisperAI is open source and you can find more information on it [here](https://github.com/openai/whisper).

## GPT to build investment research reports

One of the new features that was announced with the [OpenBB Terminal 2.0](https://openbb.co/blog/openbb-terminal-2-acai) was the automated reports generation that utilizes [Netflix's papermill](https://netflixtechblog.com/notebook-innovation-591ee3221233) to leverage jupyter notebook templates.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/gHVyAZTampQ?si=s-4uIElohM-qzmNh"
        width="800"
        height="400"
    />
</div>

As it stands creating one of these notebook templates requires some coding skills and reading [OpenBB documentation](https://docs.openbb.co) to understand how to retrieve the data of interest providing the correct function and necessary arguments.

But, for a second, imagine if you could build these notebook templates with almost no-code?

The proof-of-concept below in combination with the automated report generation should allow you to further understand the breakthrough that we may accomplish in the future.

![image](/blog/2023-04-03-the-role-of-ai-and-openbb-in-the-future-of-investment-research_2.png)

My prediction is that open source + AI will disrupt the financial sector in the upcoming years, and OpenBB will be leading that wave.

---

---
slug: free-investment-research-ecosystem-to-consistently-beat-the-market
title: Free investment research ecosystem to consistently beat the market
date: 2023-05-05
image: /blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market.png
tags: ['OpenBB', 'Investment Research', 'OpenBB Terminal', 'OpenBB Bot', 'OpenBB SDK', 'OpenBB Hub']
---

<p align="center">
    <img width="600" src="/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market.png"/>
</p>

<br />

The OpenBB Hub is a comprehensive platform for managing all products, data, subscriptions, and content for users, aiming to empower investors globally with tools previously exclusive to institutions.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The OpenBB Hub is the new one-stop-shop for managing all products, data, subscriptions, and content for users!

## Introduction

When we started this journey, we always wanted to empower investors across the globe to have access to tools previously only available to institutions.

We started by building the [OpenBB Terminal](https://my.openbb.co/app/terminal) which is an open source investment research platform that users can customize as they see fit and build on top of.

If you haven’t starred the repo, now is a good chance to do so [here](https://github.com/OpenBB-finance/OpenBBTerminal) ⭐️.

Then, we wanted to address the social nature of investing. Instead of adding the chat functionality to OpenBB Terminal, we brought investment research data where these communities were already having fruitful discussions (Discord and Telegram). This makes much more sense from a user-convenience standpoint, and that’s how the OpenBB Bot was born. More information [here](https://my.openbb.co/app/bot).

As much customization as the OpenBB Terminal allowed, we didn’t give creators as much freedom as we could have since they would need to download the source code of the terminal in order to leverage our core.

![image](/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market_1.png)

But we we wanted to make this experience as seamless as possible so users could build on top of our foundation. Thus, we repurposed the core of the OpenBB Terminal into an OpenBB SDK that is “_pip installable_” from everywhere — [OpenBB](https://pypi.org/project/openbb/) . This means that all you need to have access to a universe of investment research data programmatically is python and running pip install openbb within a notebook.

This was a big win since the community reaction was very positive and we are now seeing it adopted by investors, educational courses, and even content creators. So much that we even created a tab to keep track of these on our [/open page](https://openbb.co/open).

However, we focused too much on the products and didn’t slow down to think about the user experience utilizing multiple OpenBB products. This is where OpenBB Hub comes into play. [OpenBB Hub](https://my.openbb.co/) is the platform we use to interact with our community, push OpenBB content, allow product management, and much more.

TL;DR:

- Allows to manage your OpenBB Terminal API keys, feature flags and settings. In addition, we allow users to save & share their openbb script routines
- Allows access to the OpenBB Terminal installer new versions
- Allows access to the OpenBB Bot dashboard — which allows fully customization from a user perspective. This improves your experience by 10x when using OpenBB Bot on Telegram or Discord.
- Allows to sign-up for early waitlist of OpenBB Terminal Pro

## OpenBB Hub - OpenBB Terminal

Since the beginning users have installed the OpenBB Terminal in multiple desktops due to its free nature. The issue? The API key management was a pain since there was not a way to sync these across different machines. Until now.

With [OpenBB Hub](https://my.openbb.co/) and using that account detail to log in the terminal, this problem gets fixed. Not only that, but users will benefit from default data sources, terminal color schema customization and even .openbb routines being manageable from Hub and more importantly accessible on a terminal instance as long as they login with their user details.

![image](/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market_2.png)

## OpenBB Hub - OpenBB Bot

Today we are also announcing the OpenBB Bot will be fully free for individuals. All you have to do is to register for the [OpenBB Hub](https://my.openbb.co/).

For users that were already users of our OpenBB Bot, the only change on the platform is pricing and an increase push towards better documentation and more tutorials. This is an initiative that we are taking company-wide to focus on better documentation and more content to fully leverage our suite of products.

OpenBB bot is critical to us as we work hard towards making a full ecosystem for investment research. And now you can access this experience for free, and share investment research data with your friends / colleagues.

![image](/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market_3.png)

## OpenBB Hub - OpenBB SDK

As the OpenBB SDK is in its core a pip installable package with its [own page on PiPy](https://pypi.org/project/openbb/) there aren’t a lot of functionalities that we can make available in this page. We allow the user to set their API keys similarly to what we do in the Terminal, to improve UX when utilizing the SDK.

In addition, we are going to display open source projects built by the community that leverage our core so that they can serve as an inspiration to you. If you are working on something that uses OpenBB at its core, tag your GitHub repository with “openbb” and we’ll add you to the list of projects that rely on our foundation.

![image](/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market_4.png)

## OpenBB Hub - OpenBB Terminal Pro (waitlist)

If all these features weren’t enough, we have decided to open the [OpenBB Terminal Pro WAITLIST](https://my.openbb.co/app/pro/early-access) for users who register on our OpenBB Hub.

The OpenBB Terminal Pro is something that has been months in the works and is yet our most exciting product to date. We have been holding back on it because we believe this will change the way investors think about investing. This time we worked with design partners and had dozens of user interviews from financial professionals to understand their pain points and what role we could fill. So even being able to start creating a waitlist around it is something that the team is very excited about.

We will gradually roll out the OpenBB Terminal Pro to a few users from the waitlist to get early feedback.

If you are one of these, I look forward to onboarding you personally 🤝

![image](/blog/2023-05-05-free-investment-research-ecosystem-to-consistently-beat-the-market_5.png)

## Final thoughts

Although OpenBB Hub is not a product per se, the amount of work that the team put together to make this happen is something nothing short of extraordinary. This was the first project where the entire team (~20 people from engineering, product, design and marketing) had to work together as whole.

The OpenBB Terminal dashboard is completely new, the concept of login had to be invented and needed to function perfectly with the Hub. The SDK page is also new. The OpenBB Bot dashboard already existed, but we made the tier for individuals completely free, so we had to update it to reflect that big pricing change. And finally, we open the OpenBB Terminal Pro waitlist.

The [OpenBB Hub](https://my.openbb.co/) is completely free.

All you have to do is to register so we can know more information about yourself regarding your primary usage for our products (professional, academic, personal) — this allows us to understand what features to prioritize in the future and improve the quality of our products.

In case you missed the webinar, you can view it below so that you are up-to-date with all the exciting new features that the team has released.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/_4dQs_q_Jtk?si=76h-YFtiqkATHisF"
        width="800"
        height="400"
    />
</div>

<br />


---

---
slug: fully-free-financial-chatbot
title: Fully free financial chatbot
date: 2023-05-09
image: /blog/2023-05-09-fully-free-financial-chatbot.png
tags: ['OpenBB Bot', 'Financial Chatbot', 'Investment', 'Free', 'Discord', 'Telegram', 'Equity', 'Crypto', 'Options', 'Darkpool', 'Economy']
description: The OpenBB Bot is a financial chatbot that allows you to access financial data from Discord or Telegram along with other users. From equity data to crypto, options, darkpool, economy and much more! Now available for free to registered users.
---

<p align="center">
    <img width="600" src="/blog/2023-05-09-fully-free-financial-chatbot.png"/>
</p>

<br />

The OpenBB Bot is a financial chatbot that allows you to access financial data from Discord or Telegram along with other users. From equity data to crypto, options, darkpool, economy and much more! Now available for free to registered users.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

We know the market conditions haven’t been great for anyone, particularly for investors. Instead of raising prices like trends, we have decided to offer our [OpenBB Bot](https://my.openbb.co/app/bot) individuals tier for free if you are a registered user.

## What does this mean

Registered users for OpenBB Bot will see the following changes:

- Users were limited to 100 options or dark pools commands per month. This limitation is completely removed.
- Users will no longer experience a 10s cooldown which means they can request investment research data sequentially and avoid breaking the conversation due to a delay imposed by the product
- Through our soon-to-be-announced new platform, you will be able to fully customize your charting style with up to 5 in chart technical indicators and 2 off charts. This is a big improvement over the 1 in chart and 1 off chart previously available.
- The number of custom alerts that the user can set for when certain threshold values are triggered has increased, from 3 to 10.
- Users can now set 10 watchlist tickers to pay close attention to and access data regarding them.

Below is a video of what the OpenBB Bot is capable of:

![1_d1vD4AkwpYk42tdbHuMupQ](/blog/2023-05-09-fully-free-financial-chatbot_1.png)

The interactive charts will open up within the [OpenBB Hub](https://my.openbb.co/) and in it you will be able to fully customize the technical analysis indicators that you see on the chart and even the candle chart color theme and type. A demo is shown below,

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/y2aYr0tXji4?si=VOV-G0Oc8INtm59Y"
        width="800"
        height="400"
    />
</div>

<br />

Like dozens of thousands of investors, join the OpenBB Hub so you can fully leverage the [OpenBB Bot](https://my.openbb.co/app/bot).

You can actually see how many users we have utilizing the bot on a daily basis on our [/open page](https://openbb.co/company/open/bot).

While others zig, we zag. Here’s the updated pricing:

![image](/blog/2023-05-09-fully-free-financial-chatbot_2.png)

Looking forward to feedback!


---

---
slug: leaving-london-to-live-in-san-francisco
title: Leaving London to live in San Francisco
date: 2023-05-13
image: /blog/2023-05-13-leaving-london-to-live-in-san-francisco.png
tags: ['San Francisco', 'London', 'Relocation', 'Visa Process', 'Startup', 'OpenBB']
description: Leaving London to live in San Francisco. A personal journey of relocating and starting a tech company in the heart of Silicon Valley.
---

<p align="center">
    <img width="600" src="/blog/2023-05-13-leaving-london-to-live-in-san-francisco.png"/>
</p>

<br />

Leaving London to live in San Francisco: A personal journey of relocating and starting a tech company in the heart of Silicon Valley.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Background

I was born in Geneva, and when I was 8 years old, we moved back to Portugal, which is where my parents are originally from. After spending most of my teenage years in Portugal, I left sunny Lisbon ☀️ to pursue a MSc. degree at Imperial College London 💻. That’s where I’ve been living and working up until now. The main reasons behind my desire to move to San Francisco ☀️ 💻 are the weather and the thriving tech ecosystem that surrounds it.

During the Covid pandemic while in London, I took the opportunity to build my own [personal open source investment research platform](https://github.com/OpenBB-finance/OpenBBTerminal). This project allowed me to secure VC funding and establish a company called [OpenBB](https://openbb.co/). As the CEO of this company, I feel privileged to have the chance to make a lasting impact on the financial industry. Embracing this adventure and collaborating with individuals who are much smarter than I am is the least I can do for our team and for OpenBB.

As a first-time founder, I often find myself feeling slightly behind, which is why I’m eager to absorb as much experience and knowledge as possible from other successful entrepreneurs. This is also why I managed to convince my wife and our dogs to join me in packing our bags and embarking on this journey into the unknown, much like my Portuguese ancestors did centuries ago 🚢.

Now, let’s dive into what truly matters. This will be a lengthy ride, so make sure you’re prepared for the journey ahead.

## VISA

First of all, you need to determine which visa you are eligible for in order to live and work in the US. You can find more information on this topic [here](https://travel.state.gov/content/travel/en/us-visas.html).

In my case, I decided to apply for an “O-1 Visa: Individuals with Extraordinary Ability or Achievement” and specifically highlighted my extraordinary ability in the field of Computer Science, specifically within the subfield of Automated Systems. It is crucial to specify a particular field to make the defense process smoother.

I had the privilege of working with an exceptional immigration lawyer who assisted me in crafting my case, significantly increasing my chances of a successful approval. Here is a portion of the O-1 Petition that was submitted:

![image](/blog/2023-05-13-leaving-london-to-live-in-san-francisco_1.png)

As you can see, there is quite a bit of paperwork required to support your case. In my situation, I needed the following documents: Curriculum Vitae, university grades, transcripts and diplomas, LinkedIn and GitHub profiles, posts that gained viral attention on platforms like Reddit and HackerNews, podcasts and conferences where I had spoken, projects that received online praise, any media coverage I had received, scholarly scientific publications, expert opinion letters, and even emails or direct messages from venture capitalists or professionals in the industry.

Essentially, any relevant evidence is used to strengthen your case. For me, the most crucial elements were the expert opinion letters provided by our lead investor, former colleagues, or respected individuals in the field who were familiar with my work, as well as the research papers I had published and the media coverage I had received.

Once my O-1 visa was approved, I simply needed to take my passport to the US embassy in London to obtain the visa stamp. It’s worth noting that if the wait time at the US embassy is lengthy, you have the option to visit another US embassy in another country where the process may be faster.

## Arriving to the country

I arrived in California on my own initially, with the plan for my wife and dogs to join me later. Thankfully, I had some contacts in California who provided me with their phone number and house address, which was helpful for getting settled. Since I didn’t have a phone before finding an apartment, I had to rely on roaming data using my plan from the UK, which resulted in additional expenses.

I would suggest either having a good deal for data roaming and international calls outside your country or obtaining a prepaid US phone. The latter is especially important if you’re traveling alone because I often encountered registration forms that didn’t accept foreign phone numbers.

Regarding payments, I used my Revolut VISA card, which offers excellent foreign exchange rates for converting pounds to dollars. It’s worth noting that I couldn’t open a US bank account without a Social Security Number (SSN).

### Social Security Number (SSN)

If you know someone in the US, it is advisable to apply for a Social Security Number (SSN) as soon as possible and provide their address and contact information if you don’t have a US address of your own. An SSN is necessary for various purposes, and it may take up to two weeks for the card to arrive. When going to you nearest Social Security Administration (SSA) office, I would suggest arriving 30 minutes before opening hours to avoid long queues.

To apply for an SSN, you will need to bring the following documents to the SSA office: your passport, the I-797 form (O-1 visa approval notice), and the I-94 form (arrival record in the US).

### Transportation

I had the fortunate opportunity of having a friend lend me a car as soon as I arrived in California, and it made my life ten times easier. I highly recommend having something lined up in terms of transportation, as having a car enables you to get anywhere you need to go much more efficiently. To ensure I was covered, I simply needed to arrange car insurance. I opted for [Progressive](https://www.progressive.com/), and the process was quick and straightforward.

While settling in, I occasionally relied on public transportation instead of driving, especially when traveling to the center of San Francisco. It took me some time to adjust to driving in the US, so public transport was a convenient alternative. If you plan on using public transportation services like BART or Caltrain, I suggest visiting [this website](https://www.iliveinthebayarea.com/knowledge-center/transit/) that provides information on available transportation options. It’s also a good idea to purchase a [Clipper card](https://www.clippercard.com/), which allows you to load funds and easily tap it when boarding.

Additionally, if you anticipate passing through tolls, bridges, or utilizing the fast lane on the freeway, I recommend looking into acquiring a [Fastrack transponder](https://www.thetollroads.com/accounts/fastrak/transponder/) for a more seamless experience.

## Finding an apartment

Apartment hunting proved to be quite stressful, considering that every day spent searching meant unnecessary expenses piling up while I still had my company to manage.

Using Uber for transportation was convenient and efficient, but the costs could add up quickly with multiple trips. To save money, I recommend scheduling house viewings on the same day in specific areas of interest and simply walking from one location to another.

While dealing with lease agents, I encountered a mix of competence levels. Some were highly efficient, while others were less so. If you’re genuinely interested in a particular apartment, it’s important to exert some pressure to keep the process moving forward. Don’t hesitate to call and inquire about updates.

I was fond of the first house we saw, so I promptly paid $300, which covered certain fees. These fees were refundable if we decided not to proceed, but more importantly, they ensured that the house would be taken off the market. At this stage, both the agents and I wanted the process to move as quickly as possible. In our case, the target timeframe was three business days; if the process exceeded that, the house would be made available again.

Even if you believe you’ve found the perfect apartment, I still recommend continuing your search until the lease contract is signed. It’s crucial to secure the apartment before assuming it’s yours.

Before obtaining the keys, we had several tasks to complete: making the first payment, setting up utilities ([PG&E](https://www.pge.com/) for Gas and Electricity, and [Conservice](https://utilitiesinfo.conservice.com/) for water), providing proof of renter’s liability insurance (I used [Assurant](https://assurantrenters.com/)’s as it was conveniently associated with the community), and undergoing a pet screening (note that certain dog breeds are considered more dangerous and may not be accepted).

Most importantly, my salary alone wasn’t sufficient to guarantee that we could afford the rent. I needed a guarantor to vouch for me, as Europe does not have the concept of credit ratings.

Fortunately, our lead investor graciously agreed to be our guarantor when I asked him. Without someone fulfilling this role, I would have had to rely on a third-party service and pay several thousands of dollars, which would have been non-refundable and solely for the right to lease the house. This arrangement seemed rather illogical.

## After the apartment

I needed to notify [USCIS](https://www.uscis.gov/) of my new address since the last one on file was associated with the hotel where I was staying. I informed them that my new residence would be the updated address.

Following that, my dogs flew from the UK using [Pets abroad UK](https://www.petsabroaduk.co.uk/). To save money, my wife didn’t accompany them on the flight; instead, she arranged for them to be transported in the cargo hold of the airplane while I waited at the destination.

However, I must admit that I didn’t enjoy the experience, and in hindsight, I would have been willing to pay more for my dogs to have a better and safer flight. Although flying them from London, meant that unfortunately cargo was the option due to UK requirements. When I picked them up, they were visibly scared, and both my wife and I held our breath with worry throughout their entire journey. Our dogs’ well-being was of utmost importance to us.

![image](/blog/2023-05-13-leaving-london-to-live-in-san-francisco_2.png)

The house was mostly empty, so to save money, we acquired a lot of second-hand items for free. It was beneficial to know people in the area who were aware of others with unused items stored in their garages, which we were able to take. To retrieve this furniture and other objects, we either needed to rent a U-Haul (which wasn’t possible without a California driver’s license) or hire a moving company.

Our next task was to search for second-hand items at significant discounts on websites such as [Craigslist](https://sfbay.craigslist.org/), [Nextdoor](https://nextdoor.com/) and [Facebook Marketplace](https://www.facebook.com/marketplace). However, we had to be cautious of scammers and remember that if a deal seemed too good to be true, it probably was.

Once we had gathered most of the second-hand items, we visited [Home Depot](https://www.homedepot.com/) to paint and improve the newly acquired furniture. For the items we couldn’t find second-hand, we made purchases at [Costco](https://www.costco.com/).

We highly recommend getting an executive membership at Costco as it provides great value for money. Additionally, the gas prices at Costco are significantly cheaper compared to other places we’ve seen.

### Wi-Fi + Mobile plan

After securing an apartment, I used my passport to visit an [AT&T](https://www.att.com/) store. Since I didn’t have my SSN yet, they were accommodating and allowed me to use my passport for identification. However, if you choose a different service provider like Xfinity, you will need your SSN. Before selecting a plan, it’s important to check the coverage in your area to ensure that 4G/5G works well.

Initially, I set up Wi-Fi through Xfinity, but then I used that as leverage to negotiate a discount with AT&T. This worked because I was interested in a double play package, which included two phone plans and Wi-Fi. As a result, I obtained an e-sim with unlimited 5G data for both myself and my wife, along with Wi-Fi for our home, at a cost of approximately $150 per month.

### Shopping

There’s going to be a big shock in terms of prices; at least, we experienced one. Life in the Bay Area is over 2x more expensive than London.

![image](/blog/2023-05-13-leaving-london-to-live-in-san-francisco_3.png)

So, we started learning how to buy things at a lower cost. Whole Foods is not a viable option as it’s one of the most expensive stores. The 10 items above cost $69.34 on Whole Foods.

Instead, we now tend to shop at Safeway and always try to time our visits to take advantage of discounts. Many shopping places offer coupons that can help you save a lot of money. Additionally, when you come across products on sale, it’s better to buy them in larger quantities as it’s usually worth it.

My wife is also a big fan of Trader Joe’s with the prices there being quite reasonable too. They also have a great selection of cheeses which is a must being from Europe.

## After obtaining an SSN

After you obtain your SSN, there are a lot of new things that you are able to do since you are recognized as a “person.”

### Bank account

Credit cards are recommended over debit cards, not just because of the security benefits, but also because of the credit rating associated with them. This is a concept that doesn’t really exist in Europe but is significant in the US. Your credit score will determine whether you are approved for a loan and what interest rate you will be charged.

The agencies that handle your credit score are [Equifax.com](http://equifax.com/), [TransUnion.com](http://transunion.com/) and [Experian.com](http://experian.com/). It’s free to register, and you should keep an eye on your credit files to ensure that your credit score doesn’t decrease for any reason.

We ended up opening an account with [Bank of America](https://www.bankofamerica.com/). However, since we didn’t have a credit score yet, we couldn’t get a regular credit card. Instead, we had to apply for a secured credit card, where the maximum spending limit is determined by the amount of cash we use to back the credit card.

We also applied for an [AMEX card](https://www.americanexpress.com/us/credit-cards/card/blue-cash-everyday/?eep=26129&irgwc=1&veid=39E0XuRS3xyNT4BTy33WSUXYUkAwp0Tx32Qt0c0&affid=1193684&pid=IR&affname=NerdWallet%2C+Inc.&sid=14011830016&pmc=795&BUID=CCG&CRTV=controlaffcps&MPR=03) because [American Express](https://www.americanexpress.com/) has a partnership with the international credit-reporting startup Nova Credit. This allows immigrants to instantly translate credit reports from the UK to U.S.-equivalent credit reports when applying for AmEx consumer cards. However, it’s important to note that AMEX cards are less widely accepted compared to VISA and MasterCard, so we were aware that they would only work in certain establishments.

For more information, these video were extremely helpful:

- [Building credit and keeping yours healthy](https://bettermoneyhabits.bankofamerica.com/en/credit/building-credit)
- [How to build credit from scratch](https://bettermoneyhabits.bankofamerica.com/en/credit/start-building-credit)
- [Top 3 credit questions](https://bettermoneyhabits.bankofamerica.com/en/credit/top-credit-questions)

### Car

It was now time for us to buy a car. We searched online for a few options. There are two things worth considering when buying a used car, as we did:

- Firstly, you can use [https://www.kbb.com/car-values/](https://www.kbb.com/car-values/) to research the value of the car. This ensures that you don’t get ripped off and provides an estimate of how much the car is worth based on the details you provide.
- Secondly, you can use [https://www.carfax.com/](https://www.carfax.com/) to research a car and its license plate. This helps you understand its accident history and any repairs it has undergone. It provides information about whether there have been major accidents in the car’s history, frequent visits to the mechanic, and whether the repairs were done by authorized mechanics (e.g., BMW) or not.

If you prefer to play it safe, you can even bring a mechanic with you to the dealership to assess the car’s condition.

We spoke with individuals, but ultimately decided to buy a car from a dealership because it offered fewer risks compared to buying from individuals. Moreover, the dealership took care of updating the vehicle records, ensuring that the vehicle would be registered under our name. This allowed us to update our car insurance with the Vehicle Identification Number (VIN) of the new vehicle.

After a few months, we received the California Certificate of Title, which confirmed that I was the legal owner of the vehicle and included important vehicle identification information. Since this was my first car, I had to add an OpenBB reference to the front plate :)

![image](/blog/2023-05-13-leaving-london-to-live-in-san-francisco_4.png)

Shoutouts to:

- [Jiffy Lube](https://www.jiffylube.com/) for their car inspection services, tire inflation, oil changes, and more. They don’t charge for the inspection and only charge for the services performed on the car. We had a great experience with them.
- [Costco gas station](https://www.costco.com/gasoline.html) for the cheapest gas we’ve found so far.

### Health Insurance

California offers a portal called [Covered California](https://www.coveredca.com/), which provides state-approved health plans from various insurance companies. If your income is low, the state can subsidize your monthly premium. These plans fall into three categories, each with differences in costs and provider networks:

<ol>
  <li>HMOs (Health Maintenance Organizations): Typically cheaper than PPOs, HMOs have smaller networks. You need to see your primary care physician before getting a referral to a specialist.</li>
  <li>PPOs (Preferred Provider Organizations): Usually more expensive, PPOs offer a larger network and the ability to see providers outside of the network. You can also see specialists without a referral.</li>
  <li>EPOS (Exclusive Provider Organizations): EPOS plans combine features of HMOs and PPOs. They have exclusive networks like HMOs, making them generally less expensive. However, you can make your own appointments with specialists, similar to PPOs.</li>
</ol>

In our case, we chose an HMO called Kaiser. [Kaiser](https://healthy.kaiserpermanente.org/northern-california/front-door) is a not-for-profit, all-inclusive healthcare company with its own doctors and hospitals. When selecting the plan within Kaiser, we had to choose between Bronze, Silver, and Gold tiers. These tiers are influenced by three main factors:

<ol>
  <li><strong>Monthly premium:</strong> The amount you pay each month for health plan coverage. It may be subsidized based on your income and household size.</li>
  <li><strong>Annual deductible:</strong> The amount you must pay before your plan starts covering services.</li>
  <li><strong>Annual maximum out-of-pocket:</strong> The total amount you pay in a calendar year (in addition to monthly premiums) for most services covered by your health care plan.</li>
</ol>

### California Driving License

The Department of Motor Vehicles (DMV) is responsible for vehicle registrations and driving licenses in California. When you arrive in California, you can use a foreign driving license for only 10 days, after which you must obtain a California Driving License (CDL).

To apply for the CDL, you can start the process online by completing the driver’s license application on the [DMV website](https://www.dmv.ca.gov/portal/). This online application saves time by allowing you to fill it out before visiting a DMV field office.

When you visit the DMV, the employees will review your completed application and request certain documents, including:

- Social Security Number (SSN)
- Unexpired foreign passport with a valid U.S. visa
- Approved I-94 form
- Bank and financial institution records
- Insurance documents

After submitting the required documents, you will have your picture taken and then proceed to take the written driving test. It’s advisable to practice for the test in advance. As I have many years of driving experience, I personally used practice tests available at [https://www.dmv-written-test.com/california/practice-test-1.html](https://www.dmv-written-test.com/california/practice-test-1.html).

A few days later, I returned to the DMV to take the written test. The test consists of 36 multiple-choice questions, and you are allowed to fail up to 6 questions. You will immediately know whether you passed or not.

Upon passing the written test, you will receive a document that allows you to schedule your driving exam. It is recommended to book the exam as soon as possible, as available slots may be several weeks away due to high demand.

On the day of the driving exam, you will need to bring someone who holds a CDL, the document provided after passing the written exam, and your passport.

The driving exam evaluates your performance, and you will receive a score sheet outlining the criteria and aspects that will be assessed during the exam. This will give you an idea of what to expect and what the examiners will be evaluating.

![image](/blog/2023-05-13-leaving-london-to-live-in-san-francisco_5.png)

After successfully passing the driving exam, the DMV will issue you a temporary document that serves as your California Driving License (CDL). This temporary document will allow you to legally drive while you wait for your physical CDL to be sent to you by mail.

It typically takes a few months for the physical CDL to be processed and mailed to your designated address. During this time, you can use the temporary document as proof of your driving privileges in California. Once you receive the physical CDL, you should carry it with you whenever you are driving.

It’s important to note that the temporary document and the physical CDL have the same validity and serve as official proof of your driver’s license status.

## Final thoughts

I’ve moved countries a few times within Europe, and those moves were much easier than moving to the USA.

Nonetheless, I think you can get settled within 3 months of moving to the country. So far, we are really enjoying our experience and can’t wait to explore more of the area.

If you are looking to do the same and want some feedback, feel free to reach out. It helped us a lot to have people who could help us with the move, so I’d love to be able to do the same for others.


---

---
slug: openbb-terminal-3-0-a-new-interactive-way-to-analyze-data
title: OpenBB Terminal 3.0 - a new interactive way to analyze data
date: 2023-05-20
image: /blog/2023-05-20-openbb-terminal-3-0-a-new-interactive-way-to-analyze-data.png
tags: ['OpenBB', 'OpenBB Terminal', 'Interactive Charts', 'Interactive Tables', 'Data Analysis', 'Open Source']
description: A game-changing update to OpenBB Terminal, introducing interactive charts and tables, empowering users with a new way to analyze data.
---

<p align="center">
    <img width="600" src="/blog/2023-05-20-openbb-terminal-3-0-a-new-interactive-way-to-analyze-data.png"/>
</p>

<br />

A game-changing update to OpenBB Terminal, introducing interactive charts and tables, empowering users with a new way to analyze data.

The open source code is available [here](https://github.com/openbb-finance/OpenBBTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Nothing has changed, yet everything is different. A game-changing update empowering users with interactive charts and tables

Our commitment to listening to user feedback and continuously improving our platform has led to a major update that will revolutionize the way you analyze data.

One of the main requests from our community has been regarding the interactivity of the charts and tables output by the [OpenBB Terminal](https://my.openbb.co/app/terminal). We are happy to say that we have delivered on this request with a complete overhaul of the terminal plotting library.

Not only that, but our engineering team wasn’t happy with the technical solutions available to bring interactivity to the terminal. So, in a true open-source fashion, the team built our own open-source library which will be announced soon.

## Interactive charts

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/oAUK-kC0uv0?si=A_5ZxITto7ADgJ2V"
        width="800"
        height="400"
    />
</div>

<br />

One of the most significant additions in this update is the introduction of interactive charts. Gone are the days of static data representations.

With the OpenBB Terminal, you can now immerse yourself in a dynamic visual experience. Hover over specific data points to reveal detailed information, or effortlessly adjust the charts using intuitive pan and zoom capabilities. But that’s not all — our drawing tools and annotations allow you to highlight crucial data points and ranges, giving you complete control over your analysis.

Through our user interviews, we discovered that many users faced challenges when overlaying financial time series. Taking this into account, we’ve designed our new charting feature to make this process seamless. With the ability to easily overlay time series data and combine it with our powerful data exporting capabilities, OpenBB Terminal empowers you to perform in-depth analysis with unparalleled ease and precision.

## Interactive tables

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/GNh7RQBHNUc?si=GKf7hYaR7VQKBLp-"
        width="800"
        height="400"
    />
</div>

<br />

We listened to our users’ concerns about readability when dealing with large tables, and we have addressed these challenges head-on. The OpenBB Terminal now boasts interactive tables that are as aesthetically pleasing as they are functional.

Leveraging our innovative open-source project, we have crafted a state-of-the-art table that is easy on the eyes and effortlessly responsive. Sorting, filtering, and manipulating table data has never been easier. This game-changing feature enables you to quickly and efficiently extract insights from vast amounts of data, enhancing your productivity and saving valuable time.

## New fixed income menu

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/mLa4rcDfYTE?si=cQkz9BYJTCZ0cTwx"
        width="800"
        height="400"
    />
</div>

<br />

In addition to the remarkable advancements in interactivity, we have squashed bugs and introduced a new Fixed Income menu. This means you now have access to an even wider range of data to fuel your analysis. OpenBB Terminal ensures that you are equipped with the right tools to gain a competitive edge in your investment research.

## Wrap up - embrace the future of data analysis

We firmly believe that these new features will take your user experience to new heights and unlock a realm of possibilities for data analysis. Our dedicated team has poured countless hours into bringing these cutting-edge features to life, and we cannot wait to witness the impact they will have on your work.

To further amplify our commitment to open source, we will open source a powerful project that taps into web browser functionality from Python, opening up endless opportunities for developers and data enthusiasts.

We value your feedback and are eager to iterate on the OpenBB Terminal to ensure it meets your evolving needs. Reach out to us via email at hello@openbb.finance, Twitter, or Discord and let us know how we can enhance your experience further.

If you missed our exciting webinar unveiling these transformative features, fear not! We’ve got you covered. Watch the video below to catch up and witness firsthand the incredible new capabilities our team has unleashed.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/_4dQs_q_Jtk?si=1BRr1pF2SRrkC3lZ"
        width="800"
        height="400"
    />
</div>

<br />

Welcome to a new era of data analysis with OpenBB Terminal. Get ready to explore, discover, and gain a competitive edge like never before.


---

---
slug: streamline-your-openbb-terminal-experience-with-openbb-hub
title: Streamline your OpenBB Terminal experience with OpenBB Hub
date: 2023-05-25
image: /blog/2023-05-25-streamline-your-openbb-terminal-experience-with-openbb-hub.png
tags: ['OpenBB', 'OpenBB Hub', 'Terminal', 'API Key Management', 'Data Customization', 'Personalization', 'Script Management']
description: Streamline your OpenBB Terminal experience with OpenBB Hub. Learn about its key features, including API key management, data customization, personalization, and script management.

---

<p align="center">
    <img width="600" src="/blog/2023-05-25-streamline-your-openbb-terminal-experience-with-openbb-hub.png"/>
</p>

<br />

Streamline your OpenBB Terminal experience with OpenBB Hub. Learn about its key features, including API key management, data customization, personalization, and script management.

The open source code is available [here](https://github.com/openbb-finance/OpenBBTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

If you’re using the OpenBB Terminal, there’s an essential component you shouldn’t miss out on: the [OpenBB Hub](https://my.openbb.co/). In this blog post, we’ll explore the significance of OpenBB Hub and why it truly matters for OpenBB users.

By delving into its key features, we’ll uncover how OpenBB Hub elevates your experience with the OpenBB Terminal, providing you with enhanced capabilities and customization options. Let’s dive in!

## Login

As highlighted in our previous blog post [Introducing the OpenBB Hub](https://openbb.co/blog/introducing-the-openbb-hub), the OpenBB Hub is more than just a platform to access the OpenBB product ecosystem; it adds value to each individual product. Specifically, when it comes to the OpenBB Terminal, having an OpenBB Hub account offers tremendous advantages.

Notably, the settings and features you configure within the hub persist across terminal updates and even when you log in from a new machine, allowing for a seamless and personalized experience.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/HNEZ6h2K9C4?si=qD9OmbHo9SGEkUM5"
        width="800"
        height="400"
    />
</div>

## Streamlining API key management

A common question we receive is about the source of our data. OpenBB doesn’t own any data; instead, we enable users to access data from various vendors by signing up for plans on their respective websites. This approach allows us to focus on platform development and data standardization while giving users the freedom to pay for the high-quality datasets they desire.

Previously, managing API keys was only accessible through the terminal CLI, which could be suboptimal. To alleviate this, we introduced the capability to manage API keys directly from a web page, reducing friction and putting the focus back on what matters most: access to data.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/IrHMEuWQiiQ?si=usaVWmOOWRPqEakq"
        width="800"
        height="400"
    />
</div>

## Enhanced data customization

With OpenBB Hub, you have the power to set default data sources, enabling you to choose the data vendor that aligns best with your needs for each command within the terminal. This flexibility empowers you to curate your preferred data sources, providing a tailored experience that optimizes your decision-making process.

## Infuse personal style into your terminal

OpenBB Hub lets you personalize your terminal by customizing its colors to your liking. From the command line interface menu to interactive tables and even charting colors, you have the freedom to create your own custom color scheme. Whether you prefer soothing pastel shades or bold neon colors, the choice is yours.

This feature not only adds a touch of personalization but also ensures a comfortable and visually pleasing experience, reducing eye strain during extended usage. Say goodbye to the standard white background and say hello to a terminal that reflects your unique style.

## Effortless routine scripts management

We’ve noticed a growing trend among our users: the development and adoption of routine scripts. These .openbb files contain OpenBB commands and allow users to save their investment research workflows, as well as share them with others.

While OpenBB Hub provides access to pre-defined scripts developed by our team, which have been extensively used in academia, it also allows you to manage your own scripts. In the near future, we will introduce a community scripts page, fostering script sharing and discussions on individual use cases.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/S0PIl8qEBCo?si=Lc4u2bG_NRWNhRhf"
        width="800"
        height="400"
    />
</div>

## Final thoughts

The OpenBB Hub has become the central platform where we closely engage with the community, continuously striving to add value to your experience when utilizing our suite of products. We encourage you to share your feedback and ideas with us to help shape the future of OpenBB.

Join the OpenBB Hub today, and spread the word among your peers, so we can grow together and create an even more vibrant community.

Check out the OpenBB Hub user metrics [here](https://openbb.co/company/open?type=hub), and if you missed our recent webinar, you can catch up on all the exciting new features in the video below.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/_4dQs_q_Jtk?si=Wqu2vi2EWUww3gfK"
        width="800"
        height="400"
    />
</div>

<br />

With the [OpenBB Hub](https://my.openbb.co/), you unlock a world of possibilities.


---

---
slug: become-an-openbb-champion
title: Become an OpenBB Champion
date: 2023-06-10
image: /blog/2023-06-10-become-an-openbb-champion.png
tags: ['OpenBB', 'OpenBB Champion', 'Investment Research', 'Open Source', 'Community']
description: Become an OpenBB Champion and join our passionate community. Share your experiences with our innovative products and help us democratize investment research through an open source approach.
---

<p align="center">
    <img width="600" src="/blog/2023-06-10-become-an-openbb-champion.png"/>
</p>

<br />

Become an OpenBB Champion and join our passionate community. Share your experiences with our innovative products and help us democratize investment research through an open source approach.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Do you find yourself unable to live without one of OpenBB’s innovative products? Have you pushed the boundaries of our tools and unlocked their full potential? If you answered yes, then this blog post is tailor-made for you!

At [OpenBB](https://openbb.co), we are actively seeking out [OpenBB Champions](https://my.openbb.co/app/hub/champions) — passionate community members who share our vision of democratizing investment research through an open source approach.

Whether you utilize the [OpenBB Terminal](https://my.openbb.co/app/terminal) to streamline your investment research workflow, leverage the [OpenBB SDK](https://my.openbb.co/app/sdk) to create your own internal dashboards and notebooks, or employ the [OpenBB Bot](https://my.openbb.co/app/bot) to extract financial data within your finance community, we want to hear from you!

To qualify as an OpenBB Champion, you need to be an active user of one of our products and be willing to share your valuable experiences with our team. We’re eager to learn more about your journey with OpenBB and how our products have transformed your workflow.

<p align="center">
    <img width="400" src="/blog/2023-06-10-become-an-openbb-champion_1.png"/>
</p>

<br />

**Where's what we would like to know:**

- Your background
- How you heard about OpenBB
- Workflow transformation since incorporating OpenBB into your toolkit
- Your favorite OpenBB product
- Your favorite feature within that product
- Future expectations from us
- Your end goal — ultimate objective or milestone

As an OpenBB Champion, your contribution will not go unnoticed. Here are the benefits you’ll receive:

### Exposure

Your testimonial will be prominently featured on OpenBB’s website, social media channels, and other marketing materials. This exposure will introduce your expertise to a wider audience, increasing your visibility within the investment research community.

### Recognition

You will be officially recognized as an OpenBB Champion, highlighting your commitment to innovation and industry-leading practices. This recognition can bolster your credibility and authority in your field of expertise.

### Networking

As part of the OpenBB Champion community, you will have exclusive access to networking opportunities with like-minded individuals who share your passion for OpenBB’s products. Forge meaningful connections, exchange ideas, and collaborate with fellow champions to amplify your impact.

### Merchandise

To show our appreciation for your support, the OpenBB team will send you exclusive OpenBB merchandise. Wear it proudly and let others know that you are part of our journey.

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

If you meet the requirements and are enthusiastic about becoming an [OpenBB Champion](https://openbb.co/blog?type=champions), we invite you to reach out to us at hello@openbb.finance. Our team will coordinate a podcast session with you.

We look forward to hearing from you.


---

---
slug: hybrid-work-sucks-its-worse-than-remote-and-office
title: Hybrid work sucks. It’s worse than remote and office.
date: 2023-06-12
image: /blog/2023-06-12-hybrid-work-sucks-its-worse-than-remote-and-office.png
tags: ['remote work', 'office work', 'hybrid work', 'productivity', 'work culture']
description: Hybrid work, a combination of remote and office work, is not as beneficial as it seems. This blog post discusses the pros and cons of remote and office work, and why hybrid work might not be the best solution.
---

<p align="center">
    <img width="600" src="/blog/2023-06-12-hybrid-work-sucks-its-worse-than-remote-and-office.png"/>
</p>

<br />

Hybrid work, a combination of remote and office work, is not as beneficial as it seems. This blog post discusses the pros and cons of remote and office work, and why hybrid work might not be the best solution.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This is my hot take for 2023, but bear with me.

## Context

Everyone on Twitter has been actively discussing that “Remote work failed”, e.g. [this tweet](https://twitter.com/DavidSacks/status/1663958149437743105?s=20) from David Sacks where he refers to [this blogpost](https://flocrivello.com/changing-my-mind-on-remote-about-being-in-san-francisco/), or [this tweet](https://twitter.com/paulg/status/1667580108247277570?s=20) from Paul Graham.

While I’m not going to pose as an expert on the topic, I feel like I’ve experienced enough to have an opinion. My career so far has been:

- 1 year of office work for a public company
- 1 year of remote work for a startup, plus a few months of hybrid work for the same startup
- 2 years of growing [OpenBB](https://openbb.co/) from 1 to 20 people, all fully remote.

Let me first go over the advantages and disadvantages of remote and office work, so that I can focus this blog post on **why hybrid sucks**.

## Remote work

First of all, let’s be pragmatic — remote works. (Before people comment, of course if you’re a factory worker or similar, this doesn’t apply).

### Advantages

<ol>
    <li><strong>Increased employee retention and satisfaction:</strong> Remote work is seen as a desirable perk, improving job satisfaction and retention rates. You can check OpenBB team engagement <a href="https://openbb.co/company/open/team">here</a>.</li>
    <li><strong>Expanded talent pool:</strong> It allows hiring from a global talent pool, resulting in a more diverse and skilled workforce, particularly in open source, where contributors come from all over the world.</li>
    <li><strong>Increased flexibility:</strong> Remote work offers employees more control over their schedules, leading to better work-life balance.</li>
    <li><strong>Improved productivity:</strong> There are fewer distractions and interruptions, which leads to increased productivity.</li>
    <li><strong>No commuting:</strong> Remote work eliminates the need to travel to the office, saving time, money, and energy.</li>
    <li><strong>Cost savings:</strong> It reduces expenses for both employees and employers, such as commuting and office-related costs.</li>
</ol>

### Disadvantages

<ol>
    <li><strong>Limited face-to-face interaction:</strong> Remote work reduces in-person collaboration and social connections among colleagues.</li>
    <li><strong>Communication challenges:</strong> Reliance on digital tools may lead to misunderstandings or misinterpretations. There may also be technical issues or connectivity problems.</li>
    <li><strong>Blurred work-life boundaries:</strong> Clear separation between work and personal life becomes challenging.</li>
    <li><strong>Potential distractions:</strong> Remote work environments expose individuals to various distractions.</li>
    <li><strong>Challenges with collaboration:</strong> Coordinating tasks and scheduling can be more difficult remotely.</li>
    <li><strong>Reduced visibility and career advancement opportunities:</strong> Remote workers may have limited visibility and access to career growth.</li>
</ol>

### Conclusion

Remote works. It’s not for everyone, but it works. It works particularly well when the company culture is built around it. For it to work exceptionally well, it boils down to two main arguments:

<ol>
    <li><strong>A strong leadership is necessary to keep the team aligned, motivated, and to create the company’s culture</strong>. This helps mainly with the limited face-to-face interaction, challenges with collaboration, and reduced visibility and career advancement opportunities.</li>
    <li><strong>Do not track team members based on time but assess work based on output. Use meritocracy to reward the best team members and let go of low performers early</strong>. Remote work is not for everyone, and for those who cannot produce output/value to the company while working remotely, it means they weren’t a good hire in the first place. In my personal opinion, the disadvantages of potential distractions and blurred work-life boundaries come down to the employee and their relationship with remote work, instead of the company.</li>
</ol>

<br />

Sometimes someone may not be producing as much value as expected, for one reason or another. _When you are working remotely, you accept that you will add value to the company, and time is no longer a measure. Thus, the emphasis on output/value becomes much stronger._

## Office Work

Office also works.

### Advantages

<ol>
    <li><strong>Enhanced company culture:</strong> Offices contribute to a shared sense of identity and mission.</li>
    <li><strong>Face-to-face collaboration:</strong> It allows for immediate interaction, fostering effective teamwork and problem-solving.</li>
    <li><strong>Social interaction:</strong> Offices provide opportunities for building relationships with coworkers, enhancing camaraderie.</li>
    <li><strong>Clear work-life boundaries:</strong> Physical office spaces establish separation between work and personal life.</li>
    <li><strong>Mentorship and learning:</strong> In-person environments facilitate mentorship and hands-on learning.</li>
    <li><strong>Improved supervision:</strong> Physical presence aids in monitoring performance and providing timely feedback.</li>
</ol>

### Disadvantages

<ol>
    <li><strong>Commuting and transportation issues:</strong> Office work often involves commuting, which can lead to time-consuming and stressful travel, traffic congestion, and transportation expenses.</li>
    <li><strong>Lack of flexibility:</strong> Office work typically follows a fixed schedule, leaving less room for personal flexibility or adjustments to achieve work-life balance.</li>
    <li><strong>Office politics:</strong> Office environments can sometimes involve office politics, conflicts, or gossip that can affect productivity and job satisfaction.</li>
    <li><strong>High overhead costs:</strong> Maintaining physical office spaces can be costly for organizations, including expenses related to rent, utilities, and office supplies.</li>
    <li><strong>Limited geographic talent pool:</strong> Offices are often location-dependent, which may restrict access to a diverse and global talent pool, potentially limiting the variety of skills and perspectives within a workforce.</li>
    <li><strong>Distractions and interruptions:</strong> Open office layouts or noisy work environments can lead to frequent interruptions, reducing focus and productivity.</li>
</ol>

### Conclusion

Office works. Most workers are used to office work, and there’s a reason why it works so well, because it is easy for both the employee and the employer.

**From the employee standpoint:** The routine of waking up, commuting, working for eight hours, commuting back, and then enjoying the evening is straightforward and requires minimal scheduling or organization. The job begins when the employee arrives at the office and ends when they leave. However, it’s important to note that this fixed schedule does not necessarily guarantee peak performance throughout the entire workday.

For senior engineers, mentorship and learning opportunities may lead to context switching, disrupting deep focused work. What some refer to social interaction, can be perceived as wasting company resources. While supervision can raise the bar for average workers, top performers do not require constant supervision to excel. So if you’re aiming for top performers, perhaps supervision isn’t really necessary at all?

**From the employer standpoint:** Leaders and managers may find it easier to have everyone in the office for quick communication and check-ins. However, relying on in-person communication may result in less documentation, which can be challenging for new joiners. Supervision becomes simpler as managers can track attendance and check on employees throughout the day, but this can also lead to time wasted for both the manager and the person being supervised. (Plus even that supervision allowed “A day in a life of” viral TikToks to highlighted inefficiencies).

**In conclusion, I’d say that your average worker will be better in the office, while your top performers will excel further in a remote environment.**

> _The question is whether you prefer your top engineers to become 10x more productive working remotely or prefer your average engineers to improve performance by 2x. Personally, I prefer to aim for 10x productivity with top engineers and let go of average ones._

## Hybrid Work

Ok, now that we’ve discussed remote and office work, let’s go over why hybrid work sucks.

People in general tend to associate hybrid work with the best of remote and the best of office, but I think that the worst of remote and office have more emphasis. Let’s go over the biggest pain points:

<ol>
    <li><strong>Decreased productivity:</strong> When compared with remote or office, hybrid has lower productivity. This is due to the context switching associated with changing working environments. Personally, I have experienced this and found it frustrating to work until late at night, packing up and thinking about what I needed to carry for the next day, plus commuting. The next day, it took me much longer to get back into the flow of work compared to waking up and immediately continuing with the problem at hand.</li>
    <li><strong>Decreased flexibility:</strong> Hybrid work offers less flexibility than remote work but somewhat more than office work. However, this flexibility is often constrained by company policies, such as designated office and remote days or specific rules regarding remote work. When the company dictates the days employees can work remotely, the flexibility becomes somewhat artificial.</li>
    <li><strong>Communication challenges:</strong> As mentioned earlier, one of the reasons that office communication is a sword of 2 edges is because while in-person communication can be effective and fast, it often results in less documentation, which can impact new joiners. In a hybrid culture, this issue is so much worse, because it’s hard to get the company aligned into the amount of level of documentation necessary. Plus, when WFH days rotate across divisions and teams, individuals working remotely may suffer from a lack of context that is shared among the team in the office, leading to silos and communication gaps.In addition to that in remote work employees can and expect to have to accommodate for different time zones but when you move people to hybrid the ones that need to go to the office will no longer adjust their times to match the ones WFH based on needs.</li>
    <li><strong>Blurred work-life boundaries:</strong> Hybrid work blurs the line between work and personal life. It no longer solely involves working from home and spending time with family but also includes being at work, interacting with co-workers, and commuting. This blurring can make it difficult to establish clear boundaries.</li>
    <li><strong>Limited geographic talent pool:</strong> Since you want employees to commute to the office a certain number of times per week or month, you can’t hire them from anywhere. The geographic scope of talent acquisition becomes restricted, potentially limiting access to diverse skills and perspectives.</li>
    <li><strong>Many more distractions:</strong> Individuals face distractions both at home when working remotely and in the office from co-workers. PLUS, you get the distractions that come from your co-workers bringing you up to speed if something happened when you weren’t in the office the day before (similar to the additional amount of chit chat that happens on Mondays due to weekend).</li>
    <li><strong>Costs and commuting:</strong> You may save some money with some WFH, but often the WFH days don’t even justify going into a lower tier than a monthly subscription to public transports. So you end up spending the same, even if you travel less. This argument is less valid here in the Bay area where most people drive. Plus commuting those 3/4 days a week, is still a pain.When we talk about the employer costs then it’s impossible to get it right. On the one hand you have too few people in the office which means you are overpaying for office space, on the other hand you cannot get everyone in. And this will always be impossible with a growing team + managing the WFH days of each team and division.</li>
    <li><strong>Decreased employee retention and satisfaction:</strong> In general, people tend to lean towards either remote work or office work. With hybrid work, those who prefer the office environment may work in the office most days, using WFH as an opportunity for personal tasks and potentially being less productive. On the other hand, those who prefer remote work will aim to WFH as much as possible and may feel dissatisfied with having to go to the office for the remaining days This can create a divide and decrease overall employee satisfaction. Additionally, this is even more pronounced when everyone in the leadership works in the office, since the company tends to follow culture from leaders and will have less incentives to accommodate team members that are not in the office.</li>
    <li><strong>Challenges with supervision:</strong> Physical presence in the office often aids in monitoring performance, but it becomes challenging to fairly evaluate the performance of team members in the office versus those working remotely in a hybrid setup. What is the basis that you use to evaluate them? Based on what you see when they are in the office? Do you still create ways to evaluate their output when WFH? Do you still check on them as often when the rest of your team is with you in the office? What about when you are WFH and have half of the team in the office and the other WFH? The amount of complexity that comes from managing this by itself, almost makes hybrid the worst choice.</li>
</ol>

## Conclusion

I’m not saying that hybrid work can’t work, but my point is that people tend to use hybrid as the perfect solution between office and remote, and I don’t think it is. In fact, I think for most companies, this is a way to sweep a problem under the rug with a half-baked solution.

As an engineer, I wouldn’t be happy working in an office because I know I could contribute much more to the company by working from home. I’d be “okay” with doing hybrid work in order to continue working for the company, but I would probably start looking elsewhere due to all the aforementioned issues.

As a leader, OpenBB has started as a remote company, and as a result, we have become highly efficient at working remotely, even when dealing with a 9-hour time difference. All team members understand that they need to make compromises with their working hours to accommodate the company’s needs. _So, it ultimately comes down to the type of team you are building and how committed they are to the mission, as well as how you can cultivate such a culture internally._

If your team grew accustomed to working in an office and had to switch to remote due to COVID, and you are noticing a decrease in performance, it may be that your team was not prepared to work remotely. In that case, it makes sense to go back to the office. However, if your team grew while working remotely, and you are not satisfied with their performance, let me tell you that bringing the team back to the office is a half-baked solution. Instead, it would be better to investigate the issue and implement better processes or address underperforming individuals.


---

---
slug: employees-are-leaving-be-proactive-about-employee-feedback
title: Employees are leaving? Be proactive about employee feedback
date: 2023-06-29
image: /blog/2023-06-29-employees-are-leaving-be-proactive-about-employee-feedback.png
tags: ['employee engagement', 'feedback', 'work culture', 'remote work', 'team happiness']
description: Employees are leaving? Be proactive about employee feedback. This blogpost discusses the importance of employee feedback and how we at OpenBB are ensuring high employee engagement through a periodic feedback survey.
---

<p align="center">
    <img width="600" src="/blog/2023-06-29-employees-are-leaving-be-proactive-about-employee-feedback.png"/>
</p>

<br />

Employees are leaving? Be proactive about employee feedback. This blogpost discusses the importance of employee feedback and how we at OpenBB are ensuring high employee engagement through a periodic feedback survey.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This blogpost shows the measures we are taking to ensure we have high employee engagement at OpenBB through a periodic feedback survey.

When we started OpenBB, I was absolutely obsessed about our product. All my focus and time was dedicated to building our suite of products (OpenBB Terminal, OpenBB SDK or OpenBB Bot), or talking about these with our users. I care deeply about the OpenBB team, but I expected everyone to be as motivated as me, 24/7.

But things just don’t work that way. Although we always have a fun quarterly event online, that isn’t enough. Everyone knows that I’m a big fan of remote work, but one clear down side of it is the lack of contact and face to face conversations which makes employee engagement more volatile. I say this, because I believe that when your team is together in the same space, it’s easier to thrive off each others excitement and motivation.

Soon enough, I realized that _“alone you can go faster, but with a team you can go far”_. This is when I started putting time into understanding what we could be doing better to improve our work culture.

Some things that we have now put into place include:

- We updated the company values as a team, based on what we currently had that they were proud of and where they would like us to be in the future. In a startup, where the pace is incredibly fast and the team is constantly changing, I strongly believe that the values change over time too.

- We had an [OpenBB rap](https://www.youtube.com/watch?time_continue=48&v=ThtSC8s0h6I&embeds_referring_euri=https%3A%2F%2Fopenbb.co%2Fblog&source_ve_path=MzY4NDIsMjg2NjMsMjg2NjY&ab_channel=OpenBB) made by a freestyler for our OpenBB Christmas event.

- We started pushing for more transparency. We were already very transparent internally, but now we started to push this value externally too. Everyone in the company has skin in the game, this allows the team to feel as accountable for the metrics as I do. I wrote more about this in this blogpost: [From open source to open startup](/blog/from-open-source-to-open-startup), and I am currently working on the OpenBB Handbook too.

- I started having office hours, where I can spend the time with the team chatting about anything (product, strategy, engineering, storytelling, even fundraising). The team knows that I’m usually available, but having that 1 hour blocked gives them the confidence to know that that time booked in the day.

However, there was something critical missing. I will explain what it is by using what I learned at university (that way I can say that my MSc in Control Systems was indeed useful for OpenBB 🙃).

What we had built is an open loop control system, and it looks something like this:

![image](/blog/2023-06-29-employees-are-leaving-be-proactive-about-employee-feedback_1.png)

The problem? open loop systems can be inaccurate and unreliable. More importantly, because there is no feedback mechanism to correct inputs as the controller (leadership) never gets the information that comes out of the system (team engagement).

The key word here is feedback. An office hour session is great, but it’s a poor “sensor device”. The reason being that you are opening the door for the team to communicate with you, but that data isn’t significant to extrapolate through the whole team.

We needed feedback. We needed to have a closed-loop system instead of an open one. By that I mean:

![image](/blog/2023-06-29-employees-are-leaving-be-proactive-about-employee-feedback_2.png)

This allows us to constantly monitor our team happiness, and be able to react when the feedback doesn’t match our desired culture.

But what is this feedback? What do we want to track? We didn’t want to reinvent the wheel, so we looked up to how the best companies do it. In particular, we studied “The Psychology of Employee Engagement” e-book from Workday written by Phillip Chambers.

This allowed us to come up with the following survey, where the team would reply anonymously to each of the questions with a rating from 1 to 10 where 1 corresponds to “strongly disagree” and 10 corresponds to “strongly agree”.

- **Accomplishment:** I feel a regular sense of accomplishment
- **Autonomy:** I feel that I am given autonomy in the way I complete my tasks
- **Meetings:** I feel that I have a good amount of meetings every week. (this question was originally about environment, but due to our remote nature we felt that the amount of meetings was something more important to measure)
- **Freedom of Opinions:** I feel that I have a voice in the company and my opinion matters
- **Goal Setting:** I feel that both my goals and expectations are set clearly
- **Growth:** I feel that I have opportunities to grow professionally
- **Management Support:** I feel that my manager cares for me and empowers me
- **Meaningful Work:** I feel that my work matters
- **Organizational Fit:** I feel like the company values align with mine and we share the same goal
- **Peer relationships:** I feel connected with my colleagues and that I can be myself with them
- **Recognition:** I feel like I get recognized for my contributions
- **Reward:** I feel like I am rewarded fairly for my work
- **Strategy:** I feel like the company strategy is being communicated effectively
- **Workload:** I feel like I can manage my workload efficiently

Now you may be wondering how we made this survey completely automated, the workflow is actually very straightforward and we were able to automate it. Here is what it looks like: Airtable + Slack ✅

![image](/blog/2023-06-29-employees-are-leaving-be-proactive-about-employee-feedback_3.png)

Even though our salaries don’t compete with the MAMAAs of this world, we believe that: our mission, our innovative products and unique culture are what makes us OpenBB. And why we can retain our talent.

You can find our employee engagement index at: https://openbb.co/company/open/team


---

---
slug: from-open-source-to-open-startup
title: From Open Source to Open Startup
date: 2023-07-06
image: /blog/2023-07-06-from-open-source-to-open-startup.png
tags: ['open-source', 'open-startup', 'transparency', 'financial world', 'OpenBB']
description: From Open Source to Open Startup. A journey of OpenBB towards transparency in the financial world.
---

<p align="center">
    <img width="600" src="/blog/2023-07-06-from-open-source-to-open-startup.png"/>
</p>

<br />

From Open Source to Open Startup: A journey of OpenBB towards transparency in the financial world.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Being open source isn’t enough, at OpenBB we want to accelerate the transparency in the financial world.

I want to start this blogpost by introducing the concept of an open startup. As this phrase can often be interpreted differently, here’s the standard definition that ChatGPT gave me:

> _“An open startup is a company that practices open innovation and transparent communication with its stakeholders, including customers, employees, and investors. This means that the company is willing to share information about its products, services, and business operations with the public and is open to input and feedback from all stakeholders._

<br />

> _Open startups typically have a strong focus on collaboration and community building, and they often use open source technology and principles in their operations. Some open startups may also be structured as cooperative or worker-owned enterprises, in which ownership and decision-making power are shared among employees.”_

## Why now?

I’ve been learning about the open startup movement for a while now and I always knew that I wanted OpenBB to follow this trend. At the end of the day, I want us to accelerate the openness and transparency in the financial world.

But until recently, this wasn’t one of our top priorities. This all changed when the cryptocurrency exchange FTX collapsed. This was a house of cards and they stood for everything but transparency — not only with their users but also with their shareholders and team alike!

John J. Ray III who has spent a career tackling large corporate failures involving allegations of criminal activity (like Enron), was appointed CEO of FTX to deal with the bankruptcy, and this is one of his quotes to the US congress:

> _“Never in my career have I seen such an utter failure of corporate controls at every level of an organization, from the lack of financial statements to a complete failure of any internal controls or governance whatsoever”_

<br />

OpenBB wants to pave the way of transparency in the financial world.

## Why open?

### Transparency

Transparency across team, shareholders, users and new hires is key. Everyone can see our growth in the same location; A single source of truth accessible to everyone at all times. We already have our code open source, which shows transparency in our engineering, so it only makes sense for us to behave in the same way with our business.

### Accountability

Everyone will know how we’re doing, for better or worse. This will make us feel responsible to show accurate sustainable growth as this information becomes public. Since everyone has equity in the company, this will be our own skin in the game.

When people ask, “How is OpenBB going?”, this can be answered with a single link to our open page.

### Community building

Every company is trying to build a community these days, but building a community is hard. By having all of our information publicly available, anyone from the community will know how we are doing at all times — similar to what the team, shareholders and investors know.

This helps to build trust in OpenBB and allow us to attract and retain talented employees who value transparency and an open culture.

### Marketing

Users will be able to share our open page to share OpenBB metrics with other users, which will help to increase awareness for us.

In addition, we want to become leaders of open culture in the financial world, which is known for being a very closed industry. We want to influence companies in this sector and start a movement.

### Fundraising

Since starting OpenBB, I’ve met well over 50 different investors, even without actively fundraising. Whilst this is a great way to start relationships, it’s not sustainable as it takes valuable time away from talking with users/customers (and let’s be honest, even developing :slight_smile:). So by having an open page, we will be able to discuss our growth async and more efficiently. And then, when we are actively fundraising, we can focus on the details.

## How will it be done?

We are adding all our metrics and stats to [/open](https://openbb.co/open).

Our open metrics will contain 4 main distinct sections to start with:

#### Social Media metrics

Twitter followers, Discord users, LinkedIn followers, YouTube views, Reddit followers. Allows to understand the strength of our community in the social media channels that we focus on.

#### Team stats

Team distribution and employee engagement coming soon. Allows to understand where we are based and employee experience at OpenBB

#### Product metrics

OpenBB Hub users, OpenBB Bot, OpenBB SDK and OpenBB Terminal. Allows to hold us accountable for our user growth and the usage that our products have

#### Developer metrics

Stars, forks, merged pull-requests, closed issues, contributors. Keep up-to-date with our development speed and how engaged the open source community is.

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

For all the metrics that are open source, there will be an ⓘ in the top right to share information on why this chart was made open source and why it’s important to us.

Once a metric is open, we do not intend to close it ever again, that is why all the metrics we are making public have gone through a thorough reasoning process and there’s enough contextual information to understand its meaning.

If you can think of a metric that you would like to see on our open page, please feel free to DM me.


---

---
slug: why-the-need-for-an-open-source-investment-research-platform
title: Why the need for an open source investment research platform?
date: 2023-07-16
image: /blog/2023-07-16-why-the-need-for-an-open-source-investment-research-platform.png
tags: ['Open Source', 'Investment Research', 'Data Licensing', 'Transparency', 'Community']
description: OpenBB Terminal, an open-source investment research platform, is transforming the financial industry by addressing issues like data licensing, full-price bundle, lack of transparency and customization, and the need for a diverse community. This post explores why open source is crucial for us and the main problems in the space.
---

<p align="center">
    <img width="600" src="/blog/2023-07-16-why-the-need-for-an-open-source-investment-research-platform.png"/>
</p>

<br />

OpenBB Terminal, an open-source investment research platform, is transforming the financial industry by addressing issues like data licensing, full-price bundle, lack of transparency and customization, and the need for a diverse community. This post explores why open source is crucial for us and the main problems in the space.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Having a closed source OpenBB Terminal was never on the table.

The [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) is the platform it is today due to its open source nature. Launched almost 2.5 years ago, the interest on this platform was clear — aggregating an impressive 4000 stars on GitHub in under 24 hours from launch.

This number kept on growing along with the community (most of which gathers on [our Discord server](http://openbb.co/discord)) and allowed us to create the company OpenBB, see the story [here](http://openbb.co/blog/gme-didnt-take-me-to-the-moon-but-gamestonk-terminal-did).

![image](/blog/2023-07-16-why-the-need-for-an-open-source-investment-research-platform_1.png)

But why is open source so important for us? To understand this, it’s important for us go over the main problems in the space.

<ol>
    <li>Data licensing</li>
    <li>Full-price bundle</li>
    <li>Transparency and customization</li>
    <li>Community</li>
</ol>

## Data licensing

Current monopolies spend an enormous amount of capital on financial data licensing. There are dozens of different asset classes (equities, options, crypto, NFTs, forex, bonds, ETFs, mutual funds, …) and these often vary based on geography. In addition, alternative datasets have grown a lot in popularity as they can provide a hedge in the market (e.g. a hurricane can impact orange juice futures).

That makes the overall investment research industry a very tough market to compete. Startups cannot disrupt the space without a massive capital injection. Explaining why the data offered by startups usually focuses on a certain asset class, in a certain geography.

This is why OpenBB doesn’t own the data (similar to Uber not owning cars, Airbnb not owning apartments, Deliveroo not owning restaurants). OpenBB wants to be the infrastructure layer between data sources and users.

This is the typical two-sided market, where on the one hand users benefit from having access to multiple datasets in one place, and on the other hand data sources benefit from having users on our platform as they can monetize their data. This allows us to focus on the product while our number of data integrations and users grows.

## Full-price bundle

Current incumbents pricing is usually a complete bundled offering. This means that regardless of what you are utilizing in terms of both breadth and depth, you pay the full price tag. A good analogy is like a restaurant ONLY having a buffet when all you want is a bottle of water, or some chips.

What happens is that a user ends up paying for data that they are not using. In 2023, this is a very outdated take. Companies are looking to get leaner, and it doesn’t make sense to pay for data that you aren’t leveraging.

Being the infrastructure between users and data sources allows you to create value to both. Users will have access to all the data they want and pay for the ones they use, and data sources will have access to a big pool of users.

In addition some data providers (e.g. a team of machine learning engineers) will not need to create a dashboard for their users to visualize their data and hire a team to start a sales/marketing motion, as they will be able to rely on OpenBB’s infrastructure.

## Transparency and customization

Current incumbents have built several in-house financial models. Although these are often customizable, their customization is typically limited. That is because what is usually customizable are the values/weights, but not necessarily the formulas — that is kept hidden in their source code. This is an issue because that code cannot be validated and users cannot modify it.

With open source, the story is completely different. Users can see every single line of code and therefore, not only audit the code quality but adapt the models/formulas to their own needs. At the end of the day, there is no point in re-inventing the wheel for financial theory that has been around for decades.

By having the code open source, users can rely on the fact that these formulas have been validated/tested by thousands or millions of users and therefore, there’s a very low chance that these are wrong. In addition, users are more secure because they can investigate the code and check/fix any vulnerabilities.

## Community

One of the best parts of open source is the integrated community that it creates. This attracts people from every background, gender or ethnicity. Such a pool of diversity allows for better ideas and pushes a project further. With people from the community being able to contribute, this also drives innovation.

OpenBB has been driven a lot by the community so far. What started as a terminal mostly focused on equities, soon evolved into including a broad range of datasets and considering several geographies. For instance: A contributor from Sweeden integrated Avanza API to the mutual funds menu that would only appear if users were looking into mutual funds from Sweden — this shows the power of community.

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

![image](/blog/2023-07-16-why-the-need-for-an-open-source-investment-research-platform_2.png)

We are close to 23,000 stars. If you haven’t already, starring our project would mean the world.

![image](/blog/2023-07-16-why-the-need-for-an-open-source-investment-research-platform_3.png)

Any feedback is welcome 🙏🏽


---

---
slug: how-to-use-openai-to-extract-insights-from-team-survey
title: How to Use OpenAI to Extract Insights from Team Survey
date: 2023-07-21
image: /blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey.png
tags: ['OpenAI', 'Team Survey', 'Insights', 'Automation', 'Slack', 'Airtable']
description: This blog post discusses how to use OpenAI to extract insights from team survey data. It covers the motivation behind the project, the requirements, and the implementation process, including the use of the Slack API and Airtable API for automation.
---

<p align="center">
    <img width="600" src="/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey.png"/>
</p>

<br />

This blog post discusses how to use OpenAI to extract insights from team survey data. It covers the motivation behind the project, the requirements, and the implementation process, including the use of the Slack API and Airtable API for automation.

The open source code is available [here](https://github.com/DidierRLopes/insights-from-team-survey).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Motivation

I’ve been wanting to play with the OpenAI API for a while, but I’ve had higher priority tasks. Yesterday, I thought that I could use the day to do this, but I didn’t want to just try it in a notebook. Instead, I wanted to use it in a real project that could save me time.

Last week, I posted about how at OpenBB we have developed a monthly team survey and automated the process of requesting information through Slack and Airtable. You can find more on that post [here](/blog/employees-are-leaving-be-proactive-about-employee-feedback).

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_1.png)

This made me think that even though I have access to all this data, which OpenBB has made fully available [here](https://openbb.co/open), I still have to spend some time looking at the data to extract insights.

<img width="1397" alt="Screenshot 2023-11-24 at 4 39 41 PM" src="/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_2.png" />

What if I could automate that analysis using OpenAI? This is what I set out to build, and this post will focus on how I went from idea to implementation.

## Requirements

I already had a notebook that I used to analyze our Airtable data with our team survey in it. However, that analysis was quite “heavy,” and it was not straightforward to extract insights. Thus, one of the requirements was to use OpenAI to analyze the team survey feedback for the current month and highlight anything worth mentioning.

Additionally, I wanted to compare the team’s experience to the prior month to understand if we were improving or not, and identify areas for further improvement. Finally, based on these insights, I wanted OpenAI to suggest what OpenBB, as a company, could do to improve our culture.

To achieve this using an OpenAI model, I could either export the team survey responses from Airtable in CSV and copy-paste them into ChatGPT, or I could automate the data retrieval using the Airtable API. Being an engineer, why would I do something in 5 minutes when I can spend 1 day automating it? 🤣

Lastly, I didn’t want to run this script and have to copy-paste the output into our Slack group so that everyone on the team could have access to the overall analysis and provide feedback/suggestions. Therefore, I would like to have a Slack integration that sends the output in a specific formatted way to our Slack channel.

So, the idea is as follows:

<ol>
    <li>Retrieve team feedback responses from Airtable</li>
    <li>Extract insights from the team survey data using OpenAI</li>
    <li>Send the insights output to the OpenBB Slack channel</li>
</ol>

## Implementation

### Slack API

First of all, I went to the [Slack API](https://api.slack.com/apps) page. There, I created an app named “Employee Voice” and selected the “OpenBB” workspace, as shown below:

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_3.png)

After clicking “Create App” I proceeded to update the display information.

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_4.png)

Then I go into “Incoming Webhooks” and select the channel I’m interested in posting messages to. That should be all the settings you need to configure for your app.

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_5.png)

The webhook URL will be necessary, so I copied it and added it to the following script. For the channel name, I used my personal name, “_Didier Lopes_”, since I was just testing if it worked. As for the message, I used the infamous “Hello World” text.

Here is a sample that you can use to test whether you can successfully send yourself a direct message using the Slack API.

```python
    SLACK_WEBHOOK_URL=<Webhook URL mentioned above>
    
    insight="Hello World"
    
    payload = {
        'text': insight,
    }
    
    req = Request(SLACK_WEBHOOK_URL, json.dumps(payload).encode('utf-8'))
    try:
        response = urlopen(req)
        response.read()
        
        print("SUCCESS: Message with insights sent to slack\n")
    except HTTPError as e:
        print(f"Request failed: {e.code} {e.reason}\n")
    except URLError as e:
        print(f"Server connection failed: {e.reason}\n")
```

### Airtable API

At OpenBB, we are using Airtable to automate the monthly team survey questionnaire and store the associated data. I wrote more about that process in [this blog](/blog/employees-are-leaving-be-proactive-about-employee-feedback).

Now, I want to have programmatic access to this data.

Firstly, I need to obtain the Airtable API key, which you can get from the [Airtable Developer Hub](https://airtable.com/create/tokens). Secondly, I navigate to Airtable and locate the table that contains the data of interest, as shown below:

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_6.png)

The name of the table, “_OpenBB_monthly_”, corresponds to the “TABLE NAME” that will be necessary. Additionally, when you are on this table view, your URL will have the following format: https://airtable.com/XXX. That XXX is your “BASE ID,” which will be the final element necessary to retrieve data from Airtable.

Next, run the following script to ensure that you have access to this data.

```python
    AIRTABLE_API_KEY=<Located in Airtable Developer Hub>
    AIRTABLE_BASE_ID=<Located in URL when accessing data>
    AIRTABLE_TABLE_NAME="OpenBB_monthly"
    
    response = requests.get(
        url=f'https://api.airtable.com/v0/{AIRTABLE_BASE_ID}/{AIRTABLE_TABLE_NAME}',
        headers={'Authorization': f'Bearer {AIRTABLE_API_KEY}'}
    )
    
    Check if the data has been loaded correctly
    if response.status_code == 200:
        data = response.json()["records"]
    else:
        print(f"Error: {response.status_code}")
    
    print(data)
```

### OpenAI API

Finally, go to [OpenAI Developer platform](https://platform.openai.com/account/api-keys) and grab your OpenAI API key.

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_7.png)

Once you have that, you are pretty much ready to test whether this works or not. In this case, we assume you have access to the data from Airtable, so you can test if the OpenAI code is set up correctly with the following:

```python
    data_previous_month=<dataframe with raw survey data from previous month>
    data_current_month=<dataframe with raw survey data from current month>
    current_month=<current month date>
    
    openai.api_key=<Located in OpenAI Developer platform>
    response = openai.ChatCompletion.create(
    model="gpt-4",  # you can use a different model
    messages=[
            {"role": "system", "content": "You are a Chief of Staff with a MSc. in Data analysis and are trying to improve the culture of the company."},
            {"role": "user", 
            "content": 
                f"""
        This table represents the company survey for the previous month: {data_previous_month}
    
        This table represents the company survey for this month: {data_current_month}.
    
        Based on this data, can you do 3 things:
        
        1. Summarize main differences since last month
        2. Summarize main highlights for current month
        3. Create suggestions for what could be done to improve those areas
        
        Please use the following format for the output:
            As the title use the following: Insights from team survey in {current_month}.
            Follow the title by 2 line breaks.
            Use bullet points within each of the points mentioned above.
            Between the 3 points, use 1 line breaks, a line with ----------------------- and another line break.
            Use `` when referring to a component like `Reward` or `Growth`.
            Do not use asterisks '*' or '**'.
            When referring to to Engineering or Product, Marketing, Design, Finance wrap them around asterisk, e.g. _Engineering_.
                """
            },
        ]
    )
    
    print(response.choices[0].message.content)
```

## Glue it together

Once you have the scripts, merging them is straightforward. I will show you what the input vs. output looks like.

Here is [OpenBB](http://openbb.co/)’s team survey data from June of 2023:

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_8.png)

If I run the script here, as shown below (yes, you guessed it right — I open-sourced this project as usual. I hope you and your team find it useful):

```console
    $ python extract_insights_from_last_team_survey.py
```

This is the expected output if the script runs successfully.

```console
    Loading environment variables...
    Loading team survey data from Airtable...
    Processing data from Airtable...
    Extracting insights from team survey data...
    Sending insights to Slack through a message...
    SUCCESS: Message with insights sent to slack
```

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_9.png)

## Automate with GitHub workflow

We’re almost there! It doesn’t make sense for us to manually run this script every month. Plus, software engineers are known for their laziness (which is actually a [virtue of a great programmer](https://thethreevirtues.com/)), so let’s create a GitHub action to automate this process.

To begin, create a file called “main.yml” in the “.github/workflows” directory.

[This workflow](https://github.com/DidierRLopes/insights-from-team-survey/blob/main/.github/workflows/main.yml) will be divided into three main sections:

### When

Specifies when this GitHub action should run.

```console
    on:
      push:
        branches:
          - main
      schedule:
        - cron: '0 0 3 * *'
```

The first section, “on: push: branches: [main]” means that whenever there is a code push to the “main” branch, this workflow will be triggered. This feature allows us to quickly test whether the action is functioning as expected.

The “schedule-cron” makes it so that the yaml gets run at a specific dates and times.

### Secrets

What do we need in advance for this to work?

```console
    env:
      SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
      AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
      AIRTABLE_TABLE_NAME: ${{ secrets.AIRTABLE_TABLE_NAME }}
```

All of these variables need to be set as action secrets. You can do this by selecting the “Settings” tab above, then going into “Scripts and variables,” and selecting “New repository secret.” Fill in the information accordingly, as shown below:

![image](/blog/2023-07-21-how-to-use-openai-to-extract-insights-from-team-survey_10.png)

### Workflow

What commands are we running with this GitHub action? In our case, these are the ones we are interested in.

```console
    jobs:
      build:
        runs-on: ubuntu-latest
    
        steps:
          - name: checkout repo content
            uses: actions/checkout@v2
    
          - name: setup python
            uses: actions/setup-python@v2
            with:
              python-version: 3.9
    
          - name: install python packages
            run: |
              python -m pip install --upgrade pip
              pip install python-dotenv
              pip install pandas
              pip install openai
    
          - name: extract insights from team feedback
            run: |
              python extract_insights_from_last_team_survey.py
```

And that’s it! You now have a complete automation pipeline from employee feedback to insights within seconds.

I hope you enjoyed reading this post, and I would love to hear your feedback. Do you appreciate the level of technical detail I go into, or would you prefer less?

Any comments are very helpful. Thank you!


---

---
slug: keep-track-of-your-startup-metrics-using-a-custom-ios-widget
title: Keep track of your startup metrics using a custom iOS widget
date: 2023-07-29
image: /blog/2023-07-29-keep-track-of-your-startup-metrics-using-a-custom-ios-widget.png
tags: ['iOS', 'Startup', 'Metrics', 'OpenBB', 'Scriptable', 'Open Source']
description: Keep track of your startup metrics using a custom iOS widget. This blog post will guide you on how to build a custom iOS widget that displays your startup metrics at all times. The entire code is open source and requires minimal coding skills.
---

<p align="center">
    <img width="600" src="/blog/2023-07-29-keep-track-of-your-startup-metrics-using-a-custom-ios-widget.png"/>
</p>

<br />

Keep track of your startup metrics using a custom iOS widget. This blog post will guide you on how to build a custom iOS widget that displays your startup metrics at all times. The entire code is open source and requires minimal coding skills.

The open source code is available [here](https://github.com/DidierRLopes/opensource-scriptable-widget/tree/main).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

If you have a high level role in your organization, you are likely obsessed over a few metrics that act as the north star for your company. Whether that is MRR, number of customers, GitHub stars, AUM, .. depends on the type and stage of company, and what you are optimizing for.

At [OpenBB](https://openbb.co) we are currently optimizing for [OpenBB Hub](https://my.openbb.co) users, since this is the place where you have access to our entire suite of products. From [OpenBB Terminal](https://my.openbb.co/app/terminal), [OpenBB SDK](https://my.openbb.co/app/sdk), [OpenBB Bot](https://my.openbb.co/app/bot) and soon — the highly awaited [OpenBB Terminal Pro](https://my.openbb.co/app/pro).

So everyday I spent some time checking our startup [/open page](https://openbb.co/open). However, whenever I had to check these on mobile I had to open up the browser, type the link and then look for the metric of interest.

Hence, to save time, I built a custom iOS widget that displays these metrics of interest at all times. All I need to do is unlock my phone and *BAM*, they are right there.

So, today, I’ll teach you how you can do the same with minimal coding skills required. I open source the entire code, so that you can get up to speed as fast as possible here: https://github.com/DidierRLopes/opensource-scriptable-widget

## Track your open source metrics

This section will provide a plug-and-play example for your open source repository.

![image](/blog/2023-07-29-keep-track-of-your-startup-metrics-using-a-custom-ios-widget_1.png)

These are the steps necessary to have it working on your iOS device:

1/ Download Scriptable app to your iOS device

2/ Open Scriptable app and click on the “+” on the top right corner

3/ Rename that script to whatever repo you would like to track

4/ Copy the code from the file opensource.js on this repository

5/ Paste it into that new script on your phone

6/ Change the 4 initial parameters from the file:

```python
    const WIDGET_TITLE = "openbb.co/open"
    const GITHUB_REPO = "OpenBB-finance/OpenBBTerminal"
    const PIP_PACKAGE_NAME = "openbb"
    const CACHED_DATA_HOURS = 1
```

- If you only want to track GitHub stats, do `PIP_PACKAGE_NAME=""`.
- If you only want to track PiPy stats, do `GITHUB_REPO=""`.
- The `CACHED_DATA_HOURS` corresponds to the amount of hours where the data is not updated.

7/ Run script to make sure that it works using the “play button” on the bottom right corner

8/ Leave the app

9/ Leave your finger pressed on the iOS homepage

10/ Click on the “+” on the left top corner

11/ In the “Search Widgets” tab look for “Scriptable”

12/ You will see “Run Script” and there are 3 pages. Select the type of widget size that you are interested in

13/ Select “Add Widget”

14/ The widget will appear with the sentence “Long press and edit widget to select the script to run”

15/ Do that and then you will have 3 options:

- Script — Select script name that you renamed to earlier
- When Interacting — Select “Open URL” — A new field will appear with “URL” then provide the link you want to open you cick on the widget (e.g. http://openbb.co)
- Parameter — If there’s any parameter needed to the script

16/ Click outside the window, and you should be all set!

Feel free to contribute to the repository with other examples / templates!


---

---
slug: how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley
title: How to handle equity at a seed-stage startup from Silicon Valley
date: 2023-08-03
image: /blog/2023-08-03-how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley.png
tags: ['startup', 'equity', 'Silicon Valley', 'seed-stage', 'OpenBB']
description: A step-by-step guide on how to handle equity at a seed-stage startup, using a fictional example from OpenBB.
---

<p align="center">
    <img width="600" src="/blog/2023-08-03-how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley.png"/>
</p>

<br />

A step-by-step guide on how to handle equity at a seed-stage startup, using a fictional example from OpenBB.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

As a startup founder and CEO, you need to wear multiple hats, from engineering and product to design, marketing, and even finance.

Today, I’m going through the details of how we handle equity at OpenBB. This blog post provides a step-by-step guide on the implementation process, including links to relevant spreadsheets that you can reuse for your startup.

To make this post easier to follow, I will create a purely fictional example.

John Doe, a software engineer from Portugal, has been contributing to the [open source OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) for a few consecutive weeks. He not only fixes bugs but also adds features that the community has requested through pull requests and on Discord. Additionally, he is a fast learner and gets along well with the current team. This sparks the interest of the OpenBB team because having this open-source contributor work with us full-time would be great, rather than being limited by his current full-time job.

From here, we set up an initial exploratory call to better understand John Doe as an individual — what he is passionate about, why he has contributed to the project, and more. We follow up the call with an interview involving engineers to assess his skills and experience. Finally, he joins a call with me, where I sell the vision of the company and explain why what OpenBB is doing matters. At this point, we extend him an offer. Up until this stage, the recruiting process is standard, except for the fact that we have a “filtered” candidate coming from the open-source community.

However, as a startup, that offer cannot (or at least should not) consist solely of cash compensation. A startup [operates at a much faster pace](http://www.paulgraham.com/growth.html) and is riskier than a company. Therefore, in exchange for hard work and long hours, you should offer part of the company through equity, allowing the employee to benefit from the upside in case the company achieves a successful exit (IPO or sale).

So, how do we decide on the equity to offer the new hire?

It’s easy. You follow your company Option Guidelines.

## Option Guidelines

The Option Guidelines are an Excel spreadsheet approved by the board. In this document, you explicitly create **bands (minimum and maximum range options)** based on the role and stage of the company. Board approval is crucial as it allows you to extend the offer directly without needing permission from the board since the guidelines have already been approved.

Here’s what the document looks like:

![image](/blog/2023-08-03-how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley_1.png)
The total number of shares is random and not representative of OpenBB.

First, you need to ask yourself what roles your company envisions needing. Within those roles, there are two things to consider:

- **Departments:** You may differentiate between Engineering, Marketing, Operations, Sales, Finance, and HR/Admin. You can also add others such as Design, Product, etc. Note that having different departments does not necessarily mean you need different band structures.

- **Titles:** You’ll want to be able to “compare” individuals based on their contributions. For instance, Vice President, Director, Manager, Senior Individual Contributor, and Individual Contributor. Note that if you have fewer titles, the bands should be wider to differentiate individuals with the same title. If you add five levels of Individual Contributors, you’ll want narrower bands.

  I recommend starting with fewer titles, KISS: keep it simple stupid. Again, having different levels does not necessarily mean the bands need to be mutually exclusive. A Manager does not necessarily have a higher band than a Senior Individual Contributor; this depends on your own company culture.

Next, you need to differentiate between **company stages**. This allows you to distinguish employees who join very early when the startup carries the most risk. We distinguish between three stages: Pre-production revenue, Pre-profit with production revenue, and Profitable.

Once all these categories are completed, you should have a similar table to the one shared above. Now, it’s important to fill in the equity percentage. For privacy reasons, I will not provide the specific values for OpenBB but will create a random example.

Let’s imagine that OpenBB Charter has a total of 1 million shares (assuming only one class of stock for simplicity). If our priced round values the company at $10 million, this means that each share is valued at $10.

On the top left of the document, we will insert the number of shares, which is 1,000,000. Then, we adjust the % LOW and % HIGH columns, representing the range of company ownership we want to grant to this individual.

Let’s go through a fake example for the SW role:

![image](/blog/2023-08-03-how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley_2.png)

The column “Low Shrs” is computed by multiplying the % LOW by the total number of shares. On the other hand, the column “High Shrs” is computed by multiplying the % HIGH by the total number of shares. This value is important as it represents the amount stipulated in the contract.

Let’s consider a scenario where the company is in the Pre-Profit stage with Production Revenue, and we want to hire an Engineering IC. Based on our assessment of their skillset and fairness in comparison to other team members, we would offer a contract that vests over time between 1000 and 2000 shares.

![image](/blog/2023-08-03-how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley_3.png)

Next, you need to decide on the vesting calendar that the company supports. The most common option is a 4-year vesting schedule with a 1-year cliff. This means that while you begin vesting during your first year, you need to stay with the company for the entire year to be able to exercise those options. The 1-year cliff protects the company from employees leaving early or underperforming.

Carta provides a good explanation on how stock options work [here](https://carta.com/blog/equity-101-stock-option-basics/) — which I recommend to everyone.

Please note that in theory, while the value of these options is $10 per share, the startup will need to conduct a 409a valuation to determine the fair market value of each option, which is likely to be much lower than the initial price, such as $1 per share. And this is the strike price that employees will need to pay to exercise the shares.

Note: when selecting the number of shares, use a number that is divisible by the number of months that the employee is vesting, e.g., for a 4-year vesting period that would be 48 (4 x 12), which ensures that employees get the same amount of shares each month, and there’s no need to account for floating numbers.

This is it for today.

In Part II, I will talk about how you can handle equity top-ups.

So follow me if you want to learn more about what that process may look like.


---

---
slug: how-to-handle-equity-top-ups-at-a-seed-stage-startup
title: How to handle equity top-ups at a seed stage startup
date: 2023-08-09
image: /blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup.png
tags: ['equity', 'startups', 'seed stage', 'equity top-ups', 'employee compensation']
description: In this post, we discuss how to handle equity top-ups at a seed stage startup, providing a step-by-step guide on the implementation process and including links to relevant spreadsheets.
---

<p align="center">
    <img width="600" src="/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup.png"/>
</p>

<br />

In this post, we discuss how to handle equity top-ups at a seed stage startup, providing a step-by-step guide on the implementation process and including links to relevant spreadsheets.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Previously, I shared how we handle equity at OpenBB in [this post](http://didierlopes.com/blog/how-to-handle-equity-at-a-seed-stage-startup-from-silicon-valley).

This blog post will continue that discussion and go over how we approach equity top-ups at OpenBB. It will provide a step-by-step guide on the implementation process and include links to relevant spreadsheets that you can use for your own startup.

I will continue using the purely fictional example that I introduced in the previous blog post with John Doe.

Let’s imagine that John Doe was indeed the right candidate for OpenBB, and on **June 15, 2021**, he was hired and accepted an offer with **2000 options** vesting over the next 4 years with a 1-year cliff. For simplicity, let’s assume that he will vest the 2000 shares by July 1, 2025 (ignoring the additional 2 weeks).

This means that by the end of June 2022, John will have vested 542 shares (13 x 2000 / 48), and for every following month, he will vest 42 shares per month. Note that we only start showing the shares from June 2022 because before that, he was in his cliff period.

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_1.png)

If you do this calculation, you’ll see that it adds up to 2022, whereas John was only granted 2000 shares. This is normal and is due to rounding, thus the shares associated with the last month are updated so that it matches the offer.

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_2.png)

If any of the following situations arise:

1. The initial assessment of the candidate was wrong, and they are not an IC but a Sr. IC.
2. The employee has exceeded expectations, and their equity no longer reflects the value they bring to the company.
3. The employee has other job offers, and you want to reinforce that they are an owner of the company and that their success is important.
4. The employee’s vesting period is coming to an end, and they are considering leaving as they joined the company for the potential upside of an exit.

One option you have is to increase cash compensation. However, offering equity (ownership) is often a better option, especially for startups with limited cash resources.

In these situations, you need to consider an equity top-up. This means offering the employee a new equity grant on top of the shares they are currently vesting. There are multiple types of equity grants, but I will focus on the approach we use at [OpenBB](https://openbb.co) and explain how you can implement it as well.

First, determine how many additional shares you want to grant to the individual and, more importantly, how many shares would be fair for them to vest each month. The former helps determine their stake in the company, while the latter helps assess their value compared to other team members.

In our case, let’s assume it’s February 2023, and John has been with the company for 20 months. We want to reward his contributions and bet on his future at the company, so we decide to grant him an additional 1,500 shares on top of his existing 2,000 shares.

In theory, some companies start a new 4-year vesting period with a 1-year cliff for the second grant. However, the issue with that approach is that the employee will start vesting two grants simultaneously: 2000/48 + 1500/48 shares per month. Once the first grant is fully vested, they will vest a lower amount of shares per month: 1500/48. This means the employee would have less incentive to stay when only the second grant is being executed.

To address this, we ensure that for the next 4 years from the vesting commencement date (VCD) of the second grant, the employee vests the same number of shares each month.

## How can we do that?

### Manual

Here is the information we have:

- 1st option grant VCD: **15 June 2021**
- 1st option grant shares: **2,000**
- 1st option grant schedule: **1/48 per month with 1 year cliff finishing on 30 June 2025**

From here, we infer that in February 2023, John is vesting 42 shares per month and has already vested 542 shares (after the 1-year cliff) + 294 shares (7 x 42).

Now, let’s discuss the decisions we need to make for the second option grant:

- 2nd option grant VCD: We want to start it ASAP, to retain employee — for instance **March 2023**
- 2nd option grant shares: **around 1,500**
- 2nd option grant schedule: **1/48 per month finishing on 30 March 2027**. Note that we removed the cliff since we know the value the employee brings and that “protection”/”retainer” can be removed.

By utilizing maths, we can create the following equation:

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_3.jpeg)

By filling in the information that we know, we get:

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_4.jpeg)

And thus we know that we can get the value that makes this happen.

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_5.jpeg)

However, we don’t want to give the employee fractional shares each month, so we select a round number around the one that makes him receive around 1,500 additional shares over the course of 4 years.

In this case, that number could be 55. This means that the top-up number would be 13 (55–42), except on the last month of vesting for the 1st grant where we need the adjustment.

When we multiply 55 shares per month for the next 48 months starting in March 2023, that adds up to **2,640**.

However, the employee was awarded **1,500 shares** (2nd grant) and still has 27 months (from March 2023 to May 2025) to vest 1st grant shares, which corresponds to a total of **1,122 shares** (42 * 26 + 30, remembering the adjustment done for the last month). This total would be **2,622**, which obviously is different from the expected 2,640.

Therefore, we update the value of the number of shares given on the 2nd grant so that John receives 55 shares per month. In this case, for that to happen, the 2nd grant has to have a value of 1,573.

But obviously, you don’t need to pick up your calculator every time you do this. I mean, what kind of engineer would I be if I didn’t somehow automate this?

### Automated

The spreadsheet below demonstrates what an employee vesting schedule looks like, and below I will write a step-by-step guide so you can fully customize it to your needs.

![image](/blog/2023-08-09-how-to-handle-equity-top-ups-at-a-seed-stage-startup_6.png)

- As a result, **E5** will be updated with 11 months afterward to represent the month before the cliff terminates, which consequently leads to the following months being displayed in **column E**.

2. Fill in the 1st grant shares in **B5**

- As a result, **G6** is updated with the total shares from the 1st grants vested after the 1st year. The following rows in **column G** are automatically updated until the vesting schedule terminates.

3. Adjust **G41** so that the sum of shares in **column G** match the shares from the 1st grant in **B5**.

4. Fill in the top up grant vesting commencement date (VCD) in **C6**

- As a result, **column H** will automatically get populated based on the value that, when added with the cells in **column G**, returns the value in cell **B19**.

- This will also allow us to compute the months that have already been vested from the initial shares in **B11** and consequently calculate the overlap between shares coming from the 1st and 2nd grant in **B12**.

5. Fill in the top-up grant shares that you are thinking about offering to the employee in **B6**.

- As a result, the same computations that were explained earlier in theory will occur. This will result in a recommendation for the top-up shares in **B15** and consequently the amount of shares that the employee will vest monthly in **B16** so that the amount of top-up grant shares is met.

6. It is very likely that the number in **B16** will not be rounded. Hence, we fill **B19** with a rounded version of that number.

- As a result, **column H** will be updated so that the total shares (from both grants) in **column F** matches the selected value in **B19**.

When looking at the total top-up shares in **H67**, that value will no longer match the total top-up shares that we wanted to grant to the employee and that we decided at the beginning in **B6**. This is because we rounded the value and thus impacted the number of shares necessary to achieve that.

The amount of shares needed to update the recommendation in **B16** to the rounded version in **B19** is displayed as an “error” in **B21**.

7. In order to fix that, we simply need to update B6 with the sum of B6 and the error value from B21.

- As a result of this, all the values should now match, and the combined total amount of shares given to the employee in **B8** should match the sum of the shares spread across dates in **F67**. Plus, the error should now be null in cell **B21**.

And that’s it.

I hope you found this useful and are able to use it internally to share with your employees so they understand how the top-ups happen at your startup.

If you want access to this Excel template, feel free to reach out to me on Twitter or LinkedIn.


---

---
slug: openbb-2-year-anniversary
title: OpenBB 2 year anniversary
date: 2023-08-20
image: /blog/2023-08-20-openbb-2-year-anniversary.png
tags: ['OpenBB', 'Anniversary', 'Achievements', 'Growth', 'Finance']
description: Two years of OpenBB. A look back at our achievements and growth in the world of open-source finance.
---

<p align="center">
    <img width="600" src="/blog/2023-08-20-openbb-2-year-anniversary.png"/>
</p>

<br />

Two years of OpenBB: A look back at our achievements and growth in the world of open-source finance.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Today is OpenBB 2 years anniversary of our incorporation. So it’s important to look back and understand the magnitude of what we achieved in 24 months.

In that time we’ve had:

- 100k+ downloads of our installer since we started tracking it
- 2.5M bot commands have been run on Discord and Telegram from over 40k users
- GitHub project grew from 8k stars to 23k+, becoming #1 open source project in the topic of finance
- Our Discord group grew from 1k users to 13k+
- Our SDK has been pip installed over 25k times
- Our team grew from 3 to 19 around the globe
- For more, see http://openbb.co/open

But where were we 2 years ago?

- Only Gamestonk Terminal, the name OpenBB only appeared when we came out of stealth mode in March 2022
- No OpenBB Hub (only launched in May 2023)
- No OpenBB SDK (only launched in Dec 2022)
- No OpenBB Bot (only launched in July 2022)
- No Terminal Pro or Excel Add-In early alpha (development started in 2023)
- No SDK v4 which allows community and data providers to build their own data connectors, easily (to be announced soon)
- No community routines — our first feature aimed at community with upvoting and sharing of routines
- No open source PyWry — A web-view rendering library in python we open source in Feb 2023
- No OpenBB Champions — Our way to highlight users that do impressive work on top of our ecosystem
- No partnerships with universities, financial societies or investment clubs
- No partnerships with data vendors — now we have close relationships with most vendors you would know

If we only focus on where Gamestonk Terminal was 2 years ago we had:

- Static charts using matplotlib (Interactive ones using PyWry was launched in May 2023)
- No way for users to run routines from other users from the terminal directly (launched 3 days ago)
- No AskOBB feature with LlamaIndex (launched in June 2023)
- No way for users to customise the terminal, select default data sources and set their API keys — all from the Hub
- No way to double click an installer and get started in a few minutes — hassle free
- The documentation on markdown files across the repository, today people often praise our documentation in conversations
- No AI features, no reports menu, no dashboards menu, no fixed income, no futures, …
- And the OpenBB Terminal charts looked like this

![image](/blog/2023-08-20-openbb-2-year-anniversary_1.png)

Bill Gates said the famous saying:

> People overestimate what they can do in one year and underestimate what they can do in 10 years.

<br />

In fast-paced startups, I think a better sentence would be, “People overestimate what they can do in one week and underestimate what they can do in 1 year”.

Looking forward to continue building the future of investment research, we’re just getting started.

PS: On a personal level within those 2 years: I quit my full-time job to build OpenBB, got 2 dogs, got married and moved to the Bay Area. Life is great ❤️


---

---
slug: target-market-analysis-with-the-help-of-llms
title: Target Market Analysis with the help of LLMs
date: 2023-09-10
image: /blog/2023-09-10-target-market-analysis-with-the-help-of-llms.png
tags: ['Target Market Analysis', 'LLMs', 'OpenBB', 'BCG Matrix', 'GE McKinsey Matrix', 'Market Attractiveness', 'Competitive Advantage']
description: This blog post provides a comprehensive guide on how to perform target market analysis for your company using LLMs. It includes a detailed explanation of the BCG Matrix and the GE McKinsey Matrix, and how these frameworks can be used to determine market attractiveness and competitive advantage.
---

<p align="center">
    <img width="600" src="/blog/2023-09-10-target-market-analysis-with-the-help-of-llms.png"/>
</p>

<br />

This blog post provides a comprehensive guide on how to perform target market analysis for your company using LLMs. It includes a detailed explanation of the BCG Matrix and the GE McKinsey Matrix, and how these frameworks can be used to determine market attractiveness and competitive advantage.

The open source code is available [here](https://github.com/DidierRLopes/target-market-analysis/tree/main).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

After working on [OpenBB](https://openbb.co) for over 2 years, we learned which markets to go after and which markets to ignore. You may think that this is intuition, but it’s actually the data that you gathered from talking with 100+ users and learning from others in the industry.

However, people who don’t know your business as well as you do (new joiners, advisors, or investors), don’t understand why your target market is X and not Y. Hence, it’s important to backtrace your “experience” with data.

This blog post will focus on how you can perform target market analysis for your company. I will provide the framework and the code to leverage OpenAI to speed up that research process. All of this will be replicable, and you can do it for your own company.

## Context

This framework is utilized for portfolio analysis in corporate strategy to analyze business units or product lines.

### BCG Matrix

Initially, BCG implemented its own framework, which you can read more about here. In a nutshell:

_It uses two variables: relative market share and the market growth rate. By combining these two variables into a matrix, a corporation can plot their business units accordingly and determine where to allocate extra (financial) resources, where to cash out and where to divest._

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_1.png)

### GE McKinsey Matrix

Then, the GE McKinsey Matrix was invented, which you can read more about here. To put it briefly:

_It uses two variables: industry attractiveness and the competitive strength of a business unit. By combining these two variables into a matrix, a corporation can plot their business units accordingly and determine where to invest, where to hold their position, and where to harvest or divest._

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_2.png)

As per the blog post, the main difference between these comes from the fact that the latter uses multiple factors that are combined to determine the measure of the two variables: industry attractiveness and competitive strength. Whereas the BCG Matrix only uses 1 variable per axis — relative market share and market growth rate.

The GE McKinsey Matrix (also known as the Nine-box matrix) has industry attractiveness on the y-axis and competitive strength on the x-axis.

For industry attractiveness, factors to consider can be: Industry size; Long-run growth rate; Industry structure; Industry life cycle; Macro environment; and Market segmentation.

For competitive strength, factors to consider can be: Profitability; Market share; Business growth; Brand equity; Level of differentiation; Firm resources; Efficiency and effectiveness of internal linkages; and Customer loyalty.

## How do you build your Matrix?

All the data will be hypothetical. The goal is to share the process and framework. Each company and market will have its own.

### 1. Define your factors

When we talk about market attractiveness, from your company’s perspective, what makes a market attractive? Consider all those factors and list them. Try to list all the factors that have a weight in that equation, but try to keep them under 10; otherwise, it’s too many to have to assess, and at some point, their weight into the attractiveness is negligible.

Now do the same for the factors that give your company a competitive advantage.

### 2. Weigh each factor
  
Not all factors are created equal. Some factors will influence whether a market is attractive or not. Similarly, for your competitive advantage, what factors give your company a bigger edge?

The goal is to select a weight for each factor so that the sum of the weights for all the factors adds up to 1. The outcome should look something like:

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_3.png)

### 3. Categorize each factor

Now you need to decide how granular you want your assessment to be. Initially, at OpenBB, we started with a scale of 1–3 where 1 is low, 2 is medium, and 3 is high. However, soon we found this to not be good enough since there was not enough granularity. Thus, we increased the range from 1 to 5.

Once you decide on that range, you need to categorize it in a way that makes sense for each factor. This ensures that everyone on the team is on the same page when it comes to assessing a factor. For instance:

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_4.png)

This Google / Excel spreadsheet should look like:

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_5.png)

### 4. Select a list of target markets you want to evaluate

Create a new Google spreadsheet / Excel page for each of them. This will allow you to contain all details for each target market on the same page.

For the purposes of this demonstration, we will use “TargetMarket1,” “TargetMarket2,” and “TargetMarket3.”

### 5. Assess a target market based on selected factors

Now that we have decided on all the factors associated with the target market attractiveness, as well as the competitive advantage, you need to assess each of these based on the target markets that you have selected.

Each target market page should look something like this:

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_6.png)

The factors and weights are automatically pulled from the “Framework page” built previously.

Here you just need to set the rating from 1 to 5 (or according to the range you previously specified) based on the evaluation criteria defined. Each of these ratings is multiplied by the weight, and all of those values are summed up together. If your selected range is from 1 to 5, then it means that the minimum and maximum values are 1 and 5, since the weights add up to 1.

Note that the last column allows you to add comments based on any additional information/criteria that you used to make a rating choice.

### 6. Discover Total Addressable Market

On the spreadsheet above, you may have seen the total addressable market value. I will address how to find this value in a subsequent post.

This is extremely important because even if the market is really attractive, its size can dictate whether to pursue it or not. Most of the time, you don’t want to be chasing a small market opportunity.

### 7. Final matrix / chart

Once you have all this data, you can build the following for each of the target markets:

![image](/blog/2023-09-10-target-market-analysis-with-the-help-of-llms_7.png)

Note that all you need from each target market is:

**Competitive advantage** — the sum of all the factors and their levels multiplied by their weights gives the x-axis.

**Target market attractiveness** — the sum of all the factors and their levels multiplied by their weights gives the y-axis.

**Total Addressable Market (TAM)** — gives the bubble size on the chart.

Then you are ready to make a decision on which market you wish to pursue, and you have data to back it up.

Note: There are a lot of assumptions, and you’ll never have it perfect. But with several iterations with your team, you’ll gain more confidence in those assumptions over time, ensuring that you are on the right track and pursuing the right opportunity.

## Using OpenAI to bounce ideas to assess a target market

Sometimes, it can be hard to provide a rating for each of the factors, or it would be better to bounce ideas off someone. This is where you can leverage OpenAI’s GPT-4 to help you get started.

I built a script that would read from an Excel spreadsheet all the information from the framework page that we have set. That basically means:

- All the factors associated with target market attractiveness, and their levels of description
- All the factors associated with competitive advantage, and their levels of description

Then I prompted GPT-4 to select a level for each of the factors of interest for both attractiveness and competitive advantage, based on what it knows about a specific target market.

For example, let’s say we want to assess the competitive advantage for the target market “Hedge Funds” — this is what the prompt looks like:

    We want to assess our competitive advantage based in relation 
    with factors where we are have an advantage. 
    
    Can you classify those for the following target market: 'Hedge Funds'
    
    The factors that we will access this market are presented below: 
    
    When assessing Data Aggregation, these are the rules:
    We attribute a value of 5 if We provide all data a market needs
    We attribute a value of 4 if We provide most data a market needs
    We attribute a value of 3 if We provide some data a market needs
    We attribute a value of 2 if We provide very little data a market needs
    We attribute a value of 1 if We provide no data a market needs
    
    When assessing Customization, these are the rules:
    We attribute a value of 5 if Market will leverage our open source code
    We attribute a value of 4 if Market will fully customize our platform to make it their own
    We attribute a value of 3 if Market will customize a bit their platform
    We attribute a value of 2 if Market will use platform as is and customize after some time
    We attribute a value of 1 if Market will use platform as is
    
    When assessing Automation, these are the rules:
    We attribute a value of 5 if Allows to save more than 70% of time
    We attribute a value of 4 if Allows to save 50%-70% of time
    We attribute a value of 3 if Allows to save 30%-50% of time
    We attribute a value of 2 if Allows to save 15%-30% of time
    We attribute a value of 1 if Doesn't save any time on automation
    
    When assessing Factor4, these are the rules:
    We attribute a value of 5 if Very high
    We attribute a value of 4 if High
    We attribute a value of 3 if Medium
    We attribute a value of 2 if Low
    We attribute a value of 1 if Very low
    
    When assessing Factor5, these are the rules:
    We attribute a value of 5 if Very high
    We attribute a value of 4 if High
    We attribute a value of 3 if Medium
    We attribute a value of 2 if Low
    We attribute a value of 1 if Very low
    
    Given this information, can you return a level for each of the factors 
    that is our competitive advantage from a viewpoint of Hedge Funds target market.
    
    Please return it in a json dictionary format with the factor and level only. 
    Do not add any other text apart from that. 
    Indent the json with 4 spaces.

Then, using the following block of code, we can get OpenAI’s GPT-4 to provide its input:

```python
    response = openai.ChatCompletion.create(
      model="gpt-4",
      messages=[
            {
                "role": "system", 
                 "content": 
                    """
    You are an outstanding financial analyst and were given the task 
    to perform market research on a possible market segment.
    The company succces relies on your accuracy to categorize a 
    segment and classify according to the factors and levels specified.
                    """
            },
            {
                "role": "user", 
                 "content": prompt
            },
        ]
    )
    print(response.choices[0].message.content)
```

This is what the output looks like:

```console
    {
        "Data Aggregation": 3,
        "Customization": 4,
        "Automation": 5,
        "Factor4": 2,
        "Factor5": 3
    }
```

**And that’s it for today.**

All of this code is open source and available on my GitHub, here: https://github.com/DidierRLopes/target-market-analysis/tree/main

I hope you find this insightful, I appreciate any feedback as always.


---

---
slug: work-life-balance-is-bullsh-t
title: Work-life balance is bullsh*t
date: 2023-09-16
image: /blog/2023-09-16-work-life-balance-is-bullsh-t.png
tags: ['work-life balance', 'success', 'career', 'hard work']
description: This blog post challenges the concept of work-life balance, arguing that success often requires sacrifices in personal time and relationships. It suggests that true balance comes from finding joy in your work and surrounding yourself with like-minded individuals.
---

<p align="center">
    <img width="600" src="/blog/2023-09-16-work-life-balance-is-bullsh-t.png"/>
</p>

<br />

This blog post challenges the concept of work-life balance, arguing that success often requires sacrifices in personal time and relationships. It suggests that true balance comes from finding joy in your work and surrounding yourself with like-minded individuals.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />


For successful individuals, achieving a work-life balance is a luxury often associated with those born into wealth.

Let me explain.

There must be a clear inverse correlation between success (let’s say measured by wealth) and the size of your circle of friends.

**If you want to be at the top of a field, you must work hard.**

End.

Regardless of what BS people say about work-life balance.

You may be lucky — right place right time kind of thing. But by default, you need to work hard to expand your luck’s surface.

And that means that you need to spend your personal time working harder, to be above average.

Since time is limited you need to sacrifice time spent outside working hours, otherwise you will only be average.

People will soon realize that in order to optimize for a successful career, cutting time spent with friends is a necessary evil.

Plus, as you become older you’ll prioritize physical health (which impacts your longevity + performance) and your relationship with your partner (which provides the most significant ROI in terms of happiness).

So, I suggest 2 things:

- Work on a problem and in a space that you truly enjoy so you don’t consider it work
- Build with people who share the same values as you so you consider them friends Once that happens, work-life balance means nothing.

What’s your take?


---

---
slug: a-500k-bet-to-build-the-best-platform-to-do-ai-using-financial-data
title: A $500k bet to build the best platform to do AI using financial data
date: 2023-10-14
image: /blog/2023-10-14-a-500k-bet-to-build-the-best-platform-to-do-ai-using-financial-data.png
tags: ['AI', 'Financial Data', 'OpenBB', 'Data Access', 'Agents']
description: This blog post discusses our $500k investment in building the best platform for AI using financial data. We focus on the rebranding of OpenBB SDK to OpenBB Platform, its features, and the potential payoff of this bet in 2024.
---

<p align="center">
    <img width="600" src="/blog/2023-10-14-a-500k-bet-to-build-the-best-platform-to-do-ai-using-financial-data.png"/>
</p>

<br />

This blog post discusses our $500k investment in building the best platform for AI using financial data. We focus on the rebranding of OpenBB SDK to OpenBB Platform, its features, and the potential payoff of this bet in 2024.

The open source code is available [here](https://github.com/DidierRLopes/openbb-agents/tree/main).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Earlier this year we made a $500k bet.

The [OpenBB SDK](https://my.openbb.co/app/sdk) had access to over 500 data endpoints. But it was built as a second thought (after the Terminal) and it was extremely time-consuming to manage all dependencies.

Plus, the SDK had more than just access to data and thus was bloated.

So we invested $500,000 to build it from the ground up and focus on data access.

Now the OpenBB Platform (rebrand) is lean and scalable.

It can be used in Python (`pip install openbb==4.0.0a2`) but also for web development. More information [here](https://pypi.org/project/openbb/).

And honestly, is the door to financial data.

**Why am I saying all this?**

Because I predict that in 2024 this bet will have a massive payoff.

**The reason?**

Agents are going to be big.

And when they are, financial firms that aren’t leveraging them are going to have to spend a lot of resources to make up for the lack of efficiency.

## Enter OpenBB Platform

- We are data vendor agnostic (we enable them)
- We are open source (everyone can contribute data)
- We standardize data across close to 100 different data providers
- We put a lot of effort into our documentation

The last 3 points are key for agents, and why people will build agents on top of the OpenBB platform.

In a few hours, I was able to use the following prompt:

```console
    Check what are TSLA peers.
    From those, check which one has the highest market cap. 
    Then, on the ticker that has the highest market cap get 
    the most recent rating from an analyst. And tell me who 
    was the analyst and what date was it that the rating was done
```

To have an agent execute this entire workflow in a 1/10th of the time that it would have taken an analyst to do.

Check for yourself the example below,

![image](/blog/2023-10-14-a-500k-bet-to-build-the-best-platform-to-do-ai-using-financial-data_1.png)


---

---
slug: building-the-worlds-investment-research-infrastructure
title: Building the world’s investment research infrastructure
date: 2023-10-19
image: /blog/2023-10-19-building-the-worlds-investment-research-infrastructure.png
tags: ['investment', 'research', 'infrastructure', 'OpenBB']
description: This blog post discusses the process and challenges of building the world's investment research infrastructure. It provides an insight into the products developed by the OpenBB team and their efficient operation.
---

<p align="center">
    <img width="600" src="/blog/2023-10-19-building-the-worlds-investment-research-infrastructure.png"/>
</p>

<br />

This blog post discusses the process and challenges of building the world's investment research infrastructure. It provides an insight into the products developed by the OpenBB team and their efficient operation.

The open source code is available [here](https://github.com/openbb-finance/OpenBBTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

[OpenBB](http://openbb.co) team is comprised of 18 FTE.

We have 8 products: [OpenBB Platform](https://my.openbb.co/app/platform), [OpenBB Terminal](https://my.openbb.co/app/terminal), [OpenBB Bot](https://my.openbb.co/app/bot), [OpenBB Terminal Pro](https://my.openbb.co/app/pro), OpenBB Excel Add-In, [OpenBB Hub](https://my.openbb.co/app/hub), [OpenBB Docs](https://docs.openbb.co) and [Marketing website](https://openbb.co).

This means that on average we have around 2 people working on each product.

This is particularly wild when you look into the complexity associated with each of these products and being at the forefront of innovation.

That average includes not only engineers but design, product, and marketing.

In addition, our [Discord community](https://openbb.co/discord) has 14k+ people and we often get praised regarding how good our support is.

Regardless of our future, I am proud of the team we put together and how efficiently we operate.

It would take a much larger company well over 5 years to build what we built in 2.


---

---
slug: writing-documentation-as-a-founder-is-underrated
title: Writing documentation, as a founder, is underrated.
date: 2023-10-29
image: /blog/2023-10-29-writing-documentation-as-a-founder-is-underrated.png
tags: ['documentation', 'founder', 'startup', 'writing', 'product']
description: This blog post emphasizes the importance of writing documentation as a founder. It discusses how it can give an edge when pitching your product and how it can result in less customer support and a better user experience overall.
---

<p align="center">
    <img width="600" src="/blog/2023-10-29-writing-documentation-as-a-founder-is-underrated.png"/>
</p>

<br />

This blog post emphasizes the importance of writing documentation as a founder. It discusses how it can give an edge when pitching your product and how it can result in less customer support and a better user experience overall.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

A founder spending time writing documentation is f*king underrated.

Working on your product documentation may not be the most rewarding task, but I strongly believe that it gives you an edge when pitching your product.

Good documentation needs to strike the perfect balance between having enough context and being straight to the point.

This week someone asked us how many people worked on our documentation.

There have been less than 3 people working on it. Our North Star metric has been common sense and putting out documentation that we would enjoy reading/learning from ourselves.

Earlier this year I also heard suggestions of hiring a dedicated technical writer.

I think that’s BS, at least at the early stages of your company.

It’s the equivalent of saying that you should hire someone to tell your company vision or that the first sales shouldn’t come from the founders.

No one knows your product better than yourself. And users (particularly devs) will notice the love put into documentation. + This will result in less customer support and a better user experience overall.

Honestly, a very underrated task if you ask me.


---

---
slug: revolutionizing-ai-at-openbb-with-new-leader-michael-struwig
title: Revolutionizing AI at OpenBB with new leader, Michael Struwig
date: 2023-11-07
image: /blog/2023-11-07-revolutionizing-ai-at-openbb-with-new-leader-michael-struwig.png
tags: ['ai', 'openbb', 'startup', 'finance', 'hiring']
description: With the launch of the OpenBB Terminal Pro approaching, we're excited to announce the hiring of Michael Struwig, a Ph.D. with expertise in AI and quantitative finance. Michael will help us to further our AI capabilities, reinforcing our commitment to innovation in the open-source finance space.
---

<p align="center">
    <img width="600" src="/blog/2023-11-07-revolutionizing-ai-at-openbb-with-new-leader-michael-struwig.png"/>
</p>

<br />

With the launch of the OpenBB Terminal Pro approaching, we're excited to announce the hiring of Michael Struwig, a Ph.D. with expertise in AI and quantitative finance. Michael will help us to further our AI capabilities, reinforcing our commitment to innovation in the open-source finance space.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

AI will be one of the technologies that will be looked back in hundreds of years as revolutionary, changing how humans live.

With the upcoming launch of the [OpenBB Terminal Pro](https://my.openbb.co/app/pro), we believe AI can push the limits of the way users do investment research.

We believe our ecosystem is positioned at the forefront of finance in terms of investment research. With the inception of the OpenBB Terminal Pro, we are standing at the cusp of a significant leap. Our journey began with [AskOBB](https://openbb.co/blog/breaking-barriers-with-openbb-and-llamaIndex), a tool that facilitated natural language interaction with financial data, but that was just the start.

Last month, I wrote a [tweet](https://twitter.com/didier_lopes/status/1706731145776566399) explaining why we spent over $500,000 in revamping our core platform. We are committed to creating the best finance platform for quants/analysts to build with. Some key features are:

<ul>
    <li>We are data vendor agnostic - we enable them</li>
    <li>We are open source - everyone can contribute data</li>
    <li>We standardize data across close to 100 different data providers</li>
    <li>We put a lot of effort into our documentation</li>
</ul>

These features allow us to bring AI to our platform from the ground up, and think about how that will impact the user experience at the core level.

For instance this is an extension that James added to the OpenBB Platform.

<p align="center">
    <img width="600" src="/blog/2023-11-07-revolutionizing-ai-at-openbb-with-new-leader-michael-struwig_1.png"/>
</p>

There are a lot of products out there utilizing generative AI for finance. Most of these can be classified as:

<ul>
    <li>Startups built around a particular feature - e.g. chatting with news. With LLMs becoming a commodity, over time it will be easy to understand that this is a feature and not a product itself.</li>
    <li>Larger companies that put a small team together to explore generative AI to be seen as leaders in the space - but without an intention to bring such to market. Often because of outdated tech stack.</li>
</ul>

We are different. The [OpenBB Terminal Pro](https://my.openbb.co/app/pro) is the most customizable investment research platform for teams of quants and analysts. It contains generative AI features, but these are embodied inside the app, and treated as part of the user experience.

Some examples below:

<li>Summarize news articles in seconds</li>
<br />

<p align="center">
    <img width="600" src="/blog/2023-11-07-revolutionizing-ai-at-openbb-with-new-leader-michael-struwig_2.png"/>
</p>

<li>Ask more detailed questions to your widgets like earnings transcript or even insider trading</li>
<br />

<p align="center">
    <img width="600" src="/blog/2023-11-07-revolutionizing-ai-at-openbb-with-new-leader-michael-struwig_3.png"/>
</p>

<li>And more.</li>
<br />

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Most of these generative AI features have been started as side projects by our team members, and once we validated the use case with financial professionals we incorporated it into the roadmap. However, we want to double down on this effort and therefore we're excited to welcome [Michael](https://twitter.com/MichaelNStruwig) to OpenBB.

[Michael](https://twitter.com/MichaelNStruwig) has a PhD in Electrical and Electronic Engineering, has been doing AI for a few years, and prior to joining us was the CEO of Hudson & Thames Quantitative Research.

I first heard him from his reading groups:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe width="619" height="400" src="https://www.youtube.com/embed/FxMDrHnKWnk" title="BloombergGPT: A Large Language Model for Finance" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

<br />

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe width="619" height="400" src="https://www.youtube.com/embed/kX_7ocfTS8g" title="FinGPT: Open-Source Financial Large Language Models" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>

From watching these videos it was clear that Michael is an expert in the field and was capable of understanding deep topics and not solely staying on the surface. So I was keen to have a chat with him. It turns out that he was a big supporter of OpenBB in particular due to our open-source approach to finance and the connection was immediate.

Michael met a few of our team members, and a week later we had a signed contract.

I couldn’t be more excited to welcome him to the team and see the amazing products we are going to build at OpenBB.

Here’s what Michael has to say about joining OpenBB:

> _"At OpenBB, I've discovered the perfect blend of my core passions: ML/AI, Opensource, and, more recently, quantitative finance. Joining the OpenBB team truly feels like a fairytale come true. I've never encountered a team so singularly-focused and driven. They genuinely "get it," and working alongside such talented individuals is incredibly inspiring. I'm ecstatic to be on board and am eager to help contribute to OpenBB's AI initiatives."_

<br />

If you are excited about the field of open source, AI, and finance, and want to help - you can reach out to Michael on [Twitter](https://twitter.com/MichaelNStruwig).


---

---
slug: openbb-bot-our-new-addition-to-the-openbb-open-source-family
title: OpenBB Bot - our new addition to the OpenBB open source family
date: 2023-11-21
image: /blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family.png
tags: ['openbb', 'bot', 'open source', 'discord', 'monetization']
description: The OpenBB Bot architecture is now open source. Check out our Discord Bot architecture now on GitHub.
---

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family.png"/>
</p>

<br />

The OpenBB Bot is now open source. Check out our Discord Bot architecture now on GitHub.

The open source code is available [here](https://github.com/OpenBB-finance/openbb-bot).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## What is the OpenBB Bot, and why did we build it?

When the OpenBB Terminal first went viral, users were writing online that one of the things missing from our product was a chat feature like other investment platforms provide.

However, we didn’t understand why the chatting experience needed to be centralized in the application where users research their financial data. Plus, with the ever-growing userbase of apps like Discord, Telegram, Slack, and others, combined with their capabilities to build apps on top, we thought we could do more.

We believe in a future where you can query financial data right from where you are. Meaning you can chat with colleagues, from any of the apps you’re already using.

This is when we partnered with OptionsFamBot (the biggest Discord financial bot that was present in 15k+ servers, reaching 1 M+ users) to build the OpenBB Bot.

You can read more about our launch in August 2022 [here](https://openbb.co/blog/openbb-bot-launch).

## Failing to monetize. Failing to grow user base.

To provide OpenBB Bot users with access to 100+ financial commands (including expensive datasets such as the options and dark pool ones) we had to pay not just the data vendors but also for the display rights.

This was relatively expensive, but we considered it a marketing cost since we expected exponential user growth. We expected that since the Bot could be deployed in any server in a few seconds, more users would be exposed to the Bot, bringing the Bot to other servers, and so on...

**However, that didn’t happen.**

In September 2022, Discord changed its command syntax to force commands to start with “/” and the user drop was noticeable.

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_1.png"/>
</p>

In the meantime, with the end of the Covid-19 Pandemic, people started leaving their houses more and spending less time with communities investing online. Other companies with financial bots were experiencing the same: investors spending less time talking about investing on apps like Discord.

We saw a trend that these same companies started increasing their prices to balance out the number of users.

This is when we went in the other direction: we upgraded our free tier package and decreased the price of our paid version. That announcement can be found [here](https://openbb.co/blog/openbb-bot-price-change).

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_2.png"/>
</p>

This happened at the same time as we added more innovative features to the bot. Features that OpenBB brought to market, while other bots copied from us today.

We created a codebase that was robust and scalable, but still flexible so that it could be quickly tweaked and deployed on other chatting apps.

A couple of days after the price reduction, we announced OpenBB Bot for Telegram (read more about this announcement [here](https://openbb.co/blog/openbb-bot-arrives-on-telegram)).

With the growth of Telegram users and crypto communities, we were well posed to capture that market.

Or so we thought. But our growth never achieved the numbers we had initially estimated.

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_3.png"/>
</p>

Our conclusion is that the market for financial chatbots is much smaller than what we had originally forecasted. This also meant that our goal with the OpenBB Bot as a marketing tool wasn’t returning the ROI that we were expecting.

So in May 2023 we went pretty much all-in on considering the OpenBB Bot as a marketing expense, and removed the individual paid tier. You can see that announcement [here](https://openbb.co/blog/openbb-bot-free-for-individuals).

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_4.png"/>
</p>

Note that we maintained the control of the Billboard message. This is a feature that allows us to add OpenBB events and announcements to the top of these commands, hence increasing awareness. See below how it looks,

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_5.png"/>
</p>

However, even with that change and [adding an AI feature](https://openbb.co/blog/openbb-midjourney-for-investing) to the OpenBB Bot, the user base never grew past what we had hoped.

So we decided to open source the architecture behind the OpenBB Bot.

## Decision to open source

When talking with Roberto Talamas (check out his [OpenBB champion story](https://openbb.co/blog/openbb-champions-roberto-talamas)), he mentioned that he was building his own financial chatbot for his fund from scratch.

That was the trigger we needed to open source our architecture, so the “Robertos” of the world wouldn’t have to start building their chatbot from scratch, but could piggyback on our architecture, which just works (it has never been down since launch and processed over 2.75 M Discord requests).

Since we failed to monetize the Bot, and our adoption trajectory never grew past our expectations, open-sourcing the architecture behind the OpenBB Bot made a ton of sense.

This architecture utilizes data from the OpenBB platform (check out last week’s [beta announcement](https://openbb.co/blog/celebrating-the-openbb-platform-v4-beta)) which means that developers can simultaneously get familiar with our platform while seeing how easy it is to pull financial data from OpenBB - effectively growing OpenBB’s ecosystem.

<p align="center">
    <img width="600" src="/blog/2023-11-21-openbb-bot-our-new-addition-to-the-openbb-open-source-family_6.png"/>
</p>

I’m looking forward to seeing what products are built around the OpenBB Bot in the future.

You can check the repository [here](https://github.com/OpenBB-finance/openbb-bot).

Welcome to the OpenBB open source family.


---

---
slug: goodbye-openbb-sdk-hello-openbb-platform
title: Goodbye OpenBB SDK. Hello OpenBB Platform
date: 2023-11-29
image: /blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform.png
tags: ['openbb', 'platform', 'sdk', 'core', 'extensions']
description: Today, we are thrilled to announce the new OpenBB SDK, a game-changing platform that is now divided into the robustness of OpenBB Core and the limitless potential of OpenBB extensions.
---

<p align="center">
    <img width="600" src="/blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform.png"/>
</p>

<br />

Today, we are thrilled to announce the new OpenBB SDK, a game-changing platform that is now divided into the robustness of OpenBB Core and the limitless potential of OpenBB extensions.

The open source code is available [here](https://github.com/OpenBB-finance/OpenBBTerminal).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

In the ever-evolving landscape of financial data integration and standardization, OpenBB has been revolutionizing the way individuals and organizations handle data from multiple data providers by utilizing our open-source products.

We have been talking about the OpenBB Platform v4 over the past few months. This is such a milestone for our team and for the financial world that we are renaming the OpenBB SDK into the OpenBB Platform.

The OpenBB Platform consists of the OpenBB Core and OpenBB Extensions.

Let’s dive into each of these, individually.

## OpenBB Core

The OpenBB Core empowers quants and finance developers to create powerful data solutions, offering unparalleled simplicity, flexibility, and scalability. It follows the principle that "less is more."

The core will consist of two main components:

1. **Data Standardization Infrastructure:** This ensures that regardless of the type of data processed by the core, users can expect consistent conventions and naming. This facilitates a seamless experience, even when the data comes from completely different data providers.

2. **Data Source Integration:** Developers will be able to effortlessly connect and integrate various data sources, including databases, APIs, and cloud storage systems.

    a) **Official partner integrations** will be available by having access to official endpoints from data vendors. This ensures the integrity of the data and provides a reference for what data is available to the end user. Our affiliate program will detail where commercial agreements are in place with OpenBB.

    b) Additionally, **community provider integrations** will be available, allowing the community to contribute their own integrations for specific use cases or share them with others through the open-source codebase.

## OpenBB Extensions

OpenBB extensions enhance the capabilities of the OpenBB Core, allowing developers to create custom functionalities and customize the overall Platform according to their specific needs. It is important to note that these extensions can be used as a standalone or integrated with the rest of the openBB ecosystem.

These extensions can be classified into two categories:

<ul>
    <li><strong>Official extensions</strong> developed and maintained by the OpenBB Team, such as the ML/AI Toolkit, Econometrics, and Reports;</li>
    <li><strong>Community extensions</strong> developed by the open-source community. These extensions focus on enabling intelligent data processing and custom workflows that assist users in their investing decision-making process.</li>
</ul>


## Key advantage of new platform V4

By combining the strengths of OpenBB Core and OpenBB Extensions, the OpenBB Platform offers unparalleled advantages for developers and organizations:

<ol>
<li><strong>Enhanced Flexibility:</strong> The modular architecture of the Platform allows developers to choose and integrate only the components they need, avoiding unnecessary complexity.</li>

<li><strong>Scalability:</strong> The OpenBB Platform seamlessly scales with your data integration requirements, ensuring smooth performance even with large volumes of data.</li>

<li><strong>Extensibility:</strong> Developers can create their own extensions and contribute to the OpenBB ecosystem, fostering collaboration and innovation.</li>

<li><strong>Time and Cost Savings:</strong> With its intuitive interface and pre-built components, the OpenBB Platform accelerates development cycles, reducing time-to-market and costs associated with custom solutions.</li>
</ol>

<br />

The reimagined OpenBB SDK into OpenBB Platform (OpenBB Core and OpenBB Extensions), revolutionizes the data integration landscape.

By leveraging the power of OpenBB Core for data integration and standardization, and harnessing the capabilities of OpenBB Extensions for customization and advanced functionality, developers can unlock new possibilities and build cutting-edge data solutions.

Whether you are working with diverse data sources or performing complex data transformations, the OpenBB Platform empowers you to conquer any data challenge and propel your organization towards data-driven success.

We invite users and enthusiasts to explore the OpenBB Platform v4, now available for download and installation from the [OpenBB Hub](https://docs.openbb.co/platform/installation), [Github](https://github.com/OpenBB-finance/OpenBBTerminal/tree/develop/openbb_platform), and [PyPI](https://pypi.org/project/openbb/).

## Inside OpenBB: A peek into our team emails

In order to adhere to one of OpenBB's core values - Transparency - we want you to understand the journey we have undergone and the reason we have dedicated the past 9 months to this endeavor.

So, for the first time, we're sharing a confidential email thread that circulated among our entire team. This thread provides insight into our thought process when it comes to handling large projects at OpenBB.

<p align="center">
    <img width="600" src="/blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform_1.png"/>
</p>

<p align="center">
    <img width="600" src="/blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform_2.png"/>
</p>

<p align="center">
    <img width="600" src="/blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform_3.png"/>
</p>

<p align="center">
    <img width="600" src="/blog/2023-11-29-goodbye-openbb-sdk-hello-openbb-platform_4.png"/>
</p>

Over the next few weeks we will keep iterating on our Platform, based on user feedback, so we can keep pushing for a platform that can be adopted by everyone - from professional investors, data scientists, quants, to students.

If you rely on financial data to do financial research or build apps, we want to hear from you!

Reach out with feedback to support@openbb.finance or join [our Discord](https://discord.com/invite/xPHTuHCmuV).


---

---
slug: the-new-finai-tech-stack
title: The new FinAI Tech Stack
date: 2023-12-15
image: /blog/2023-12-15-the-new-finai-tech-stack.png
tags: ['openbb', 'finance', 'ai', 'agents', 'langchain', 'llamaindex', 'mindsdb', 'nixtla']
description: This blog post delves into how our collaboration with MindsDB, Nixtla, LlamaIndex, and Langchain is revolutionizing the financial world. Read on to learn all about the event "The New FinAI Tech Stack" held last week in SF, California.
---

<p align="center">
    <img width="600" src="/blog/2023-12-15-the-new-finai-tech-stack.png"/>
</p>

<br />

This blog post delves into how our collaboration with MindsDB, Nixtla, LlamaIndex, and Langchain is revolutionizing the financial world. Read on to learn all about the event "The New FinAI Tech Stack" held last week in SF, California.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Context

In early September, I attended a “Future of Finance” event in NYC. Despite the presence of well-known financial professionals from top firms in the industry, I found the event lacked practical applications demonstrating how AI is impacting the financial sector.

Once I was back in the Bay Area, I had a barbecue with Jorge and Max from MindsDB and Nixtla, and I was commenting on that experience. To which Jorge promptly replied - why don’t we do it ourselves? So following this discussion, we decided to put the AI in finance event in motion.

<p align="center">
    <img width="600" src="/blog/2023-12-15-the-new-finai-tech-stack_1.png"/>
</p>

At OpenBB, AI has become a key component in our approach to refactoring the OpenBB Platform from the ground up. We've recently recruited a Head of AI to help us build our strategy and work on this effort full-time.

You can find more details on this [here](/blog/revolutionizing-ai-at-openbb-with-new-leader-michael-struwig).

<p align="center">
    <img width="600" src="/blog/2023-12-15-the-new-finai-tech-stack_2.png"/>
</p>

## OpenBB x MindsDB

A few days later, I visited the MindsDB office to discuss collaborating with Jorge on potential partnerships. I suggested the idea of gaining access to MindsDB's data, a proposal that seemed feasible to implement.

Eventually, we accomplished this, and I even showcased it during the event last week. The code for this endeavour is open source. Take a look [here](https://github.com/OpenBB-finance/backend-for-terminal-pro/tree/main/mindsdb_python).

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/bbc1b3c9-2617-46a1-aae6-f41cfd4d3745"
    />
</video>

However, Jorge had an even bigger idea. He proposed the concept of granting MindsDB users access to OpenBB data via SQL and harnessing MindsDB's capabilities for machine learning. Essentially, we could convert the data frame in runtime into a virtual SQL table, since we have access to the Pydantic model from the OpenBB platform, and we can build that on the go.

After [tweeting about this](https://twitter.com/didier_lopes/status/1710560436398264756?s=20), I received numerous messages, which validated that there was interest in OBB SQL. So, we set off to work on this. Together with the OpenBB team, we made it easy to access all available inputs/outputs for each endpoint, while the MindsDB team worked on virtualizing the tables. The result can be seen [here](https://github.com/mindsdb/mindsdb/tree/staging/mindsdb/integrations/handlers/openbb_handler).

At the event last week, Jorge shared this work. Additionally, in collaboration with LangChain, he successfully developed a Slack bot with direct access to this data, all accessible within Slack

## OpenBB x Nixtla

Back in August, Nixtla introduced the initial foundation generative AI model for temporal data at MindsDB. At that time, we received an invitation to showcase the practical applications of TimeGPT in production, and for the first time, we unveiled Terminal Pro briefly.

I detailed this experience in a [blog post](https://openbb.co/blog/openbb-incorporates-the-first-generative-AI-model-for-temporal-data-timegpt) and shared a similar demo during the event last week.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/a8a391c9-33e8-4c6b-821c-620617d4fe33"
    />
</video>

Following that, Max and Azul from Nixtla proceeded to share a presentation where they used OpenBB data to assess price targets from analysts and develop an approach on how it is possible to reduce the bias inherent to price estimates and produce better estimates.

## OpenBB x LlamaIndex

Back in July, we initiated the development of AskOBB, enabling users to interact with the open source [OpenBB Terminal](https://github.com/OpenBB-finance/OpenBBTerminal) using natural language. In this effort, we leveraged LlamaIndex and you can see more about it [here](https://openbb.co/blog/breaking-barriers-with-openbb-and-llamaIndex).

So when we started discussing an AI in Finance event, it only made sense to reach out to Jerry and Simon to invite their team to present at the event. And so we did. Jerry ended up presenting their [open source SEC insights repo](https://github.com/run-llama/sec-insights) that uses the Retrieval Augmented Generation (RAG) capabilities of LlamaIndex to answer questions about SEC 10-K & 10-Q documents.

As for the OpenBB Terminal Pro, we demonstrated how we are using LlamaIndex to chat with documents that are uploaded to the OpenBB Terminal Pro. The video below highlights these features.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/3c4190be-2676-4790-a59e-c33c6006a195"
    />
</video>

## OpenBB x Langchain

After attending the AI Engineering Summit event, specifically Harrison’s workshop on how to get started with agents using Langchain, I felt inspired to create an agent on top of the OpenBB platform.

So that very day, I went home and started to work on [this repo](https://github.com/DidierRLopes/openbb-agents). By the end of the day, the agent was already able to perform complex queries.

Over time I iterated on it to make the agent more robust, but the improvement on the architecture started to happen after Michael joined OpenBB and he was able to focus on this full-time - the progress can be found on [this open source repo](https://github.com/OpenBB-finance/openbb-agents). An example of a prompt that the agent can answer is:

> _Check what are TSLA peers. From those, check which one has the highest market cap. Then, on the ticker that has the highest market cap get the most recent price target estimate from an analyst, and tell me who it was and on what date the estimate was made._

<br />

So at the event, Harrison presented this architecture which heavily relies on Langchain and OpenBB tools.

<p align="center">
    <img width="600" src="/blog/2023-12-15-the-new-finai-tech-stack_3.png"/>
</p>

Later on, I demonstrated how we can integrate this architecture into OpenBB Copilot and make it available from the OpenBB Terminal Pro.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/a3c20953-ca08-4bdd-b7d5-93878edc7e07"
    />
</video>

## Wrap up

Finally, this was an amazing event organized by MindsDB and a team that put together 5 of the most prominent open-source companies working on problems at the intersection of AI and Finance.

You can rewatch the entire event here:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/V1rYmWWVbIY?si=25HUWPxjAB8sfUPx"
        width="800"
        height="400"
    />
</div>

<br />

We're considering organizing another event like this soon, possibly even in NYC.

And if your firm is interested in early access to the OpenBB Terminal Pro, you can reach out to hello@openbb.finance, we’d love to chat.

---

---
slug: creating-an-ai-powered-financial-analyst
title: Creating an AI-powered financial analyst
date: 2023-12-27
image: /blog/2023-12-27-creating-an-ai-powered-financial-analyst.png
tags: ['ai', 'llm', 'agents', 'tools', 'function calling', 'openbb']
description: Our Platform aims to empower the OpenBB Copilot, an AI-powered financial analyst, to perform tasks ranging from knowledge retrieval to fully autonomous analysis. The architecture involves task decomposition, tool retrieval, and subtask agents, showcasing impressive results in both deterministic and non-deterministic workflows. Read on to explore its capabilities and don't forget to watch the demos.
---

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst.png"/>
</p>

<br />

Our Platform aims to empower the OpenBB Copilot, an AI-powered financial analyst, to perform tasks ranging from knowledge retrieval to fully autonomous analysis. The architecture involves task decomposition, tool retrieval, and subtask agents, showcasing impressive results in both deterministic and non-deterministic workflows. Read on to explore its capabilities and don't forget to watch the demos.

The open source code is available [here](https://github.com/OpenBB-finance/openbb-agents).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Introduction

At OpenBB, we have been thinking deeply about how AI will impact the lives of analysts and quants. We recently [announced the OpenBB Platform](https://openbb.co/blog/goodbye-openbb-sdk-hello-openbb-platform) and have refactored it from the ground up to make it easier and simpler for quants/developers to access financial data. In addition, we hired a new head of AI to lead our AI efforts - you can read more about it [here](https://openbb.co/blog/revolutionizing-ai-at-openbb-with-new-leader-michael-struwig).

I did a 20-minute presentation at the Open Core Summit on this topic that you can watch here:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/A-43EKK2PhE?si=o_lO_lVLpWwwfbvF"
        width="800"
        height="400"
    />
</div>

<br />

Otherwise, the following post will summarize what we presented.

## AI-Powered financial analyst roadmap

When discussing what tasks we wanted our AI-powered Financial Analyst to be able to perform, we arrived at the following levels (in order of complexity):

1. **Knowledge retrieval**: The agent can answer general financial queries without external resources. (eg. ChatGPT "as-is"). Here, the agent relies solely on its training data to answer questions.

2. **Data retrieval**: The agent can answer queries using information inserted into the context (usually as part of a separate data retrieval process that isn’t controlled by the model, such as using [similarity search](https://en.wikipedia.org/wiki/Similarity_search) across a knowledge database using the user’s query).

3. **Autonomous data retrieval**: The agent can answer queries by dynamically retrieving data not currently present in the context or the training data via function calling.

4. **Complex workflow execution**: The agent can reason and answer queries that require a logical arrangement of knowledge retrieval, data retrieval, and autonomous data retrieval calling. It includes action planning and decision-making.

5. **Fully autonomous analyst**: The agent can do all of the above but is self-directed. The agent can dynamically generate additional hypotheses, modify plans of action, and retrieve the necessary data, all while mid-workflow. The agent can make arguments for certain decisions, carry a discussion on the topic, and reason with you.

Our goal is to enable OpenBB Copilot to perform all of the above. I presented a demo of how it would work in this video:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/V1rYmWWVbIY?si=ShScenxTI4bHtERS"
        width="800"
        height="400"
    />
</div>

<br />

## Two types of prompts

Rather than first building an AI-powered financial analyst for the sake of it, we instead started from what we wanted to achieve. We came up with two distinct prompts and our goal was for the agent to be able to successfully perform both of these, but utilizing the same underlying “agentic” architecture.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_1.png"/>
</p>

- **Prompt A (on the left)** - requires linear reasoning (where future answers depend on previous answers). This kind of prompt is generally deterministic, which allows us to access (and verify) the agent’s answers immediately because we can check the underlying facts and data. It also involves a few complex operations across multiple steps, such as extracting a list of tickers from an endpoint and iterating through that list using a different endpoint. Then based on those outputs, a reasoning can be made and a final answer is given.

- **Prompt B (on the right)** - requires independent reasoning (fetching and combining different pieces of independent information). This prompt is typically less deterministic and allows us to leverage LLMs to provide alpha by uncovering insights that would be hard for a human to discover (or, at the very least, discover at scale). Instead of telling the agent what to do explicitly, we instead pose a question and expect the agent to execute an analysis and perform reasoning, without specific guidance or guardrails.

## OpenBB Platform

Getting started with our Platform is extremely easy (docs [here](https://docs.openbb.co/platform)). All you need is `pip install openbb` and you are ready to access 100+ different datasets.

We standardize the data so that you can read our docs once and interact with the Platform the same way, regardless of the type of data you are looking at.

In addition, using the OpenBB Hub, you can set up your API keys which we can manage on your behalf, and all you need to access data via OpenBB is a Personal Access Token.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_2.png"/>
</p>

Crucially, we use Pydantic for all of our endpoints. This ensures that we have both structured inputs and structured outputs. This is extremely important as we feed these models into our agent so that it understands both the input schema during function calling, but also the output schema of the resulting function call. This is standardized across multiple data vendors across the OpenBB Platform.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_3.png"/>
</p>

### OpenBB Tools

From having 100+ different data endpoints that you can access using Python, we created “tools” that an agent “understands” and can use. This is extremely important since this collection of tools will give real-time data to the agent based on the prompt asked.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_4.png"/>
</p>

Since the OpenBB Platform has high-quality documentation, we use each function’s docstring as well as the output field names (with some basic preprocessing). This tweak allows the agent to know where to get the market cap information from, even if it’s within a differently-named endpoint (for example the `equity.fundamentals.overview` endpoint).

Each of these tool descriptions is converted into embeddings that can be retrieved later on based on the query the user provides. This allows our agent to pick the right tools for the job - i.e. if I want to have access to Apple’s market cap, I want to get the tool `equity.fundamentals.overview` because I know that by providing the symbol `AAPL` I can get the market cap value.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_5.png"/>
</p>

So, we create a vector store using FAISS (Facebook AI Similarity Search) and OpenAIEmbeddings, although any vector store with similarity search would also work.

## OpenBB Agent Architecture

<p align="center">
    <img width="900" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_6.png"/>
</p>

This is the overall architecture that our agent will follow, and below we will talk about each of these components individually.

### Task Decomposition

First of all, we don’t want to tackle the user query in one go. This is because LLMs have limited context. Plus, we want the agent to retrieve all the necessary tools to answer the query. But the vector’s store similarity search doesn’t work with one prompt that needs multiple different tools. Additionally, similar to human analysts, breaking a larger question up into smaller manageable subquestions leads to better analysis and results.

So, we break the user’s main query into:

- **List of simpler tasks**: self-explanatory

- **List of tasks dependency**: does the current subtask need a prior subtask to tackle the current subtask?

- **List of “tool search” keywords associated with each subtask**: instead of using the subtask question itself to directly retrieve the correct selection of tools using the embeddings in the vector store, empirically we found that if the LLM could select the most important keywords associated with the task using keyword search. This ended up resulting in a big jump in retrieval performance. This is expected since we are effectively reducing the noise. E.g. “What are Tesla peers” → “peers”.

This is the system message we are utilizing:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_7.png"/>
</p>

To ensure that we have a structured output with the format specified, we create a Pydantic Data model to be used as format in the instruction:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_8.png"/>
</p>

This is what the code looks like, and you can see that the `PydanticOutputParser` goes into the `format_instructions`:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_9.png"/>
</p>

### Tool Retrieval

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_10.png"/>
</p>

This is the function that the agent uses to retrieve the right subset of tools to answer each of the subtasks. Empirically, we found good results by using the similarity score threshold of 0.65. In other words, we retrieve all tools with descriptions that return a better similarity score than that value. In the case where the search yields less than two tools, we return the 2 tools with the highest similarity score instead.

As previously mentioned, you can see that we are not using the subtask query itself but the keywords associated with it. The embeddings of the keywords are (from experimentation) closer to the embeddings of the correct docstring by focusing solely on a few keywords rather than the entire sentence.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_11.png"/>
</p>

### Subtask Agents

Each subtask agent is provided with the original query from the user, one of the subtasks from the task decomposition step, the output from another subtask agent IF there was a subtask dependency AND a set of retrieved tools necessary to answer the subtask.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_12.png"/>
</p>

This is what the agent looks like:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_13.png"/>
</p>

### Final Agent

We then combine the entire context from subquestions and outputs to be given to the final agent:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_14.png"/>
</p>

Finally, we give the final agent the main prompt and the list of tasks from task decomposition and that’s it!

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_15.png"/>
</p>

## OpenBB Results

### Prompt A

_"Check what are TSLA peers. From those, check which one has the highest market cap. Then, on the ticker that has the highest market cap get the most recent price target estimate from an analyst, and tell me who it was and on what date the estimate was made."_

The output can be seen here:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_16.png"/>
</p>

Since this is a deterministic workflow, we can look at the raw data to check whether the output is correct or not - which we can validate below.

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_17.png"/>
</p>

### Prompt B

_“Perform a fundamentals financial analysis of AMZN using the most recently available data. What do you find that’s interesting?”_

The output can be seen here:

<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_18.png"/>
</p>
<p align="center">
    <img width="600" src="/blog/2023-12-27-creating-an-ai-powered-financial-analyst_19.png"/>
</p>

As can be seen above, the results are extremely impressive. We achieved this with a couple of weeks of work, but there are still a lot of areas that we can improve and in which we are currently working on. However, the current results make this an extremely exciting space to be.

All this work is open source and can be found on GitHub [here](https://github.com/OpenBB-finance/openbb-agents).

We are just getting started.

---

---
slug: prediction-for-2024
title: Prediction for 2024
date: 2024-01-01
image: /blog/2024-01-01-prediction-for-2024.png
tags: ['openbb', 'finance', 'ai', 'agents', 'copilot', 'llm', 'pro', 'fine-tune']
description: Companies will own multiple fine-tuned LLMs/SLMs for specific tasks.
---

<p align="center">
    <img width="600" src="/blog/2024-01-01-prediction-for-2024.png"/>
</p>

<br />

Companies will own multiple fine-tuned LLMs/SLMs for specific tasks.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

LLMs like ChatGPT are great for showing what these models are capable of doing in terms of breadth, but at the end of the day, you’re going to look for depth. Instead of relying on one-size-fits-all solutions, companies will look towards the integration of multiple, fine-tuned language models tailored for specific actions.

Enterprises are recognizing the importance of accuracy in their AI applications. General-purpose language models have been revolutionary, but the demand for specialized models is on the rise. From customer support interactions to complex data analysis, having dedicated language models for specific tasks enhances accuracy and efficiency. This is easy to understand since the weights that are being used for the LLM to have a big breadth of knowledge are repurposed for depth.

Personalization is no longer a luxury but a necessity. Specialized language models enable enterprises to deliver personalized experiences to their customers. We have to assume that everyone is utilizing the same models today, so offering ChatGPT in your product isn’t good enough. You need to add alpha to it. And that is done through fine-tuning utilizing your private data.

In an era of increasing cyber threats and stringent regulations, the deployment of fine-tuned language models allows enterprises to enhance their security measures and ensure compliance with industry standards.

As for the financial industry, this is 100% going to happen. Firms will fine-tune language models locally utilizing their proprietary datasets and providing access to their Snowflake/Elastic/ClickHouse/.. instances. This collection of models will effectively enhance the productivity of the firm by 2/3x, even displacing jobs.

We are preparing for this shift at OpenBB and I spent the last few days working on a proof-of-concept with José Donato that will allow users to bring their own copilots to the Terminal Pro. And even have these interact with each other.

<p align="center">
    <img width="600" src="/blog/2024-01-01-prediction-for-2024_1.png"/>
</p>

For a video on how this works you can check: https://x.com/josedonato__/status/1741151037031845986?s=20


---

---
slug: building-my-personal-website-in-docusaurus
title: Building my personal website in Docusaurus
date: 2024-01-08
image: /blog/2024-01-08-building-my-personal-website-in-docusaurus.png
tags: ['docusaurus', 'website', 'blog']
description: How I'm using Docusaurus to build my own personal website.
---

<p align="center">
    <img width="600" src="/blog/2024-01-08-building-my-personal-website-in-docusaurus.png"/>
</p>

<br />

How I'm using Docusaurus to build my own personal website.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

One of my goals for 2023 was to learn web development. Given that I knew 0 to nothing last year, I am extremely happy with my progress.

I never had the time to fully dedicate to it in terms of doing a program/course — but as with anything in life, the best way to learn is by doing.

And this year I worked on web development for:

* OpenBB Hub — https://my.openbb.co
* OpenBB marketing website — https://openbb.co
* OpenBB docs — https://docs.openbb.co
* OpenBB Terminal Pro — https://pro.openbb.co

Thank you José Donato for always helping me with anything!

In addition, I’ve always wanted to have my own personal website. So I felt that this would be the perfect opportunity to do so as I could spend some time with it over weekends.

And so I did, and open source here: https://github.com/DidierRLopes/personal-website

However, this website was taking too much of my spare time, which I could use for more important work. And at the time I became very familiar with Docusaurus, which is what we use for OpenBB docs.

So I thought — why not just use Docusaurus to make my personal website? It’s easy to edit, I’m already very familiar with the architecture, and it’s very easy to update when there’s new information.

So that’s what I did, and also made the entire code open source here: https://github.com/DidierRLopes/my-website

You can access the full website here — https://didierlopes.com/, and there you can find: my personal projects, books I’ve read or want to read, interviews/webinars/podcasts, resume or even my blog.

Any feedback is welcome.

---

---
slug: slack-gpt-summarizing-messages
title: SlackGPT - Your Slack bot that summarizes unread messages
date: 2024-01-15
image: /blog/2024-01-15-slack-gpt-summarizing-messages.png
tags: ['slack', 'slackgpt', 'llm', 'summarization', 'open source', 'bot']
description: The SlackGPT is a Slack bot that summarizes conversations and sends you a summary per channel.
---

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages.png"/>
</p>

<br />

The SlackGPT is a Slack bot that summarizes conversations and sends you a summary per channel.

The open source code is available [here](https://github.com/DidierRLopes/slackGPT).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Context

Saw someone the other day tweeting that it would be great if there was a SlackGPT that could summarize all the Slack messages for when they wake up.

And I immediately related to that. We are a team of 20, and I'm the only one in SF. So when I wake up, most of the team is already half a day in or has just wrapped up.

That means that I always spend the first 30 minutes of the day reading messages to catch-up on everything.

And tonight felt like hacking something quick.

So I created a script that:

* Reads all Slack messages from the time I go to bed
* Summarizes the conversation of each channel
* The bot sends me a message with this summary

## Getting Started

Clone the open source project [here](https://github.com/DidierRLopes/slackGPT).

### Slack API

1. Go to [Slack API page](https://api.slack.com/apps) and create a new app.

2. Install the app in the workspace you are interested in summarizing Slack messages.

3. Get the User OAuth Token which exists in the Install App settings. This will be needed to use Slack's SDK. Set this value as the `SLACK_TOKEN` on a `.env` file if you want to run the script locally or as a GitHub secret if you want to leverage the GitHub workflow.

<br />

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_1.png"/>
</p>

4. Create a **Webhook URL** for your channel so that you can receive messages' summary. Set this value as the `SLACK_WEBHOOK_URL`` on a `.env` file if you want to run the script locally or as a GitHub secret if you want to leverage the GitHub workflow.

5. Depending on the type of access needed, different **User Token Scopes** need to be set. Here's the methods that we will need and the associated user token scopes.
    - conversations_history: This method retrieves a conversation's history of messages and events. It requires the **channels:history** scope for public channels, or **groups:history** for private channels and im:history for direct messages.

    - users_info: This method returns information about a user. It requires the **users:read** scope.

    - conversations_info: This method retrieves information about a conversation. It requires the **channels:read** scope for public channels, or **groups:read** for private channels and im:read for direct messages.

<br />

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_2.png"/>
</p>

### OpenAI API

Go to [OpenAI API page](https://platform.openai.com/api-keys) to extract the API key. Set this value as the `OPENAI_API_KEY` on a `.env` file if you want to run the script locally or as a GitHub secret if you want to leverage the GitHub workflow.

<br />

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_3.png"/>
</p>

### Slack channels

Get the Channel IDs that you are interested in reading messages from.

Set those values as the `SLACK_CHANNEL_IDS` on a `.env` file if you want to run the script locally or as a GitHub secret if you want to leverage the GitHub workflow. If you want to read from multiple channels you can set `SLACK_CHANNEL_IDS` with multiple IDs separated by commas (with no space), e.g. ABC123,DEF456,GHI789.

<br />

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_4.png"/>
</p>

### Running

After you fork the project [here](https://github.com/DidierRLopes/slackGPT), there are 2 ways you can run the code.

1. Ad-hoc by running the python script with `python slackgpt.py`

2. Automatically, by leveraging GitHub actions. For this you will need to set up GitHub secrets and you can modify [this workflow](https://github.com/DidierRLopes/slackGPT/blob/main/.github/workflows/main.yml) in order to change the frequency of the messages sumary. 

The most important part of this script is the `cron: '0 8 * * 1-5'` which specifies the frequency. In this case, the expression means that the task will run at 8:00 AM from Monday to Friday, and breaks down as follows:

- 0: Specifies the minute when the task will run (in this case, 0 minutes).

- 8: Specifies the hour when the task will run (in this case, 8 AM).

- *: Represents any day of the month, meaning the task is not restricted to a specific day.

- *: Represents any month, meaning the task is not restricted to a specific month.

- 1-5: Specifies the days of the week when the task will run (Monday to Friday).

## Results

By inputting the following text on the Slack channel of my choice:

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_5.png"/>
</p>

The SlackGPT summarized it as follows:

<p align="center">
    <img width="600" src="/blog/2024-01-15-slack-gpt-summarizing-messages_6.png"/>
</p>



---

---
slug: introducing-the-openbb-add-in-for-excel
title: Introducing the OpenBB Add-in for Excel
date: 2024-01-17
image: /blog/2024-01-17-introducing-the-openbb-add-in-for-excel.png
tags: ['excel', 'launch', 'openbb', 'announcement']
description: We acknowledged the enduring centrality of Excel in the financial sector, so we're now making data from the Terminal Pro readily available in Excel. We're also excitedly working to integrate the "Bring Your Own Data" feature into our Excel Add-in, a move we foresee as a transformative step in the financial data industry.
---

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel.png"/>
</p>

<br />

We acknowledged the enduring centrality of Excel in the financial sector, so we're now making data from the Terminal Pro readily available in Excel. We're also excitedly working to integrate the "Bring Your Own Data" feature into our Excel Add-in, a move we foresee as a transformative step in the financial data industry.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Introduction

Building something people truly want requires direct engagement with them. After conducting over 100 interviews with analysts and quants, three key insights surfaced:

1. The financial world runs on Excel.

2. The primary value of the OpenBB Terminal Pro lies in its customization (bring your own data + widget/dashboard creation) and AI features.

3. The financial world, **LITERALLY**, still runs on Excel.

For topic number 2, we were well underway towards building the [Terminal Pro](https://openbb.co/products/pro) as the most customizable and efficient financial terminal.

But for topics number 1 and 3, we weren’t.

So we devised a small task force to tackle this effort and work with design partners towards building the [OpenBB Add-in for Excel](https://openbb.co/products/excel).

The goal was simple: **financial data available on the Terminal Pro should be accessible in Excel**.

But as we do for all our products, we wanted to understand where this product would sit in our ecosystem.

Since the Terminal Pro offers a basic data tier (including historical price, fundamentals, analyst estimates, news, macro-economy, and forex) with redistribution rights, we decided to make those same datasets available in Excel.

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_1.png"/>
</p>

## Getting Started

So, in simple terms, we allow the user to access financial data right from Excel, by connecting with the OpenBB server to do the data request.

In the example below you can see that we are using the formula `=OBB.EQUITY.ESTIMATES.PRICE_TARGET("AAPL")` which retrieves the latest data about AAPL’s price target.

You can read more information about it in our [Documentation](https://docs.openbb.co/excel/reference/equity/estimates/price_target).

This is how it looks:

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_2.png"/>
</p>

This was a huge step for us.

However, another question came up:

**As the datasets keep expanding, discoverability will become a big problem.**

And we haven’t been around for 40 years for users to be familiar with our terminology.

So, how would users know what function to use, to access the datasets they are interested in?

We figured that enterprise users would be interested in accessing the data they are already visualizing in the [OpenBB Terminal Pro](https://openbb.co/products/pro).

So we allowed them to get the Excel function directly from each widget:

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_3.png"/>
</p>

After clicking on the “Functions” button in the ellipsis icon of the widget data you are interested in, this is what a user sees:

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_4.png"/>
</p>

## Templates

Since [OpenBB Terminal Pro](https://my.openbb.co/app/pro) users are used to the templates they have access to with our product, e.g. our equity analyst template:

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_5.png"/>
</p>

We ensured that similar templates were available for the Excel Add-in, and you can find them [here](https://my.openbb.co/app/excel/templates).

<p align="center">
    <img width="600" src="/blog/2024-01-17-introducing-the-openbb-add-in-for-excel_6.png"/>
</p>

## What's Next

Last but not least, we are working on the upcoming integration of the "Bring Your Own Data" (BYOD) feature into our Excel Add-in.

Until now, this capability has been exclusive to the OpenBB Terminal Pro and is a **cornerstone of our offering**.

But it doesn’t have to stop there.

Our foundation on an open-source platform empowers us to facilitate open data access across multiple interfaces, whether through the Terminal Pro or the Excel Add-in.

We expect this to be a complete game-changer in the industry. While numerous financial Excel add-ins exist, they lack the flexibility to seamlessly incorporate third-party or proprietary datasets.

We are currently working with design partners on this. So if this sounds like something you are interested in - please reach out.

We have a 5,000+ [waitlist](https://my.openbb.co/app/pro/early-access) to the Terminal Pro and have already started onboarding users. As part of the Terminal Pro free trial, you will be granted access to the OpenBB Add-in for Excel as long as you have Microsoft Excel.

Wondering how to get started easily? Here is a video to help:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/Rn3M36H_6Cw?si=hxCf3zMw2y4kIi7N"
        width="800"
        height="400"
    />
</div>

<br />

You can find more tutorials in the [Documentation](https://docs.openbb.co/excel/getting-started/installation).

For more information, contact us at sales@openbb.finance or sign up for [our waitlist](https://my.openbb.co/app/pro/early-access).



---

---
slug: 12-things-i-learned-in-2023
title: 12 things I learned in 2023
date: 2024-01-22
image: /blog/2024-01-22-12-things-i-learned-in-2023.png
tags: ['learning', 'experience', 'growth']
description: The 12 things I learned in 2023
---

<p align="center">
    <img width="600" src="/blog/2024-01-22-12-things-i-learned-in-2023.png"/>
</p>

<br />

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The 12 things I learned in 2023

### 1. Don't delegate anything that you wouldn't do yourself.

It's extremely important to work on little things to show your team that nothing is too small to spend time on, and sets a precedent that you are willing to work on the ground next to them.

E.g. Elon Musk sleeping at the gigafactory to show his team that he was there next to them.

### 2. Be curious and humble enough to be willing to ask dumb questions.

If I don't know something, I never pretend understanding what the person is talking about.

I would take the knowledge over a "smart" label, any day.

### 3. Implement feedback loops on everything you do, otherwise you can't adapt.

Last year I decided to work on [tracking our employee engagement](https://openbb.co/company/open/team), and this is one of the best and most valuable initiatives I have worked on.

It has provided us tons of feedback that we were able to act on, and improve what it's like to work for OpenBB. More information on this [here](https://openbb.co/blog/employee-engagement).

### 4. UX is more important than UI.

I keep seeing tweets about UI improvements on a website and/or product. I love that type of posts, and wish there was a similar trend going on for UX improvements.

While UI is critical to attract users, UX is king to retain them.

It’s like dating - the looks is in the UI and the personality is the UX.

While they may be perceived as their own separate bubble, they are not. Someone with an amazing personality (UX) will appear as more beautiful (UI).

### 5. If in presence of a 2-way door decision, you should decide fast.

Being fast to decide to do A instead of B in a 2-way door decision is ideal because even if that wasn’t the correct decision, adapting after will still be better than being stuck at the decision stage.

Plus, you’ll be surprised by how many time you actually get it right given the level of context and knowledge you have in the space.

Knowing what is a 1 and a 2-way door decision, separates great from poor leaders.

I like [this video](https://tiktok.com/@evancarmichael/video/7317081673865235717) from Jeff Bezzos talking about this.

### 6. There’s a ton of data in intuition and common sense.

As a leader, most of the times you have to make decisions with no hard data evidence. And by hard data I mean a spreadsheet with numbers or a powerpoint with charts.

However, you do have that data. It’s just not in a clean format and lives on your head.

This data has been aggregating by spending more time thinking about the problem you are solving than anyone else, by talking with customers, by talking with partners, and everything in between.

Trust your intuition, more often than not presentations are done to justify decisions that you knew were right all along. Skip that and you will be able to move faster.

### 7. Hear feedback from everyone but only listen from a few.

People paying for your product, will provide you 10x feedback compared to others. Use common sense for others.

### 8. Be there for your team.

Make sure to remind your team that you couldn't do it without them.

A single off-line event per year is not enough.

Show that you care by being there: asking about their family/pets/hobbies, messaging them when they perform above expectations, send them gifts when something negative happens, ... act like a friend but manage like a captain

### 9. Fire B and C players early. 

Keeping a team of A players is hard but extremely rewarding, and necessary. 

It sets the precedent that average work is not enough to work at your company, and high performers will want to work for you to be surrounded by people that push them everyday.

### 10. Distribution is more important than product.

Took me some time to understand this, but I have no doubts about this now.

This is why the sentence of “A good product with great distribution will almost always beat a great product with poor distribution.”

### 11. Leave your comfort zone.

I'm really shy on stage and this year I've presented a few times. And I’ve impressed myself, while I'm far from good I've come a long way.

When i started learning english my goal was to be able to make people laugh in english, that took a while.

I've now been able to make people laugh whilst on stage and I didn't expect that I’d be able to do this anytime soon.

### 12. Tell your loved ones how much they mean to you.

Most of us have someone by our side that allow us to keep performing at highest level day in and day out.

Ensure they know you couldn't be the person you are today without them.


---

---
slug: openbb-copilot-now-available-to-all-terminal-pro-users
title: OpenBB Copilot is now available to all Terminal Pro users
date: 2024-02-27
image: /blog/2024-02-27-openbb-copilot-now-available-to-all-terminal-pro-users.png
tags: ['openbb', 'copilot', 'generative ai', 'ai', 'llm']
description: Introducing the OpenBB Copilot, an ever-present financial analyst at your fingertips with the OpenBB Terminal Pro.
---

<p align="center">
    <img width="600" src="/blog/2024-02-27-openbb-copilot-now-available-to-all-terminal-pro-users.png"/>
</p>

For the past few weeks, we’ve been working on the OpenBB Copilot, an ever-present financial analyst at your fingertips with the OpenBB Terminal Pro.

<br />

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The [OpenBB Copilo](https://openbb.co/use-cases/ai) is our latest addition to the [Terminal Pro](https://openbb.co/products/pro), and we could not be more excited to share it with you.

If you don't have access yet, join the [Terminal Pro waitlist](https://my.openbb.co/app/pro/early-access) and enjoy your 3-week free trial soon!

Now, take a moment to meet your new **AI investment research partner**.


## What can the OpenBB Copilot do?

OpenBB Copilot is multi-functional and can perform several tasks that are useful to analysts. We’ll be exploring these below.


### Generic financial knowledge

Using OpenBB Copilot, you can ask any general financial question. For example:

**What is the P/E ratio?**

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/7c8c9658-4c4d-4090-8a61-826de823981b"
    />
</video>

As an additional bonus feature, OpenBB Copilot includes a LaTeX renderer to display mathematical formulas and equations.


### Conversation capability

OpenBB Copilot is a conversational agent and is, therefore, aware of the chat history of the current conversation.

As a result, you can ask follow-up questions and steer OpenBB Copilot toward your line of inquiry while developing an investment thesis.

To clear the message history, for example, when investigating a new asset, you can click on the trashcan icon to start a new conversation.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/3e1170f2-59b4-458a-bc6e-cd86c688b8db"
    />
</video>


### Terminal Pro as context

If you ask questions about the data on the dashboard, OpenBB Copilot will query the Terminal Pro for the data necessary to answer your query.

The Copilot has access to the dashboard metadata on the backend and can decide to retrieve data from any of the widgets currently on your dashboard.

In most cases, if you can see the data on your dashboard, you can assume OpenBB Copilot has access to it.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/6c22201f-67ce-49a7-ab4d-213b594c657b"
    />
</video>

This is an application of what’s known in the AI world as function calling, which allows LLMs to interact with external systems.

The OpenBB Copilot can choose to automatically retrieve the data from your dashboard if it needs it to answer your query.

The advantage of this approach is that, since you can retrieve data from any widget, you can also expand OpenBB Copilot’s knowledge by adding custom widgets or by bringing your own data to the Terminal Pro.


### Query specific widgets

Sometimes, you may wish to focus your analysis and use OpenBB Copilot with only a specific subset of widgets.

For example, you may want to use OpenBB Copilot to assist you in a deep analysis of an earnings transcript in the "Earnings Transcript" widget without retrieving data from the rest of the dashboard.

To achieve this, you can chat with specifically selected widgets by clicking on the "Add widgets as context".

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/dc74b30a-73ed-4b85-af23-9bb8ab9c844c"
    />
</video>

Selecting a widget will make that widget's data available to OpenBB Copilot while excluding all the other widgets.

You can then use the Copilot as normal and the unselected widgets will be ignored by the Copilot.


### Query your own documents

You’re also not limited by the data that is available in Terminal Pro.

You can upload your own documents for OpenBB Copilot to use as context while answering your queries.

OpenBB Copilot currently supports txt, PDF, CSV and XLSX documents.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/dec690c2-ed07-40c1-8b3e-ff0ad7294258"
    />
</video>

### Citations

We understand that sometimes getting an answer from an AI chatbot with financial knowledge isn’t satisfactory.

You often want to do further research or do your own fact-checking of the sources used to answer to your query.

That is why OpenBB Copilot provides citations as part of its answers.

When using the Terminal Pro as context or chatting with your uploaded data files, the Copilot will cite which data sources it used to formulate the answers.

Simply mouse over the citation to see which widget data was used, or which uploaded file was referenced. For PDF document specifically, the Copilot will also source the specific page that was used to answer your query.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/e35a0b2c-8150-4d2b-9743-a72862ba3b6d"
    />
</video>

## What if you don't want to use our copilot?

You don’t have to. That is the reason we came up with the Bring Your Own Copilot concept.

If you’re an OpenBB Terminal Pro user, you’re able to bring your own financial Copilot that has been fine-tuned and tweaked on your enterprise’s private data.

This provides an edge to financial firms as they can access their own fine-tuned LLM with access to real-time data provided by the OpenBB Terminal Pro - making this the perfect combo to perform investment research.

We have an [open-source repository](https://github.com/OpenBB-finance/copilot-for-terminal-pro/tree/main) to help you make your own copilots accessible on the Terminal Pro.

You can also see the video below:

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/2703e8d8-2497-40ab-b513-678d78989f5b"
    />
</video>

<br />

Check out our [AI page](https://openbb.co/use-cases/ai) to learn more about these features and stay updated in the future.


---

---
slug: moving-from-london-to-the-bay-area-and-what-changed
title: Moving from London to the Bay Area and what changed
date: 2024-03-02
image: /blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed.png
tags: ['learning', 'experience', 'growth', 'moving', 'london', 'bay', 'US', 'travel']
description: Moving from London to the Bay Area and what changed
---

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed.png"/>
</p>

The culture shock from moving to the Bay Area from London.

<br />

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

A few months ago, I wrote a blogpost about what was needed in order for my wife and our 2 dogs to move to the Bay Area from London. You can check that blog post [here](/blog/leaving-london-to-live-in-san-francisco/).

Since then, I’ve had some people asking me after living in the Bay for 1 year, what are the biggest differences I’ve experienced in terms of lifestyle & culture.

I will write a section below for each of the major topics I experienced. Note that this is based on my experience, and you may disagree/have different opinions than me on some of these - which are very welcome.

## Living costs

Back in 2016 when I was at university, in Portugal, I used to pay 200 euros/month to live in an apartment with a roommate. My university cost was 800 euros/year and my parents gave me a monthly allowance of 300 euros/month to pay for food and anything else. I didn’t do many activities and would rarely go out, so I was able to live comfortably on that.

Once I moved to London (in 2017) to pursue a MSc. at Imperial College I was paying 1.6k £/month for a studio in Earl’s Court. This was walking distance from Imperial (didn’t have to pay for transportation) and was cheaper than the accommodations that the university offered. The university was no longer 800 euros/year, it cost £11k for the entire MSc (1 year).

So there was a shock that I experienced in terms of living costs from Lisbon to London.

Once I decided to move to the Bay Area (2023) I knew that the living costs were going to be higher, but in my head “how higher can these be?”.

Oh boy.

Apparently, a lot.

### Shopping

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_1.png"/>
</p>

This was the first shopping trip I had in the Bay (Whole foods is the equivalent to Waitrose in London, I often still confuse them and my wife finds it funny - anyway, they call it whole paycheck here bc $$$). These 10 items cost me $69.34. I couldn’t believe it.

Costco is arguably my favorite shop. It’s like a better IKEA. We would spend at least 2 hours shopping but we would get supplies for 3 weeks, the famous hot dog/pizza combo and put gas in the car. The membership (120$/year) pays itself really fast at Costco. The main downside is that since we were only 2 and I hate throwing food out, it happened a few times that I had to adapt my meals to make sure no food would go to waste. E.g. Eat a guacamole pack a day since the smaller pack brings 24 and it there were 24 days until the expiry date.

PS: I like Costco so much that I always took the friends/family who visited to it, as if it was an attraction. Sometimes we would even go directly to Costco from the airport, to breathe in Costco and all its magnificence upon arrival :D


<p align="center" className="flex items-center gap-2 justify-center">
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_2.png" />
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_3.png" />
</p>

### Apartment

Since I went to the US with the sole purpose of working hard and making OpenBB successful, I ended up picking a nice apartment in San Mateo - given that we spend 90% of our time at home. Our monthly rent for a 2-bedroom flat was 4.4k $/month with everything included (including both dogs rent, lol).

The apartment had a small gym, a common pool & bbq area and an outdoor hot tub. But more importantly, it was located right by 101, walking distance from Peets & Starbucks and very pet friendly. In addition, I was 40m from SF, 10m from the airport and 20m from Palo Alto. This meant that we were in a very calm area whilst being close to the most important hubs.

The common pool and BBQ area (+ the sunny weather) were insane, sometimes I wish I had spent more time there. But I guess you tend to value things more when you don’t have them :)

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_4.png" />
</p>

### Tipping culture

In Europe, I very very rarely tipped. Not just me, but all people I know. It’s just not part of our culture. Everything is factored in. Even in London, most restaurants will have a “service charge” which is kind of a tip BUT it’s included in the bill and so you don’t need to think about how much you are going to tip.

In the US, if you don’t tip - people will judge you. The system is done in a way that tipping is not a “should” but closer to a “must”. Workers rely on your tips when thinking about their total compensation. And now I understand why my friends who work in restaurants/cafes enjoy Americans so much, it’s because they bring their tipping culture to Europe and so that extra money is very meaningful for European folks.

Some rules that I follow:

- If I go to a coffee shop and just do takeaway, I don’t tip. If I sit down in a table, then I tip between 15-20%.
- When in a restaurant, I always tip. But the percentage varies based on the quality of the service and food. If I didn’t like it, I still tip 10%. If I really enjoy it then I tip 20%. If it was just good, I do 15%. This is a rule of thumb. In practice, I do this but then round to a multiple of $5 because yes (this is the equivalent to my wife not allowing odd numbers as the TV volume).

The best way to get used to this is to just internally assume that 20% extra cost on whatever you are seeing on the menu. If a burger + drink costs $30, assume it will be $36 after taxes and tip.

Note that in restaurants they expect you to leave your credit card on the top of the bill. This is so they can “freeze” the bill and once they bring the receipt back they will wait for you to add the amount for the tip (+ total). Once you fill this and sign (in theory, the signing is mandatory) - only then they will be able to withdraw the bill amount + the tip.

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_5.png" />
</p>

## Sports

Growing up in Portugal I used to watch every Benfica game and then in high school you would talk about the games you watched during the weekend. There was no other sport, it was a binary - either you are a soccer fan or you don’t watch any sports at all. When I moved to London, this changed slightly, there were people that liked other sports but Soccer was still the main sport by a very big margin. People would fill up a pub to watch Soccer only - maybe the other sport that came closest was Cricket.

In the US, people don’t really care about Soccer. It feels like it’s a sport that kids do, but adults don’t really talk about it or watch it. They know about Messi/Ronaldo, but aren’t really fans. On the other hand, American football, Basketball and Baseball are very big. Aquatic pole also seems to be popular in the Bay Area.

I remember when we got the apartment, I was walking my dogs and there was a soccer pitch nearby. I was super happy because I thought that I could do what I used to do in London and just show up to the ground on the weekend and do a pick-up play with random folks. Unfortunately, after several attempts of walking nearby I realized that the pitch was only used for kids to play soccer and never adults. In London, on a sunny day, it’s hard (maybe impossible?) to find a soccer field empty.

<p align="center" className="flex items-center gap-2 justify-center">
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_6.png" />
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_7.png" />
</p>


### College sports

While in Europe in general, no one cares about college sports. The reality in the US is completely different. Not only do they fill their stadiums with 50k+ people, but these games bring a TON of money. People will literally sit outside the stadium in the morning and wait for the time of the match. It’s called tailgating.

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_8.png" />
</p>

I’ve noticed that some people don’t even go to the stadium, they just sit outside the stadium watching the game in the car park on their TV and drinking. I still don’t fully get why you would do that, but I guess it’s a tradition.

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_9.png" />
</p>

## Working Culture

My plan was to live in the US for the duration of my visa (O-1) and then return after 3 years. But the working culture is the reason why I hope to stay for longer. Most people you will meet in the Bay work very hard. They don’t finish the day at 5/6pm but do long hours to get shit done. What motivates them is building the future and being part of something bigger than themselves.

In London, I felt like the culture was very strong towards finishing your working day and going to the pub at 5/6pm - get drunk. And then repeat. Before London I didn’t drink alcohol, and in London I started drinking sometimes to socialize. In the Bay I feel like there isn’t an expectation that everyone wants to drink, and people leave events early because they want to head home to work on something - which is something I used to do back in London.

I also feel like in the Bay Area, when you go to events you can talk about what you are working on without people judging you for bringing “work” into the conversation. And I tend to find these conversations more interesting. In London, there’s less emphasis in tech, and the interests tend to be a bit broader: music, arts, history, etc..

While people say that London is a big hub for startups & founders, I didn’t find this to be the case. In the Bay Area, the likelihood of you encountering someone on the street and them working at a startup (most of the time their own) is really high. You can even feel the strength of this tech community on Twitter, whereas that doesn’t exist (AFAIK) in London.

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_10.png"/>
    <p>Elad Gil fireside with Satya Nadella at Stripe's HQ</p>
</p>

### Equity as part of compensation package

Most European startups do not offer any equity. In the Bay Area, all startups offer equity. The earlier you join (higher risk) the more meaningful the options you get are. One of the reasons this works is because US employees are, in general, hard-working and will go the long way for their company. So this makes it so that incentives are aligned, and employees want to work harder because that equity can become much more meaningful than their base salary (potentially life-changing).

One of the reasons this works so well is that pretty much every US person knows someone in firsthand who made f-u money by selling their shares in secondaries, or has at least heard stories about this. While I was in the UK, before starting OpenBB, I didn’t hear about this once. Also because companies have no interest in offering you equity if they don’t have to.

E.g. at my previous startup I used to stay working late into the night, because in my perspective this would increase the startup's chances of success. However, I had no equity. So this meant that if the startup was wildly successful, I would have no direct gains from it and the company would not owe me anything. Offering equity through a typical 4-year vesting schedule (with 1-year cliff) provides the perfect type of alignment.

### Holidays

The amount of holidays is a good example that demonstrates the hard-working culture that so well characterizes the US. In the US they are used to having 2-weeks off in a full calendar year. In London, most companies offer at least 4-weeks, which is effectively 2x the number of holidays.

## Driving culture

The London underground works impressively, I lived there for 5 years and never once even considered owning a car.

I thought I could do the same in the US and people were being dramatic. That thought lasted maybe 2 days?

On the first day I had to go to Fedex which was a 15-20m walk, and when I told the apartment administrator that I was going to walk there she looked at me like I was crazy and said “you need to take your car”. After walking there I understood what she meant and that unless you are in a city, the pedestrian sidewalks/roads just aren’t prepared for pedestrians.

### Differences

- You drive on the right (x2) side of the road. Since I didn’t drive in the UK, this was very easy for me as I’m used to driving in Portugal where we also drive on the right side of the road.
- In the UK (or Europe, in general) having more than 3 lanes on the highway is atypical. In the US, having 6 lanes it’s considered normal. Sometimes it’s tricky and you can’t be in the most right side because the 2 right lanes may both exit and thus you need to hop over 2 lanes to keep on the same route. This mistake can be costly.
- There are very very few roundabouts in the Bay. There are a LOT of intersections. I like it less (not because I think it’s slower) but because it’s more “boring” to wait for the green light and from my point of view, people are more likely to grab their phone during that time because they don’t need to pay as much attention, at least compared to a roundabout where you are waiting for an opening to keep moving. (there are so few roundabouts that the first time I saw one I took a picture to share with my wife)
- There’s a “Right on Red” policy. This means that if you are at an intersection and it’s red for you to proceed if there’s no incoming car from the left side you can turn right on the red. I like this because it allows for traffic to flow better. My wife doesn’t like it because as a pedestrian sometimes cars start accelerating and don’t respect pedestrian as much. Nonetheless, I love to make this joke when people from Europe visit, where I say that I’m going to pass a red and they are shocked when they see me turning right on a red light.
- In the Bay they have FastTrack which allows people to pay to use the most-left lane and avoid traffic. Although this is capitalist I like it because if I’m in a rush I can pay a few dollars to avoid the congestion - it’s a type of SaaS - Speed as a Service 😄

### Waymo

Waymo, a self-driving car division that started off Google, was the first startup I applied to when I finished university. I have been bullish on self-driving cars since university - my dissertation was on that topic and I had to propose it myself, since there were no proposals for such. So seeing Waymo operating in SF was mind-blowing to me.

Autonomous cars are a matter of time - and SF (and the Bay Area) being the city where Waymo starts operating, shows a lot about how progressive this city is. I recommend everyone to try one out.

My dad, someone who was born and raised in a small town in Portugal, and who understands very little about technology seeing this was something. Him seated in the passenger’s seat for the full 16 min drive recording a wheel with no driver and ending the journey telling me “I never thought I would see this in my life, thank you” is something that no amount of money in this world could buy.

<p align="center" className="flex items-center gap-2 justify-center">
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_11.png" />
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_12.png" />
</p>

### Driving license

Even though I have a Portuguese driving license since I was 18. That’s only accepted for 10 days or so - and if you have an international driving license for it to work for longer (I didn’t go this route). So I had to apply for a California Driving License (CDL) which meant taking a written exam and doing a driving test.

The written exam was actually fairly easy compared to the one I had in Portugal. In the Bay, the test consists of 36 multiple-choice questions, and you are allowed to fail up to 6 questions.  In Portugal I had 30 multiple-choice questions and could only fail up to 3.

I found the written exam to be easy after doing multiple practice tests online. Most of the questions ended up being somewhat similar to the ones I had practiced the day before.

Doing the written exam was very different though. In Portugal we did it in a closed room with someone watching us and everyone else in silence. In the Bay Area I did it in a corner of the DMV with a lot of background noise behind me. I had to use both my hands to cover my ears to be able to focus, which was annoying.

The driving exam is much easier than the one I did in Portugal. It lasted for maybe 20-25 minutes and it was just around the DMV. When doing it in Portugal, the test lasts 40 minutes and includes: parallel parking, reversing while tracking a curb (without touching it), stopping in a hill (harder when driving with a stick), roundabout and highway.

Also, the DMV is as bad as they say it is. This movie scene is pretty accurate:

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_13.png" />
</p>

## Cards

In the US, as in the UK, the driving license acts as citizen card. Even if you don’t drive it’s worth getting your drivers license since everywhere you go that is used for you to prove who you are.

When doing anything official in the UK, you get asked about your passport (and the passport number). That ID is all they need to recognize who you are. In the US you have a Social Security Number (SSN) which is this super-confidential number that you are meant to keep secret, yet they keep asking you about it when you rent an apartment, set up a phone plan, go to the doctor, buy a car, … It’s a weird concept. The difference is that in the UK if someone gets your passport number, nothing really happens. In the US if someone gets your SSN, it can be used to commit fraud, open new credit and bank accounts, obtain employment, and access medical care or other benefits.

### Debit vs credit card

In Portugal and the UK, I only had a Debit card which had access to all the cash in the bank. When moving to the Bay Area, everyone told me to get a credit card and leave the debit card at home. There are a lot of scams in the US, and having a credit card is safer since banks limit the withdrawal amounts based on your credit score and will protect in case of theft.

In the UK, there isn’t a concept of a credit score - at least publicly. Banks will have something like that based on how on time you pay for things, but it’s only used internally for loans or others. In the US, everything revolves around your credit score. The amount of money you can withdraw from your credit card, the loans you get, the apartments you can rent, … so it’s important to pay everything on time and avoid debt.

## Employment

Employment in the US is very different from the one in the UK. 

In the UK, you get paid a value at the end of the month that corresponds to the value you take home and the employer handles both your Income taxes and the National insurance (which goes to the NHS).

In the US, you need to handle your taxes at the end of a fiscal year. There are multiple taxes applied and hence it’s not as simple as the tax system that exists in the UK.

In addition, there isn’t a public “free” NHS (healthcare) in the United States. As an individual, you need to select the plan you are interested in (based on a few choices that your employer offers you). Hence you need to consider not only what the monthly premium entails, but how the deductible works - and as weird as it sounds you need to “estimate” your likelihood of getting into an accident to select something that works for you. This is hard to grasp coming from a country where there’s “free” healthcare and everyone has access to the same services.

## Others

### Student debt

In Portugal, the concept of student debt doesn’t really exist. In general, parents pay their kids' tuition. This is possible because the tuition costs for public universities aren’t very high.

In the UK, students tend to have student debt since university costs can be rather expensive (e.g. around 10k pounds/year). 

In the US, student debt is much higher. We are talking about starting a career with 300k in student loans, which is absolutely wild.

### Phone plan

While I was paying around 8 pounds/month for my UK phone plan with unlimited data. For a similar plan in the US, the cost is around 70 $/month. A funny story about this is when I bought my phone plan, they told me that the cost was 70$ for their cheapest plan and I thought they meant yearly. When they told me it was monthly, I had to call my co-founder to make sure this wasn’t a rip-off. To which he said: “Welcome to the US”.

### Guns & Alcohol

In the UK (and Europe in general), it’s illegal to own a gun and you can start drinking at 18 years old. In the US, you can buy a gun as soon as you are 18 but aren’t allowed to drink until 21. 

And also, Kinder Surprise is illegal in the US because of the toy that comes inside. So you can’t buy a chocolate with a toy inside because you can choke on it, but can go to the store to buy a gun.

<p align="center" className="flex items-center gap-2 justify-center">
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_14.png" />
    <img width="300" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_15.png" />
</p>

### Dog Parks

One of my all-time favorite things in the US and that Europe in general should learn from. The US has a LOT of dog parks. These are spaces that are gated where people bring their dogs for them to play together. These spaces come fully prepared with water, bags, cleaning kits and even seats. I’ve seen friends hang out at the park while their dogs are having fun playing with other dogs. These parks usually also have 2 areas, one for smaller and one for larger dogs - which is great since we have a small pomeranian.

<p align="center">
    <img width="600" src="/blog/2024-03-02-moving-from-london-to-the-bay-area-and-what-changed_16.png" />
</p>

## Conclusion

Overall, I'm very happy that I moved to the US. I think it was the right decision for both the company and my family. Plus the network that I'm building between other founders, customers and investors is something that I couldn't have done in Europe.

---

---
slug: moving-countries-and-starting-a-company-aint-so-different
title: Moving countries and starting a company ain't so different
date: 2024-03-24
image: /blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack.png
tags: ['learning', 'experience', 'growth', 'moving', 'london', 'bay', 'US', 'travel', 'startup', 'nyc']
description: I have started a company. I have moved countries. It turns out that there's a lot in common between these.
---

<p align="center">
    <img width="600" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack.png"/>
</p>

I have started a company. I have moved countries. It turns out that there's a lot in common between these.

<br />

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Recently, I wrote a blogpost about the [difference in culture between London and San Francisco](/blog/moving-from-london-to-the-bay-area-and-what-changed). I convinced my wife and dogs, packed our bags, and didn't look back. After all, I would live in the city with the highest density of builders per capita.

**But why?**

Most of my friends and family didn't understand why I would leave London. I liked the city, I enjoyed my lifestyle, I had friends, I played football with the same group every week, had dinner at the same restaurants, was close to family, and wouldn't be able to save money.

Logically speaking, this move didn't make any sense. No one really told me that I was doing the right thing, but internally, I knew I had to.

I believe this isn't so different from creating a startup. This blog post will explain what they have in common and why I did it.

## Creating a startup / Deciding to leave your country

[Elad Gil](http://eladgil.com/) wrote a really good [article](https://blog.eladgil.com/p/startups-are-an-act-of-desperation) on how creating a startup is an act of desperation. I believe that post could be equally applicable to moving countries, so I will list the same points used by Elad in the context of moving countries and provide examples. Most of the time, the person moving countries has a mix of the below bullet points.

> **Career desperation.** Startups allow people early or stuck in their careers to jump a few steps ahead.

<br />

This applies equally to moving, and is why I left Portugal to pursue an MSc at Imperial College London.

> **Financial desperation.** If successful, a startup will also leapfrog you financially.

<br />

This is the biggest motivation for people to move countries. This is why I was born in Switzerland, even though my parents are Portuguese. Having blue-collar jobs, they emigrated to a country with a better economy to provide my brother and me with a better life.

> **Product or mission desperation.** The other reason startups often exist is that the founders are desperate for a product to exist in the world.

<br />

In this case, it's the equivalent of hearing about Silicon Valley in documentaries or watching Steve Jobs presenting the iPhone in 2007. You cannot ignore that as an engineer, so you are desperate to move to be part of that tech scene.

> **Desperation to do something big or important, and to avoid wasted time.** Some people want to "make a dent in the universe" and are motivated by doing something useful with their lives.

<br />

This is what the "American dream" is all about. People moved to the US to do something bigger than themselves and achieve the promised dream.

> **Revenge vs the Arena**

<br />

The equivalent to this is when someone returns to their home country after several years outside with more wealth and/or experience.

## Growing a startup / Living abroad

### Mission and Vision

When creating a company, you must have a clear mission and vision. This allows you to create a community/team that will be with you for the long run. Similarly, when moving countries, it's essential to have a well-defined goal. This doesn't mean that the goal cannot change; after all, companies pivot. However, you need to have a strategy that you follow until you don't.

### Risk and Uncertainty

Startups and moving to a new country both involve stepping into the unknown. Entrepreneurs often take financial and personal risks, while those moving countries leave behind familiar surroundings, support systems, and sometimes even their careers. Uncertainty becomes a constant companion, demanding adaptability, problem-solving skills, and the ability to embrace change with open arms.

### Cultural Integration and Networking

Building a successful startup requires networking, forming strategic partnerships, and understanding the market. Similarly, when moving countries, one must navigate cultural differences, learn new languages, and establish a network of contacts. Expanding social circles, building relationships, and immersing oneself in the local culture contribute to personal growth and enhance professional opportunities, just like in the startup world.

### Resilience and Persistence

Building a startup and moving countries demands unwavering resilience and persistence in facing challenges. Startups encounter setbacks, pivots, and failures, but successful entrepreneurs persist and learn from their experiences. Similarly, moving countries can bring unexpected hurdles, such as language barriers, difficulties making friends, challenges adapting to a new culture, or not finding a routine. Embracing these challenges with determination and adaptability paves the way for growth and achievement.

### Learning and Growth

Startups and moving countries are transformative experiences that offer immense personal and professional growth opportunities. Entrepreneurs continuously learn from their successes and failures in the startup world, refining their strategies and acquiring new skills. Likewise, moving countries provides a unique chance to learn about different cultures, broaden perspectives, and develop resilience, patience, and empathy. Both experiences foster personal development and shape individuals into more well-rounded and adaptable individuals.

## Why did I do it?

The reason why I started OpenBB and also moved country is a combination of 2 factors:

### Product or mission desperation.

On a startup level, I have experienced the need for an open-source investment research platform. That's why I wanted to create this platform, which was yet to exist. I think it wouldn't be possible if I didn't dedicate my time to it. This is why OpenBB's success is so important-it will enable millions of investors to have better access to data and better understand the financial market.

Growing up as an engineer fascinated by tech and innovation, the US has always been home to the biggest companies and hottest products. I've always been attracted to Silicon Valley, but before OpenBB, I never had the chance to. The first job I applied to after finishing university was Waymo in CA, but they didn't sponsor VISAs for that role.

### Desperation to do something big or important. 

On a startup level, I want to work on something bigger than myself. I want to solve a problem that no one has solved before and build something useful for millions of people that can withstand time.

I will do whatever it takes to build the first truly open-source investment research platform. Moving to SF increased my network opportunities with other entrepreneurs and builders from whom I can learn. I want to be fully immersed in this ecosystem and give it my all to do everything possible to help OpenBB succeed as a company, regardless of the outcome.

Note: A few weeks ago, I moved to NYC because I truly believe living here would increase the chances of OpenBB's success compared to living in SF.


---

---
slug: goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack
title: Goh Analyst - The AI-powered financial analyst who lives on Slack
date: 2024-03-26
image: /blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack.png
tags: ['learning', 'experience', 'growth', 'moving', 'london', 'bay', 'US', 'travel', 'startup', 'nyc']
description: How I built a financial analyst that lives on Slack and has access to OpenBB.
---

<p align="center">
    <img width="600" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_1.png"/>
</p>

How I built a financial analyst that lives on Slack and has access to OpenBB.

The open source code is available [here](https://github.com/DidierRLopes/openbb-slack-agent).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Context

At OpenBB, we have the tradition of hosting an internal Creaton on the penultimate week of the year.

The OpenBB Creaton is our creative Hackathon, where every team member picks a project to work on throughout the week and gets fully focused on it. The only rule is that it relies on OpenBB technology.

It’s a way for us to get further contact with our technology, but it also allows us to create proofs-of-concept of products/features that we may invest in the feature. Think of it as an R&D week.

We do it then because our team members get the last week of the year as time off. So, if they want to present their project to the rest of the team in January, they can also use that time to wrap up.

## My Project

At the Open Core Summit III, I presented a way of creating an AI-powered financial analyst capable of handling complex financial queries.

I wrote more about this in this [blog post](/blog/creating-an-ai-powered-financial-analyst). This robust architecture can access 100+ financial datasets from OpenBB tools and reason about them. The code is open source here.

I shared how our AI-powered financial analyst was able to answer

> “Check what TSLA peers are. From those, check which one has the highest market cap. Then, for the ticker that has the highest market cap, get the most recent price target estimate from an analyst, and tell me who it was and on what date the estimate was made.”

<br />

and

> “Perform a fundamentals financial analysis of AMZN using the most recently available data. What do you find that’s interesting?”

<br />

Since that was already working so well (watch the [presentation video here](https://www.youtube.com/watch?v=A-43EKK2PhE&embeds_referring_euri=https://openbb.co/blog/creating-an-ai-powered-financial-analyst&source_ve_path=MjM4NTE)), I wanted to bring these capabilities to Slack, show that this could be the future, and prove it would impact every analyst job.

That’s when Goh Analyst was born.

<p align="center">
    <img width="800" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_2.png"/>
</p>

Note: Goh Analyst together is GOHANalyst, which is why the image is Gohan from Dragon Ball with the OpenBB logo on his forehead.

## How does it work?

To get started, you can see the [open-source repository and instructions](https://github.com/DidierRLopes/openbb-slack-agent/tree/main).

First, I forked the [open-source code of the OpenBB agents repository](https://github.com/OpenBB-finance/openbb-agents) that we have been using for R&D. This repository contains all the code for the OpenBB agent and has access to 100+ financial datasets.

Then, I modified it to my needs:

Created the Slack bot interface

When a Slack message mentions @Gohanalyst this workflow gets triggered

When the Slack message contains the word “OpenBB”, I send that message through the OpenBB agent since the assumption is that data retrieval will be necessary. Otherwise, it goes straight through OpenAI.

In a nutshell, this is what the architecture looks like:

<p align="center">
    <img width="800" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_3.png"/>
</p>

I made Goh Analyst slightly sarcastic to make it a bit more fun. This makes interacting in a public channel somewhat more human and exciting. It can handle simple financial questions, retrieve data using OpenBB tools, or even answer more complex reasoning questions.

<p align="center">
    <img width="800" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_4.png"/>
</p>

<p align="center">
    <img width="800" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_5.png"/>
</p>

Now imagine that every organization has an analyst on their Slack to help make decisions.

## What's next

As I mentioned earlier, one of the advantages we get from OpenBB Creaton is that we test our products and give feedback to the team on what went well or less well. After working on this project, this is what I shared with the team:

<p align="center">
    <img width="800" src="/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_6.png"/>
</p>

Exciting times we live in. If you want to leverage AI within your financial firm, we can help you 🤝

---

---
slug: rabbit-r1-there-is-hope
title: rabbit r1, there is hope
date: 2024-04-28
image: /blog/2024-04-28-rabbit-r1-there-is-hope.png
tags: ['rabbit r1', 'tech', 'review', 'ai', 'gadget']
description: I can see a future where people use rabbit r1 for very particular use cases where phone is suboptimal. For instance, when multiple people want to interact with said phone (e.g. selecting music at a party without having to give phone away) and that is not ideal due to personal information on phone, or when the phone isn't ideal because it has too many distractions and user wants to focus on doing something (e.g. practicing a presentation using recording session and then asking for feedback).
---

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope.png"/>
</p>

I can see a future where people use rabbit r1 for very particular use cases where phone is suboptimal. For instance, when multiple people want to interact with said phone (e.g. selecting music at a party without having to give phone away) and that is not ideal due to personal information on phone, or when the phone isn't ideal because it has too many distractions and user wants to focus on doing something (e.g. practicing a presentation using recording session and then asking for feedback).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## What is the rabbit r1

Rabbit r1 was first introduced at CES 2024 as a pocket AI companion (watch the keynote [here](https://www.rabbit.tech/rabbit-r1)).

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_1.png"/>
</p>

The main distinction over being just a "ChatGPT on-the-go" is the fact that they introduced what they call a Large Action Model (LAM), which is an agent capable of taking requests and making different function calls (e.g., translation, weather, finance, vision, taking notes, and more).

There are now quite a few consumer products that are trying to win this category. Here are a few:

- [AI pin](https://humane.com/) from Humane. MKBHD did a good [review](https://www.youtube.com/watch?v=TitZV6k8zfA) on this product (or should I say 'bad review'?).

- [pendant](https://www.limitless.ai/) from Limitless (previously Rewind AI).

- [01](https://www.openinterpreter.com/) from Open Interpreter. I ordered this one because it's [open source](https://github.com/OpenInterpreter/open-interpreter) and I can build on top.

While at the surface these devices are somewhat similar, they approach the problem from a different angle. AI pin relies on users to clip their device to their clothes, the pendant is put on the collar of your top and 01 is held handheld. Rabbit r1 is also handheld, but unlike the others contains a screen to interact with - so it's closer to a phone than the others.

Nonetheless, according to Jesse (rabbit's CEO) they are currently the most successful AI device in terms of sales (sold over 100,000 rabbit r1 in a few weeks).

## How I got my r1

My wife saw me watching a few videos of rabbit r1 and decided to surprise me with one, a one-time $199 purchase without any subscription fee. I wonder why she didn’t do it when I was watching Apple Vision Pro 😄.

But they didn’t ship immediately. My batch was only meant to be shipped sometime in June. However, rabbit tweeted that there would be a Pickup Party in NYC. I added notifications on their X account and once they announced that registrations were open I was ready. I RSVPd and this week I attended the event to grab mine.

The event was well organized. One thing is for sure, rabbit knows how to build a community and hype with their users.

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_2.png"/>
</p>

The keynote presented at the event can be found [here](https://www.rabbit.tech/live-unboxing). In it, rabbit's CEO unboxes a rabbit r1 and shows everything it can do on stage.

## My experience

I have been playing with rabbit r1 for a couple of days now. A few funny things I've done since:

- Jailbreak rabbit r1 to say [f*ck which falls outside the guidelines](https://x.com/didier_lopes/status/1783335809459859708)

- Ask it what LLM it was using under the hood, to which it said [it was using a fine-tuned version of OpenAI's GPT-3](https://x.com/didier_lopes/status/1783346493832753477)

- Have rabbit r1 make a [Deez Nuts joke](https://x.com/didier_lopes/status/1784228313717776505)

- Use rabbit r1 as a [Not Hotdog app](https://x.com/didier_lopes/status/1784357946920505387) ([Silicon Valley reference](https://www.imdb.com/title/tt2575988/))

But now onto the serious stuff. Since I was at the Pickup Party where Jesse split the presentation based on the major features of the products, I want to address each of these individually after having time to play with them.

### Search

For search, rabbit r1 relies on [Perplexity](https://www.perplexity.ai/). I'm a Perplexity fan myself and at some point I even replaced my default [Arc browser](https://arc.net/) search engine with Perplexity. This only lasted one day because then I realized how many times I just wanted to end up on a landing page or on someone's LinkedIn/X. It made me realize why Google is, well, Google. Regardless, this is something that I do with my phone, and so I don't think it's a strong use case.

However, if you have a kid that is curious to understand the world. I think a rabbit r1 is well worth it to use it to ask questions that they are curious about, without having the distractions that a phone provides.

### Vision

**What is this** - I just don't think this is a strong use case overall. This is not something that you do daily, weekly, or even monthly. Maybe once a year or so. The last time I did it was last year in Mexico to know the name of an animal that was nearby. I went to Google and looked for "Mexico animal that looks like a racoon" and the first answer was Coati which was what I was looking for. If that query didn't work, I would have taken a picture of the animal and then Google search - but that's my second choice because of the effort of doing so. This to say that it's not really a pain point that users will have.

**Edit spreadsheet** - This is a somewhat interesting use case choice, I wonder if they picked it up because no other device showed being capable of doing this (taking a picture to a handwritten table, asking for a change and emailing the image to your email). Personally, I don't write tables that much anymore on paper, and the ones I do are small enough that if I want to transcribe it takes me seconds to do. It may be a strong use case for certain jobs, but I’m not sure about it, nor the performance it would have on large tables. The example Jesse shared at the event was a 5x3 tabl.

### Terminal mode

It’s like using ChatGPT but with a worse interface. The keyboard reminds me of BlackBerry but it’s gimmicky to use - personally, I didn’t like the experience. I would always pick up my phone to use ChatGPT over using the Terminal mode for instance.

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_3.png"/>
</p>

### Translation

YES. Having Portuguese parents that don’t speak english, whenever they are with my wife, I need to be the translator. So having a device that allows them to translate in “real-time” both ways is a huge value add.

Yes, I know that Google already has this feature - but it's shit and if you disagree, you never actually used it. LLMs can understand expression and meaning, in a way that a model like BERT cannot. I actually did this post where I prompted ChatGPT to do exactly this - act as a device that stays in the middle of a conversation translating from one language to another based on who the speaker was (tweet [here](https://x.com/didier_lopes/status/1740049615804846461), it went kind of viral).

Sure, this could be an app, but I quite like the idea of having a device that just does this. I think that’s because the translation works both ways, so I imagine you passing the device to the other person to press the button when they want to speak. So that way, it feels more like a “common” object whereas your phone is more personal.

Although I was excited about this, and it was the first thing I tried it failed badly. The CTO of the company [replied](https://x.com/LiaoPeiyuan/status/1783001793573843078) to [my tweet](https://x.com/didier_lopes/status/1783000272278569412) saying that they are working on fixing it.

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_4.png"/>
</p>


### Notes

Yay, another note-taking app. NOT. I’d prefer an integration with the Apple Notes app or Notion, so I don’t need to then go into yet another website and copy-paste those notes to some other place.

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_5.png"/>
</p>

### Voice Recording

The voice recording feature is pretty good. If you are a content creator (e.g., writer, youtuber), I think this is very powerful. The way I see it is that rabbit offers way less distractions than your phone, so you could go on a walk and take r1 and just speak with it to brainstorm ideas. Then go to the website and analyze your ideas to transform it into content.

Personally, when I have ideas like this I just drop a voice note to my wife’s WhatsApp and then mark the message as unread. It’s hacky but it works and I've been doing it for a long time now. We have an inside joke where I start these audios with “Note to self” and she always makes fun of it.

<div className="flex justify-center gap-2">
  <img src="/blog/2024-04-28-rabbit-r1-there-is-hope_6.png" width="50%" /> 
  <img src="/blog/2024-04-28-rabbit-r1-there-is-hope_7.png" width="50%" />
</div>

### Music

Last year for my birthday my wife gave me a [Divoom Ditoo-Pro Retro](https://divoom.com/products/divoom-pro) - it does a lot of things (e.g. music, radio, alarm, voice memo, games, music, planner, pixel art). Honestly, I just use it for music. It lived in my car during the entire year as a speaker since I didn't have bluetooth audio in the car. I think the advantage of rabbit r1 over it is that I can use my voice to change the music, which is handy if you are driving. On the other hand, my Divoom allows me to listen to my audibles since it acts as a bluetooth speaker whereas rabbit r1 would need an audible integration.

I think this can be a compelling use case as sitting in the middle of the table at a dinner or party with friends, where if someone wants to change the music they can just use the rabbit r1 to ask for something - and this way you can keep your phone/laptop on you instead of using it for everybody else to touch.

### Apps

**Doordash/Uber** - I haven’t tried it yet, but I feel like the phone is so good at it already and with a rich UI/UX, that I don’t see the point in using rabbit r1.

**Generative AI** - This is an interesting use case. Personally I don’t use Midjourney so I'm not the target audience. I do find it interesting that you can generate these images on the go on r1 directly without having to go through Discord (suboptimal) experience. I'm excited about the opportunities that this presents - for instance, integrating with [OpenBB Bot](https://openbb.co/products/bot) to display financial data on rabbit r1 directly.

### Teach mode

Jesse showed a brief preview of how teach mode works but mentioned that this feature is not yet available and they want to nail the user experience and add guardrails so users cannot use it for something malicious. I'm very excited about the teach mode prospect, since I think this falls in the category of "app creation" and allows users to use the device for very specific needs, hence opening the total addressable market.

## Conclusion

First of all, the rabbit r1 is beautiful. It's light, well made and has this bright appealing color. This isn't surprising since it was done in collaboration with [Teenage Engineering](https://teenage.engineering/) (a company known for making products that I want without knowing what they do).

This may be controversial, but the thing I like the least about the hardware is the button being located on the right side. The reason why I hate that decision is that I cannot easily use the device with one hand only. If I try, it becomes very gimmicky where I do gymnastics just to press the button. I don't get why they didn't make it right under the scrolling wheel, it would resemble more a controller/phone which is something that our hands have long been accustomed to. Even if the button was located on the upper side of the device, the UX would be MUCH better. 

That's one of my biggest complaints against the hardware itself, see image below to see what I mean. I almost need to bend my right thumb in order to reach the button which is used very often. One can argue that I can wrap my hands more around the device to give a better experiencing in clicking the button which is 100% true, HOWEVER, if I do that then I can't reach the wheel to scroll.

<div className="flex justify-center gap-2">
  <img src="/blog/2024-04-28-rabbit-r1-there-is-hope_8.png" width="50%" /> 
  <img src="/blog/2024-04-28-rabbit-r1-there-is-hope_9.png" width="50%" />
</div>

<br />

Also, related with the picture from the above. The battery is pretty weak, it needs to be charged often.

The rabbit r1 OS has a lot of room for improvement, a few things I've experienced:
- Having a black screen that doesn't recover until I manually power off device;
- Not triggering the function I want - sometimes it looks for a specific wording, e.g. "start a recording session" works but "do a voice recording" does not. I would have expected for it to be able to understand intent;
- Sometimes I get a "The app is under maintenance. Please try again later" for functions that I know it is capable of doing;
- Every few minutes getting "unable to connect to Rabbit OS";
- Randomly losing the previous context - I assume this is because of the number of tokens that can fit in the context?;
- Spotify integration broken;
- Even though it knows my location (due to getting weather app location correct), the time is not correct and I can't update it through the settings.

But this is also the first product version and LLMs are by nature non-deterministic so these type of bugs are kind of expected.

It's a one-time $199 price tag. There's no recurring subscription. As a consumer, I like this a lot. A one-time purchase allows users to buy the product to experiment without any strong commitment (apart from that one-time fee of course). In terms of economics, I'm not sure how Rabbit will handle a growing user base and better LLMs. During the event, they mentioned a partnership with both OpenAI and Anthropic. If they are using one of these models, someone needs to be paying for these tokens. For instance, for [OpenBB Terminal Pro](https://openbb.co/products/pro) we decided to allow usage similarly to how the ChatGPT free tier works, which basically rate limits based on usage and allows us to keep our costs controlled.

Meta is attempting to commoditize LLMs, so if I were in rabbit's shoes I would consider hosting [Llama 3](https://llama.meta.com/llama3/) locally and providing inference from this directly. Maybe even do a partnership with [Groq](https://groq.com/) for users paying a small subscription - not so much because of the impressive 800 tokens/s inference (using Llama 3) since rabbit r1 uses voice and inference speed is less relevant, but for the cold start (i.e. the lag between user question and output). Meta's commercial license only applies to companies with over 700 Million active users, so I think Rabbit would be good for some time.

Personally, I wouldn’t recommend rabbit r1 as a phone alternative. Not even close. If someone says that they stopped using their phone after having their rabbit r1, I can guarantee you that they weren’t using their phone a lot anyway. I agree a lot with MKBHD in saying [Phones are OP](https://www.youtube.com/watch?v=TitZV6k8zfA).

But if you are reading this, you are probably wondering what are the use cases where I would recommend Rabbit r1. So let's do that.

### This is a buy if

- For kids that are curious and want to learn more about the world. Being able to have it before a phone, is very compelling. Imagine your kid being able to ask r1 what a word means and how to use it in a sentence, who person X is, how something works, to practice learning another language, as a complement when reading a book/studying. The advantage over the phone is that it doesn't have any other distractions. It would basically be Perplexity on the go, and thus the Perplexity tagline "Where knowledge begins" makes total sense.

- As a device for two-way translation. The two-way is important, because if it’s just one-way then using the phone is preferred. But being two-way allows for both people to interact with the device, which in my opinion is less personal than a phone and more like a gadget. We aren't there yet, but I'm sure the model will keep improving and becoming better at this.

- For content creators who want to “zone out” and leave their phone at home and just use the record feature to record content, whether that is a blog post, a new lyrics or a podcast idea. 

- As a music device to be at the center of a table at a dinner, in the corner at a party selecting the tunes or on a roadtrip. People will enjoy interacting with it due to its unique nature, and that way you don't need to be blocked from using your phone.

- As a virtual assistant. If the alarm feature was already implemented, I would've likely already replace my Alexa, since rabbit r1 looks much nicer. Even more with the cool standing case.

... and of course, the use case is worth $200 for you. There are likely devices that can achieve the same for a cheaper cost. I like the fact that is state-of-the-art and they are trying to innovate.

Also, the rabbit effect going up and down waiting to be prompted and the hears going up when listening is pretty sweet - see it [here](/blog/2024-04-28-rabbit-r1-there-is-hope_10.png).

In any case, there are two recurring topics in these use cases, so let's talk about each individually.

### Main use cases

1. **A very targeted use case** - The phone can be a double-edged sword. On the one hand, it's your door to the world and what's happening. On the other hand, it's your door to the world and what's happening. I say it this way because this can be extremely good or bad depending on the use case. Phones are optimized for users to spend time on them, apps are optimized to provide dopamine hits so users use them for longer. Notifications will interrupt you throughout the day so you remember to go back to the app, etc.. But sometimes you only want to do 1 thing, and don't want to be distracted from it. The best example are E-Books. You can read on your phone, iPad or laptop - yet people decide to buy a kindle so they can just do that. Read with no distractions. You are paying a premium for a product to remove the distractions. I believe that rabbit r1 can achieve this, particularly if they allow developers to build specific apps for specific use cases.

2. **Gadget to be used by multiple people** (examples above: two-way translation or music device) - The phone has become a very personal device over the years. If someone gets access to your phone unlocked they have access to who you are (important emails, personal photos, chat conversations, the apps you use and how do you spend your time, the songs you listen or books you read, even confidential documents). So, there are certain scenarios where you don't want to borrow your phone to someone to do something, since that requires trust that they won't see anything that is confidential. I think Rabbit r1 can go after this category because its a shiny gadget that doesn't really hold any personal information from the user, and this way allows the user to keep their phone in their pocket while using rabbit r1 for some tasks that the phone could also do but would require for others to have access to it.

<br />
<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_11.png"/>
</p>

## Excited about

### Developer Ecosystem

Apple became Apple not because of their revolutionary LCD screen without a keyboard, but because of the developer ecosystem they created. The iPhone became stickier over time, because there were more apps being built on top of it that users could easily tap into. It also allowed Apple to generate revenue from the monetization of these apps.

I truly hope that this is the direction that Jesse and team want to take. If I were in their shoes, I would prioritize that over any other feature. Just allow developers to create apps (in this case functions) that the LAM can call to do something very specific.

Instead of having their team working on all these features, create the foundational marketplace that allows developers to do so. Start by only allowing free apps and see what developers are building and what users are utilizing. Then move to allow developers to monetize and take a cut from it. And allow users to decide what apps are enabled within their devices and which ones aren't - show which apps are the most downloaded and used and link it to a user profile. Make it so that the user profile needs to be a rabbit r1 holder to avoid scams..

A few examples: Someone building a Pokedex app for animals, you take r1 to the zoo and just take a picture of the animals with it, then you go home and look into your pokedex. Or a Pokedex for travel monuments. Or integrating OpenBB so I could do research on-the-go.

<p align="center">
    <img width="600" src="/blog/2024-04-28-rabbit-r1-there-is-hope_12.png"/>
</p>


### Native AI-phone

[Nothing](https://us.nothing.tech/) has one of the best consumer tech brands out there. If the Apple ecosystem wasn't as sticky as it is today, I would buy one. Both Nothing and Rabbit are very unique brands, and I think a partnership between them could be a game-changer.

I'm imagining a Native AI-phone built on Android with rabbit's LAM. So, in simple terms, it would be like Nothing Phone (2) but it would have an r1 button that you can use to interact with it through voice instead of fingers. The challenge would be combining the LAM from rabbit r1 to all the apps that Nothing Phone (2) provides - but I believe in a future where applications will be built not only thinking about how humans will utilize them but also LLMs - at least [we are doing that at OpenBB](https://github.com/OpenBB-finance/openbb-agents) with the [OpenBB Platform](https://github.com/OpenBB-finance/OpenBBTerminal).



---

---
slug: 29-years-old-and-sitting-on-the-top-of-giants
title: 29 years old and sitting on the top of giants
date: 2024-06-05
image: /blog/2024-06-05-29-years-old-and-sitting-on-the-top-of-giants.png
tags: ['birthday', 'dad', 'family']
description: Yesterday was my 29th birthday, and I was reflecting on my life and on how sitting on the top of giants isn’t given enough credit. My giants are my parents.
---

<p align="center">
    <img width="600" src="/blog/2024-06-05-29-years-old-and-sitting-on-the-top-of-giants.png"/>
</p>

Yesterday was my 29th birthday, and I was reflecting on my life and on how sitting on the top of giants isn’t given enough credit. My giants are my parents.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Yesterday I turned 29 years old.

The night before, I was speaking with my dad about how grateful I am for everything he’s done for my brother and I.  I always had everything - food at the table, a roof and education.

I’m the person I am today because of my parents.

But my dad didn’t have it easy.

And so instead of writing about how grateful I am for the life I have today, I want to share some parts of my dad’s life.

I don’t like to share personal information about my family, but I feel like from all the posts I read on success - sitting on the top of giants isn’t given enough credit.

My giants are my parents.

Here’s his story.

My dad grew up with very little in a town in the middle of nowhere in Portugal with 6 siblings.

He did a few years in school and after classes he would come home and watch his parents sheep until it was dark. He did his homework during that time since there was no electricity back then.

If a sheep ran away while he was doing his homework, his dad would punish him with whatever was at hand, a stick or a belt.

Times were different back then.

In school, if he got questions like 7x8 wrong, teachers wouldn’t just say the correct answer. They had a special ruler that was used to hit a student’s hand.

Again, times were different.

After a couple of years in school - he didn’t like it (I wonder why eh) and they didn’t have a lot of money. So he started working at the age of 11 in construction.

An 11 year old kid, taking 2 buckets of cement up and down the stairs to build houses.

At the age of 17 he moved to Geneva (Switzerland) for a better paid job, as a bricklayer but also did painting jobs and similar.

At 18, his mum died.  She was run over by a car near our hometown.

At 20, he had to come to Portugal because of his passport and he met my mum.

1 year later, my mum moved to Geneva to be with him. She worked in a factory making boxes for Rolex watches.

At 22, his dad died from a disease.

He kept working his ass off. 6 days a week, starting at 6 am whether it was snowing, raining or extremely hot.

No travelling or unnecessary expenses, except tobacco, it was his only addiction as everyone around him smoked - it was a social thing.

At 24 he got married with my mum. My mum’s family didn’t like his, so they didn’t attend the wedding and they had to cover it with all of their savings.

At 31, he had me.

The week before I was born would be the last he would ever smoke, since my mum said that she didn’t want smoke near us because of our health. At some point he was smoking 2 packs a day, and he stopped from one day to the other which is wild.

At 32 his painting shift had just finished and his boss asked him to give one more painting layer to the outside of an apartment. And he went up the ladder, and it broke. He fell from a 2-story apartment on his foot, and his foot bone got smashed into pieces. (He had actually mentioned to his boss that the ladder didn’t feel very stable earlier that day).
 The doctor told him that he would never be able to do any physical work ever again. 24 years later, and he still struggles to walk for long periods of time.

At 33, he had my brother.

Because of the accident, he stayed at home to raise my brother and I.

A bit after, Portugal joined the Euro. So my dad thought that the living conditions in Portugal would improve overall like other European countries (spoiler alert: it didn’t).

So, he decided to start building a house on the same land where his hometown house was, in Portugal.

They couldn’t afford to buy a house in Geneva, but had enough savings that they could build one in his hometown.

They went back when he was 39 (I was 8), and that’s where I grew up.

My mum struggled to find a job for many years - she only got a job as a secretary at a furniture store - until they went bankrupt.

My dad had depression since he was stuck at home with nothing to do.

Growing up, I wanted to work as a bricklayer in summers to make some cash and my dad forbid me doing so.

He said that it was dangerous and he didn’t want me to have that life. He has seen a lot of young people dropping out of school because they start receiving salaries early and prioritise short-term outcomes over long-term ones.

He didn’t want me to follow that path.

He wanted to give me the opportunities that he didn’t have growing up. And he did.

One day I got home from high school, and commented that someone I knew always had expensive clothes and watches. He happened to know their family and got upset. He was upset because he knew that they owed a lot of money to a lot of people - and kept living a luxury lifestyle.
 So he told me “You may not wear all of that, but you will never hear in your life that we owe anything to anyone. Everything you have has been bought with a lot of hard work from your mother and I, and not by stealing or owing anything to anyone”.

I still think about this often, and how appearances are often just that. 

A few years later after I got into university, my parents decided to move back to Switzerland.

My mum still didn’t have a job and we weren’t going home as much (we both studied relatively far from our hometown). It was hard on her to move away from us, but it was the right thing to do.

She found a job as a cleaner, which she has been doing for almost 10 years now.

In the meantime my dad wondered if he could leverage all the skills he had learned growing up to manage a housing project. So he bought land in Portugal, and was heavily involved in the management of the project. Meaning he worked across everything, except the physical aspects of the job.

It was an investment, but after having so many years in real estate - it was hard for someone to have as much knowledge breadth as he did in terms of costs of materials and staff since he had been on the other side of the coin for a long time. 

Now he does that every now and then, which keeps him busy. But since it involves being far from my mum, this time he’s hiring an agency to be more involved at the expense of less headaches and a lower margin.

He has a good life now. But he came from nothing, literally.

Most people on his shoes, don’t make it.

Damn.

Most people with more opportunities than him don’t make it.

I often feel guilty because I get to live life in a way that my parents could never.

The best way I can think to repay them is to work hard and show them that their hard life will be the last that the future Lopes generation will have to endure.

That and hopefully buying them a nice car one day.


---

---
slug: why-chat-only-AI-Financial-Assistants-are-not-the-future
title: Why chat-only AI financial assistants are not the future
date: 2024-06-15
image: /blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future.png
tags: ['finance', 'ai', 'openbb', 'chat', 'finance assistant', 'chatgpt', 'perplexity', 'investment research']
description: Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research. 
---

<p align="center">
    <img width="600" src="/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future.png"/>
</p>

Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research. They are limited by their one-dimensional approach, which hinders efficient data retrieval and long-term usability. Read on to discover how OpenBB Terminal Pro addresses these issues with a three-dimensional solution.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This is a spicy take but bear with me.

The more I think about “ChatGPT for Finance” products, the more I think this is not the answer.

They are extremely good knowledge retrieval engines because you can ask what you want to know and get the answer immediately.

My problem with their approach is what happens after.

However, very little thought is given to the real-world investment workflow. That's why I strongly believe that a chat-only financial platform will never be successful on its own.

Sure, they can win in the categories of “search” or “screening”, but they won’t be able to compete in the category of “investment research platform”.

To do that, they would need to evolve.

Let me explain why and how OpenBB differs from them.

## 1-Dimensional vs N-Dimensional

Financial assistants are, in general, 1-dimensional. By that, I mean that all you have on a screen is a “dashboard” with an unlimited y-axis (1 single dimension).

<p align="center">
    <img width="600" src="/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_1.png"/>
</p>

This means that whatever information they output will always be in the same position, which is great for the short term.

But for the long term? Not so much. If the user wants to find specific information, they will need to keep scrolling up the text to find it.

When financial assistants allow multiple conversations, then we start having 2 dimensions, where each conversation introduces a new axis.

The problem with this approach is that you can’t easily find data within one of those past conversations since the assistant focuses on answering your question and not on data retrieval from the previous outputs.

## Our 3-dimensional solution on Terminal Pro

How do we handle those issues? We have 3 dimensions.

<p align="center">
    <img width="600" src="/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_2.png"/>
</p>

Our Terminal Pro has a Copilot on the side, similar to other financial assistants.

However, its big advantage is that when you want to save Copilot’s output for later, you can convert it into a text widget. And when you do so, you can place it wherever you want in this space — with the axis being infinite vertical scroll, tabs, dashboards, and folders.

<video controls>
    <source
        src="https://openbb-cms.directus.app/assets/ebdda68a-95f7-425b-aebe-5c98936c9189"
    />
</video>

## Storage-based solutions are not optimized for investment research

Again, financial assistants are optimized for search rather than information storage.

This means that, by nature, chat-only financial assistants assume that their output will not matter in the future, so they answer your queries similarly to how a text conversation works. It's literally called ChatGPT for that reason.

However, that’s not ideal for investment research.

If analysts and researchers need to access these financial assistants' output at some point in the future, they won’t be able to do it quickly. Instead, they’ll have to go through a long chat history.

This is why, in our Terminal Pro, we allow users to create a markdown-based text widget from the Copilot’s output, as shown above, so that you can have that information quickly accessible, but also editable.

## There’s no simple way to know where the data comes from

Financial assistants are great, and they are improving every day. But if there’s something I’ve learned from talking with financial firms for over three years, it's that this is a very slow-moving industry, and adopting new technologies takes time.

But with AI, it seems different. It’s so revolutionary that people are willing to incorporate it into their workflow faster because they immediately understand the benefits it can bring to their business.

However, hallucinations are still a big problem — so it’s essential for these firms to be able to verify the raw data and sources.

The current level of AI is equivalent to having a smart intern that you would need to double-check their work or trust but verify.

This is why our Copilot always answers based on data that is readily available on the dashboard — and (due to our “Bring Your Own Data” technology) that data can be brought by your firm rather than being limited to what we offer out of the box.

<p align="center">
    <img width="600" src="/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_3.png"/>
</p>

## Financial chats are not collaborative

Financial assistants are not collaborative by default.

When someone opens a tool like ChatGPT, they are interested in getting an answer to their question. Can you imagine what would happen if more people had access to that conversation and asked ChatGPT a different question? That would translate into a horrible user experience.

The interesting thing is that investment research starts as an individual process but ends up being a collaborative effort where the findings are shared and discussed within a team.

So, financial assistants have a challenging task: multiple people on a team should be able to access all the conversations without being able to interact with these chats.

But what if you go through a colleague’s chat where they were asking questions about a company’s earnings, and you want to do a follow-up question?

That’s a complex problem.

At OpenBB, we are in a very good position to solve this for our users.

Since we allow them to create a widget from their conversation with the Copilot, users can effectively create the ideal dashboard to share with their team. On their turn, other team members will then be able to use the Copilot on that same dashboard to make their questions.

And guess what?

This can be considered yet another dimension that we allow users to explore.

<p align="center">
    <img width="600" src="/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_4.png"/>
</p>

## Wrap up

In a nutshell,

- Most AI financial assistant products are 1-dimensional. Great at retrieving an answer quickly but poor at the overall task of doing investment research.

- OpenBB Terminal Pro is positioning itself as a flexible and customizable investment research platform with N-dimensions that an AI copilot can control to produce a full investment dashboard as if it were an analyst.

I'm biased, but once we provide the OpenBB Copilot with the capability to interact with the interface (create widgets, dashboards and folders) we might be the company that gets closest to replace an analyst's job.

---

---
slug: my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt
title: My first-hand experience on AI impacting education through Perplexity, Cursor and ChatGPT
date: 2024-06-30
image: /blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt.png
tags: ['education', 'ai', 'perplexity', 'chatgpt', 'cursor', 'students', 'big data', 'analytics', 'supervised learning', 'machine learning']
description: AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.
---

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt.png"/>
</p>

AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.

The open source code is available [here](https://github.com/DidierRLopes/supervised-learning).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Recently I was invited to teach a course in Big Data and Data Analytics at Europeia University. I gave 4 hours of classes, divided into:

- Supervised Learning - Theory
- Supervised Learning - Practice

And then evaluated the students coursework.

## Creating a new syllabus

My past experience as a teacher happened during my BSc., back in 2016, where I was a TA for the course of Signal Theory and had to help students in their coursework through Matlab/Octave.

Things were different at the time because I had a syllabus to follow and most of my time was spent helping students if they were blocked coding-wise or had some questions regarding the theory.

And of course - there was no AI. At least not in the sense that we speak about today - i.e. there were no LLMs.

This time was different - I had the flexibility to choose what I was going to cover about Supervised Learning.

I’ve never worked as a Data Scientist per se, but have been passionate about data for a while and spent a lot of time reading books and learning about the topic. In my previous company, I started playing with IMU data in my spare time which lead me to publish a paper at ICMLA where I used [Support Vector Machine (SVM) for Step Detection using Nurvv trackers](https://ieeexplore.ieee.org/document/9680024) and even open sourced the code [here](https://github.com/DidierRLopes/step-detection-ML/tree/main).

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_svm_paper.png"/>
</p>

I've wrote about this and how I managed to write the entire code in my spare time in a single week, and missing the yearly team event in order to pull this off. You can read more about it [here](/blog/how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla).

But so the question is:

_"Where do I start?"_

My first intuition was to gather some of my favorite books and courses on the topic and understand how they presented the overall subject. I wouldn’t have the same time, so I would need to touch on most topics briefly - enough for students to know about it and explore further if curious.

However, given my time constraints with running OpenBB, I would have had a hard time since I would need to:

1. Consume the content of these books and courses
2. Mix and match them
3. Cut to fit the time constraints
4. Produce a final syllabus that I’m confident about

<br />

This was not a trivial task, and definitely not a weekend job.

Except that **IT WAS**.

### Perplexity enters the chat

Since Perplexity’s main value proposition is being better at Google than Google - I popped the following prompt into it.

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_perplexity.png"/>
</p>

BAM.💥

This was exactly what I was looking for.

Did it give me the content end-to-end that I was expecting?

No.

Was it a perfect starting point?

Yes.

I didn’t literally copy-paste it. I took the parts I liked, re-iterated on the ones I didn't until I eventually did. Plus, use my experience to prioritize parts that I felt should be more relevant vs others.

Were there some hallucinations?

Yes, it’s not a silver bullet.

But it saved me DAYS of work.

I was dreading having to write the syllabus and like this, it was actually fun. It was fun because I felt like Perplexity was acting as my assistant and I was engaging in a conversation of what should be contained within the course and what shouldn’t.

After having all the content ready, I asked my wife to help me with some images to make it easier for students to understand concepts.

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_assets.png"/>
</p>

I was happy with the results - but wanted a second opinion. So I asked a friend of mine who’s been a DS for over 6 years what his thoughts were on the materials I worked on - and he was impressed about the speed.

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_ai_friend_message.jpeg"/>
</p>

Being a fan of open source, I have open sourced all the theory and practice of the course and you can access it here: https://github.com/DidierRLopes/supervised-learning

For the practice exercises I made it so that users can run it with colab directly on the browser to focus on the learning and not on the installation of libraries - highly recommend doing this.

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_colab.jpeg"/>
</p>

## Assessing students grades

After presenting the classes to the students, they had to work on a final project that involved supervised learning - and I had to grade their work on it. The grade was from 0 to 5 and I was given freedom in terms of what criteria to use.

So I did what someone else in my shoes would do.

## ChatGPT to define grading criteria

I typed [chat.openai.com](http://chat.openai.com) and had a conversation with ChatGPT about the best way to grade the coursework. I wanted it to be as fair as possible, but also evaluate students based on criteria outside of coding, such as problem formulation and documentation/clarity.

Note: Story for another day but with the raise of LLMs, I have a very strong opinion that documentation and clarity will be as important as the code itself.

This is the outcome of that conversation:

> **PART I - Problem Formulation**
> - 1.a. **Clarity and Definition:** Is the problem clearly defined and well-formulated? Are the project's objectives explicitly mentioned?
>
> - 1.b. **Relevance and Context:** Is the relevance of the problem within the application domain explained? Does the problem justify the use of supervised learning?

<br />

> **PART II - Documentation and Quality**
> - **2.a. Code Quality and Readability:** Clarity and Structure: Is the code well-organized with clear and consistent formatting? Are comments used effectively to explain complex logic? Best Practices: Does the code follow standard coding practices (e.g., naming conventions, modularization)? Are functions and classes used appropriately?
>
> - **2.b. Documentation and Explanation in Comments or Notebook Markdown**: Clarity: Are the results and methodology clearly documented? Is there a detailed explanation of the steps taken and the reasons behind them? Visualization: Are visual aids (e.g., graphs, plots) used to illustrate key points and results? Are these visualizations clear and informative?

<br />

> **PART III - Code**
>
> - **3.a. Data Preprocessing and Cleaning**: Completeness: Are all necessary steps for data preprocessing included (e.g., handling missing values, encoding categorical variables, scaling features)? Justification: Are the preprocessing steps justified and explained? Is there a clear reason for the choices made?
>
> - **3.b. Data Exploration**: Initial Analysis: Is there an exploratory data analysis? Are descriptive statistics used to better understand the data? Visualization: Are visualizations (e.g., graphs, plots) used to illustrate data distribution, correlations, and important patterns? Are these visualizations clear and informative?
>
> - **3.c. Model Implementation and Training**: Correctness: Is the model implemented correctly according to the chosen algorithm? Are appropriate libraries and functions used? Parameter Tuning: Is there evidence of parameter tuning or optimization? Are the chosen parameters explained and justified?
>
> - **3.d. Evaluation and Validation**: Metrics: Are appropriate evaluation metrics chosen and calculated? Are these metrics relevant to the problem at hand? Validation Techniques: Are appropriate validation techniques used (e.g., cross-validation, train-test split)? Is there an analysis of the model's performance on both training and testing data?

<br />

This was it.

Exactly what I was looking for.

Now I could grade a student on each of these criteria, then select a final grade weight for each criteria (e.g. 5-15%), create a spreadsheet with such a table and call it a day.

However, the most time-consuming task was coming - the grading itself.

There were 10 groups in total. So 10 notebooks that I had to look into, exploring completely different datasets with a different ML model being used, different ways to do exploratory data analysis, different ways to assess the model, different objectives, …

### Cursor helping with grading

I opened [cursor](https://www.cursor.com/) (which is basically VSCode + ChatGPT) and probably the software I’ve recommended the most to developers in 2024.

And opened my first notebook.

Then I thought, what if I had GPT-4o on my side - helping me to assess this coursework.

It didn’t need to be perfect because I was doing it myself, but it could help me understand if there was any critical thing that I missed OR if it completely had a different grade than the one I was going to provide - which would enable me to spend more time on that criteria and iterate.

It gave me confidence that I was being fair to the students.

And made me realize how hard it is for professors when they have 100s of students and have a subjective answer to grade. It’s impossible to get it right. They try their best, but as soon as the answer is not binary (0 or 1), they are doomed to fail.

So how did I do it?

Given that I just wanted GPT-4o to quickly review each of the criterias based on the code, I created a prompt that I could use for all of notebooks that the students sent.

This is what my setup looked like

<p align="center">
    <img width="1000" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor.png"/>
</p>

Having the code on the left side and the copilot on the right side that I could use to chat really enabled me to grade more confidently.

Here’s an example of a section of a response I got to one of the student’s notebooks

<p align="center">
    <img width="600" src="/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor_output.png"/>
</p>

One thing I did to have the copilot produce better outputs was to push it to do chain-of-thought (CoT). Meaning that I prompted the model to explain the reasoning behind a decision before providing a grade. This has been proved to yield to less hallucinations and more accurate responses - which is what I was looking for.

**What if I wanted to do this at scale?**

I would have put more effort into the prompt and focused on evaluating 1 criteria at a time. I would have done few-shot prompting where I put examples of what grades 1,2,3,4,5 look like for such criteria so the model has those references and can check for similarity of issues committed or successful tasks performed.

Note: the model was able to interpret comments written in Portuguese which is another benefit.

## Democratizing access to tutors

While I was working on my prompts to get some feedback from AI in terms of student’s coursework I realized that I only need $20/mo to access them.

But then I realized - so do the students.

This means that the students have no reason to NOT run their entire coursework by a LLM that can act as a critic of their work.

They can keep iterating until the model doesn’t find anything - hence making students feel more confident about the work they are putting forward.

My initial thought was: “this feels like cheating” (right after the - “I wish I had this a few years ago”).

But it actually isn’t.

Tutors have existed for a long time.

Students pay tutors to spend time with them to learn outside of classes - whether it’s explaining the theory or helping with coursework.

However, tutors are a vitamin and not a painkiller (they are a nice-to-have and not a must-have). And because they aren’t a requirement, it’s not a typical choice among lower-income families.

On the other hand, kids from wealthy families often have multiple tutors. Not for students who are almost failing their class, but who want to bump their grades from A- to an A+.

But this is about to change.

For the most part, GPT-3.5 is accessible for free.

This means that everyone can have access to a tutor that they can work with to have better grades but also produce better coursework.

This means that the concept of a tutor will be democratized and the playing field between students who come from different wealth backgrounds will be leveled and fair.

## A final thought on open source

Another class that I had to give to students was "Data Analytics in Financial Markets".

The goal here was to have a more real-life application of data analytics, particularly in financial markets - and even feature OpenBB which has partnered with this university.

But when I started working on the content from scratch, I wondered.

Can't I find a repository on GitHub that suits my needs?

And I did.

The GitHub repository I found was the GitHub repository that contains the code for the case studies in the O'Reilly book "Machine Learning and Data Science Blueprints for Finance" written by my friend [Hariom Tatsat](https://www.linkedin.com/in/hariomtatsat/): https://github.com/tatsath/fin-ml.

So why would I spend the time re-inventing the wheel when I could just walk students through a few of these case studies?

This is what I did.

Which then made me think that all of this data has been already fed into foundational models, and so even if I were to apply the same approach I did earlier with Perplexity or ChatGPT - it is likely that with a good prompt some of the main examples would have been derived from this repository.

But in this case, this repository already had the perfect case-study format I was looking for, and so I can more easily credit the author.

which made me wonder:

_How will open source authors be able to get credit for their work when all of it is being translated into weights in a big neural network architecture?_


---

---
slug: inspired-by-bia-how-her-fight-against-cancer-changed-my-life
title: Inspired by Bia - How her fight against cancer changed my life
date: 2024-08-01
image: /blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG
tags: ['cancer', 'development', 'disease', 'charity', 'personal']
description: In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.
---

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG"/>
</p>

In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This cause could not have been a personal one, but it is.

As a young kid from a small town in Portugal, people who die from cancer are on TV and I don't know them personally.
 
My friends & family are “protected” by an imaginary shield that I created in my head.

Until they aren’t.

Let me go back down memory lane and talk about Beatriz.

Bia was in my class in high school.

We started talking here and there.

Before I knew it, she was my best friend.

We would talk for hours about everything and nothing - always laughing.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG"/>
</p>

We would sit next to each other and professors would have a hard time with us because we liked to chit chat.

So we created a new communication medium to not get caught.

We would rip the side of those pages and write in very small font notes to each other.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_1.jpg"/>
</p>

We would go through multiple of these in each class.

It was our thing.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_2.JPG"/>
</p>

A few months later, we had a sports class and she felt weak from her wrist.

She didn't really like sports. So I remember making fun of her for trying to find an excuse to skip sports class.

That would be the last time I made fun of that.

She went to the hospital the day after, and to another one soon for a second opinion.

She had cancer. On her back.

Her floor was pulled from under her.

She was 16 and while kids her age were worrying about boys and school grades, she had to fight for her life.

At fucking 16.

The crazy part is that the attitude she had with others was the same.

She would not display any weakness throughout none of it.

She was so strong. At 16.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_3.png"/>
</p>

One day I visited her and she had no hair because of chemotherapy.

She was still the same beautiful and happy girl that I loved.

Underneath it all, I don't know where she got the strength to go through it.

The school adapted the classes to be livestream so that she could attend from home.

Not only she wasn't gonna lose this battle but she didn't want to lose 1 year of school either.

She was incredibly smart for her age. So losing a year wasn't an option for her.

At the graduation she wrote me a message. She didn't have strength in her hand to write so she used her wrist to be able to write it in an iPad.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_4.JPG"/>
</p>

The translation doesn’t make it justice, but it reads as:

<blockquote>
    <p>Didier</p>
    <br />
    <p>It was in the middle of laughter, in the middle of playfulness.</p>
    <br />
    <p>It was in the middle of tantrums and misunderstandings.</p>
    <br />
    <p>It was in the middle of sheets of paper fallen on the floor and of pieces of paper so efficiently utilized.</p>
    <br />
    <p>It was like this that our friendship grew!</p>
    <br />
    <p>Beatriz ❤️</p>
</blockquote>

<br />

Saturday morning I got a call. A common friend let me know that she passed away unexpectedly.

I was still in bed. I cried for hours. I didn't want to wake up. Maybe some part of me never did.

She had her entire life ahead of her.

She was kind, curious and loving. She would have accomplished so much.

Yet she was gone.

No one deserves to lose their best friend at 17. Not like that. It wasn't fair.

But that's cancer for you.

Cancer doesn't care.

It never did.

From that moment onwards I changed my attitude towards life.

I stopped doing things for the sake of doing them and always put 120%.

I went from spending most of my time as a gamer and doing just enough to have good grades in high school to being the best student of my year in my BSc in Electrical and Computer Engineering, moving to London to have a distinction at Imperial College London (top 2 uni in the world) and now moving to NYC to increase chances of success for my startup.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_5.jpeg"/>
</p>

I have a tattoo that says “All her would-haves are our opportunities" (which is from Anne Frank's house in Amsterdam) to remind me that every day I have opportunities that she didn't get to experience.

But I hope that in some way, shape or form, she is.

And that I make her proud.

Stories like this are not as uncommon as you may think they are.

It took me over 10 years to talk about how cancer took my best friend’s life away.

Imagine the number of people who never write about how it impacted their lives.

If anything, my objective with this post is to highlight that cancer is real.

In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day...

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

[Haymakers for Hope](https://haymakersforhope.org/) is an organization dedicated to raising funds for cancer research and care. They organize unique events that combine athleticism with philanthropy, making a significant impact in the fight against cancer.

On March 16, 2025, I will be running the NYC Half Marathon as part of the Haymakers for Hope team.

Join me in this fight against cancer, for Bia and for all those whose lives have been touched by this disease.

I've created a [fundraising page](https://haymakersforhope.org/events/running/nyc-half-marathon-2025/runners/Didier-Lopes) where you can support this cause.

<p align="center">
    <img width="600" src="/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_6.png"/>
</p>

<p className="text-center">
    <a href="https://haymakersforhope.org/events/running/nyc-half-marathon-2025/runners/Didier-Lopes" className="inline-block px-5 py-2.5 bg-[#0088CC] text-white rounded font-bold hover:bg-[#006699] transition-colors duration-300">Donate here</a>
</p>

Every donation matters. ❤️

---

---
slug: why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare
title: Why AI Will Replace Jobs in Finance and How You Should Prepare
date: 2024-08-06
image: /blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png
tags: ['artificial intelligence', 'finance', 'career development', 'technology', 'future of work']
description: As AI continues to advance, many jobs in finance are at risk. Learn why this shift is happening and how to prepare for the future.
---

<p align="center">
    <img width="600" src="/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png"/>
</p>

It's not a matter of if, but a matter of when. AI will replace analysts' jobs, and we actually believe that's a good thing. In this blog post, we explain why and how you can prepare for this revolutionary change in the world of finance.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Introduction

This is the current state of Quant/Finance/Investing conferences in 2024

<p align="center">
    <img width="600" src="/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_1.png"/>
</p>

I’ve heard panels defending both sides: Yes and No.

I think that people who say “No” don’t understand how AI fundamentally works, and most people who say “Yes” are understating the impact it will have.

Personally, a much better question is “When will AI replace financial analysts?” or “How can I prepare for the shift?”.

## History

If we look back at the automotive industry, 100 years ago - this is what a Ford factory looked like:

<p align="center">
    <img width="600" src="/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png"/>
</p>

How many of these blue-collar workers would have said that their jobs would be extinct in less than 100 years? And for the most part, they are.

This is where we are today in terms of AI.

Some tooling (read: AI) can help humans do their job, but it still needs to be supervised.

But with enough time (for the automotive industry that was 100 years), AI will take over.

This is what Tesla’s Giga Berlin factory looks like today.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/7-4yOx1CnXE?si=k-adJ_cOlXS6Ldlv"
        width="800"
        height="400"
    />
</div>

## When will AI replace financial analysts?

Bill Gates famously said: “Most people overestimate what they can achieve in a year and underestimate what they can achieve in ten years”.

I’ve found this to be mostly true for everything tech.

EXCEPT AI.

This is why I’m so bullish on the category as a whole.

I subscribe to a few newsletters that share daily AI updates, and it’s crazy that every single day there’s something big happening. Either a new model is released and open source, a new framework to do RAG or fine-tune, a new company announces they are working on foundational models, a new paper that pushes the field forward, or a new investment from a big corporation.

I mean, even enterprises are rushing to jump into the AI train. Either releasing AI features to millions of users before proper testing (e.g. Gemini overview on Google and the whole Reddit answers), adding AI where it isn’t really necessary (e.g. Meta AI on WhatsApp), exploring new monetization opportunities (e.g. Amazon Bedrock for fine-tuning) or risking on their values to not be left behind (e.g. Apple partnering with OpenAI — risking the security brand they worked so hard for).

So, I think this will happen soon.

And it’s with that in mind that we have been building OpenBB.

## How can I prepare for the shift?

I think that the most important question that financial analysts should ask themselves is not ‘**when**’ but ‘**what can I do to prepare myself for when AI starts taking over**’.

There’s going to be multiple stages before AI fully takes over. Here’s how I envision it playing out:

<p align="center">
    <img width="600" src="/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_2.png"/>
</p>

(For what it’s worth, I think this is equivalent to what will happen to developers in general).

### Short term

We are starting to enter this timeline.

A timeline where analysts will use AI to augment their output.

A good analyst using AI will be able to perform at a better level than a great analyst who doesn’t use AI.

Interestingly, a mediocre analyst will be able to increase their output but nowhere as much as a good or great analyst. This is because the AI usage will supervised and still “driven” by the analyst (through prompts). So mediocre analysts will not benefit as much because they will either trust too much the AI (without being able to discern its validity), not use the best prompts because they don’t know what to use the AI for, or not use the output because they won’t comprehend the insights that the AI is generating.

During this period, the gap between mediocre and great analysts will be at an all-time high. This will expose more who is pushing their weight and who isn’t.

Another thing is that firms that will be hiring high-talented juniors/interns will start adding AI experience as a requirement (e.g. OpenBB experience) since they understand that they will have a higher leverage and their output will be much better. Potentially even replacing a current analyst with many years of experience that doesn’t leverage AI in the day-to-day.

I think there are 2 reasons for this:

1. **AI will allow financial analysts to have much broader mandates** as they will be able to automate the process of research and screen the best companies. Instead of analyzing 20 companies per quarter, they will do 500.

2. **AI will be able to extract trends and patterns that humans simply can’t due to the amount of data necessary to process**. The amount of data that financial firms use to invest is constantly on the rise, that’s where they get their alpha from. Given that an analyst has a limited amount of resources, they will either have to narrow down the companies in their mandate or process less data for each.

### Long term

In the long term, AI will start taking the reigns.

This is the equivalent of self-driving cars becoming fully autonomous.

The gap between mediocre and great analysts will narrow over time because AI is doing all the heavy work.

At that time, it will be very hard to distinguish the competency of mediocre and great analysts — the main indicator will be how they interpret/understand the AI model, i.e. how they can explain what led to the AI “deciding” to invest in companies based on hundreds of different datasets.

This is why we spend hours obsessing over the UX of the [OpenBB Terminal Pro](https://openbb.co/products/pro). We want to make sure analysts know at all times what the AI Copilot is doing and thinking. Because interpretability will be a big topic in the future.

It’s important to note that the best analysts will be the ones who have their jobs more secure over time. That is because provided the AI is taking the reigns, when it fully takes the reigns, the output of all analysts will be more or less the same. However, in the period before, the great analyst will have an edge because their skill is still in use and so the leverage lever is bigger.

I think that when AI fully takes over analysts' jobs, the best ones will move towards opening their investment firms and focus on the human part of the job: communication.

Communicating to their investors why they made their decisions, e.g. “We have access to this dataset which others don’t, and our AI model correlated that data with x, y, and z which enabled us to invest ahead of the rest of the market”. This is the “interpretability” of the AI that I mentioned earlier.

## What can you do?

You should still pursue a career in the space.

But you should do so with AI in mind.

Experiment with products out there that leverage AI to make you more efficient (you can try OpenBB for free at pro.openbb.co). You will soon realize that your output can compete with someone who is neglecting AI in their day-to-day.

Being a top financial analyst is still something you should strive for since these are going to be the last to be replaced. And when they are, you will still have an edge because your role is likely to evolve into a communication/management role that explains what the AI is doing to investors. And that would be much easier if you’re a top analyst in the first place - because you would understand the insights extracted from an AI copilot.

What is your opinion on this topic?


---

---
slug: what-i-learned-in-3-years-at-openb
title: What I learned in 3 Years at OpenBB
date: 2024-08-20
image: /blog/2024-08-20-what-i-learned-in-3-years-at-openb.jpeg
tags: ['career development', 'technology', 'OpenBB', 'learning', 'leadership']
description: The OpenBB journey started officially 3 years ago. So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.

---

<p align="center">
    <img width="600" src="/blog/2024-08-20-what-i-learned-in-3-years-at-openb.jpeg"/>
</p>

The OpenBB journey started officially 3 years ago.

So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The OpenBB journey started officially 3 years ago.

So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.

1. Be curious.

2. Talk to users.

3. Protect your time.

4. Do the right thing.

5. Culture is everything.

6. Energy is contagious.

7. Hire slow and fire fast.

8. Write everything down.

9. Reward people who care.

10. Celebrate every little win.

11. Work on your storytelling.

12. Ship often and iterate fast.

13. Listen more than you speak.

14. Be comfortable with saying no.

15. When in doubt, there's no doubt.

16. Over communicate with the team.

17. Have an inherent sense of urgency.

18. Don't overthink, estimate and iterate.

19. Failing is ok, not learning from it isn't.

20. Measure success by impact, not effort.

21. Do not run away from hard conversations.

22. Having common sense is a very powerful skill.

23. How you do anything is how you do everything.

24. It's not because you can build it that you should.

25. Seeing your vision materialize gives goosebumps.

26. Be so excited in your product that users can feel it.

27. Lack of focus is likely the biggest risk you face as a company.

28. It turns out that there's a ton of data in your gut feeling.

29. Make people accountable for both successes and failures.

30. Hiring is the most important thing you will do at your company.

31. Create a culture where feedback is not only welcome but expected.

32. Work side-by-side with the team on things that are considered "boring".

33. Be there for your team when they need you, they will repay you with loyalty.

34. One of the worst things you can do is optimizing something that shouldn't exist.

35. Vast majority of decisions are 2-way door decisions. Make a decision and move on.

36. Startups are hard and fun. Working with people you like makes it less hard and more fun.

<br />

In the past 3 years, we have:

- The [open source repo](https://github.com/OpenBB-finance/OpenBB) has been starred over 28,000 times and 220 contributors
- The OG OpenBB Terminal installer was downloaded over 150k times
- Refactored that application to a platform that could be pip installable
- Enabled users to fully [automate their research workflow in a script](https://youtu.be/cgeN3Ep2nEw?si=8e5en_xunWcBdKMM)
- Open-sourced an [LLM-powered financial analyst agent built on top of the OpenBB platform](https://github.com/OpenBB-finance/openbb-agents)
- Made an [OpenBB Bot](https://openbb.co/products/bot) that run over 4M commands in 20k+ servers with 50k+ users
- Developed an [Add-in for Excel](https://openbb.co/products/excel)
- Grew to a team of 16
- Built a community of over 100k people
- And finally, we built the foundation of the [first AI-powered financial terminal](https://openbb.co/products/pro) - more on this very very soon.

<br />

Personally, during that timeline:

- I got a second dog
- Visited US for the first time
- Got married on that first visit
- Left London to move to the Bay area a couple weeks after
- Moved to NYC
- Started boxing regularly

We are more locked in than ever before.

Can’t wait for the next 3 years. 🥂

---

---
slug: why-i-love-boxing
title: Why I love boxing
date: 2024-09-09
image: /blog/2024-09-09-why-i-love-boxing.jpeg
tags: ['boxing', 'startups', 'learning', 'growth']
description: Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.
hideSidebar: true

---

<p align="center">
    <img width="300" src="/blog/2024-09-09-why-i-love-boxing.jpeg"/>
</p>

Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Recently, I finished reading “The Art of Learning” - a really good book that I’ve recommend to everyone (btw, [here](https://x.com/didier_lopes/status/1742748040220328189?s=20) is a page of all the books I’ve read in the past few years).

In it, the author Josh Waitzkin, reflects on his journey from chess champion to martial arts practicioner - and how anyone can master the art of learning.

<p align="center">
    <img width="300" src="/blog/2024-09-09-why-i-love-boxing_1.png"/>
</p>

It made me wonder, why at 29 years old did I decide to step into a ring with boxers who have been fighting for 10+ years? 🥊

As my friend Max says, “You don’t play boxing”. So why am I doing it?

Similar to setting up a startup, this isn’t something that’s easy to explain. The most rationale thing to do would be to go for a run outside or just go to the gym.

Yet, I hop in a ring to fight.

Why?

For starters, there’s something thrilling about stepping into the ring and knowing that you are going to get punched.

You need to get comfortable with something that - by definition - it’s uncomfortable.

## Boxing is the physical to what startups are for the mind

Think about it. Most activities that people do in their spare time have a “controlled” level of intensity. You get progressively more tired but “know” it’s coming - e.g. gym, swimming, tennis, running, etc.

Contact sports are in general like this too, although every now and then you can get injured. Although this rate is small, and sports in general equip athletes to be protected against injuries.

Boxing (and martial arts) don’t work this way. You step in the ring and within the first few seconds, you may get a hook that gives you a bruise next to your eye or a uppercut that makes you stop breathing for a few seconds.

My point is that with boxing, you don’t know when you are going to get hurt, but you learn to be comfortable with it and over time your body gets used to that level of pain - so it will take even more to make you uncomfortable.

<p align="center">
    <img width="600" src="/blog/2024-09-09-why-i-love-boxing_2.png"/>
</p>

## First sparring session

I still remember my first sparring session, I got hit on the nose and had tears coming out of my eyes from it. My nose hurt for 3 days in a row. It doesn’t matter how many times the coach told me to keep my hands up, nothing taught me quicker than that cross on my nose.

For the remainder of the fight, I was mostly protecting myself and keeping my distance. I was “humbled” by the other fighter, and was pushed to outside my comfort zone.

This is not so much different from startup life where mentally you have to be in uncomfortable places - for me this is the equivalent to speaking on a stage. For an introvert like myself, that was something that was hard to overcome. Although I am still not comfortable on a stage, I am much more comfortable than I used to be.

<p align="center">
    <img width="600" src="/blog/2024-09-09-why-i-love-boxing_3.png"/>
    <p style={{fontSize: '0.8em'}}>Presenting at CIBC a few weeks ago at New York AI meetup</p>
</p>

## Next sparring sessions

Currently when I step in a ring I have mixed feelings, I’m somewhat anxious but also excited about it.

It’s weird.

I mean, I know full well that I’m going against folks who’ve been in a ring since they were young - and I also know full well that I’m going to get hit much more than I will hit.

**However**, there’s something exciting (poetic maybe?) about knowing that each time I step into the ring again, I will be able to land more punches, avoid more hits and be better mentally.

Learning is the nature of the game.

And the only failure is to not take any lessons from each fight.

This is the same for startups. I like what Bezos has to say on the topic, about [pushing Amazon to embrace failure](https://www.youtube.com/shorts/HmYj-UDT8jM).

<p align="center">
    <img width="300" src="/blog/2024-09-09-why-i-love-boxing_4.JPG"/>
    <p style={{fontSize: '0.8em'}}>This picture was what convinced me to buy my own head gear</p>
</p>

## So, why do I love boxing?

I think ultimately, the reason why I love boxing is the same as why I love startups.

Startups push me everyday to be the best that I can be in so many different areas, there isn’t a role that - for me - is as stimulating mentally as being a startup founder.

There are 100 different initiatives ongoing at all times, you have a team of composed of human beings (by nature, highly complex with different backgrounds and life experiences), you have startups trying to disrupt your business, you have well established incumbents, etc..

Boxing is the same... but at the physical level.

I step in the ring and need to be the best I can in multiple verticals - it isn’t enough to be the best in one.

I need to have a faster reaction to avoid punches, be light on my feet to surprise an opponent, land the combos where I put most of my energy in, trade-off balance between combos and stamina, and obviously all the mental side that comes from it too - which turns out is quite a lot.

Ultimately, as cheesy as it sounds, being a startup founder and doing boxing make me feel alive.

<p align="center">
    <img width="300" src="/blog/2024-09-09-why-i-love-boxing_5.jpeg"/>
    <p style={{fontSize: '0.8em'}}>Taking my father-in-law for a class</p>
</p>

---

---
slug: chatgpt-and-the-future-of-ai-in-finance
title: ChatGPT and The Future of AI in Finance
date: 2024-09-21
image: /blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance.jpg
tags: ['finance', 'ai', 'agents', 'chatgpt', 'quant', 'cornell', 'twosigma', 'blackrock', 'citadel']
description: I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT & The Future of AI in Finance.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance.jpg"/>
</p>

I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT & The Future of AI in Finance.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Last week, I participated in a panel at the Cornell Financial Engineering Manhattan Conference. The topic of the panel was ‘ChatGPT & The Future of AI in Finance.’

The other panelists were:

- **Yu Yu**, Director of Data Science - BlackRock
- **Tony Berkman**, Managing Director - Two Sigma
- **Samson Qian**, Trader - Citadel

After the discussion, several people reached out, mentioning it was one of their favorite panels of the day.

Since this wasn't recorded, I took the opportunity to write down some of the topics discussed, along with a few additional thoughts that I believe in.

I will organize the following sections based on the topics discussed at the event:

1. Hallucinations
2. Agents are the future
3. When does it make sense to fine-tune?
4. Compliance and Data security

## 1. Hallucinations

When talking about the topic of hallucinations, I have a [quote](https://x.com/didier_lopes/status/1675630822093918209) that I love from Marc Andreesen:

> “Hallucination is what we call when we don't like it. Creativity is what we call it when we do like it.”

### Confident hallucinations

The fundamental issue with hallucinations is the fact that the model hallucinates with confidence.

Imagine asking two different friends: “Do you know where location X is?”

**Friend A**: It’s there.

**Friend B**: Hmm, I’m not really sure. If I had to guess, I’d say there, but I’m not 100% certain.

If both gave wrong directions, you would consider **Friend A** a liar, but not Friend B. This is because **Friend B** lacked confidence in their answer, they were trying to help but highlighted that they weren’t sure about it.

The problem with current LLMs is that they are, for the most part, like **Friend A**. They say wrong things with certainty.

Hallucinations would be less problematic if the default behavior were more like the answer on the right, when the LLM is not 100% confident.

<div className="flex justify-center items-center">
  <img width="350" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_1.png" style={{marginRight: '10px'}}/>
  <img width="350" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_2.png"/>
</div>
<br />

The problem with confident hallucinations is that, similar to why everyone dislikes liars, it leads to a lack of trust. So users begin to put everything that is output by an LLM under a microscope - even if what the model says is accurate.

### How to avoid hallucinations

There are ways to address this and one of the key approaches we are extremely strong about at OpenBB is always tapping into information that is available.

When a user asks a question that requires financial data, the OpenBB Copilot always searches for that data on OpenBB (either through data we make available or through private data that customers bring).

The Copilot will only answer the question if that data exists. This allows the model to cite the data used in its response, so the user can double-check.

This is how it looks.

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_3.png"/>
</p>

While I've heard a few vendors promising 100% accuracy, this is simply not true.

We are at a stage where technology is not even yet at the ‘trust but verify’ level.

So instead of hallucinating with confidence, when data is unavailable, we prompt the model to return that there was no real-time information accessible to answer the query.

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_4.png"/>
</p>

### Function calling to increase accuracy

One thing we found that significantly reduces hallucinations is enabling our agent, OpenBB Copilot, to have access to all the API backends that users have through OpenBB or those they've added themselves.

Here’s the sequence of actions that happen:

1. The user asks the OpenBB Copilot a question.
2. The prompt is converted into embeddings.
3. We compare that embedding with all the ones that we have on an OpenBB vector store which contains widget signatures - name, description, category, subcategory and source.
4. We retrieve the widgets with the highest similarity.
5. The Copilot then decides which widget to use based on the prompt.
6. Then Copilot also decides what parameters to use when calling that API

<br />

This leads to less hallucination because the LLM isn't outputting tokens based on a prompt and its internal weights. Instead, it's using its internal weights, the prompt, and a function call.

Assuming the function call succeeds - with correct widget retrieval and parameters - the data becomes available for the Copilot to use, which leads to higher accuracy.

Note: This still means that Copilot needs to use the correct widget and the correct parameter, but there's a **higher likelihood of success** because if it isn't, the API call will fail, prompting the LLM to try again.

Here's how it works behind the scenes, the OpenBB Copilot highlights its step-by-step reasoning so users can understand its thought process. Transparency is key.

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_5.png"/>
</p>

### Workflows to avoid hallucinations

In order to reduce the number of hallucinations, there are two things that can be done.

#### Enable users to quickly detect whether a hallucination has occurred

For instance, if a user utilizes the following prompt on the OpenBB Copilot:

>_Using the earnings transcript, create a table with columns: financial metric, value, sentence in the earnings where it was extracted from. Double check whether the information you are using is correct._

<br />

They get the "_Sentence Extracted From_" column, which they can copy and paste into a search field added at the top of the Earnings Transcript widget. This enable users to quickly validate the numbers that have been found.

See example below,

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_6.png"/>
</p>

#### Add deterministic processes to check for hallucinations

For example, let’s say the user prompt involves a data retrieval task.

We can run a deterministic process to check whether the retrieved values exist or not. Sure this won't be 100% accurate because the numbers could be flagged by referring to another thing, BUT it's all about improving the overall accuracy of Copilot.

Ultimately, whatever can be done to improve the Copilot’s accuracy should be done.

## 2. Agents are the future

When we think about how humans operate, we recognize that the brain coordinates all the actions of our body and our thought processes. This is similar to how agents work.

If I'm playing soccer, the muscles I use are different from those I would use if I were boxing. If I'm programming, the parts of my brain I use differ from those I would use when listening to music.

However, it's not as simple as "activity A requires legs". Most of your body and mind are always involved, but at different times and in different capacities. And what dictates that are external factors.

For instance, if I am playing soccer as a winger and my team is attacking, I will likely be using both legs to run forward and a lot of mental energy to decide where to position myself on the field.

And that will change a lot based on where the ball is. If the ball is on the opposite side, I'll likely run less and stay more in the middle to be ready for a counterattack. If the ball is in the middle, I'll probably be running at full speed to create space. If the ball is close to me I have to worry more about controlling it and understand what I can do with it next.

The environment affects my plan to carry out an action where I want to have a successful outcome.

**This is how agents work.**

Agents aren't just about a single LLM performing well, but about a full workflow that interacts with multiple language models, function calls, or any other process to carry an action.

At the core, the biggest advantage of an agent over a LLM is that an agent has a full feedback loop. It understands the impact of the LLM output and can use that data in the next step of the process. Whereas a single LLM API call returns its best output but won't know how that affected the external environment.

This is why, at OpenBB, we believe in compound AI systems.

And apparently, [so does Sequoia](https://finance.yahoo.com/news/sequoia-sees-bigger-money-ai-203655254.html?guccounter=1).

<p align="center">
    <img width="300" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_7.png"/>
</p>

### The “Strawberry” issue will be solved

A panelist commented on stage that LLMs can’t even count how many R's are in the word "Strawberry".

This [tweet](https://x.com/MwangoCapital/status/1828857579860095428) offers a good explanation of why this happens — it turns out it's due to the tokenizer, and it can be solved. In fact, it's solved by simply ensuring that the model takes each letter as a token. See below,

<div className="flex justify-center items-center">
  <img width="300" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_8.png" style={{marginRight: '10px'}}/>
  <img width="300" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_9.png"/>
</div>
<br />

This means that the model's output can be improved by doing extra work at the input level.

Data cleaning and pre-processing strikes again? 😃

Interestingly, a few days ago, [OpenAI announced OpenAI o1](https://openai.com/o1/). Which is basically GPT-4o with Chain-of-Thought (COT). This means that this model is a "wannabe agent".

It takes in a prompt from the user and decomposes it in natural steps to solve it. Then at each step, it takes the output of the model from the previous step and predicts the next token. It turns out that this improves accuracy substantially.

However, it still doesn’t have access to external data. And that is why I call it a "wannabe agent".

I love how Jeremiah put it in this [tweet](https://x.com/jlowin/status/1834722014839418962):

> (...) Agents are also characterized by iterative behavior. But there's a key difference: while models like o1 iterate internally to refine their reasoning, agents engage in iterative interactions with the external world. They perceive the environment, take actions, observe the outcomes (or side effects) and adjust accordingly. This recursive process enables agents to handle tasks that require adaptability and responsiveness to real-world changes. (...)

<br />

So, o1's model isn't an agent - but it can solve this problem. The reason is that it applies its own data cleaning/pre-processing step on its own, and doesn't rely on external factors.

### Small Language Models

Once agents work, Small Language Models (SLM) will be much more viable for very specific use cases.

In logical terms, a Large Language Model is a model with weights.

Large means that it has a lot of them. But what tends to happen is LLMs need to be very big because they want these models to be really good at everything. The problem is that if you want the exact same model to be good at discussing soccer, programming, and speaking Portuguese, its weights are updated using these drastically different datasets. Now the premise is that the more weights there are, the less each weight will be affected by data from completely different domains.

What a big LLM like GPT-4o is doing is trying to build a single Jarvis that knows about everything. Whereas we could have an SLM that does something extremely well and just focus on that, e.g. translating from English to Portuguese. The benefit of an SLM is that inference is likely faster, can be hosted on devices, and, in theory, it's better on a topic because it's been less "contaminated" during training by data that doesn't relate to the task at hand.

Imagine that a firm decides to use an SLM trained to retrieve data from SEC filings quickly and at scale. Or, we could train our own SLM to understand user intent and interact directly with the OpenBB Terminal interface.

### Large Language Models as orchestrator

In my opinion, the best LLM in each category will win. And the second and third won't matter. It's a winner-takes-all kind of market. Unless in specific verticals such as inference time or open weights (e.g. for data security; more on this later).

The best example of this is OpenAI vs Anthropic.

I had been using OpenAI's GPT-4 for coding for several months. After trying Anthropic's Sonnet 3.5 for coding, I never went back to OpenAI.

<p align="center">
    <img width="400" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_10.png"/>
</p>

The market share for the best LLM will be gigantic. That’s why [OpenAI is looking to raise at a $150 billion valuation](https://www.bloomberg.com/news/articles/2024-09-11/openai-fundraising-set-to-vault-startup-s-value-to-150-billion). While the valuation reflects the market size, the amount that will be raised represents the capital needed to reach that valuation. This is why only a few players will be able to compete at that level.

In an "agentic future", I believe the best LLM will serve as the core "brain" - the main LLM that routes all prompts and decides what happens next.

And who wouldn't want the smartest model controlling the actions with a list of models, functions and data at its disposal?

I know I would.

That's also why, when discussing OpenBB Copilot, we don’t rely on a single foundational model. Instead, we use the models that are best suited for each specific task.

For instance, OpenAI o1 can be the brains, but when a user uses @web it triggers the Perplexity model, and when they upload an image, we have Anthropic's Haiku. Or maybe if they want to do intraday trading, we use Llama 3.1 through Groq for fast inference.

You get the idea.

## 3. When does it make sense to fine-tune

A good comment was made on the panel: "_it’s expensive to spend time fine-tuning a new model, just for that entire work to be 'eradicated' by a new model that has a higher performance in that specific domain than the model has been fine-tuned_".

In my opinion, this happens because the timing isn't right yet. We are still unlocking remarkable achievements through each new model release. Although there is a massive bump in terms of capability between these releases, I wouldn't recommend that a firm fine-tune its own models at this stage.

However, at some point, whether due to a lack of data to train or architecture needing to be reinvented, improvements in LLM performance won't be substantial - they may not even be noticeable. This is when the fine-tuning technique becomes relevant because at this stage you are trying to repurpose everything the model has towards a specific vertical / use-case - and at that vertical/use-case that model will be better than the following one.

Then after some new models come out, you may consider reapplying fine-tuning to that model, but this would likely be years later, not weeks or months. So, the ROI can be quite high. Particularly when you are trying to win in your specific market.

This is how I see it working in my head:

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_11.png"/>
</p>

## 4. Compliance and Data security

Another question I received was about compliance and data security.

Recently, during a discussion with one of the largest hedge funds in the world, we were asked about the entire workflow of the data when our AI Copilot has access to it.

Their main concern was ensuring that no data was being shared with third-party vendors like OpenAI. For such firms, their data is their alpha, and keeping it within their network is paramount.

Crypto enthusiasts often say, "Not your keys, not your coins" to emphasize the importance of storing assets in a cold wallet rather than leaving them on an exchange that might implode (looking at you, FTX). The same principle applies here: "Not your weights, not your data".

When you send information to a large foundation model provider like OpenAI, your data enters their ecosystem, and you have to trust they’ll honor the terms of your contract.

A more secure approach is to host an open-source model locally within your firm, ensuring that sensitive data remains entirely within your infrastructure and network.

Although open-source models aren’t yet as powerful as closed-source ones, they are catching up quickly. If you think that GPT-4o can already do a lot for you, think about how at some point there will be an open-source model that is GPT-4o equivalent. Sure, at that time closed-source models will be better, but the question is: How much better?

Or better, the question is: **"How much are you willing to sacrifice in terms of data security for performance?”**.

At OpenBB, we take this very seriously and have taken measures to allow enterprise customers to fully control their data.

### Bring your own copilot

Enable firms to bring their own LLMs to access data within OpenBB. This means that we provide an interface for research, but also allow them to integrate their internal LLMs and interact directly with it from OpenBB.

<div className="flex justify-center items-center">
  <img width="350" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_12.png" style={{marginRight: '10px'}}/>
  <img width="350" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_13.png"/>
</div>
<br />

We believe in this idea so much, that we have open-source the architecture for firms to bring their own Copilot to OpenBB. More information is available [here](https://github.com/OpenBB-finance/copilot-for-terminal-pro/).

### Turn off AI workflows

We have incorporated workflows that make users' lives MUCH better. But they come at a cost: sharing data with an LLM provider.

These are the features:

- **Widget title/description suggestion from Copilot**: This sends the content of the table or note output by Copilot to an LLM provider to receive suggestions of a title and description.

<p align="center">
    <img width="600" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_14.png" />
</p>

- **Widget title/description suggestion upon upload**: It sends the content of the file that has been uploaded to an LLM provider to receive suggestions of title and description.

<p align="center">
    <img width="600" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_15.png" />
</p>

- **Copilot chat title generation**: Upon the first user prompt, the content is sent to an LLM provider to update the chat title, reflecting the nature of the conversation.

<p align="center">
    <img width="600" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_16.png" />
</p>

- **Dashboard name generation**: When renaming the dashboard, we send the title and descriptions of all widgets on that dashboard to an LLM provider, to ensure that the suggested name is relevant.

<p align="center">
    <img width="600" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_17.png" />
</p>

To allow firms to keep their data within their network, one of our enterprise features is the option to disable these AI workflows.

<p align="center">
    <img width="900" src="/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_18.png" />
</p>

In the future, we could direct these AI workflows to use an LLM that our customers are running locally.

## So, in a nutshell, what can you expect from OpenBB?

We are building an AI-powered research workspace.

At the core it is an AI compound system, where users can bring their own data (structured, unstructured, API, custom backend, database, data warehouse, etc..) and have our (or their own copilot) access all this data seamlessly - in an interface that is customizable, flexible and enables teams to work together.

If you want to learn more, e-mail me directly at didier.lopes@openbb.finance


---

---
slug: openbb-mobile-app-coming-soon
title: OpenBB Mobile App - Coming soon
date: 2024-10-05
image: /blog/2024-10-05-openbb-mobile-app-coming-soon.png
tags: ['openbb', 'mobile', 'pwa', 'web-development', 'ux', 'engineering']
description: How we built a mobile app, in 1 evening, with 1 engineer.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-10-05-openbb-mobile-app-coming-soon.png"/>
</p>

How we built a mobile app, in 1 evening, with 1 engineer.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Let’s start with a bit of background to this story. 📖

Back in September 2021, our first full-time team member was [Jose Donato](https://x.com/josedonato__?utm_source=didierlopes.beehiiv.com&utm_medium=referral&utm_campaign=openbb-mobile-app-coming-soon). He started full-time, even before I did (due to my 3 months notice period in Europe, yikes).

We met through Reddit, only to discover that we are both Portuguese and our hometowns aren’t far from each other.

I’ve learned more from him about web development than from any YouTube, tutorial or book - combined.

One of the topics he was very passionate about, was the concept of Progressive Web Apps (PWAs). So much so, that he talked about it in his thesis ([2.2 native applications](https://jose-donato.deno.dev/master_thesis.pdf?utm_source=didierlopes.beehiiv.com&utm_medium=referral&utm_campaign=openbb-mobile-app-coming-soon)).

I had never heard of it before, but the concept intrigued me. Why wouldn’t more companies do that?

Jose is currently writing a post about it, you can subscribe to the [company newsletter](https://openbb.co/newsletter?utm_source=didierlopes.beehiiv.com&utm_medium=referral&utm_campaign=openbb-mobile-app-coming-soon) to keep an eye out for it.

## Mobile compatibility

Fast forward to September 3rd, 2024. 🏃‍♂️

We are 1 week away from one of the biggest launches in the company. Earlier surprise for my subscribers, but we are about to announce a free version of our enterprise product.

A web app that allows users to bring any type of data and have access to an agent to interact with all these different datasets to extract patterns, trends and insights.

This web app has been built over 2 years and all workflows, tests, and iterations have been done for desktop usage.

Jose sent me a video of a mobile version somewhat polished. It had the same UX as the terminal, but it rendered nicely on mobile.

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_2.png"/>
</p>

Given that we were aiming at adoption, he believed it was important for users to be able to access the terminal through their phones on the web.

And so over 2 weeks, he spent no more than 3h polishing the mobile version.

## Mobile UX

On the 23rd of September, I pinged [Rita Soares](https://www.linkedin.com/in/ana-rita-soares-48b247152/?utm_source=didierlopes.beehiiv.com&utm_medium=referral&utm_campaign=openbb-mobile-app-coming-soon) - our lead UI/UX.

I had been thinking about mobile user experience and wasn’t happy that we just adapted the interface to work with mobile. But, mobile represents a completely different paradigm on how we use a product. The screen space, the speed at which you can type, not necessarily used for work, more distractions, etc…

So, I asked Rita to create a few mobile mockups for me - the idea was to improve the UX to make the copilot shine. I.e. more front and center and have the data visualization pushed more to the background.

That same evening, she shared these mockups with me:

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_3.png"/>
</p>

I promptly shared in a group with her and Jose - this was 7:35 pm my time, which would be 0:35 am their time.

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_4.png"/>
</p>

In less than 24 hours the bulk of the mockups had been implemented.

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_5.png"/>
</p>

### Progressive Web Apps (PWAs)

On that same day, after Jose shared the bulk of mockups implemented.

I sent him this message at 8:55 pm EST (1:55 am Portugal time for Jose).

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_7.png"/>
</p>

To which he replied:

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_8.png"/>
</p>

I was right, it didn’t take him 30s. But it didn’t take him much longer (15 minutes).

<p align="center">
    <img width="900" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_9.png"/>
</p>

15 minutes to have OpenBB as an application on my phone.

I was mind-blown.

We iterated on it for an additional 1h30m together, until we had something we would be proud to share with the team the following day.

<p align="center">
    <img width="300" src="/blog/2024-10-05-openbb-mobile-app-coming-soon_10.png"/>
</p>

We still had to iterate on a few more areas and involve more people from the team. But the bulk of the mobile app was done.

In pretty much 1 evening.

With 1 person.

### Conclusion

I could tell you that this doesn’t happen often, but it does.

Small, highly motivated teams (or individuals like Jose) with a strong initiative and a drive to make a difference, can have a tremendous impact on the company.

I hope this post inspires more builders to share behind the scenes on how great products/features are built and how serendipity can play a role in it.

---

---
slug: implement-feedback-loops-everywhere-you-can
title: Implement feedback loops EVERYWHERE you can
date: 2024-10-25
image: /blog/2024-10-25-implement-feedback-loops-everywhere-you-can.jpeg
tags: ['openbb', 'management', 'leadership', 'feedback', 'transparency', 'culture', 'remote-work']
description: Maximizing team transparency through focused feedback sessions.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-10-25-implement-feedback-loops-everywhere-you-can.jpeg"/>
</p>

Maximizing team transparency through focused feedback sessions.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

A couple of months ago, my co-founder came to NYC for our board meeting.

During that week, we took a day to sync up with everyone on the team—literally. We had 14 conversations, each lasting up to 30 minutes. Apart from lunch, we did all these back-to-back.

The goal of this exercise was 2-fold:

- Check up on the team. Basically, a more in-depth version of:
  https://openbb.co/company/open/team

- Have the team share anything they want with leadership or ask any questions openly.

<p align="center">
    <img width="900" src="/blog/2024-10-25-implement-feedback-loops-everywhere-you-can_2.jpeg"/>
</p>

## Structure

### Part 1 - 20 minutes

For the first 20 minutes, we asked the following questions to each team member:

1. How do you feel working for OpenBB today?

2. What do you enjoy the most about working at this company?

3. Who do you get along the best? and why?

4. Who do you feel like you have a not-so-close relationship with? and why?

5. What does your day-to-day look like?

6. How would you describe the relationship with your manager/team lead?

7. It's 2028 and OpenBB didn't make it. What are potential reasons that you would bet on that lead to this?

8. If you had to tell us what your biggest achievement is since being in the company, which one would you pick?

9. What was your lowest moment during company time - and why? What could we have done better?

10. (for managers/team leads) How do you feel about the team you have today?

### Part 2 - 10 minutes

During the last 10 minutes, the team could ask us about anything.

Funnily enough, we learned just as much (if not more) from the questions the team asked than the ones from Part 1.

## Results

Lack of focus is the biggest risk/challenge that we face as a company.

### Culture

- Handbook is important (folks didn't know about personal development budget, PIP, etc…)

- The team's main reasons for being happy at OpenBB are autonomy, ownership, smart team, transparency and freedom - very aligned with our values.

- Remote work is a benefit that more people should take advantage of. Celebrate it even more.

- It's vital to set boundaries when overworking and know when to decompress to avoid burnout

### Management

- It's key to consider that each person has different preferences in terms of management style - execution vs contributing to discussion.

- 1:1s are essential and everyone should have them set.

- 1:1s should be focused on the direct report and not necessarily on tasks at hand. Several people highlighted that they felt that their manager cared about them based on conversations about their personal life and personal development.

- Feedback should go both ways, the manager/leader appreciates when feedback is provided.

- Setting up expectations clearly for each individual is critical. People appreciate when they know exactly what is expected of them, so they understand how their value is perceived from the company's perspective.

### Rituals

- Monthly update emails are very good. Sometimes even more details would be better.

- Some people are so focused on execution that they try to protect their time at all costs. It's important to respect this decision and default to async text-based conversations instead of setting up a meeting

- Dogfood the product from people from different backgrounds is important as it gives different points of view that we can leverage to make our product better

### Communicatiions

- Be aware of different comms styles throughout org. In general, people have shared that they appreciate when others send them a DM with feedback based on a conversation in a public channel.

- Sometimes team members need to put themselves in the shoes of other people first instead of defaulting to defence.

- We shouldn't compromise on quality. We should aim to agree first on the best solution and then adapt if there's a lack of resources, but knowing what the best solution is and what is the trade-off that is being made

- When a conversation is taking a few messages back and forth, sometimes a quick huddle should be done

- Making sure that all stakeholders are involved regarding features or changes in the product before any green light is given to execute. It happened that a green light was given, mockups were created based on that context and the engineering team added the feature. Only for that to get pushed back because a stakeholder that wasn't involved in the discussion saw the final result on Slack chat.

### Transparency

- More transparency when deals are closed - e.g. what are they interested in, how many seats, what do they do on a day-to-day basis

- When mentioning increased transparency, the vast majority of people think that our level of transparency is very high.

- A common answer: "If I have any questions I know can just DM you and you will answer"

- Add a Q&A at the end of the status update where everyone can put questions to be answered

- A common answer: "I don't like when someone leaves out of a sudden". Unfortunately, we can't do anything here. We've also asked for feedback on what we could do better, but people understood that there's not much we can do. This is a conversation between the person and the manager and it's unfair for the person being let go if we share their personal information. There's a PIP and that means that before everyone leaves the company they are in 3-4 weeks PIP, where expectations are set clearly and their continuity depends on their output.

- People appreciate feedback a lot, regardless of if it's positive or not. It's the best way for them to improve.

### Thoughts

I think, at an early stage, everyone should do this. And maybe even at a later stage but in each subset of the org.

One of the reasons I think this worked so well is that for the first 20 minutes, you are asking the exact same questions to everyone and so that allows you to get answers that you can compare across the board.

Then, once those 20 minutes are over, the team member feels that they have already been so transparent that they openly ask questions that they are curious about.

The final result was a presentation with all the combined learnings and actionable.

**What do you think?**

---

---
slug: why-we-got-rid-of-pips-at-openbb
title: Why we got rid of PIPs at OpenBB
date: 2024-11-09
image: /blog/2024-11-09-why-we-got-rid-of-pips-at-openbb.png
tags: ['openbb', 'management', 'leadership', 'talent', 'hiring', 'performance', 'company-culture', 'startups']
description: My thoughts on how removing PIPs can increase the company talent level
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb.png"/>
</p>

At OpenBB, we removed Performance Improvement Plans (PIPs) in an attempt to increase the company's talent density pool rate.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## How did we get here?

We are currently 16 FTE and since the company started 3 years ago, we’ve let go 15 people.

This means we’re letting go of more than 1 person a quarter since the start of OpenBB.

Most people had a 3-week PIP process before their departures. But out of the 15 PIPs done, only one was successful. All the others have resulted in a contract termination.

That’s a success rate of less than 7%, which is extremely low.

### Statistics

If we go into the machine learning domain and have a model that predicts that a team member who gets into a PIP is let go every time - this is the classification matrix that we would have.

<p align="center">
    <img width="900" src="/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb_02.png"/>
</p>

Which has:

- 93.3% precision - answers: of all the people predicted to be let go (15), how many were let go? (14)

- 100% recall - answers: of all the people that were let go (14), how many were predicted correctly (14)

Now, this isn’t the full story.

This is the equivalent of a physics book treating an object as a point mass, considering the body as perfectly rigid or assuming the system is isolated with no external forces.

So what are the other things to consider? Let’s separate these time-wise:

1. Before a PIP happens

2. During the PIP

3. After the PIP

## Before a PIP

Before someone starts a PIP, their performance has already been subpar.

By definition, performance is a lagging indicator, which means you are already late when you catch this person not pulling as much value as others.

Particularly when you consider that the person who would be initiating the PIP is the team lead (TL)/manager and isn’t working as closely with this person as others on a daily basis. Hence, coworkers are likely to see firsthand this suboptimal performance in advance of the team lead or manager.

So, the suboptimal performance from this person over a few days or weeks is likely to go unnoticed and slow down the company.

In addition, individual contributors (ICs) who work closely with this person are likely to notice this before the TL/manager, thus impacting their motivation.

***"If this person can get the same compensation as I do for average work, why am I putting in so much time and effort?"***

Honestly, if there’s one thing that I’ve learned, it’s that A players get motivated by other A players (“A players attract A players”).

## During a PIP

A PIP takes time. **A LOT of it.**

And that’s the one thing that startups don’t have.

Imagine that you have the following org:

<p align="center">
    <img width="900" src="/blog/2024-11-09-why-we-got-rid-of-pips-at-openbb_03.png"/>
</p>

If an IC is underperforming, the TL will discuss it with the IC in advance.

Then the team lead may ask for feedback from other ICs who work with the IC in question.

After that, the TL will talk with the Director about this before initiating the PIP.

Then the Director will mention this to the CEO of the company.

The CEO will likely want to talk with the team lead about this, given that in an organization of 15 people, each team member accounts for more than 5% of the org.

Now, you may be thinking, “But this happens before the PIP”.

This happens before and continues throughout the entire PIP. But, during the PIP, it’s even worse because there are regular meetings for a shorter feedback loop, and there needs to be documentation on the progress.

So yes, this not only takes a lot of time, but it’s also a distraction to the team.

And that’s the other thing that companies need: “focus”.

You can’t fully focus at 100% when you know that someone is “fighting” for their job. And not being able to focus impacts each individual’s performance.

So this inefficiency ends up spreading across the team.

## After the PIP
### Needs to be let go

Ok, someone was underperforming and needs to be let go.

The company needs to figure out:

- How many options this person has vested and handle the paperwork if they want to buy them

- Whether they have company equipment that needs to be returned

- What the severance package will be

- How to handle the news and how the team will react

Again, this will be a distraction for at least an additional week and will affect other team members, who may be surprised by this.

Particularly because, most of the time, they aren’t aware that the PIP is happening and from their perspective, someone they liked to work with was let go.

### Has a successful PIP

Let’s be honest, these cases are very rare.

Not just at OpenBB. I’ve spoken with other founders, and this is the same feedback I’ve received.

But let’s ignore that, we already mentioned it at the start.

Someone on a PIP—almost by definition—isn’t a high performer. They could be a high performer in some parts of the job, but not as a whole. However, this is the exception, not the rule.

The rule, often, is that this person has been doing just enough to be competent at the company—but not excel. Then, over a period of time, due to internal reasons, lack of motivation, etc., they fall below that threshold.

This means that even after a successful PIP, you are putting all of these resources toward getting—not a high performer, but a B+ player.

And ultimately, this is why we are getting rid of the PIP at OpenBB.

Being **“good enough”** isn’t the culture we want for OpenBB and doesn’t represent our team today. If you let the bar slip, you won’t even realize it until it’s too late.

Again, performance is a lagging indicator and can have both positive and negative effects on the team—so it’s important to protect the team from poor performers.

There are two exceptions to this:

**1. Imagine that this person can turn their output into 4x, imagine they had a wake-up call.**

Several questions need to be asked:

- If this person can perform at this level, why weren't they doing it before?

- How long will they maintain this level of performance?

- Will we need to have another serious conversation to get this person to reach this level of competency again at a later stage?

- Will they always resent the company because of the PIP?

It all boils down to this: if this person isn’t motivated by what we’re building, regardless of their skill set, they weren’t a good fit in the first place.

We’re fortunate to have a pipeline of people applying for positions at OpenBB, not just for the money but for the product and the mission of the company.

**2. The person is a high performer but has been performing poorly in some areas of the job (e.g. communications, testing, documentation, …)**

This person had likely received feedback multiple times, but the PIP made it more real: *“This is what we are looking for in a person for your role; you have 2-3 weeks to prove that you can double down on your weaknesses and reach the level the team needs you to be at.”*

This is what happened to us, and the person improved significantly, so much so that they are now a core part of who OpenBB is today.

This success story was one of the main reasons we continued doing PIPs.

But the likelihood of it happening again is so low that it’s not worth keeping PIP to look for another success story like this one.

## So what’s next?
### How we think about talent level at OpenBB

Let’s say you define company’s talent value as the sum of the talent of each individual divided by the total number of team members.

There are two ways to increase this value:

- Hire people who are above OpenBB’s talent level

- Let go of people who fall below the talent level

Or, ideally, do both.

The problem is that for the first option, you often need **a LOT** of capital.

For the second, you don’t. Not only that but letting go of low performers will accomplish two things simultaneously:

- Increase OpenBB’s talent level immediately.

- Free up resources that can be invested in someone above OpenBB’s current talent value (assuming that companies should always seek high performers and avoid settling for underperformers).

And that’s why removing PIPs leads to an increase in the company’s talent level. You’re not just increasing the talent level once, but likely twice.

Here’s an example:

Imagine we have 5 people at OpenBB with talent scores of 2, 7, 7, 7, and 9. Then OpenBB’s talent level is:

(2+7+7+7+9)/5 = 6.4

If we let go of the employee with a talent score of 2, our talent level becomes 7.4. Then, if we bring in someone with a score of 8 using the same resources, that talent level increases to 7.6.

You get the idea.

### What the team can expect?

Full transparency.

We want to build a culture where feedback is an ever-present element, and we don’t need to wait for performance reviews to give feedback that can substantially improve team performance and push the company forward.

In fact, not sharing this feedback puts the company in a worse position, and it is your duty to share it. But do so with candor, in a constructive manner that keeps the team member motivated.

However, each team member must care. This means you can’t rely solely on your team lead to give you feedback every day—you need to ask for it regularly. That’s the best way for you to grow.

## Final notes

We made this decision after reading *No Rules Rules: Netflix and the Culture of Reinvention*, where they also removed PIPs.

Unlike Netflix, we don’t have the resources to:

- Pay top of the market

- Offer a generous severance

We still pay good salaries, just not enough to compete with public companies. This means we need to spend much more time finding diamonds in the rough.

And that’s why we have a higher turnover; finding diamonds in the rough is much riskier.

In any case, I think optimizing to pay top of the market is misguided—at least for startups—as it incentivizes the wrong type of talent.

It incentivizes mercenaries instead of missionaries.

At an early stage, you need people who want a lot of ownership and autonomy, who are excited to work with a team and on a product they believe in, and who have a chip on their shoulders.

Regardless of the startup, I have yet to see someone with this mentality who doesn’t end up being successful.

**Note**: Most of the people who were let go would be considered good employees in most companies today, and they had strong referrals. But companies have different types of needs that evolve over time, and as founders, it’s our role to look at the company as a whole and understand what it needs at the moment and, more importantly, what it will need in the coming months and years.

---

---
slug: today-i-saw-a-glimpse-of-the-future
title: Today I saw a glimpse of the future
date: 2024-12-18
image: /blog/2024-12-18-today-i-saw-a-glimpse-of-the-future.jpeg
tags: ['openbb', 'ai', 'interface', 'crypto', 'open source', 'customization']
description: My friend Matt, from VanEck, built a backend with data from Coingecko, Velodata, Artemis, CCdata, Glassnode, MSTR Tracker, Telegram and Google - all in OpenBB.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-12-18-today-i-saw-a-glimpse-of-the-future.jpeg"/>
</p>

My friend Matt, from VanEck, built a backend with data from Coingecko, Velodata, Artemis, CCdata, Glassnode, MSTR Tracker, Telegram and Google - all in OpenBB.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

[Matt Maximo](https://x.com/mattmaximo1) has been building a backend with data from Coingecko, Velodata, Artemis, CCdata, Glassnode, MSTR Tracker, Telegram and Google.

However, he didn't find the best product where he could:

1. Bring all this data into one interface
2. Leverage an intelligence layer on top
3. Collaborate with his team on it

<br />

Until he did.

With our free tier - Matt was able to single-handedly create almost 50 different data widgets that he (and his team) will be able to access seamlessly on OpenBB.

As we shift to firms being more in control of their data, and with the clear gains from having an additional intelligence layer on top of that data - the need for OpenBB in the market has never been clearer.

Shifting the control back to financial firms.

More open. More adaptable.

If you want help on connecting your own backend (crypto or other) to OpenBB - reach out to myself and team.

---

---
slug: why-ai-analysts-need-human-like-workspaces-not-just-chat-interfaces
title: Why AI analysts need human-like workspaces, not just chat interfaces
date: 2024-12-20
image: /blog/2024-12-20-why-ai-analysts-need-human-like-workspaces-not-just-chat-interfaces.jpeg
tags: ['openbb', 'ai', 'analyst', 'agent', 'workspace', 'vision']
description: Why I believe AI agents need the same comprehensive workspace tools as human analysts, moving beyond simple chat interfaces to enable true financial research and analytics.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-12-20-why-ai-analysts-need-human-like-workspaces-not-just-chat-interfaces.jpeg"/>
</p>

Why I believe AI agents need the same comprehensive workspace tools as human analysts, moving beyond simple chat interfaces to enable true financial research and analytics.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This week, Insight Partners published ["The state of the AI Agents ecosystem: The tech, use cases, and economics"](https://www.insightpartners.com/ideas/state-of-the-ai-agent-ecosystem-use-cases-and-learnings-for-technology-builders-and-buyers/) which mentions OpenBB on the map in terms of Financial Services AI agents.

I'd like to explain our flavor of AI analyst.

An AI agent is defined as "a program that can interact with its environment, collect data, and use the data to perform self-determined tasks to meet predetermined goals".

If I were to describe the role of an Analyst I could use that exact same sentence, except that I wouldn't use "program" but "human".

Yet most companies and products out there are focusing on the data and forgetting about the interface.

If the job to be done by an AI agent is the same as the human agent - why aren't we starting from the assumption that they need the same tools and interface as a human analyst would.

I mean, I don't see financial analysts spending their day doing analysis & research on Slack or on a chat-only interface.

This is where we differ and where we decided to take the longer path in doing what's right.

No shortcuts.

Yes, our AI agent (or the one our users bring) has access to their own data.

But more importantly, it is interconnected with a workspace, effectively having the same type of capabilities that an analyst would so it can truly perform research and analytics.

The goal is actually straightforward:

The AI agent should be able to do anything and everything that a user can with a mouse and keyboard.

That includes:

- Extracting insights from multiple datasets
- Adding a particular widget to a dashboard
- Creating a dashboard from scratch based on data available
- Run a particular prediction model with pre-define parameters
- Collaborating on a dashboard with a colleague
- Having access to the internet to add research notes to the dashboard
- Join datasets efficiently
- Write SQL queries to extract particular data from a data warehouse
- etc...

Agree or disagree?


---

---
slug: openbb-and-our-global-reach-since-leaving-beta
title: OpenBB and our global reach since leaving beta
date: 2024-12-22
image: /blog/2024-12-22-openbb-and-our-global-reach-since-leaving-beta.jpeg
tags: ['openbb', 'global audience', 'reach', 'internationalization', 'languages', 'pwa']
description: This is how OpenBB is reaching users worldwide with Chrome's translation features, making financial analytics accessible in multiple languages and expanding our presence across 84% of countries since launch.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-12-22-openbb-and-our-global-reach-since-leaving-beta.jpeg"/>
</p>

This is how OpenBB is reaching users worldwide with Chrome's translation features, making financial analytics accessible in multiple languages and expanding our presence across 84% of countries since launch.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Since our launch on October 7th, we realized that while the majority of our audience is based in the US - we have users utilizing OpenBB from all around the globe.

In fact, if we count sign ups since October we have a 84% country representation.

Today, most of the top financial firms have reached out to OpenBB to learn more. Either because they heard about us from others, or had someone internally speaking about OpenBB.

However - it has also happened having conversation with firms that focus so much on emerging markets (e.g. LatAm) that they speak mostly Portuguese or Spanish.

So, here I am showing you that you can utilize the Google Translate feature that comes with Google Chrome in under 10 seconds to have our product being translated in real-time to your language of choice.

<p align="center">
    <img width="600" src="/blog/2024-12-22-openbb-and-our-global-reach-since-leaving-beta_1.jpeg"/>
</p>

<p align="center">
    <img width="600" src="/blog/2024-12-22-openbb-and-our-global-reach-since-leaving-beta_2.jpeg"/>
</p>

I've been playing with it in Portuguese, and it works *surprisingly* well.

This even means that you can utilize your AI copilot in your language of choice, which is mind blowing!

It's this Christmas that I will be able to convert my family to DAU. 😃


---

---
slug: ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will
title: AI chatbots won't revolutionize finance, but intelligent workspaces will
date: 2024-12-27
image: /blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will
tags: ['openbb', 'artificial intelligence', 'chatgpt', 'financial analytics', 'future of finance']
description: Beyond the AI hype - why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png"/>
</p>

Why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

When ChatGPT launched, everyone rushed to build financial chatbots. But they missed two fundamental truths:

- The best AI model is useless without access to your data.
- Access to data isn't enough - AI needs to handle complete workflows, not just conversations.

The limitations of most financial chatbots:

1. They only work on a specific dataset (e.g 10-K/10-Q)
2. They can't handle complex financial workflows
3. They force analysts to work in an unnatural chat interface

<br />

Here's how OpenBB addresses these challenges:

First, we ensure comprehensive data access:

- Run everything on-premise or in your VPC
- Connect any data source: internal files, APIs, third-party feeds, market data - anything
- Use a universal data layer that standardizes everything (whether it's CSV, Excel, Snowflake, or APIs)

But the real innovation?

We're building AI differently.

Instead of forcing analysts to chat with a bot, we're embedding intelligence directly into their workspace.

Think dashboards with widgets, not chat windows. Data visualization, not text conversations.

This is exactly what Kimberly Tan (partner @ a16z) predicted in [her analysis](https://a16z.com/big-ideas-in-tech-2025/):

> _"Chat was the first experimental interface — now I expect there will be new, novel interaction mechanisms. In this phase, AI agents will be able to take direct action in the workflow, and the UI will be reimagined for humans to review work or do QA."_

<br />

The result?

<p align="center">
    <img width="1200" src="/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png"/>
</p>

A workspace where:

- AI appears only when needed (for insights, summaries, or generating visualizations)
- Firms can adopt AI at their own pace
- Analysts keep their familiar workflows while gaining AI superpowers

Let me show you this in action.

Last week, I shared how [Matt from VanEck](https://x.com/mattmaximo1/status/1869413550210625818) built a powerful dashboard integrating multiple distinct data sources on OpenBB. Post with comments can be found [here](https://www.linkedin.com/posts/didier-lopes_today-i-saw-a-glimpse-of-the-future-matt-activity-7275174801860636672-qoy4?utm_source=share&utm_medium=member_desktop).

I only showed a screenshot of this dashboard with data.

There was no sign of AI in it.

However, if I had simply pressed shortcut "Ctrl+L", the copilot window would have opened and I would have been able to natively interact with the data - and generate new data from it.

<p align="center">
    <img width="1200" src="/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will_1.png"/>
</p>

This demonstrates that the future of financial AI isn't about chatbots - it's about intelligent workspaces.

As [Jason from PyQuantNews](https://x.com/pyquantnews) astutely observes: _"OpenBB solves the data aggregation and centralization challenge without relying on AI, creating a ton of value from it. And then, you allow users to utilize AI in their workflows as they see fit."_

This isn't just another AI product.

It's the future of financial analysis - where AI enhances your workspace instead of replacing it.


---

---
slug: building-an-ai-agent-from-scratch-that-can-post-on-bluesky
title: Building an AI agent from scratch that can post on bluesky
date: 2025-01-04
image: /blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky
tags: ['openbb', 'artificial intelligence', 'ai', 'agent', 'open source', 'ollama', 'llama', 'telegram', 'bluesky', 'xai', 'grok', 'perplexity']
description: A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.png"/>
</p>

A practical guide to building an AI agent that processes Telegram messages through a local LLM, gathers context from various sources (OpenBB, Perplexity, Grok), and automatically posts content to Bluesky.

The open source code is available [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post).

<!-- truncate -->

import CodeBlock from '@theme/CodeBlock';
import Details from '@theme/Details';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Over the Christmas break, I decided to explore the world of fine-tuning while assessing the quality of open-source models that can run locally. This exploration is particularly important for me, as we frequently discuss with prospects the possibility of integrating local AI agents into OpenBB to avoid reliance on third-party vendors.

To make this experiment practical and engaging, I needed a well-defined use case. My objective was straightforward: to develop an agent capable of focusing on a specific topic, gathering external information, and crafting a post to share on Bluesky triggered by myself.

<p align="center">
    <img width="600" src="/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky_1.jpg"/>
</p>

This is the workflow we are looking at:

1. I send a message to my Telegram bot with the idea of what I want to post on Bluesky.
2. That message gets processed by my fine-tune agent, which runs locally.
3. That message is used to extract further context either from:
	1. OpenBB if financial information is needed.
	2. xAI if latest news from social media is needed.
	3. Perplexity if more information from the web is necessary.
4. The agent then writes a thought on the topic.
5. Then it pushes that post to Bluesky.

## Getting Started

### Environment Setup

You have a Bluesky account - like mine here:  [https://bsky.app/profile/didierlopes.com](https://bsky.app/profile/didierlopes.com).

- You will need `BLUESKY_HANDLE` and `BLUESKY_PASSWORD`.

You have a Telegram account and you have created a bot by following the steps highlighted here:  [https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token](https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token).

- You will need `TELEGRAM_BOT_TOKEN`.

You have installed Ollama and are running a model like `Llama3.2:latest` locally.

Additionally, you will need the following tokens for the agent's tools:
- `OPENBB_PAT` which you can retrieve from: https://my.openbb.co/app/platform/pat
- `PERPLEXITY_API_KEY` which you can retrieve from: https://www.perplexity.ai/settings/api
- `GROK_API_KEY` which you can retrieve from: https://console.x.ai/

### Main libraries

The bot is built using several key libraries:
- **ATProto Client**: For interacting with the Bluesky social network
- **Python-Telegram-Bot**: For handling Telegram interactions
- **Asyncio**: For handling asynchronous operations
- **OpenBB**: To access financial data
- **OpenAI**: to hit Perplexity and Grok OpenAI compatible endpoints

## Implementation

For this tutorial, I'm not going to write about fine-tuning my own LLM to keep it simpler. I will leave that for another post where I want to share more on what I learned about doing so.

I'm also going through the step-by-step I performed in order to complete this project, so that this can serve as an inspiration for somebody starting something.

I have a folder called "experiments" [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/tree/main/experiments) which I use to show you how I experiment each subsystem independently and only after each individually works I merge them together. Dividing and conquering here is fundamental.

### 1. Bluesky API

I can't push a post to Bluesky if the API doesn't allow me to do so. Therefore, this is where I started.

<CodeBlock
    language="python"
    title={
        <a 
            href="https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/bluesky-api.ipynb"
            target="_blank"
            rel="noopener noreferrer"
            style={{ fontWeight: 'bold', color: '#0366d6' }}
        >
            /experiments/bluesky-api.ipynb
        </a>
    }
    showLineNumbers>
    {`from atproto import Client, client_utils
import os
from dotenv import load_dotenv

load_dotenv()

client = Client()
profile = client.login(
    os.getenv('BLUESKY_HANDLE'),
    os.getenv('BLUESKY_PASSWORD')
)
print('Welcome,', profile.display_name)

text = client_utils.TextBuilder().text('Merry Christmas!')
post = client.send_post(text)
client.like(post.uri, post.cid)
`}
</CodeBlock>

The code is extremely simple, this made me understand how easy Bluesky API is to interact with.

The only thing I added to this was to create a thread of posts if the 300 character post limit was crossed. I didn't know the limit was 300 characters, and so had to handle that situation after when merging all the pieces together since, it turns out, AI agents like to write long posts (or my prompt didn't hint at not doing so strong enough).

### 2. Telegram API

In order to push a post to Bluesky, I need to have something that triggers it.

I could have automated this process as in "at 9am every day post something on a topic", but I wanted the subject to vary and retain control over what my agent does research on.

Therefore, I chose Telegram to act as the "trigger". I have used Discord and Slack in the past, this allowed me to get familiar with interacting with a bot on Telegram.

I was actually mind-blown by how simple they made the process. More on this here: https://www.siteguarding.com/en/how-to-get-telegram-bot-api-token.

Then I tested that I could send a Telegram bot a message that I would receive on the terminal where this code was running.

<details summary="View Telegram API Code">
<CodeBlock
    language="python"
    title={
        <a 
            href="https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/telegram-api.py"
            target="_blank"
            rel="noopener noreferrer"
            style={{ fontWeight: 'bold', color: '#0366d6' }}
        >
            /experiments/telegram-api.py
        </a>
    }
    showLineNumbers>
    {`import logging
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)
import os
from dotenv import load_dotenv
import argparse

# Load token from .env file
load_dotenv()
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

if not TOKEN:
    raise ValueError("No TOKEN found in .env file")

# Initialize logger
logger = logging.getLogger(__name__)


# Move logging setup into a function
def setup_logging(verbose: bool) -> None:
    level = logging.INFO if verbose else logging.WARNING
    logging.basicConfig(
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=level
    )


async def start(update: Update, _context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    await update.message.reply_html(
        f"Hi {user.mention_html()}! "
        f"I'm a bot. Send me a message and I'll print it on the console."
    )


async def handle_message(update: Update, _context: ContextTypes.DEFAULT_TYPE) -> None:
    """Print the user message on the console."""
    message = update.message.text
    user = update.effective_user
    chat_id = update.effective_chat.id

    logger.info(
        "New message received from @%s (chat_id: %s): %s",
        user.username,
        chat_id,
        message,
    )

    print(f"Message from @{user.username}: {message}")


async def error_handler(_update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log errors caused by Updates."""
    logger.error("Exception while handling an update:", exc_info=context.error)


def main() -> None:
    # Add argument parsing
    parser = argparse.ArgumentParser()
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    args = parser.parse_args()

    # Setup logging based on verbose flag
    setup_logging(args.verbose)

    logger.info("Bot started. Waiting for messages...")

    # Create application
    app = Application.builder().token(TOKEN).build()

    # Add handlers
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Register error handler
    app.add_error_handler(error_handler)

    # Start polling
    app.run_polling(poll_interval=1.0)


if __name__ == "__main__":
    main()`}
</CodeBlock>

</details>


The only additional things I added afterwards for a better user experience were: 
- Shows processing status in text
- Provides the Bluesky post URL when complete
- Indicates if the post was threaded
- Reports any errors

### 3. Agent brain

I have used Ollama and `Llama3.2:latest` previously, and knew how easy it was to call the model. So I didn't bother spending time testing it up in advance.

<CodeBlock
    language="python"
>
    {`response = requests.post(
	"http://localhost:11434/api/generate",
	json={"model": model, "prompt": post_prompt, "stream": False},
)`}
</CodeBlock>

However, I wanted to give some form of flexibility in case someone found some interest in the project - so they could bring their own custom models.

So I put this code into a folder called `agents` and each file here has a class `LanguageModelWrapper`and works as an agent with (potential) access to tools.

The code for the `LLama3.2:latest` agent can be found here: https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/llama_3_2_ollama.py

### 4. Tools for the agent

Finally, I wanted the agent to have access to a few tools, so I created a folder within agents called `tools` where I added each of these. It can be found [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/tree/main/agents/tools).

```
agents/
    llama_3_2_ollama.py
    phi_3_mini_4k_instruct_ft_on_didier_blog.py
    ...
    tools/
        grok.py
        openbb.py
        perplexity.py
        ...
```

The implementation for how function calling is performed can be found [here]( https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/llama_3_2_ollama.py).

I didn't do anything fancy, just followed the [documentation from Meta](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2) and checked that the model would return the function in the right format.

The implementation is also very straightforward:
- Check what the topic is (that I wrote on Telegram)
- Check if it needs to do research using any of the tools provided
	- Currently can only use up to one of them
- Uses the topic I wrote on Telegram + the output from the function call to write a post

#### 4.1. OpenBB

I'm biased here, but wanted to throw OpenBB in the mix for financial information.

In this case there are 2 tools that the agent has access to:

`openbb_news_search` is used when the agent needs:
- General news articles from various sources
- Latest headlines on a specific topic

`openbb_news_on_company_search`  is used when the agent needs:
- Specific news articles about a particular company
- Latest information on a company

Here's how I tested that I could get this data easily:

<CodeBlock
    language="python"
    title={
        <a 
            href="https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_openbb.py"
            target="_blank"
            rel="noopener noreferrer"
            style={{ fontWeight: 'bold', color: '#0366d6' }}
        >
            /experiments/test_openbb.py
        </a>
    }
    showLineNumbers>
    {`import os
from openbb import obb
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Initialize the OpenBB SDK
obb.account.login(pat=os.getenv("OPENBB_PAT"))

def openbb_news_search(query):
    """Retrieve news results for a given query using OpenBB's news world endpoint."""

    # Fetch news from the world endpoint
    return obb.news.world(query=query, limit=5, provider="benzinga")

def openbb_news_on_company_search(query):
    """Retrieve news results for a given query using OpenBB's news world endpoint."""

    # Fetch news from the company news endpoint
    return obb.news.company(query=query, limit=5, provider="benzinga")


if __name__ == "__main__":
    result = openbb_news_search("technology")
    print(result)

    result = openbb_news_on_company_search("Apple")
    print(result)`}
</CodeBlock>

And the real implementation is [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/openbb.py).

#### 4.2. Perplexity

`perplexity_web_search` is used when the agent needs:
- General web information
- Detailed background information

Here's how I tested that the API worked:

<CodeBlock
    language="python"
    title={
        <a 
            href="https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_perplexity.py"
            target="_blank"
            rel="noopener noreferrer"
            style={{ fontWeight: 'bold', color: '#0366d6' }}
        >
            /experiments/test_perplexity.py
        </a>
    }
    showLineNumbers>
    {`import os
import re
from openai import OpenAI
from dotenv import load_dotenv

def perplexity_query(messages):
    client = OpenAI(
        api_key=os.getenv("PERPLEXITY_API_KEY"),
        base_url="https://api.perplexity.ai"
    )

    response = client.chat.completions.create(
        model="llama-3.1-sonar-small-128k-online",
        messages=messages,
        stream=False,
    )

    # Remove citations using regex
    content = response.choices[0].message.content
    cleaned_content = re.sub(r'\[\d+\]', '', content)
    return cleaned_content.strip()

if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()

    # Example message
    example_messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ]

    # Run the query
    result = perplexity_query(example_messages)
    print("Response:", result)
`}
</CodeBlock>

And the implementation is [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/perplexity.py).

#### 4.3. Grok

`grok_x_search` is used when the agent needs:
- Recent social media discussions
- Twitter/X specific content
- Real-time reactions and trends

Here's how I tested the API:

<CodeBlock
    language="python"
    title={
        <a 
            href="https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/experiments/test_grok.py"
            target="_blank"
            rel="noopener noreferrer"
            style={{ fontWeight: 'bold', color: '#0366d6' }}
        >
            /experiments/test_grok.py
        </a>
    }
    showLineNumbers>
    {`import os
import re
from openai import OpenAI
from dotenv import load_dotenv


def grok_x_search(query):
    """Retrieve web search results for a given query using Grok."""
    client = OpenAI(
        api_key=os.getenv("GROK_API_KEY"),
        base_url="https://api.x.ai/v1",
    )
    messages = [
        {
            "role": "system",
            "content": (
                "You are a helpful assistant with access to up-to-date information "
                "from the web. You can provide context on various topics, especially "
                "recent events and developments. Your task is to provide enough "
                "content so the user can craft an informative and engaging post "
                "based on the given query."
            ),
        },
        {"role": "user", "content": query},
    ]

    response = client.chat.completions.create(
        model="grok-beta",
        messages=messages,
        stream=False,
    )

    # Remove citations using regex
    content = response.choices[0].message.content
    cleaned_content = re.sub(r"\[\d+\]", "", content)
    return cleaned_content.strip()

if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()
    # Run the query
    result = grok_x_search("What are the latest developments in AI?")
    print("Response:", result)
`}
</CodeBlock>

And the implementation is [here](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/agents/tools/grok.py).

### 5. Put it all together

Finally, I merged it all together in [this file](https://github.com/DidierRLopes/telegram-text-to-bluesky-post/blob/main/bluesky-agent.py).

This is what the architecture looks like:

<p align="center">
    <img width="900" src="/blog/2025-01-04-building-an-ai-agent-from-scratch-that-can-post-on-bluesky.png"/>
</p>

## Conclusion

I enjoyed working on this project. It didn't take me much time to do it, and allowed me to learn:
- Utilizing Telegram API and bot convention
- Posting on Bluesky
- Playing with local models through Ollama
- Using xAI API for the first time - made extremely easy with OpenAI compatibility

The architecture I went with offers several advantages:
1. **Privacy**: Using a local LLM means sensitive data stays on your machine
2. **Customization**: The system prompt can be easily modified to change the AI's tone
3. **Reliability**: Asynchronous design prevents the bot from hanging
4. **Scalability**: The modular design makes it easy to add new tools or models

<br />

This hasn't been heavily tested - just enough for me to test that it works end-to-end.

Over the next few days I'm going to play with [Eliza from ai16z](https://github.com/elizaOS/eliza) which I learned about only after having this implemented. It looks like it has a similar concept but agents "live" natively on X.

Any feedback please let me know!


---

---
slug: tracking-my-writing-progress-through-an-open-source-blog-tracker-generator
title: Tracking my writing progress through an open source blog tracker generator
date: 2025-01-07
image: /blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator
tags: ['writing', 'productivity', 'open source', 'svg', 'visualization', 'blog', 'tracking', 'metrics']
description: Learn how I built an open-source tool that generates beautiful SVG visualizations of your blog post history, supporting both JSON and ATOM XML feeds. Perfect for keeping yourself accountable and monitoring your writing progress over time.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator.png"/>
</p>

Learn how I built an open-source tool that generates beautiful SVG visualizations of your blog post history, supporting both JSON and ATOM XML feeds. Perfect for keeping yourself accountable and monitoring your writing progress over time.

The open source code is available [here](https://github.com/DidierRLopes/blog-history-generator).

<!-- truncate -->

import CodeBlock from '@theme/CodeBlock';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

As a developer, you measure your productivity based on the ~~amount~~ quality of code you produce.

If we assume that the quality coming from an engineer remains constant (slightly improving) based on their current experience and continuously growing knowledge of the codebase, then we can assume that their productivity can be measured based on the amount of code they push into the codebase.

As the founder of OpenBB, I don't have a lot of time to code (at least not as much as I used to).

But I love programming, so I try to hop into Cursor at least once a day (every day). Sometimes I just don't have the bandwidth, but it's much easier to fall into that if you are not constantly reminding yourself that you haven't coded since x days ago.

So, in order to keep myself accountable I bought a DeskHub which sits on my desk and I use to keep track of when I am shipping.

<p align="center">
    <img width="600" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_1.jpeg"/>
</p>

I am less interested in the quality and quantity, but that every day I open Cursor and do one of the following:

- Fix a small bug or improve UI/UX on OpenBB (usually during the day)
- Add a new feature (usually during evening as more time is required)
- Write a new post on my website, like this one (evenings or weekend)
- Do a side project (weekend or holidays)

While this has been working for a while, I realized that - for me - writing is as important as coding.

It not only helps me communicate better as a leader, but also (and more importantly) think more clearly.

But I didn't have a way to track that I have been practicing writing and putting myself out there.

So, I built one.

I built a program that generates an SVG visualization of your blog post history - as long as you get your blog post history in ATOM XML or JSON feed.

And open source it <a href="https://github.com/DidierRLopes/blog-history-generator" target="_blank" rel="noopener noreferrer">here</a>.

## Blog format

<CodeBlock
    language="javascript"
    title="Common interface that all formats must conform to"
    showLineNumbers
>
{`interface Post {
  id: string;
  title: string;
  url: string;
  content_html: string;     // Falls back to 'content' in some formats
  summary: string;           // Falls back to 'excerpt' in some formats
  date_modified: string;  // Falls back to date_published/date/updated/published
  tags: string[];                // Defaults to [] if missing
}`}
</CodeBlock>

## Examples

<Tabs>
  <TabItem value="json" label="JSON" default>

Example: <a href="https://didierlopes.com/blog/feed.json" target="_blank" rel="noopener noreferrer">https://didierlopes.com/blog/feed.json</a>

<br/>

<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_2.png"/>
</p>
  </TabItem>
  <TabItem value="atom" label="ATOM XML">

Example: <a href="https://simonwillison.net/tags/datasette.atom" target="_blank" rel="noopener noreferrer">https://simonwillison.net/tags/datasette.atom</a>

<br/>

<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_3.png"/>
</p>

  </TabItem>
</Tabs>

## Quick Setup

1. Fork this <a href="https://github.com/DidierRLopes/blog-history-generator" target="_blank" rel="noopener noreferrer">repository</a>.

2. Give the repo the correct permissions.
    1. Click on Settings.
    2. Then go into Actions and click General.
    3. Scroll down and in Workflow permissions set "Read and write permissions".

<br/>
<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_4.png"/>
</p>

3. Run the workflow.
    1. Click on Actions.
    2. Click on "Generate Blog History" on the left side.
    3. On the right side click on "Run workflow".
    4. A blog feed URL will be required to run this (e.g. https://didierlopes.com/blog/feed.json or https://simonwillison.net/tags/datasette.atom).
    5. Click "Run workflow".

<br/>
<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_5.png"/>
</p>  

That's it.

The SVG will be available here: [./output/blog-history.svg](https://github.com/DidierRLopes/blog-history-generator/blob/main/output/blog-history.svg).

<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_6.png"/>
</p>

## More customization

If you want further customization, you need to:

1. Clone this repository.

2. Install dependencies.

```
npm install
```

3. Run script.

```
npm run generate
```

## Interactive

If for some reason you want this widget to be interactive, you can check [this](https://github.com/DidierRLopes/my-website/blob/main/src/components/BlogHistory.tsx) which is the one I used to integrate into [my homepage](/).

<p align="center">
    <img width="900" src="/blog/2025-01-07-tracking-my-writing-progress-through-an-open-source-blog-tracker-generator_7.png"/>
</p>

---

---
slug: the-cost-of-building-software-is-plummeting-to-zero
title: The cost of building software is plummeting to zero
date: 2025-01-09
image: /blog/2025-01-09-the-cost-of-building-software-is-plummeting-to-zero
tags: ['ai', 'software development', 'fintech', 'data infrastructure', 'open source', 'snowflake', 'openbb', 'portfolio optimization']
description: AI is revolutionizing software development costs and shifting value creation in the financial industry. I talk about the growing importance of data infrastructure, the rise of customizable solutions, and how OpenBB Workspace enables firms to build specialized AI-powered financial tools.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-09-the-cost-of-building-software-is-plummeting-to-zero.png" />
</p>

AI is revolutionizing software development costs and shifting value creation in the financial industry. I talk about the growing importance of data infrastructure, the rise of customizable solutions, and how OpenBB Workspace enables firms to build specialized AI-powered financial tools.

<!-- truncate -->

The cost of building software is plummeting to zero—and it's happening faster than anyone predicted.

AI isn't just transforming software development; it's completely rewriting the rules of the game. What once took months and millions now takes days and thousands.

But here's the critical insight: this seismic shift is redistributing where value is created.

Traditional desktop financial applications? They're becoming commodities. The real value is migrating rapidly to the data layer, the foundation beneath the application.

Look at Snowflake's meteoric rise in financial services. It's not just adoption; it's a fundamental restructuring of how the industry manages and leverages data.

So how do you build lasting value in this new landscape?

The answer is threefold:

1. Provide flexible, customizable infrastructure
2. Embrace open-source and on-premise deployment
3. Enable seamless integration of proprietary datasets

<br />

But 2025 brings an even more transformative opportunity: AI agents that can be built on top of these applications, creating hyper-specialized workflows that adapt to each user's needs.

While we're still under wraps about some of our client work, here's a concrete example: During the holiday break, our Director of Engineering showcased the future of portfolio management.

Using OpenBB Workspace, he built a sophisticated portfolio optimization system that:

- Integrates his proprietary (and sensitive) portfolio data
- Leverages a custom AI agent for risk analysis
- Automatically rebalances his portfolio based on complex criteria

This isn't just a tool - it's a glimpse into how OpenBB Workspace can transform entire departments within investment firms.

This 6-minute demo of OpenBB Workspace is one of the most compelling I’ve seen.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/K80ayaZYyk4?si=IA9sNtq2figh1k5m"
        width="800"
        height="400"
    />
</div>

<br />

The future of financial software is here.


---

---
slug: theres-a-zero-percent-chance-that-open-source-doesnt-win
title: There's a zero percent chance that open source doesn't win
date: 2025-01-16
image: /blog/2025-01-16-theres-a-zero-percent-chance-that-open-source-doesnt-win
tags: ['open-source', 'ai', 'software-development', 'future-of-tech', 'democratization', 'startup', 'innovation']
description: AI is democratizing software development at an unprecedented pace, and it's creating a virtuous cycle that makes open source unstoppable. As development costs plummet and AI tools make codebases more accessible than ever, the traditional moats of proprietary software are evaporating. Here's why I believe that the future of software is inevitably open.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-16-theres-a-zero-percent-chance-that-open-source-doesnt-win.png"/>
</p>

AI is transforming software development at a groundbreaking pace, creating a reinforcing cycle that makes open source unstoppable.

As development costs plummet and AI tools make codebases more accessible than ever, the traditional moats of proprietary software are evaporating.

Here's why I believe that the future of software is inevitably open.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

The pendulum of software development has swung between open and closed source for decades. While closed source has dominated many sectors due to massive capital investments by tech giants, we're approaching an inflection point where open source's victory seems not just possible, but unavoidable.

The traditional moat of proprietary software companies – their secret sauce of complex codebases built over years with massive engineering teams – is rapidly eroding.

AI tools are democratizing software development to an unprecedented degree (I recently wrote a small post about this <a href="https://didierlopes.com/blog/the-cost-of-building-software-is-plummeting-to-zero/" target="_blank" rel="noopener noreferrer">here</a>). A small team can now accomplish what previously required hundreds of engineers, dramatically reducing the cost and complexity of building sophisticated software systems.

What's particularly interesting is how AI itself has been trained on vast repositories of open-source code. This creates a virtuous cycle: more open-source code leads to better AI models, which in turn simplifies contributions and enhances collaborative projects. The barriers to entry for meaningful code contributions have never been lower.

<p align="center">
    <img width="600" src="/blog/2025-01-16-theres-a-zero-percent-chance-that-open-source-doesnt-win.png"/>
</p>

## The economic equation is shifting

Historically, companies might have chosen closed-source solutions because the cost of customizing open-source alternatives was prohibitively high. You needed specialized engineers who understood the codebase intimately, and modifications often required significant time and resources. This equation is evolving swiftly.
Modern AI tools can:

- Analyze and explain complex codebases in seconds
- Suggest modifications and optimizations
- Generate custom implementations based on specific requirements
- Debug and troubleshoot issues perfectly

This means companies can now take battle-tested open-source solutions and adapt them to their specific needs at a fraction of the traditional cost. The economic advantage of closed-source solutions is diminishing daily.

## The network effect accelerates

What makes this transformation particularly powerful is its self-reinforcing nature. Every company that chooses open source over proprietary solutions adds to the collective knowledge base. Each contribution, no matter how small, becomes part of the foundation that AI models learn from, making the next implementation easier and more robust.

As AI tools get better at understanding and manipulating code, the advantages of open source multiply:

- Faster innovation cycles
- More diverse contributions from global developers
- Better security through transparent code review
- Reduced dependency on single vendors
- Lower total cost of ownership

## The path forward

We're entering an era where the question isn't whether open source will win, but how long until it does.

Companies that embrace this reality early will have a significant advantage. They'll benefit from:

- Reduced development costs
	- Larger pool of talent
	- Benefit from AI models being trained on this data
- Greater flexibility in customization
- Enhanced ability to attract talent who prefer working with open technologies
- Future-proofed technology stacks that can evolve with community innovations

The momentum behind open source is becoming inescapable. As AI continues to lower the barriers to entry and make code more accessible, the advantages of closed-source systems will continue to erode. The future is open, and it's approaching faster than many realize.

I mean, I can now literally run a 7b Mistral AI model on my machine, fine-tune it, and run it locally. From a technological perspective, this is the best time there ever was to build software.

If you agree with this statement, why are you not building accordingly?


---

---
slug: turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm
title: Turn my blog feed into a QA dataset to fine-tune a LLM
date: 2025-01-21
image: /blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm
tags: ['artificial intelligence', 'machine learning', 'llm', 'dataset', 'hugging face', 'ollama', 'llama', 'fine-tuning', 'qa', 'blog']
description: This project converts blog feed content into a structured Question-Answer dataset using LLaMA 3.2 (via Ollama) for local processing. The generated dataset follows a conversational format and can be automatically pushed to Hugging Face.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm.png"/>
</p>

This project converts blog feed content into a structured Question-Answer dataset using LLaMA 3.2 (via Ollama) for local processing. The generated dataset follows a conversational format and can be automatically pushed to Hugging Face.

The open source code is available [here](https://github.com/DidierRLopes/turn-blog-feed-into-qa-dataset).

<!-- truncate -->

import CodeBlock from '@theme/CodeBlock';
import Details from '@theme/Details';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I was looking to fine-tune an open source LLM with content that I have produced in the past to see how advanced such LLMs were and how close I could get a model running locally to "output tokens" the same way I would.

According to Daniel Kahneman and his book <a href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555" target="_blank" rel="noopener noreferrer">Thinking, Fast and Slow</a>, humans have two modes of thought:

- **System 1**: Fast, instinctive and emotional. An example of this are my <a href="https://x.com/didier_lopes" target="_blank" rel="noopener noreferrer">posts on X</a>.

There are multiple libraries out there to scrape data from X. One that I used recently, and liked (without requiring an X API key) was <a href="https://github.com/elizaOS/twitter-scraper-finetune" target="_blank" rel="noopener noreferrer">Twitter scraper finetune from ElizaOS</a>.

- **System 2**: Slower, more deliberative and more logic. An example of this is my blog, where some of these posts take me several hours to write and need to sleep on the topic before pushing.

For this, I didn't find any good out-of-the-box library that allowed me to convert my posts into a QA dataset to fine-tune a model.

So this is what I ended up building.

## Getting Started

In order to do this you will need:

- Python 3.11
- Poetry (for python dependencies)
- Ollama (to run Llama 3.2)
- Hugging Face account (for dataset upload)

and obviously your blog in a JSON feed like <a href="https://didierlopes.com/blog/feed.json" target="_blank" rel="noopener noreferrer">https://didierlopes.com/blog/feed.json</a>.

#### 1. Install dependencies

<CodeBlock language="bash">
{`poetry install
poetry run python -m spacy download en_core_web_sm`}
</CodeBlock>

#### 2. Install Ollama and pull Llama 3.2

Follow instructions to install Ollama: https://ollama.com/

Select a model to run locally using https://ollama.com/search.

In this case, we want to run `llama3.2:latest` (https://ollama.com/library/llama3.2).

<CodeBlock language="bash">
{`ollama pull llama3.2:latest`}
</CodeBlock>

<p align="center">
    <img width="900" src="/blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm_1.png"/>
</p>

Then, we can check that the model has been downloaded with:

<CodeBlock language="bash">
{`ollama list`}
</CodeBlock>

<p align="center">
    <img width="900" src="/blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm_2.png"/>
</p>

Finally, we can test that it works with:

<CodeBlock language="bash">
{`ollama run llama3.2:latest`}
</CodeBlock>

<p align="center">
    <img width="900" src="/blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm_3.png"/>
</p>

#### 3. Configure Hugging Face

- Create a write-enabled token at [Hugging Face](https://huggingface.co/docs/hub/en/security-tokens)

- Create a `.env` file:

<CodeBlock language="bash">
{`HF_TOKEN=your_token_here`}
</CodeBlock>

## Usage

**1. Update the blog feed URL in <a href="https://github.com/DidierRLopes/turn-blog-feed-into-qa-dataset/blob/main/turn-blog-feed-into-qa-dataset.ipynb" target="_blank" rel="noopener noreferrer">this notebook</a>.**

Below you can see the feed structure being used - which is the default coming from <a href="https://docusaurus.io/docs/blog" target="_blank" rel="noopener noreferrer">Docusaurus</a>, which is the framework I'm using to auto-generate the feed for my personal blog.

<CodeBlock language="python">
{`url = "https://didierlopes.com/blog/feed.json"`}
</CodeBlock>

<details summary="JSON Feed Structure">

<CodeBlock language="json">
{`{
  "version": "https://jsonfeed.org/version/1",
  "title": "Didier Lopes Blog", 
  "home_page_url": "https://didierlopes.com/blog",
  "description": "Didier Lopes Blog",
  "items": [
    {
      "id": "URL of the post",
      "content_html": "HTML content of the post", 
      "url": "URL of the post",
      "title": "Title of the post",
      "summary": "Brief summary of the post",
      "date_modified": "ISO 8601 date format",
      "tags": [
        "array",
        "of", 
        "tags"
      ]
    },
    // ... more items
  ]
}`}
</CodeBlock>

</details>

<br />

**2. Set your Hugging Face dataset repository name:**

<CodeBlock language="python">
{`dataset_repo = "didierlopes/my-blog-qa-dataset"`}
</CodeBlock>

This is what the dataset will look like in HuggingFace: https://huggingface.co/datasets/didierlopes/my-blog-qa-dataset/viewer.

<p align="center">
    <img width="900" src="/blog/2025-01-21-turn-my-blog-feed-into-a-qa-dataset-to-fine-tune-a-llm_4.png"/>
</p>

<br />

**3. Run the notebook cells sequentially.**

The notebook contains detailed explanations throughout to guide you through the process step-by-step.

## Dataset Format

The generated dataset includes:

- `title`: Blog post title
- `conversation`: Array of Q&A pairs in role-based format
- `context`: Original cleaned blog content
- `url`: Source blog post URL
- `date`: Publication date

Note: This is the format of the conversation field:

<CodeBlock language="python">
{`conversation = [
    {
        "role": "user", 
        "content": (
            "You mentioned that when ChatGPT launched, everyone rushed to build "
            "financial chatbots. What were some of the fundamental truths that "
            "those who built these chatbots missed?"
        )
    },
    {
        "role": "assistant",
        "content": (
            "Those building financial chatbots missed two fundamental truths:"
            "1. AI models are useless without access to your data."
            "2. Access to data isn't enough - AI needs to handle complete "
            "workflows, not just conversations."
            "These limitations led to chatbots that can't access proprietary "
            "data, can't handle complex workflows and restrict analysts to an"
            "unnatural chat interface."
        )
    },
    # ... more Q&A pairs following the same pattern
]`}
</CodeBlock>

## Summary of how it works

1. Fetches blog content from JSON feed
2. Cleans HTML to markdown format
3. Analyzes sentence count to determine Q&A pair quantity
4. Generates contextual questions using LLaMA 3.2 running locally
5. Creates corresponding answers
6. Filters and removes duplicate Q&A pairs
7. Formats data for Hugging Face
8. Pushes to Hugging Face Hub


---

---
slug: building-a-developer-friendly-interface-for-financial-analysts
title: Building a developer friendly interface for financial analysts
date: 2025-01-24
image: /blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts
tags: ['openbb', 'plg', 'pls', 'open-source', 'fintech', 'ux', 'sales', 'startup']
description: In the financial software industry, there's a well-worn playbook - build proprietary software, deploy large sales teams, and leverage executive relationships. At OpenBB, we're taking a fundamentally different approach - creating open-source financial tools that users genuinely love to use.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts.png"/>
</p>

It's an open, AI-native application that unifies data, streamlines workflows, and delivers enterprise-grade collaboration and control for teams of all sizes

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

**What is the OpenBB Workspace, and how is it reimagining financial analysis?**

Our workspace represents a paradigm shift in financial analysis - a unified platform that combines enterprise-grade power with an interface users love. We've created an ecosystem that doesn't just solve today's challenges in data integration and analysis - it anticipates tomorrow's needs.

### Collaborative

<p align="center">
    <img width="600" src="/blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts_1.png"/>
</p>

The OpenBB workspace combines three essential pillars that transform how teams work with financial data:

- **Empowering analysts**: Break free from technical constraints - analysts can create sophisticated workflows and dynamic dashboards with an intuitive interface, accelerating time-to-insight without writing a single line of code.

- **Unmatched security and control**: Enterprise-grade security meets operational flexibility with on-premises deployment options, granular access controls, and complete audit trails that satisfy the most stringent compliance requirements.

- **Truly collaborative platform**: Transform siloed analysis into synchronized teamwork with real-time collaboration features that enable instant sharing, live co-editing, and seamless knowledge transfer across teams.


### Unified data integration

<p align="center">
    <img width="600" src="/blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts_2.png"/>
</p>

Our open source data integration framework (<a href="https://github.com/OpenBB-finance/backend-for-terminal-pro" target="_blank" rel="noopener noreferrer">open source repository here</a>) supports:

- **Open ecosystem for developers**: Drive innovation with our MIT-licensed framework - developers can rapidly build and deploy custom widgets that seamlessly integrate any data source, from proprietary feeds to public datasets.

- **Data agnostic**: No data left behind - our platform effortlessly handles any financial data type, from traditional equities to crypto assets, adapting to your evolving analytical needs.

- **Built for scale**: Enterprise-ready architecture that scales with your ambition - analyze thousands of datasets simultaneously, build complex dashboards, and leverage AI seamlessly.


### AI-powered intelligence

A single interface that transforms complex financial analysis into an intuitive, powerful experience.

<p align="center">
    <img width="600" src="/blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts_3.png"/>
</p>

Our open agentic framework (<a href="https://github.com/OpenBB-finance/copilot-for-openbb" target="_blank" rel="noopener noreferrer">open source repository here</a>) delivers intelligent capabilities through three key pillars:

- **Integrated  intelligence**: Experience seamless AI augmentation that enhances rather than disrupts - AI agents work invisibly alongside your team, amplifying capabilities while maintaining absolute data privacy and security.

- **Tailored and secure**: Purpose-built AI systems that understand the nuances of financial data - delivering precise, context-aware insights while maintaining security standards and complete control over your data.

- **Transparent and actionable**: AI you can trust and verify - every insight comes with clear reasoning and sourcing, automatically integrated into your dashboards for immediate action and impact.

## Unified Workspace

<p align="center">
    <img width="900" src="/blog/2025-01-24-building-a-developer-friendly-interface-for-financial-analysts.png"/>
</p>

We have organically grown our user base to nearly 80,000 through strategic partnerships and an unwavering commitment to user experience.

We're not just building software – we're pioneering a future where financial tools are:

- Loved by users for their intuitive design and powerful capabilities
- Trusted by organizations for enterprise-grade security and control
- Designed for seamless, real-world collaboration at any scale

<p align="center">
  <a href="https://www.producthunt.com/golden-kitty-awards/finance-tech-2" target="_blank">
    <img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=491158&theme=dark" 
         alt="OpenBB&#0032;Terminal&#0032;2&#0046;0 - Open&#0032;source&#0032;investment&#0032;research&#0032;platform | Product Hunt" 
         style={{width: '250px', height: '54px'}}/>
  </a>
</p>

If you read this far, we'd appreciate your vote in the [Finance Tech category of the Golden Kitty Awards on Product Hunt](https://www.producthunt.com/golden-kitty-awards/finance-tech-2).

Thank you.


---

---
slug: what-it-means-to-have-skin-in-the-game
title: What it means to have skin in the game
date: 2025-01-30
image: /blog/2025-01-30-what-it-means-to-have-skin-in-the-game
tags: ['openbb', 'leadership', 'accountability', 'commitment', 'startup']
description: From getting the OpenBB logo tattooed to honoring a promise of a Bali trip, this is a personal reflection on what it truly means to have "skin in the game". It's not about reckless commitment, but about standing fully behind your words and actions - a principle that's shaped both my personal life and my approach to building OpenBB.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-01-30-what-it-means-to-have-skin-in-the-game.png"/>
</p>

From getting the OpenBB logo tattooed to honoring a promise of a Bali trip, this is a personal reflection on what it truly means to have "skin in the game". It's not about reckless commitment, but about standing fully behind your words and actions - a principle that's shaped both my personal life and my approach to building OpenBB.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I just finished reading Nassim Taleb's "Skin in the Game," and it hit home in a big way. (PS: you can find more books that I've read over the years <a href="/books/already-read" target="_blank" rel="noopener noreferrer">here</a>).

<p align="center">
    <img width="600" src="/blog/2025-01-30-what-it-means-to-have-skin-in-the-game_1.png"/>
</p>

The idea of having real stakes in your decisions isn’t new to me – it’s something I’ve lived by for as long as I can remember. Taleb’s writing puts it into words beautifully, but for me, this has always been a way of life.

I believe in going all-in on what matters. In fact, I’m so committed to this philosophy that I have OpenBB logo tattooed on my body.

<p align="center">
    <img width="600" src="/blog/2025-01-30-what-it-means-to-have-skin-in-the-game.png"/>
</p>

It’s not about showing off or trying to prove something. It’s a reminder that when I’m in, I’m all the way in. No half measures, no excuses. This isn’t about taking wild risks for the sake of it – it’s about standing behind what you believe in, fully and without hesitation.

This mindset started when I was young, mostly from my dad.

I learned that our word has to mean something. Promises weren’t just things I would say, they were real commitments that I always followed through.

I remember when we were kids I told one of my friends jokingly "if you do x, I will give you 2 euros" and he did it and we laughed. The day after I brought him 2 euros to school and he had forgotten about it.

More recently, I promised my friends that if the open source project I had started (Gamestonk Terminal) ever became a company, I'd cover a two-week stay accommodation in Bali. When <a href="https://openbb.co/blog/gme-didnt-take-me-to-the-moon-but-gamestonk-terminal-did" target="_blank" rel="noopener noreferrer">OpenBB raised money</a>, I let them know and we booked that trip for the following year.

<p align="center">
    <img width="600" src="/blog/2025-01-30-what-it-means-to-have-skin-in-the-game_2.JPG"/>
</p>

That wasn’t just talk. It was a real promise, tied to real accountability.

The way I see it, taking risks and owning the results – good or bad – is what separates people who truly stand for something from those who just talk about it. When you’re all in, you can’t hide. If things go wrong, you take the hit. If they go right, you’ve earned it. Either way, you’re accountable.

This idea of skin in the game just makes so much sense to me, why wouldn't you?

It’s about showing up fully in everything you do, whether it’s work, relationships, or personal goals. And it’s about being honest with yourself and others when things don’t go as planned.

Trust is built by following through, especially when it’s hard. When people know you’ll keep your word, even when it’s inconvenient, you build something way more valuable than a quick win: you build real trust. And that trust isn’t just given; it’s earned through consistency and integrity.

These days, it feels like too many people are afraid to commit. They hedge their bets, avoid risks, and try to keep their options open. But I’ve found that being all-in – really having skin in the game – is the best way to live life.

You can also see this by the fact that I am pretty much an open book - either sharing what I'm thinking through blogs like this or sharing all my code on GitHub.

For the better, or the worst.


---

---
slug: 2025-02-18-long-live-long-context-with-gemini
title: Long live long context with Gemini
date: 2025-02-18
image: /blog/2025-02-18-long-live-long-context-with-gemini
tags: ['long context window', 'gemini', 'streamlit', 'rag', 'pdf parsing', 'analyst']
description: A practical exploration of using Gemini's long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-02-18-long-live-long-context-with-gemini.png" />
</p>

A practical exploration of using Gemini's long context window capabilities to analyze multi-page documents, featuring a Streamlit app for testing and iterating prompts.

Learn how to move beyond traditional RAG approaches for document analysis and leverage the power of large context windows for more accurate information retrieval.

The open source code is available [here](https://github.com/DidierRLopes/long-live-long-context).

<!-- truncate -->

import CodeBlock from '@theme/CodeBlock';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Introduction

Last week, a friend of mine was mentioning an interesting challenge that they had. They had to handle multiple documents with over 200-300 pages each with text, tables and images. Their current process of doing this with RAG wasn't leading to the best results and it was very time consuming when analyzing the results. But also there wasn't a systematic approach being taken to improve the prompt for data retrieval (e.g. few-shot prompt).

Given that I had been reading about people saying that "RAG is dead" because of Gemini models havign 1M+ input context, I wanted to test this model myself. At the same time I wanted to help my friend in setting up a pipeline that would help them automating their data retrieval pipeline.

This post is going to focus on the approach I took, why and how you can set it up yourself.

Note: This isn't meant to be a production ready pipeline, but enable you to "vibe test" your ingestion pipeline + data retrieval model + prompts. Funnily enough, this was mostly built in a day through _vibe coding_ (Karpathy's coined the term recently).

<p align="center">
    <img width="600" src="/blog/2025-02-18-long-live-long-context-with-gemini_1.png" />
    <p align="center" className="mt-1" style={{fontSize: "0.75em"}}>
        <a href="https://x.com/karpathy/status/1886192184808149383" target="_blank" rel="noopener noreferrer">Karpathy tweet</a>
    </p>
</p>

## Starting point

This is what my friend sent me:

- Complex PDFs with 200 pages comprised of text, images and tables
- An Excel spreadsheet with rows corresponding to values that were being attempted to retrieve and columns including prompt, value returned and correct value.

The Excel spreadsheet effectively served as eval, which enabled them to understand whether a better model/pipeline would lead to better results or not. However, this process was very manual.

The equivalent here is the following:

- I will be using the following documents: [DeepSeek_R1 paper](https://github.com/DidierRLopes/long-live-long-context/blob/main/DeepSeek_R1.pdf) and [Capital Market Outlook report](https://github.com/DidierRLopes/long-live-long-context/blob/main/ME-cio-weekly-letter.pdf). I just had these two at hand to serve as an example.

- I won't be using an Excel spreadsheet, but instead will rely on files in a directory called `data` within the project.

Here are the prompts that I'm going to test:

| idx | ID | Prompt | Expected Result |
| --- | --- | --- | --- |
| 0 | Consumer Discretionary vs Consumer Staples comparison cap-weighted | By how much did Consumer Discretionary outperform Consumer Staples over the last three months on cap-weighted? | +17% |
| 1 | Consumer Discretionary vs Consumer Staples comparison equal-weighted | By how much did Consumer Discretionary outperform Consumer Staples over the last three months on equal-weighted? | +13% |
| 2 | Fed funds rate Q4 2024E | What is the Fed funds rate, end period (%) for Q4 2024E? | 4.38 |
| 3 | DeepSeek-R1-Zero GPQA Diamond pass@1 | What was DeepSeek-R1-Zero GPQA Diamond pass@1 benchmark? | 73.3 |
| 4 | DeepSeek V3 C-SimpleQA | What was DeepSeek V3 C-SimpleQA bemchmark? | 68.0% |
| 5 | Number of reasoning related training samples | How many reasoning related training samples were collected? | 600k |

Note: Prompts 0-2 can be found in Capital Market Outlook report whilst prompts 3-5 in DeepSeek R1 paper.

## Setting up this experiment

### Architecture

Create a folder called data with the following structure: 

```bash
data/
├── system_prompt.txt
├── 0/
│   ├── id.txt
│   ├── prompt.txt
│   └── expected.txt
└── 1/
    ├── id.txt
    ├── prompt.txt
    └── expected.txt
```

See our example [here](https://github.com/DidierRLopes/long-live-long-context/tree/main/data).

Let's go through each of these:

### System prompt

Contains the system prompt to be used throughout entire application in a `system_prompt.txt` file.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_2.png" />
</p>

### Prompt

Each prompt will have a folder with the idx in the order of it being run - e.g. 0, 1, 2, ...

Inside this folder you will find 3 files: `id.txt`, `prompt.txt` and `expected.txt`. Note that this follows the table that we displayed above.

#### ID

Contains an identifier that we can use to understand what prompt that is. This can be a slug of the prompt, a KPI number or anything else. It doesn't affect anything apart from helping user to be able to distinguish more easily between prompts at a higher level.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_3.png" />
</p>

#### Prompt

Contains the actual prompt to run through all the documents that have been loaded.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_4.png" />
</p>

#### Expected

Contains the expected value or information to be retrieved.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_5.png" />
</p>

## Running the Streamlit app

Clone [this repository](https://github.com/DidierRLopes/long-live-long-context).

Install the following libraries with `pip install <library>`:

```bash
streamlit
google-generativeai
PyMuPDF
pytesseract
pdf2image
Pillow
```

or simply do `pip install -r requirements.txt`.

Retrieve a Gemini API key from [here](https://ai.google.dev/gemini-api/docs/api-key).

And finally run `streamlit run app.py`.

Note: This application has 500 lines of code and all the logic lives in [app.py](https://github.com/DidierRLopes/long-live-long-context/blob/main/app.py).

## How the app works

### 1. Gemini API key

Since the purpose of this is to test Gemini 2.0 Flash model, then we are asking for the API key to be inserted at the top of the script. It could also have been done through `.env` variable which in general is a better alternative, but I wanted to make this more easier on the people who will run this script.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_6.png" />
</p>

### 2. System Prompt

This is the system prompt that will be used across all prompts utilized to retrieve data from context.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_7.png" />
</p>

The EDIT button allows user to modify the content that lives in [`data/system_prompt.txt`](https://github.com/DidierRLopes/long-live-long-context/blob/main/data/system_prompt.txt) and override it.

### 3. Load documents

This allows the user to pick any document that are next to the `app.py` file on the root of the project. You can select multiple documents and their content will be appended together.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_8.png" />
</p>

When a document is loaded, you will be able to understand how many tokens each document utilizes when being pushed into Gemini 2.0 flash - through `model.count_tokens()`. In addition, you will understand how many tokens are being utilized with the combination of all documents uploaded.

### 4. Run prompts

This one is slightly more complex, let's take it each section at a time.

<p align="center">
    <img width="1200" src="/blog/2025-02-18-long-live-long-context-with-gemini_9.png" />
</p>

#### Run all prompts

By clicking on "▶️▶️▶️ Run all prompts", all prompts get run utilizing Gemini 2.0 Flash with the context provided, in the following format:

<CodeBlock language="python">
{`response = model.generate_content(
    f"""
    {system_prompt}
    ---
    {st.session_state.document_content}
    ---
    {prompt}
    """,
    generation_config={"temperature": 0},
)
`}
</CodeBlock>

The "Free Gemini tier (adds timer if running all prompts)" toggle is meant for users that aren't paying for Google API and adds a 60s delay after running each prompt. Note: Upgrading to a paid API key is recommended if you are dealing with sensitive data, so that your data is not used by Google for training.

Remember: "If something is free, you are the product" 🙂.

Now you may be wondering:

> _"Why is there a green '✅ Response matches expected result' box. How does the model know that the answer is accurate?"_.

<br />

That is because after running the prompt, I take the output and use Gemini 2.0 Flash to compare it against the compared answer. Basically doing LLM as a judge so I have a quick sense of how many prompts I got correct and which ones I didn't and work on the failed ones.

This is the prompt that happens under the hood:

<CodeBlock language="python">
{`comparison_response = model.generate_content(
    f"""
    Compare these two texts and return only 'True' if they convey the same meaning,
    or 'False' if they differ in meaning.
    Don't worry about units as long as the numerical value are the same.

    Do not add anything else. Just one word: 'True' or 'False'.
    
    Expected:
    {expected}
    
    Actual:
    {response.text}

    The meaning of the expected response and the actual response is the same. This statement is: 
    """,
    generation_config={
        "temperature": 0,
        "candidate_count": 1
    },
)
`}
</CodeBlock>

#### Individual prompts

The concept of running an individual prompt is very similar to the run all prompts, with the exception that it takes approximately "Run all prompts time"/"Number of all prompts" for each. So it's better to iterate on a single prompt and the quality of its data retrieval.

In addition, it has a few additional features that can be helpful to iterate:

- You can click on "EDIT" to edit the `prompt.txt` directly from the interface. This enables to tweak the prompt to be better at retrieving that specific information (e.g. few shot prompt, which is something that my friend wasn't doing and was contributing to lower accuracy).
- You can click on "EDIT" to edit the `expected.txt` directly from the interface. This was particularly relevant when I saw that the LLM as a judge failed when the model retrieved 68.0% for a particular prompt and the expected string I had was 68.0. In this case, the model was actually accurate and my expected value should have been either 68.0% or 0.68.

## Final thoughts

### Data ingestion

This is one of the most important parts of the workflow:

<CodeBlock language="python">
{`# Convert PDF to images
images = convert_from_path(tmp_path, dpi=300)  # can be increased for higher accuracy

# Open PDF with fitz
pdf_document = fitz.open(tmp_path)

file_content = ""

# Process each page
for page_number in range(len(pdf_document)):
    page = pdf_document.load_page(page_number)
    if page.get_drawings():  # OCR needed for vector content
        text = pytesseract.image_to_string(
            images[page_number], lang="eng"
        )
    else:  # Extract text directly
        text = page.get_text("text")
    file_content += text + "\\n"

pdf_document.close()
`}
</CodeBlock>

From my friend results, I saw that it was consistently failing for a few prompts. The main reason for that was because the data was in a table that was an image underneat and the PDF reader didn't parse images. That meant that it didn't matter how good the prompt was, the model was set up for failure.

I don't think the pipeline I've built is particularly strong but it highlights an example of how one can handle a scenario with text, tables and images going through each page individually by:

- Check if there is an image
    - If there is, do OCR using Tesseract to extract text
    - If there isn't, use PyMuPDF to extract text

I believe that something that would improve results immediately is running the output of the OCR by a LLM and trying to reconstruct the table/image in markdown format if possible. I say this because I noticed that sometimes the OCR output can be a bit messy, and having an LLM focused on adding structure to each page OCR may lead to better outcomes.


### Long context is a blessing

Something I noticed from the data my friend shared is that the RAG pipeline they had implemented struggled when the value that the model had to return wasn't immediate but it had to pick values from different places to piece it together.

Imagine you were asking the model about the number of reasoning related training samples and the PDF mentioned that the number of reasoning related training samples was 2% of the training dataset samples. And in another page it said that the training dataset has 30 million samples. You need to get both of these in order to infer that the number of reasoning related training samples is 600k samples.

### Subject matter experts are more relevant than ever

Despite advances in LLM capabilities, domain expertise remains crucial for effective prompt engineering. During testing, many retrieval failures stemmed not from model limitations, but from prompts that didn't properly account for domain-specific context and terminology.

As a non-expert, I found it challenging to craft effective prompts because I lacked deep understanding of:

- How specific data points are typically represented in this type of document
- The precise meaning and significance of domain terminology
- Common document structures and conventions in the field
- How small variations in wording could make it so that the metric extracted wasn't the correct one

### Set a benchmark and work reverse from there

Before starting this work I had a benchmark where I was working backwards from. This was super helpful as it allows me to understand how this workflow, out-of-the-box, compares with my friends' one.

Then we can work backwards from there and:

- Improve the system prompt
- Use a different model (and get rid of RAG eheh)
- Improve ingestion pipeline to process images
- Automate process a bit better with a Streamlit app
- Improve each individual prompt to retrieve information more accurately (few-shot prompt)

### Prompt testing and validation

Using LLMs as judges and being able to run prompts from the app, enabled to have a much more seamless workflow. This approach:

- Provides immediate feedback on prompt effectiveness
- Helps iterate and refine prompting strategies
- Ensures consistency in information extraction
- Reduces the need for manual verification

## Long live Long Context

Honestly, long context is f*ing awesome.

Here are a few things that made me really happy:

- Ability to handle multiple documents at once without having to worry about chunking or managing context windows
- No need to worry about losing context between different sections of a document
- Reduced complexity in the overall pipeline since we don't need complex RAG infrastructure
- Better accuracy (in theory) since the model has access to the full context and can make connections across different parts of the document
- Faster development time since we don't need to spend time optimizing chunking strategies or fine-tuning retrieval mechanisms

## Next

I won't be spending more time on this project, as I did it to help a friend on their specific problem. I wrote this post so that I could share this with them and any other person in the future that is getting into LLMs.

Feel free to fork the project and go wild.


---

---
slug: ui-layer-is-the-next-big-frontier
title: UI layer is the next big frontier
date: 2025-02-25
image: /blog/2025-02-25-ui-layer-is-the-next-big-frontier
tags: ['openbb', 'fintech', 'ui', 'innovation', 'financial-software']
description: A deep dive into why the UI layer represents the next major frontier in financial technology. While the industry has heavily invested in data, the user interface remains a critical yet overlooked bridge between raw information and actionable intelligence. This piece explores how OpenBB is leading the charge in revolutionizing how financial professionals interact with data.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-02-25-ui-layer-is-the-next-big-frontier.png" />
</p>

A deep dive into why the UI layer represents the next major frontier in financial technology.

While the industry has heavily invested in data, the user interface remains a critical yet overlooked bridge between raw information and actionable intelligence. This piece explores how OpenBB is leading the charge in revolutionizing how financial professionals interact with data.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

> ***Note**: This post was written after reading the <a href="https://open.substack.com/pub/theterminalist/p/10000x-bloombergs-return-and-why" target="_blank" rel="noopener noreferrer">10,000x. Bloomberg's return and why financial data is so darn lucrative</a> from the <a href="https://x.com/TheTerminalist" target="_blank" rel="noopener noreferrer">TheTerminalist</a>.*

<br />

For decades, financial research and analytics have been locked in complex, fragmented workflows.

Firms rely on an ever-expanding set of data providers, yet the tools they use to extract value from that data remain clunky and disconnected. The market has seen heavy investment in solving the data layer, but little attention has been paid to the UI layer—the critical bridge between raw data and actionable intelligence.

**Why?**

Because building intuitive financial UIs requires a rare combination of deep market knowledge and modern technical expertise.

Most financial professionals excel at understanding markets but aren't software engineers, while most software engineers don't have extensive financial domain experience.

This expertise gap has led to a reliance on familiar but limited tools like Excel, or third party desktop apps.

But the shift is happening. With AI dramatically reducing the cost and complexity of building software, the barriers between financial expertise and technical implementation are finally breaking down.

And OpenBB is here to bootstrap that revolution.

## The challenge at the delivery stage

<p align="center">
    <img width="600" src="/blog/2025-02-25-ui-layer-is-the-next-big-frontier_1.png" />
    <p align="center" className="mt-1" style={{fontSize: "0.75em"}}>
        <div>Excerpt from <a href="https://x.com/TheTerminalist" target="_blank" rel="noopener noreferrer">TheTerminalist</a>'s blogpost: </div>
        <a href="https://open.substack.com/pub/theterminalist/p/10000x-bloombergs-return-and-why" target="_blank" rel="noopener noreferrer">10,000x. Bloomberg's return and why financial data is so darn lucrative</a>
    </p>
</p>

The finance and AI space is cost-intensive.

Innovation requires deep R&D, technical expertise, and the ability to handle highly flexible yet complex workflows. This is why many past attempts to improve financial research software have been set up for failure - they focused on owning or controlling data rather than optimizing how users interact with it.

The real opportunity lies at the application layer.

Data is increasingly commoditized, and as financial marketplaces grow, the real value is shifting towards how that data is consumed.

Intelligence - how insights are generated, refined, and acted upon—is where the competitive edge lies.

## Why the UI layer has been overlooked

Building a beloved financial desktop application isn’t just about better charts or a sleeker interface. It requires a fundamental rethink of how users interact with their data.

The industry’s reliance on fragmented workflows has meant that firms have learned to tolerate inefficiencies, simply because “it works.”

<p align="center">
    <img width="600" src="/blog/2025-02-25-ui-layer-is-the-next-big-frontier_2.png" />
    <p align="center" className="mt-1" style={{fontSize: "0.75em"}}>
        <div>Excerpt from <a href="https://x.com/TheTerminalist" target="_blank" rel="noopener noreferrer">TheTerminalist</a>'s blogpost: </div>
        <a href="https://open.substack.com/pub/theterminalist/p/10000x-bloombergs-return-and-why" target="_blank" rel="noopener noreferrer">10,000x. Bloomberg's return and why financial data is so darn lucrative</a>
    </p>
</p>

## The OpenBB approach: a different path

We aren’t competing with data vendors.

Instead, we’re offering something that no one else has attempted: a flexible, modular workspace where firms can build on top of their own data. Imagine a world where research is seamless, where AI is not just bolted on but deeply embedded into workflows, and where analysts spend more time uncovering insights rather than wrangling data.

Data providers are starting to recognize this shift, but innovation on their platforms is slow.

Meanwhile, AI is accelerating workflows at a pace that demands a new approach.

AI chatbots alone aren’t enough; without a stronger visualization and interaction layer, they remain a novelty rather than a necessity.

With OpenBB, we are deliberately avoiding the data layer because we believe intelligence — the ability to derive value from data—is the future. Firms want more control over their data and the ability to leverage it without leakage.

That’s why the biggest demand we’ve seen is for on-prem deployments, ensuring security while unlocking intelligence.

## Timing matters: why now?

<p align="center">
    <img width="600" src="/blog/2025-02-25-ui-layer-is-the-next-big-frontier_3.png" />
    <p align="center" className="mt-1" style={{fontSize: "0.75em"}}>
        <div>Excerpt from <a href="https://x.com/TheTerminalist" target="_blank" rel="noopener noreferrer">TheTerminalist</a>'s blogpost: </div>
        <a href="https://open.substack.com/pub/theterminalist/p/10000x-bloombergs-return-and-why" target="_blank" rel="noopener noreferrer">10,000x. Bloomberg's return and why financial data is so darn lucrative</a>
    </p>
</p>

The cost of compute has dropped, making powerful AI-driven applications more feasible.

The best products emerge at the intersection of technical and domain expertise, and that’s exactly where OpenBB sits—with deep engineering talent combined with financial knowledge.

One of our clients recently put it best:

> _“OpenBB is the bridge infrastructure between my data and my intelligence.”_

<br />

That’s the mission.

Not just another financial tool, but a true workspace for the next generation of research and analytics.

If you have your own data in Snowflake, Databricks, GCP, Azure or other, and want to build a customized workspace that fits your needs - reach out.

The future of finance is being rewritten.

---

---
slug: 2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb
title: How function calling and context-aware AI shapes OpenBB
date: 2025-03-01
image: /blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb
tags: ['AI', 'function calling', 'data analytics', 'openbb', 'financial analysis', 'agent', 'copilot']
description: Building on OpenBB's presentation at the Anote AI Day Summit, this post explores how intelligent function calling serves as the cornerstone of our AI-native workspace for data analytics.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb.png" />
</p>

Building on OpenBB's presentation at the Anote AI Day Summit, this post explores how intelligent function calling serves as the cornerstone of our AI-native workspace for data analytics.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I recently had the opportunity to present our OpenBB Copilot and how most of what it does is function calling, in the Anote AI Day Summit: [It is All Function Calling - Anote AI Day Summit 2025](https://www.youtube.com/watch?v=gH1mMtRa84Y).

This blog post is a similar presentation in text-written format.

## Our vision for the OpenBB Workspace

At the core of our product is the OpenBB workspace, a fully customizable dashboard where users can control their data visualization and analysis. The middle section shows a dashboard that you can fully customize with widgets containing relevant data widgets. We've designed it with a practical sidebar for managing dashboards, folder organization, sharing capabilities, templates, and data connections.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_1.png" />
</p>

But what I'm going to talk about is our agentic sidebar on the right. This is effectively your AI agent that works as an analyst with access to all the data inside the product. And this is where our implementation of function calling becomes crucial.

## Context is key

We've developed three ways to provide context to our Copilot:

1. **Explicit context**: We've added a simple button on the top right of widgets that allows users to directly add them to the Copilot's context. You can also simply drop files into the Copilot window.

<br />

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_2.png" />
</p>

2. **Dashboard context**: In this case, the Copilot can access all data present on the current dashboard and will then inform the user which widgets were used.

<br />

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_3.png" />
</p>

3. **Global context**: Through a feature flag, users can also enable searching across all widgets within the workspace.

<br />

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_4.png" />
</p>

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_5.png" />
</p>

What's important is how we've prioritized these: explicit context takes precedence, followed by dashboard context, and then global context.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_6.png" />
</p>

It's similar to an analyst's process—you begin by examining the document in front of you, then assess the items on your desk, and finally consider your wider resources, such as Google Drive or Slack.

### The power of widget metadata

One of our key innovations is our metadata system.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_7.png" />
</p>

Each widget in our product has what we call "widget metadata" composed of five components:

- Title
- Category
- Subcategory
- Description
- Data source

We convert this metadata into embeddings and compare it against user prompts to determine which functions the Copilot should access. This allows us to scale effectively while maintaining accuracy, especially since there can be literally thousands of data widgets. Due to the metadata, widgets are only invoked when a user triggers a relevant prompt.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_8.png" />
</p>


## Function Calling in practice

Let me share some real examples of how this works.

### Basic function calls

When analyzing unstructured data like market reports, our Copilot can extract specific information without parameter changes:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_9.png" />
</p>

Copilot understands from widget metadata that the user requires information from it and queries it:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_10.png" />
</p>

In turn that data is utilized to answer the prompt:


<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_11.png" />
</p>

### Parameter-modified calls

We can handle cases where users want to switch contexts.

For instance, even if you're looking at Apple news, you can ask about Palantir, and our system will automatically adjust the parameters:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_12.png" />
</p>

Copilot understands from widget metadata that the user requires information from it and queries it:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_13.png" />
</p>

But, not as is. It requires updating input parameters accordingly (symbol and dates):

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_14.png" />
</p>

In turn, that data is utilized to answer the prompt:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_15.png" />
</p>

Finally, the utilized widget (with updated parameters) can be added to the dashboard seamlessly.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_16.png" />
</p>

### Complex analysis

For more sophisticated tasks like analyzing futures contracts for arbitrage opportunities, our Copilot can make multiple function calls, process the data, and create visualizations.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_17.png" />
</p>

Copilot understands from widget metadata that the user requires information from it, with updated parameters, and queries it.

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_18.png" />
</p>


In turn, that data is utilized to answer the prompt...

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_19.png" />
</p>

and creating a chart like the user asked:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_20.png" />
</p>

Finally, the resulting artifact (in this case, a chart) can be added to the dashboard:

<p align="center">
    <img width="900" src="/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb_21.png" />
</p>

## Verification and output

We're particularly proud of our verification system for the Copilot. It allows users to:

- See the step-by-step reasoning
- Access data sources through citations
- Add source widgets to their dashboard
- Get highlights of specific data references

The output can be added directly to the dashboard as new widgets, creating a seamless workflow from query to visualization to presentation.

## Looking forward

We've built something that I believe truly changes how people can interact with financial data, and we're just getting started. The combination of intelligent function calling, context awareness, and user-friendly interface is making sophisticated financial analysis more accessible than ever before.

You can get started for free at [pro.openbb.co](http://pro.openbb.co).

---

---
slug: 2025-03-03-building-a-custom-widget-for-my-friends-newsletter
title: Building a custom widget for my friends newsletter
date: 2025-03-03
image: /blog/2025-03-03-building-a-custom-widget-for-my-friends-newsletter
tags: ['openbb', 'financial-services', 'widget', 'automation', 'open-source']
description: How I built a custom OpenBB widget to save my friend hours of manual work on his newsletter with 190,000+ subscribers.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-03-03-building-a-custom-widget-for-my-friends-newsletter.png" />
</p>

How I built a custom OpenBB widget to save my friend hours of manual work on his newsletter with 190,000+ subscribers.

The open source code is available [here](https://github.com/DidierRLopes/opening-bell-daily-openbb).

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Last weekend I spoke with my friend <a href="https://www.linkedin.com/in/philrosen/" target="_blank">Phil Rosen</a>.

He used to work as a Senior Markets Reporter at Business Insider.

And left to start his own news and research outlet: <a href="https://www.openingbelldailynews.com/" target="_blank">Opening Bell Daily</a>, just over 1 year ago.

He's been sharing a newsletter everyday since and has crossed over 190,000 subscribers!!!

Funnily enough, we commented on how we were speaking on a Saturday morning and the weekends are the times where we are the most productive.

As I was sharing more of OpenBB and how he can utilize it for the content in his newsletter, he shared a table chart that he crafts manually to his audience, which always takes him a significant amount of time to do every single day.

Well, I wouldn't be an engineer by training if I didn't solve this for him.

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/9hQtFL_0NjU?si=oUC-X0XsnKad-V9E"
        width="1000"
        height="500"
    />
</div>

More than that - to celebrate 1 year of Opening Bell Daily: 

> Any OpenBB user can add this URL as a custom backend application on OpenBB and have Phil's market snapshot on their screen every day. https://openbb-opening-bell-daily.fly.dev

<br />

Or you can also sign up to Phil's newsletter and get it in your inbox along with insightful content, every day!

<p align="center">
    <img width="900" src="/blog/2025-03-03-building-a-custom-widget-for-my-friends-newsletter_1.png" />
</p>

PS: I have made this code [open source](https://github.com/DidierRLopes/opening-bell-daily-openbb) so others can create their own widgets for OpenBB or get inspired.


---

---
slug: 2025-03-05-my-key-takeaways-from-institutional-investor-conference
title: My key takeaways from Institutional Investor conference
date: 2025-03-05
image: /blog/2025-03-05-my-key-takeaways-from-institutional-investor-conference.jpg
tags: ['openbb', 'financial-services', 'ai-adoption', 'data-privacy', 'enterprise-ai', 'build-vs-buy', 'open-source', 'finance', 'local-deployment']
description: Key insights from financial services technology leaders on AI adoption, including build vs. buy strategies, data privacy concerns, technology adoption divides, and the challenges of moving from prototypes to production-ready solutions.
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-03-05-my-key-takeaways-from-institutional-investor-conference.jpg" />
</p>

Key insights from financial services technology leaders on AI adoption, including build vs. buy strategies, data privacy concerns, technology adoption divides, and the challenges of moving from prototypes to production-ready solutions.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I just returned from an insightful financial services technology conference where CTOs, CIOs, and technology leaders shared their perspectives on AI.

I was on the stage on the topic of "Autonomous Agents — The Next Step in AI Applications?" which was one of my favorite panels that I've ever done.

This allowed me to have extremely insigthful conversations with industry leaders managing dozens to hundreds of billions of dollars in AUM.

Here are the most valuable insights I gathered:

## The build vs. buy evolution

Financial institutions increasingly prefer building over buying complete solutions. Most follow a hybrid approach—purchasing foundational technology but building customized layers on top. The consensus is that this approach reduces complexity in the long term while avoiding vendor lock-in.

> **OpenBB hat on**: This is one of the reasons we love open source - it gives users a third option: building on top of an infrastructure that is continuously maintained and improved, allowing firms to focus solely on their workflows.

<br />


## AI adoption challenges

Despite the hype, financial services firms struggle with AI implementation, primarily due to unclear use cases. There is no dominant AI product in the industry, and most organizations cautiously use general tools under strict controls.

> **OpenBB hat on**: This is a great sign that we are still early, and there isn't yet a clear winner in AI financial products. It also indicates that companies need to invest capital in educating the market—not just about their products (I'm guilty of this) but about the workflows that AI can enable. (Luckily, [Ihsan](https://www.linkedin.com/in/ihsan-erman-saracgil-42628454/) joined the team recently, and I've seen him build full workflows for clients like this [earnings workflow](https://www.youtube.com/watch?v=JTlyU6HdWjQ) solely on OpenBB. If you're looking for something specific, he's the person to ask!)

<br />

<p align="center">
    <img width="900" src="/blog/2025-03-05-my-key-takeaways-from-institutional-investor-conference_1.jpg" />
</p>

## Data privacy concerns without local solutions

Significant concern was expressed about data leakage when using AI tools, with strict policies such as "no credit card swipes for AI tools" and "turn off uploads" being common. Interestingly, no one mentioned running open-weight models locally, a solution that would address these privacy concerns by keeping data in-house. This represents a major market education opportunity, as firms are worried about data leaving their environment but aren't aware of alternatives to cloud-based AI services.

> **OpenBB hat on**: This one really surprised me. It may be because most products currently follow a traditional SaaS model. However, I saw a clear need for on-prem/VPC deployments where firms run open-weight models locally with zero data leakage. We can do this — and we might be one of the few products on the market that can today.

<br />

## Technology adoption divide

A clear divide exists between technology resistors and embracers. Some professionals cling to legacy tools and manual processes, seemingly to preserve their relevance. Meanwhile, AI adopters are achieving remarkable productivity gains, quickly building React applications, simulations, and analytical tools.

> **OpenBB hat on**:  This trend was expected. I've personally experienced how AI has dramatically increased my coding efficiency. As the cost of building continues to approach zero, we'll see exponential opportunities to automate workflows. Talent with AI expertise won't just deliver 2-3x value for their firms but potentially 10x or more. This represents both a challenge and an opportunity for organizations ready to embrace these new capabilities.

<br />

## Prototype-to-production gap

A common challenge is bridging the gap between 70% done prototypes and enterprise-ready solutions. AI enables rapid development and impressive demos, but the real challenge is implementing governance, security, compliance, and scalability for production environments. Organizations need talent that can leverage AI for rapid innovation while also understanding enterprise requirements to bring projects to completion.

> **OpenBB hat on**: This reality is particularly evident in development practices. A quick demo in Streamlit can be built in minutes—great for rapid prototyping. However, such solutions rarely meet enterprise standards. Developing production-ready features like RBAC, SSO, administrative controls, sharing capabilities, comprehensive logging, and reporting systems requires an entirely different skill set and approach. We often see firms approaching us after realizing their prototype tools won't scale to meet their long-term strategic objectives.

<br />

## What this means for OpenBB

OpenBB is uniquely positioned at the intersection of these trends. As an open workspace that supports bring-your-own-data, local AI deployment, and enterprise-grade features, we provide financial institutions with the flexibility to build custom solutions while addressing security concerns and bridging the prototype-to-production gap.

Our approach aligns perfectly with the industry's evolving needs, making us an ideal partner for forward-thinking financial organizations navigating AI transformation.

If you want to chat, feel free to e-mail me at didier.lopes[at]openbb.finance.

---

---
slug: 2025-03-07-proactive-agents-are-the-future-of-ai-in-finance
title: Proactive Agents Are the Future of AI in Finance
date: 2025-03-07
image: /blog/2025-03-07-proactive-agents-are-the-future-of-ai-in-finance
tags: ['openbb', 'financial-services', 'ai', 'investment', 'proactive-agents', 'agents', 'future']
description: How AI is evolving from reactive to proactive in financial services, and why this shift will transform how investors discover opportunities and generate alpha.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-03-07-proactive-agents-are-the-future-of-ai-in-finance.png" />
</p>

How AI is evolving from reactive to proactive in financial services, and why this shift will transform how investors discover opportunities and generate alpha.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Imagine waking up to find your AI assistant has already analyzed overnight market movements, identified three potential investment opportunities aligned with your strategy, and prepared a briefing on key economic indicators that might impact your portfolio today. This isn't science fiction—it's the imminent future of AI in finance.

## The Evolution of Financial AI: From Reactive to Proactive

This week I was asked the question "Where is OpenBB with AI next year?".

Our play here is clear, we are the Enterprise UI that lives between data and AI.

So when someone asks this question, they are ultimately asking "What will be possible to do on OpenBB as models get better and cheaper".

And I think that it all comes down to: **Reactive VS Proactive**

### The Current State: Reactive AI

Today, LLMs/agents/AI is reactive for the most part.

It requires users to have a clear intent on what they want the LLM to do, they are required to be prompted (pun intended). You ask a question, the AI answers. You request an analysis, the AI delivers. The interaction is fundamentally user-initiated and bounded by the specificity of your requests.

This reactive paradigm, while powerful, places the burden of discovery on the human user. You need to know what to ask for, when to ask for it, and how to frame your questions.

### The Future State: Proactive AI

However, what happens when models get better and cheaper and they have an interface that has access to all their data in one place?

Simple.

It can scan the data every few seconds and generate investment ideas, find alpha and truly act like a partner. A proactive AI agent might:

- Alert you to unusual trading patterns in a sector you're tracking
- Identify correlations between market events and your portfolio performance
- Suggest portfolio rebalancing based on changing market conditions
- Highlight emerging trends before they become mainstream investment theses

More importantly, as the agent starts to engage with the user, we will be able to provide feedback to the model: "this wasn't a good idea because of X", "semi-conductors are not part of my mandate", ... and these models will adapt to become more personalized.

## Real-World Applications

Imagine a portfolio manager receiving an alert: "Three companies in your watchlist have shown unusual options activity following yesterday's Fed announcement. Based on your previous trading patterns, this may represent an opportunity in line with your contrarian strategy."

Or consider a risk analyst being notified: "We've detected a 3.2 standard deviation move in correlation between your two largest positions. Here's an analysis of what might be driving this change and three potential hedging strategies."

The exciting thing?

We aren't that far off from this being a reality.

## The OpenBB Vision

At OpenBB, we're building the infrastructure to make this proactive AI future possible. By creating a unified interface between financial data and AI capabilities, we're enabling the next generation of intelligent financial assistants that don't just answer questions—they anticipate needs.

This is how I envision the future:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/xTvaks7EDh0?si=szd8RNFyMD_SPAHm"
        width="1000"
        height="500"
    />
</div>

## What this means for you

The shift from reactive to proactive AI will fundamentally change how financial professionals work:

1. **Time efficiency**: Less time spent on routine data gathering and more time on high-value decision making
2. **Expanded opportunity set**: Discover investment ideas outside your usual information channels
3. **Personalized intelligence**: AI that learns your preferences, risk tolerance, and investment style
4. **Competitive edge**: Early identification of market shifts and anomalies

<br />

The future of finance isn't just about having better answers—it's about having an AI partner that asks better questions.


---

---
slug: 2025-03-11-the-10-trillion-openbb-copilot-validation
title: The $10 trillion OpenBB Copilot validation
date: 2025-03-11
image: /blog/2025-03-11-the-10-trillion-openbb-copilot-validation
tags: ['openbb', 'blackrock', 'copilot', 'enterprise', 'agent', 'widgets', 'architecture', 'open-source', 'finance', 'portfolio', 'security']
description: "At the recent AI Engineering Summit, BlackRock unveiled their Aladdin Copilot - a platform remarkably similar to what we've built at OpenBB, but with a key difference. While they've invested massive resources into building a closed system, we've created an open-source solution that achieves the same goals: multi-application support, seamless agent integration, explainable AI, and enterprise-grade security. Here's a deep dive into how the world's largest asset manager validated our approach to AI-powered financial workflows."
hideSidebar: true

---

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation.png" />
</p>

At the recent AI Engineering Summit, BlackRock unveiled their Aladdin Copilot - a platform remarkably similar to what we've built at OpenBB, but with a key difference.

While they've invested massive resources into building a closed system, we've created an open-source solution that achieves the same goals: multi-application support, seamless agent integration, explainable AI, and enterprise-grade security. Here's a deep dive into how the world's largest asset manager validated our approach to AI-powered financial workflows.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

On Friday 21st, I attended the [AI Engineering Summit](https://www.ai.engineer/summit/2025) from @swyx and Ben. If you're working in the agentic space, this is arguably one of the best conferences available.

One presentation that particularly caught my attention was BlackRock's session about their Aladdin Copilot. While I can't share the presentation materials as they're conference-exclusive, what I saw left me incredibly bullish about OpenBB's direction.

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_1.png" />
</p>

Here's why: BlackRock's copilot is remarkably similar to what we've built at OpenBB - but with 1% of their resources and one major distinction.

Let's dive into the striking similarities first.

## Not a single workflow, but multiple applications

BlackRock's Aladdin platform centers heavily on Portfolio - enabling users to handle portfolio construction, management, and monitoring.

In contrast, OpenBB's Workspace functions as an open playground. While it certainly handles portfolio management (as demonstrated in [this example](https://www.youtube.com/watch?v=K80ayaZYyk4)), it extends far beyond that. Our platform supports risk management, equity/crypto/macro research, ideation, ranking, client advisory, and even compliance workflows.

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_2.png" />
</p>

This versatility stems from our workspace architecture where users build on their own data. The flexible widget creation system can accommodate virtually any workflow - provided users have the necessary data.

## Not a single chatting interface, the agent is on the side and is invoked when needed

This is a hill I'm willing to die on.

For the most part, analysts and PMs don't want a chat-only interface for their daily work. I wrote about this extensively [8 months ago](https://openbb.co/blog/why-chat-only-ai-financial-assistants-are-not-the-answer-you-might-think-they-are), and my conviction has only strengthened.

BlackRock appears to share this view. Their agentic copilot acts as a sidebar to the main interface, allowing users to query dashboard data and quickly validate information without disrupting their workflow.

Seeing this in their demo was genuinely shocking - it looked remarkably similar to what we've had in OpenBB for over a year now. It's validating to see the world's largest asset manager (with 20k employees) arriving at the same conclusions we did.

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_3.png" />
</p>

## Explainability

Both platforms prioritize data transparency. Every copilot response that references dashboard data clearly highlights its source. This enables users to validate LLM outputs and trace information back to its origin, maintaining trust and accountability.

An example of how it can highlight sentence or table level in unstructured document:

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_4.png" />
</p>

An example of how it can highlight the widget origin that was used to answer to the prompt:

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_5.png" />
</p>

## Secure environment first approach

This is non-negotiable in finance, where both data and prompts can be competitive advantages. Our president, [Heidi Jonhson](https://www.linkedin.com/in/heidisjohnson/), recently detailed our approach to this in our [on-prem announcement](https://openbb.co/blog/run-openbb-on-premises-and-be-in-control-of-your-data-and-UI).

## Architecture

While I can't share specifics from BlackRock's presentation, I can explain OpenBB's architecture, which appears to follow identical principles.

Our OpenBB Copilot acts as an orchestrator, gathering context from three main sources (in order of importance):

1. **In-context**: Either attached files or explicitly referenced data widgets
2. **Dashboard**: Data currently visible in the dashboard
3. **Product-wide**: Connected to the workspace but not visible

<br />

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_6.png" />
</p>

This context exists in the form of widgets, and there can be thousands! In the case of BlackRock, they refer to this as Plugin Registry.

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_7.png" />
</p>

### What is a widget?

In our system, a widget combines:

- Data origin (API endpoint, static file, SQL query with DB connection, etc)
- The parameters that can be modified to query a variation of the data
- Metadata (title, description, category, sub-category, and source)

The metadata enables our copilot to identify and utilize appropriate widget based on user prompts, by controlling the widget through its parameters.

<p align="center">
    <img width="900" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_8.png" />
</p>

You can think of these widgets effectively as tools that are rendered on our workspace. Therefore, our agent can call different widgets to retrieve the data it needs to reply more effectively to the user.

For a deeper dive into this architecture, check out my recent [10-minute presentation](https://www.youtube.com/watch?v=gH1mMtRa84Y) or the blog [here](https://didierlopes.com/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb).

## Distinction

So what is the main distinction?

How Open we are.

<p align="center">
    <img width="1200" src="/blog/2025-03-11-the-10-trillion-openbb-copilot-validation_9.png" />
</p>

We have an open source data integration framework that enables any firm from bringing any type of data into our product.

We have an open source agentic framework that enables any firm to build their own agent (even one running locally).

And we intend to open source much more.

We believe in a future where each firm will build their own tools on top of the most popular open source infra.

If you fall under that umbrella, reach out.


---

---
slug: 2025-03-18-my-first-half-marathon
title: Doing my first Half Marathon
date: 2025-03-18
image: /blog/2025-03-18-my-first-half-marathon
tags: ['running', 'half-marathon', 'nyc', 'charity', 'fitness', 'personal']
description: A personal journey through my first NYC Half Marathon, from fundraising $1,615 for cancer research to crossing the finish line in 1h45min, complete with training insights and my race day experience.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon.JPG" />
</p>

A personal journey through my first NYC Half Marathon, from fundraising $1,615 for cancer research to crossing the finish line in 1h45min, complete with training insights and my race day experience.

<!-- truncate -->

import Admonition from '@theme/Admonition';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Background

I'm currently 29 years old.

That means that as other hundred of thousands of runners, I'm having a mid-life crisis... just kidding.

Last year, I signed up to participate in a boxing match for Haymakers for Hope - where I would have to raise $10k for Cancer research.

I didn't get selected in the end.

However, raising money for charity (something I had never done before) was something that I've always wanted to do. Particularly when it affected me so much at a young age (more on that <a href="http://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life/" target="_blank">here</a>).

So when I received an email about the United NYC Half marathon, organized by Haymakers for Hope. I had to sign up.

## Fundraising

The New York City Half Marathon is incredibly popular, with nearly 30,000 people participating this year. Unlike most races, you can't simply sign up - you actually need to apply through an organization that has allocated "bibs" for the race.

If you're accepted, you commit to raising money for the chosen cause. I love this approach because it means everyone running on race day has raised funds for organizations they're passionate about, giving the event deeper meaning and purpose.

In my case, I commit to raise at least $1500. In total I was able to raise $1615.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_1.png" />
</p>

Although I've previously raised $8.9M for OpenBB, as mentioned in <a href="https://venturebeat.com/data-infrastructure/openbb-wants-to-be-an-open-source-challenger-to-bloomberg-terminal/" target="_blank">this article</a>. Raising wasn't straightforward.

Here are a few things that I did in order to raise this amount:

- I shared the <a href="http://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life/" target="_blank">story of Bia</a> and why this cause is important to me. First on socials and then on my newsletter.
- I asked my closest friends and family to support me in this cause.
- For the people that couldn't support, I asked to repost my fundraising efforts for higher visibility.
- Added that CTA on the top of my website, where I share blogs weekly.

Other things that I was thinking of doing, but ended up not requiring to do so:

- Asking if any company would like to contribute to the fundraising and I would run with their merch
- Doing a stream on building something from scratch where I have on the banner that I'm raising money for Cancer
- Selling items that I don't use as much anymore

## Preparation and paperwork

The administrative side of race preparation was straightforward but required attention to detail:

First, I had to sign up with New York Road Runners (<a href="https://www.nyrr.org/" target="_blank">NYRR</a>).

<Admonition type="note">
Important tip: be realistic about your estimated completion time.
<br />
This determines your starting wave. I conservatively estimated 2 hours since it was my first half marathon, but I should have put 1:45 instead. A faster wave would have meant less congestion at the start, and going with runners that are aiming to do the same time as I am.
</Admonition>

This is what the wave scheduled looked like.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_2.png" />
</p>

After paying the race fee, I scheduled my bib pickup.

The pickup location was actually great! There was a ton of race merchandise, giveaways, photoshoots and more going on.

<Admonition type="note">
Check that you get the running bib, your number that contains the chip tracker and the clips to set them on. For instance, mine had a missing clip to attach it to the shirt.
</Admonition>

The location also displayed a wall with all runner's names, my mom actually found my name on the wall!

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_3.jpeg" />
</p>

I also took an event guide, which had pretty much all the information I needed for the day of the race.

<div style={{ display: 'flex', justifyContent: 'center', gap: '20px' }}>
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_4.jpeg" />
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_5.jpeg" />
</div>

## Training

My training wasn't as structured as it could have been, but my regular boxing sessions (2-3 times weekly) provided a great foundation.

To ensure I could complete the distance, I ran a practice half marathon one month before the race near my boxing Gym Gleason's, finishing in 2 hours. This gave me confidence and a benchmark to improve upon.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_6.jpeg" />
</p>

<div style={{ display: 'flex', justifyContent: 'center', gap: '20px' }}>
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_7.PNG" />
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_8.PNG" />
</div>

<br />

A week before the event, I completed a 12-mile run with elevation in Central Park to prepare for any challenging terrain. This made me understand how elevation actually plays a role, since in that previous training session the terrain was very much flat!

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_9.jpeg" />
</p>

<div style={{ display: 'flex', justifyContent: 'center', gap: '20px' }}>
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_10.jpeg" />
    <img width="45%" src="/blog/2025-03-18-my-first-half-marathon_11.jpeg" />
</div>

## Race day

For the race day I woke up a couple hours before the event.

For breakfast, I had three eggs and a banana to provide energy for the run.

I wore the bib given by the organization with my number plate, non-grip socks, running shoes, shorts with pockets for my airpods box and the Haymakers for Hope hat. This was a good shout as I saw someone from our team on the starting line and they recognized me because of that.

For garments I brought my AirPods to listen to a Spotify playlist that I had prepared the day before with fast paced music to give a boost. Example of songs in that playlist include:

- <a href="https://www.youtube.com/watch?v=cdgbI17JbII" target="_blank" rel="noopener noreferrer">Camo & Krooked - Climax</a>
- <a href="https://www.youtube.com/watch?v=xvtNS6hbVy4" target="_blank" rel="noopener noreferrer">Deadmau5 feat Chris James - The Veldt</a>
- <a href="https://www.youtube.com/watch?v=Lo0ELoepTCM" target="_blank" rel="noopener noreferrer">Monolink - Return to Oz (ARTBAT Remix)</a>

Shoutout to [Ulyana](https://www.linkedin.com/in/ulyanaermolova/) who shared some of the songs she listens while running!

I also brought an old sweater to stay warm before the race, which I later donated through the race's clothing drive for charity. I loved this concept.

<Admonition type="note">
You can actually take more things with you and then check-in that bag before the race. The organization will take that bag to the finish line which you can then pick up by using your bib number or name.
</Admonition>

With all this preparation, I forgot something that was critical - and I still cannot believe that I did. I forgot my Apple Watch!! 🤦🏽‍♂️

This resulted in me running with the phone in my hand throughout the race, looking like a schmuck.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_12.png" />
</p>

Note: LLMs are getting so good, that Gemini 2.0 Flash (Image Generation) is now able to remove watermarks of pictures. See [this tweet](https://x.com/didier_lopes/status/1902067982123319637) for reference.

### During the race

Just before starting, I consumed one of my energy gels for an initial boost.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_13.jpeg" />
</p>

The race experience was awesome in itself. Your timing chip activates when you cross the start line, so your official time is accurate regardless of where you stand in your wave.

However, starting in a slower wave meant navigating through crowds of runners, which proved challenging at times.

There were several water and Gatorade stations throughout the course, eliminating the need to carry your own water bottle.

You will actually receive map course information before the race so you can prepare for where these stations are.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_14.png" />
</p>

The elevation chart on this map is actually very important. This allows you to be strategic when you think about when to conserve your energy or speed up.

I saw many runners that started walking when they were on a uphill. I think that being able to push through in these sections is critical, since if you break your rhythm then it becomes harder to keep going.

Running across the Brooklyn Bridge (a first ever for any race!) and through Times Square were big highlights for me.

<div style={{ display: 'flex', justifyContent: 'center', gap: '10px', flexWrap: 'wrap' }}>
    <img width="32%" src="/blog/2025-03-18-my-first-half-marathon_15.jpeg" />
    <img width="32%" src="/blog/2025-03-18-my-first-half-marathon_16.jpeg" />
    <img width="32%" src="/blog/2025-03-18-my-first-half-marathon_17.jpeg" />
</div>

<br />

The energy from spectators was also incredible, with creative and humorous signs everywhere.

Some of my favorites included:

- "Pain is temporary, Strava is 4eva"
- "Your outie is running a half marathon"
- "If you slow down I'll drop this" held by a naked spectator with a strategically placed sign
- "When you need to actually run the race you signed up for" with the face of someone screaming
- "From 1 to 10, you are a 13"
- "Run now, beer later"
- "You are only running this race because you are half crazy"

Around mile 9, I used another of my energy gel to keep going. I used my one instead of the ones provided by the organization as my body knows that gel, and you don't want any surprises on the day.

Without my watch, I paced myself by mental calculations from my start time. I saved energy for a final push in the last mile to hit my target of 1h:45m.

Having my parents and wife near the finish line providing support was amazing.

This is a picture taken by them, with less than 400m left:

<p align="center">
    <img width="900" src="/blog/2025-03-18-my-first-half-marathon_18.JPG" />
</p>

## After the race

As soon as I crossed the finish line, volunteers handed out care packages containing water, Gatorade, a cereal bar, pretzels, and an apple.

As you walk a few dozen meters, they also hand you your medal and blankets to warm you up. Then there's also locations where people can take pictures.

Here's the picture I took with my family after leaving the half marathon area.

<p align="center">
    <img width="600" src="/blog/2025-03-18-my-first-half-marathon_19.jpeg" />
</p>

The entire experience exceeded my expectations.

While running isn't my favorite activity, completing a half marathon with my parents on the finish line was awesome.

Finally, at home, I sent an e-mail to everyone who donated thanking them for the donation, letting them know how much was raised, and how the event went.

<p align="center">
    <img width="900" src="/blog/2025-03-18-my-first-half-marathon_20.png" />
</p>

This is something I borrowed from my friend [Nick](https://www.linkedin.com/in/nicolasbcarreras/) when I donated to his team relay race.

Looking forward to doing a full marathon next!

## Stats

Some stats below for the curious,

<div style={{ display: 'flex', justifyContent: 'center', gap: '10px', flexWrap: 'wrap' }}>
    <img width="49%" src="/blog/2025-03-18-my-first-half-marathon_21.png" />
    <img width="49%" src="/blog/2025-03-18-my-first-half-marathon_22.png" />
</div>

---

---
slug: 2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow
title: OpenBB enables streamlined Client Advisory AI workflow
date: 2025-03-23
image: /blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow
tags: ['AI', 'investment', 'client advisory', 'automation', 'LLM', 'openbb']
description: In this blog post, I’ll show you how an AI agent can transform your funds performance, macro data, news around your holding companies, and more into a draft investor letter that has the same writing style as your team.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow.png" />
</p>

In this blog post, I’ll show you how an AI agent can transform your funds performance, macro data, news around your holding companies, and more into a draft investor letter that has the same writing style as your team.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Gathering performance data, analyzing market shifts, and crafting detailed investor communications is a process that demands precision, consistency, and a personal touch.

But what if your analysts could have an AI writing partner that thinks and communicates just like your team and could prepare those drafts in a few minutes?

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_1.png" />
</p>

## How does it work?

### Step 1: Custom PDF parsing of factsheets

First, the agent tackles the challenge of extracting structured data from your quarterly factsheets.

Using a combination of OCR and state-of-the-art LLM models with structured output, it can capture all the relevant information from the document with a high degree of accuracy.

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_2.png" />
</p>

### Step 2: Learning your communication style

Processing your investor letters is significantly easier, as they usually consist of text, which can be easily parsed to markdown format (ideal for LLMs), and simpler tables, easily identified by the latest models.

So in this step, the important aspect is identifying what makes your ~10-page investor letter unique. To be able to do that, the agent needs several quarter investor letters so it can understand the patterns and similarities between them and answer questions like:

- How does the analyst write the intro?
- How do they wrap up the letter? Does it change based on the overall flow?
- What are the sections of the document (e.g., performance review, outlook)?
- What is the analyst’s tone of voice in general? Does it change based on the performance review?
- How much detail does it go into regarding the major holdings?
- Do they talk about positions that were exited and why? What about new ones?
…

Ultimately, the model needs to understand what makes your investor letter unique.

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_3.png" />
</p>

### Step 3: Pattern recognition between factsheet and investor letter

At this point, it already knows what makes your investor letter unique. However, it still does not know what makes the analyst write certain comments vs others. Where do these come from?

For that, we are picking the concept of “supervised learning” from machine learning, where a model is trained based on the input and output to understand the trends between the two.

In this case:

- The model is the LLM of your choice (e.g., local LLM so data doesn’t leave your machine)
- The input is the factsheet data
- The output is the investor letter

And we use a prompt along the lines of:

> Can you extract the structure/pattern between the factsheet data and what is written in this investor letter? Your goal is to output instructions that can be used as a prompt for a model to predict what the analyst would write based on that factsheet data.

<br />

We are ultimately looking for a detailed "recipe" that connects your factsheet data to what your analyst would write.

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_4.png" />
</p>

The AI learns exactly how your team moves from raw numbers to meaningful insights, maintaining your analytical frameworks and professional voice.

It allows you to understand which factsheet data tables impact which section of the investor letter and how.

**Tips & tricks:**

1. Feed the model with multiple different “Factsheet → Investor letter” examples so it’s easier for it to capture edge cases. Example: The last quarter of the year might have a different section to wrap up the year

2. Do not use examples that had a different writing style than what you're trying to achieve as that can impact the results. Example: an example from 7 years ago might no longer be relevant due to overall style changes

3. Go more granular. Instead of using the entire document as an example, go after a subset of the data. Example: If the performance section of the Investor letter only relies on 4 of the 14 tables, focus on those only to extract a pattern

4. Get the main analyst responsible for the investment letters involved in this process. Having a subject matter expert is essential here and will be a deal breaker.

### Step 4: Preparing your prompt

The agent has now found:

- Your communication style, which will be used as a system prompt
- The recipe to write the investor letter based on factsheet data, which will be used as the user prompt
- Examples of factsheet data and their resulting investor letters, which will be used for few-shot prompt
- A model that we have decided to use (whether OpenAI, open weights model like Llama, or other)

However, we still need to provide the model with:

- Latest factsheet data
- Any additional context to be included in the letter (e.g., tickers of interest for this quarter, macro, ..)

That’s where the OpenBB workspace is crucial.

### Step 5: Connect this custom agent to the OpenBB workspace

It doesn’t matter how good this pipeline is if your team does not have a good interface to interact with it easily—feed it the data it requires, review its output, iterate, etc.

By connecting this custom agent to the OpenBB workspace, your firm can access it directly from there and combine it with the other features OpenBB offers.

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_5.png" />
</p>

Those features include:

- Being able to drag and drop to the workspace the latest factsheet data and any additional context that the model will require
- Interact with the model directly on OpenBB’s interface
- Review the generated draft directly and ask for quick edits or adjustments
- Convert that draft into a widget on the workspace
- Share this initial draft version with your team for feedback

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_6.png" />
</p>

Our unique solution consists of an AI-ready interface where firms can seamlessly integrate their own data and AI agents. This means that these agents are accessible right where your analysts perform their analysis and research, eliminating the need to switch between platforms or learn new tools. This approach allows portfolio managers and analysts to leverage AI to complement their existing processes, rather than relying on generic solutions.

OpenBB also stands out because it’s built on an open-source foundation, unlike anything else in the market, translating into unparalleled transparency, flexibility, and the ability to adapt to your unique needs.

Additionally, our flexible on-prem deployment option means that firms can run open-weight AI models locally and that data never leaves their environment, ensuring privacy and compliance.

## Summing up

While the results can make it look simple, in reality, this is how the pipeline works under the hood:

<p align="center">
    <img width="600" src="/blog/2025-03-23-openbb-enables-streamlined-client-advisory-ai-workflow_7.png" />
</p>

### Real-life results on our clients' operations

The impact of this workflow on our clients' operations has been transformative. Analysts now have first drafts ready within minutes of receiving factsheet data, giving them more time to focus on analysis and personalization. The consistency in communications has improved, while the accuracy of data and insights remains impeccable.

### Increase your team’s throughput and efficiency with AI

Imagine you have an AI partner that thinks like your team, writes like your team, and helps maintain the high standards your investors expect. A partner that's always available, consistently accurate, and infinitely scalable.

That's something OpenBB can help you achieve.

Whether you manage multiple funds, communicate in different languages, or simply want to give your analysts more time for high-value work, we're excited to explore how we can transform your investment communications process.

Interested in seeing how this could work for your firm?

Let's discuss how we can customize this solution for your organization’s unique needs and communication style. Contact me at didier.lopes@openbb.finance.


---

---
slug: 2025-03-25-one-data-vendor-to-rule-them-all-really
title: One data vendor to rule them all. Really?
date: 2025-03-25
image: /blog/2025-03-25-one-data-vendor-to-rule-them-all-really
tags: ['openbb', 'financial-data', 'data-aggregation', 'investment-research', 'workflow-automation', 'data-vendors', 'alpha-generation']
description: Exploring why relying on a single data vendor for financial research is unrealistic in today's complex market landscape, and how AI-driven platforms like OpenBB are transforming how professionals interact with diverse data sources to find alpha and gain competitive advantage.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-03-25-one-data-vendor-to-rule-them-all-really.png" />
</p>

Exploring why relying on a single data vendor for financial research is unrealistic in today's complex market landscape, and how AI-driven platforms like OpenBB are transforming how professionals interact with diverse data sources to find alpha and gain competitive advantage.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Context

For those who don't know, the main reason I started OpenBB was because my investment research process started taking too much time.

As I was adding more data I wanted to analyze in my workflow (e.g. insider trading, macro, options), I spent more time doing "research".

I say "research" because in reality, I was spending most of my time on manual tasks.

Those tasks were a combination of:

- Going into a certain browser tab
- Logging in into my account in the website
- Selecting the ticker of interest
- Extracting the data (e.g. download or taking a screenshot to the chart)
- Potentially processing that data in some capacity (e.g. sentiment for text from Stocktwits or X)
- Putting that data into a document

<br />

As a full-time sensor fusion engineer, I didn't have that many hours a day to spend doing research - so this started to occupy most of my weekends.

As an engineer would, I decided to automate my workflow and that's when I started working on OpenBB as a data aggregator that I could use to become more efficient.

When I open sourced OpenBB, we saw hundreds of contributors adding data sources they were interested in exploring. Here are a few we incorporated: FMP, Intrinio, Polygon, Tiingo, Yahoo Finance, CoinGecko, CoinPaprika, Coinbase, Binance, CryptoCompare, Alpha Vantage, OANDA, ExchangeRate-API, Federal Reserve Economic Data (FRED), World Bank, OECD, U.S. Department of the Treasury, FINRA, Quandl, SentimentInvestor, Reddit, Stocktwits, Twitter, Google Trends, News API, Finnhub, Benzinga, Seeking Alpha, Wall Street Journal, MarketWatch, Databento, CBOE, SEC EDGAR, Biztoc, StockGrid, Finviz, and more.

Yup, there was a lot.

My screen looked like this:

<p align="center">
    <img width="600" src="/blog/2025-03-25-one-data-vendor-to-rule-them-all-really_1.jpg" />
</p>

It turns out that professionals had the same pain points that I did. This widespread adoption revealed a fundamental truth about the financial data landscape that continues to shape our vision today.

## A single data vendor

How likely is it that ALL the data you will want exists under a single data vendor?

It's just not realistic, even for a company like Bloomberg.

I mean, think about the following categories and the amount of companies that have a strong hold in the market:

- Equity Market Data & Analytics: Bloomberg, FactSet, LSEG
- Credit Ratings: S&P Global Ratings, Moody's
- Risk Analytics: MSCI
- Portfolio Management: BlackRock (Aladdin platform)
- Fixed Income Data: Bloomberg
- Derivatives & Exchange Trading Infrastructure: CME Group, ICE
- Commodities Trading Data: CME Group, London Metal Exchange (LME)
- Crypto: Dune, Messari, Nansen

This means that professionals have two paths:

### Need multiple products

If they cannot do all of their work from a single platform, that means that almost by definition their process is flawed.

They will have issues combining data, finding edge between different datasets or even learning different tools to get the job done.

This gets particularly worse when professionals want to incorporate their own internal data.

### Can do everything in one product

If they can do all of their work within one interface, then that's perfect.

The main question they need to ask is: "Can I trust this company to adapt to AI so I can be as efficient as my peers?".

If the answer is yes, then they shouldn't look at other products.

If not, then they should prepare to adapt.

## The role of AI

As AI gets better, it will be harder for humans to find Alpha.

This isn't just speculation. We're already seeing evidence of this transformation.

I believe that AI will be able to find Alpha at the intersection of different datasets and their relationships, or even utilizing proprietary data (which third party products do not offer).

Regardless, for that you need an AI-first enterprise UI.

This is what we are building at OpenBB – not just another data aggregator, but an intelligent interface that:

- Unifies fragmented data sources into a coherent ecosystem
- Applies AI to identify patterns and relationships that humans might miss
- Adapts to your unique workflow and proprietary data
- Reduces the friction between question and insight

<p align="center">
    <img width="900" src="/blog/2025-03-25-one-data-vendor-to-rule-them-all-really_2.png" />
</p>

## The role of data

Due to the role of AI, and how data-hungry it is - it's becoming clear that investment firms will start acquiring more and more data internally.

The issue with this is that data by itself doesn't do much.

You need an interface to analyze that data or for AI to do so.

OpenBB Workspace is precisely this – the critical missing piece that transforms raw data into actionable intelligence.

Where traditional platforms simply aggregate information, our solution applies intelligence to that information, creating a multiplier effect on your data investments.

## The power shift: From data to interface

<p align="center">
    <img width="600" src="/blog/2025-03-25-one-data-vendor-to-rule-them-all-really_3.jpeg" />
</p>

Historically, the power in financial markets has been centered around data access. The interface was merely a distribution channel - a means to an end.

But this model has been limiting for some time now.

Think about it: All humans are different in how we process information, yet somehow we're all expected to use the same software interfaces?

Make it make sense.

The reality is that each professional has unique cognitive patterns, analytical strengths, and decision-making processes. A one-size-fits-all approach to financial interfaces is fundamentally at odds with how humans actually work.

## Owning your workflow

As firms consume more data from diverse sources, they should also own their workflow and interface.

Why?

1. **Competitive advantage**: Your unique process is what differentiates you in the market
2. **Adaptability**: Markets evolve rapidly - your tools should evolve with them
3. **Integration**: Proprietary data becomes truly valuable when seamlessly incorporated into your workflow
4. **Personalization**: Different team members need different views of the same data

<br />

This is why OpenBB Workspace is designed to be adaptable to your specific needs - not forcing you into a rigid framework, but empowering you to create the exact workflow that matches how your team thinks and operates.

Plus, you can **fully own** your workflow, data and everything in between.

<p align="center">
    <img width="900" src="/blog/2025-03-25-one-data-vendor-to-rule-them-all-really_4.png" />
</p>


## Looking ahead

The financial data landscape will only grow more complex. The winners will be those who can seamlessly integrate diverse data sources, apply AI effectively, and maintain adaptability as technology evolves.

OpenBB Workspace is designed with this future in mind – not just solving today's problems but positioning our clients to thrive in the AI-driven financial world that's rapidly emerging.

If you're ready to transform how your team interacts with financial data, we'd love to show you what's possible with OpenBB Workspace.


---

---
slug: 2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero
title: Building your own Crypto app from scratch - zero to hero
date: 2025-03-30
image: /blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero
tags: ['openbb', 'crypto', 'dashboard', 'tutorial', 'data visualization', 'AI', 'workflows']
description: A comprehensive guide to building sophisticated crypto applications using OpenBB. Learn how to create custom dashboards, implement consistent styling, leverage widget specifications, build template workflows, and customize AI agents for your specific use case.
hideSidebar: true
unlisted: true

---

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero.png" />
</p>

A comprehensive guide to building sophisticated crypto applications using OpenBB. Learn how to create custom dashboards, implement consistent styling, leverage widget specifications, build template workflows, and customize AI agents for your specific use case.

<!-- truncate -->

import CodeBlock from '@theme/CodeBlock';
import Details from '@theme/Details';
import Admonition from '@theme/Admonition';

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

## Background

My friend Matt Maximo is an investor in digital assets at VanEck. The first time he shared with me what he was working on, I was impressed.

So impressed that I shared a <a href="https://www.linkedin.com/feed/update/urn:li:activity:7275174801860636672/" target="_blank">post about it</a> on LinkedIn, which got over 50k impressions.

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_1.png" />
</p>

However, I wanted to take the dashboard he built to the next level. So I'm going to highlight the 5 different OpenBB levels that enable you to go from zero to hero.

I'll be sharing some minimal code just for reference. The code will be in Python and the framework used was FastAPI. But if you are comfortable with other languages and frameworks, you should be able to use those.

## Level 1 - Bringing data
You are able to bring data from different data vendors into OpenBB.

In order to do this, you will have to create a custom backend that parses data from the data vendors of your interest and pushes it out.

Luckily for you, we have <a href="https://github.com/OpenBB-finance/backend-examples-for-openbb-workspace/tree/main" target="_blank">open sourced this data integration</a> layer to make it as easy as possible.

This is already impressive particularly because you can see that the data you are interested in visualizing is right there available to you.

AND, you get out-of-the-box:

- Mix and matching the datasets into the layout you are interested in
- Sharing dashboards with your team
- Utilizing an AI model on top of those datasets

This is where I would say Matt's dashboard was.

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_2.png" />
</p>

## Level 2 - Data style rendering

Once you bring all the data into OpenBB, it's important that it all matches a certain style. Think of it as your own design system for OpenBB widgets.

At this stage you are still working on the custom backend code and the data it outputs.

### Plotly

Something we support is a Plotly chart, and if you're familiar with Plotly, you know it comes with a large amount of options that a user can customize.

So, here I recommend creating a Plotly config that you will be utilizing throughout your App. This ensures that your interface retains the same branding regardless of what workflow you're getting done.

<details summary="Example of Plotly config">
<CodeBlock
    language="python"
    title="ploty_config.py"
    showLineNumbers
>
{`def get_layout_update(theme="dark"):
    """
    Returns standard layout updates to apply to all charts.
    
    Parameters:
        theme (str): The theme to use, either "light" or "dark"
    
    Returns:
        dict: A dictionary of layout settings to update Plotly charts
    """
    # Define color schemes based on theme
    if theme == "light":
        text_color = '#333333'
        grid_color = 'rgba(221, 221, 221, 0.3)'  # Very faded grid
        line_color = '#AAAAAA'
        tick_color = '#AAAAAA'
        bg_color = '#ffffff'  # More opaque background
        active_color = '#3366CC'  # Nice blue color for light theme
        # Black text for better contrast in light mode
        legend_text_color = '#000000'
        # Darker border for better visibility
        legend_border_color = '#ffffff'
    else:  # dark theme (default)
        text_color = '#FFFFFF'
        grid_color = 'rgba(51, 51, 51, 0.3)'  # Very faded grid
        line_color = '#444444'
        tick_color = '#444444'
        bg_color = '#151518'  # More opaque background
        active_color = '#FF8000'  # Orange color for dark theme
        legend_text_color = text_color  # Use the same text color
        legend_border_color = "#151518"  # Use the same border color
    
    return {
        'uirevision': 'constant',  # Maintains view state during updates
        'autosize': True,  # Enables auto-sizing for responsive behavior
        'dragmode': 'zoom',  # Sets default mode to zoom instead of pan
        'hovermode': 'closest',  # Improves hover experience
        'clickmode': 'event',  # Makes clicking more responsive
        'margin': {
            't': 50,  # Top margin - increase this for more modebar space
            'r': 30,  # Right margin
            'b': 40,  # Bottom margin
            'l': 40,  # Left margin
            'pad': 4   # Padding between the plotting area and the axis lines
        },
        'transition': {
            'duration': 50,  # Small transition for smoother feel
            'easing': 'cubic-in-out'  # Smooth easing function
        },
        'modebar': {
            'orientation': 'v',  # Vertical orientation for modebar
            'activecolor': active_color  # Active button color
        },
        'font': {
            'family': 'Arial, sans-serif',  # Sans-serif font
            'size': 12,
            'color': text_color  # Text color based on theme
        },
        'xaxis': {
            'rangeslider': {'visible': False},  # Disable rangeslider
            'autorange': True,  # Enable autorange
            'constrain': 'domain',  # Constrain to domain for better zoom
            'showgrid': True,  # Show vertical grid lines
            'gridcolor': grid_color,  # Very faded grid lines
            'linecolor': line_color,  # Axis line color based on theme
            'tickcolor': tick_color,  # Tick color based on theme
            'linewidth': 1,  # Match y-axis line width
            'mirror': True,  # Mirror axis to match y-axis
            'showline': False,  # Hide the axis line to remove the box
            'zeroline': False,  # Hide zero line to match y-axis
            'ticks': 'outside',  # Place ticks outside
            'tickwidth': 1  # Match y-axis tick width
        },
        'yaxis': {
            'autorange': True,  # Enable autorange
            'constrain': 'domain',  # Constrain to domain
            'fixedrange': False,  # Allow y-axis zooming
            'showgrid': True,  # Show horizontal grid lines
            'gridcolor': grid_color,  # Very faded grid lines
            'linecolor': line_color,  # Axis line color based on theme
            'tickcolor': tick_color,  # Tick color based on theme
            'linewidth': 1,  # Consistent line width
            'mirror': True,  # Mirror axis
            'showline': False,  # Hide the axis line to remove the box
            'zeroline': False,  # Hide zero line
            'ticks': 'outside',  # Place ticks outside
            'tickwidth': 1  # Consistent tick width
        },
        'legend': {
            # Legend text color with better contrast
            'font': {'color': legend_text_color},
            'bgcolor': bg_color,  # More opaque background
            'bordercolor': legend_border_color,  # Better visible border
            'borderwidth': 1  # Add border width for better visibility
        },
    }
`}
</CodeBlock>
</details>
Here's an example of how a dashboard that utilizes the same Plotly config file looks:

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_3.png" />
</p>

Notice the visual consistency.

### Theme

Pretty much everyone on our team is a dark mode fan. This might be due to our origins and the OG Gamestonk Terminal command line interface.

However, from customer conversations, some users had a strong preference for light mode. So we developed OpenBB workspace to support both. You can switch with a simple Ctrl+M shortcut.

Here's how the previous dashboard looks in light mode:

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_4.png" />
</p>

As seen above, the Plotly config file is prepared for both dark and light mode. However, how does it know which to use?

That's because whenever the user retrieves their data through a request, we send an additional `theme` parameter that specifies if the user is in `dark` or `light` mode.

Let's look at a simple example of how we handle theme in our API endpoints:

<CodeBlock
    language="python"
    title="Example of a Fast API endpoint with theme support"
    showLineNumbers
>
{`async def get_velo_net_liquidations(
    coin: str = "BTC",
    begin: str = None,
    resolution: str = "1d",
    theme: str = "dark"  # defaults to dark mode
)`}
</CodeBlock>

This ensures a consistent visual experience regardless of the user's theme preference.

## Level 3 - OpenBB Widget spec
When you bring data into OpenBB, you will see a table or a chart that effectively lives within a container.

That entire container is what we call a widget.

It's not just the data that you are pushing into OpenBB - it also comes with the concepts of parameters and metadata.

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_5.png" />
</p>

Once you understand this, you enter a whole new domain.

This spec is what allows you to control the user experience around how data flows in the workspace, and is defined through a JSON.

Here's an example of a decorator from an endpoint that has a specific widget spec.

<CodeBlock
    language="python"
    title="Example of a widget spec decorator"
    showLineNumbers
>
{`@register_widget({
    "name": "Net Liquidations",
    "description": "Net liquidations (long - short) across exchanges",
    "category": "crypto",
    "source": "VeloData",
    "endpoint": "velo/net-liquidations",
    "type": "chart",
    "data": {"chart": {"type": "line"}},
    "gridData": {"w": 40, "h": 12},
    "params": [
        {
            "paramName": "coin",
            "value": "ETH",
            "label": "Coin",
            "show": True,
            "description": "Cryptocurrency to display data for",
        },
        {
            "paramName": "resolution",
            "value": "1d",
            "label": "Resolution",
            "show": True,
            "description": "Time resolution for data points",
            "type": "endpoint",
            "optionsEndpoint": "velo/resolution-options",
        },
        {
            "paramName": "begin",
            "value": "2024-01-01",
            "label": "Start Date",
            "show": True,
            "description": "Start date for the data",
            "type": "date",
        }
    ],
})`}
</CodeBlock>

<Admonition type="note">
This decorator is something that we built to make it easier to add to each widget, but it isn't required. You may simply have a widgets.json file that has the specs for each widget, as done <a href="https://github.com/OpenBB-finance/backend-examples-for-openbb-workspace/blob/main/widget_examples/chart_widget/widgets.json" target="_blank">here</a>.
</Admonition>

There are many arguments that are important, but let me divide them into 3 categories:

### Parameters

Parameters are what allow the user to change a ticker on a widget in the interface, triggering another request on the backend to update the data with the latest ticker selected. This also works for dates, numbers, dropdowns, or any other input type.

Funny story: Recently a customer asked us for an input form field. Once we supported that, someone on our team built a widget that effectively enables users to execute trades on OpenBB.

If we go through the parameters example above, you'll start to understand the capabilities you have at your disposal.

1. The coin symbol parameter is a string, and you can see that it has "ETH" as its default value. The "Coin" label and the "Cryptocurrency to display data for" description appear when hovering over the field. Note that these fields are also important for the AI agent which can use them to make different data requests for the dataset.

<br />

<CodeBlock
    language="python"
    title="Coin ticker"
    showLineNumbers
>
{`{
  "paramName": "coin",
  "value": "ETH",
  "label": "Coin",
  "show": True,
  "description": "Cryptocurrency to display data for",
}`}
</CodeBlock>

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_6.png" />
</p>
2. The resolution dropdown highlights that there's a component that takes another endpoint for the list of choices that the user has at their disposal, and even that they can search for the right options. This enables developers to limit the selections that the end user will have when utilizing OpenBB.

<br />

<CodeBlock
    language="python"
    title="Resolution dropdown"
    showLineNumbers
>
{`{
  "paramName": "resolution",
  "value": "1d",
  "label": "Resolution",
  "show": True,
  "description": "Time resolution for data points",
  "type": "endpoint",
  "optionsEndpoint": "velo/resolution-options",
}`}
</CodeBlock>

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_7.png" />
</p>

3. The "date" type parameter is a common one, as a lot of financial data requires users to select a starting date. This functionality is controlled by the selection in the "type" field.

<br />

<CodeBlock
    language="python"
    title="Calendar date type"
    showLineNumbers
>
{`{
  "paramName": "begin",
  "value": "2024-01-01",
  "label": "Start Date",
  "show": True,
  "description": "Start date for the data",
  "type": "date",
}`}
</CodeBlock>

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_8.png" />
</p>
More information on parameters can be found <a href="https://docs.openbb.co/terminal/custom-backend/widgets-json-reference" target="_blank">here</a>.

### Metadata

Metadata is data associated with the widget that is relevant for the agent on the workspace. It includes: title, description, category, sub category and source. This is pushed into embedding so that when the user asks anything, that prompt is pushed into embedding and through similarity search it will understand the best data widget to use as context to answer the question.

Here's an example, for when asking "What was net liquidation of BTC on March 17 of this year?".

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_9.png" />
</p>

It gets the right data, but how given the data isn't available right there?

This is done through function calling, and I have an entire post about it which you can find <a href="http://didierlopes.com/blog/2025-03-01-how-function-calling-and-context-aware-ai-shapes-openbb" target="_blank">here</a>.

But if you were interested in getting the data that was used to answer the prompt right there you can simply go to the citation, and add the widget to the dashboard.

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_10.png" />
</p>

The widget added will look like this:

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_11.png" />
</p>

Note that all the parameters are the correct ones to get the right data.

### Others

Anything else falls here. That includes:

- The real endpoint being used to access this data, in this case "velo/net-liquidations"
- The data type, in this case chart of type line
- The default visualization type, in this case chart. This argument exists so users can toggle between chart and raw data.
- The widget dimensions, i.e. the widget dimensions when added to the dashboard
- And others

## Level 4 - Template workflows

Once you have all the data you want on OpenBB. And the UI/UX is great, what's next?

Then you wrap it all together.

### Interface

You create a template workflow, which basically means that anyone that has access to what you build can click on said workflow and it will render that exact same dashboard for you to nail a specific workflow. Even the grouping relationship between the widgets are preserved!

And you can create many of these.

This can be done by simply exporting template from a dashboard that you like. Like this:

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_12.png" />
</p>

And then pushing it into templates.json.

Here's an example of having multiple custom template workflows to choose from.

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_13.png" />
</p>

### Prompts

For us it is important that a workflow is not just a collection of widgets, grouping and its display, but it ultimately enables you to automate a task that is manual and takes a lot of time.

This is why we allow users to add prompts to their template workflows.

<p align="center">
    <img width="600" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_14.png" />
</p>

After running that prompt on the data available within this template workflow.

<p align="center">
    <img width="900" src="/blog/2025-03-30-building-your-own-crypto-app-from-scratch-zero-to-hero_15.png" />
</p>

## Level 5 - Custom AI agent

Now that you have all the data in OpenBB, a great UI/UX and you have your workflow templates ready... there's only one thing missing.

Customizing your AI agent.

Instead of relying on our generic implementation that can work on top of your data out-of-the-box, you can integrate a more tailored agent for a specific workflow.

Ultimately you may have multiple agents for different workflows based on the task they are trying to get done, and you are in control.

You can find more examples of building your agent on OpenBB in <a href="https://github.com/OpenBB-finance/copilot-for-openbb" target="_blank">this open source repo</a>.

## Concluding remarks

In this post I go through the fundamentals of creating a powerful crypto dashboard on OpenBB.

I tried to not be too technical, but rather give an overview of all the capabilities of our product so you can understand that once you learn the patterns you can build your own powerful desktop application.

Given the requests for this, I'm preparing a workshop on how to create an OpenBB app from scratch.

Focused on people who want to build apps on OpenBB.

If you want to sponsor the event by providing data to the audience, ping me.

Sign up in here: tbd.


---

---
slug: 2025-04-03-stop-building-ai-products-start-building-workflows
title: Stop building AI products, start building workflows
date: 2025-04-03
image: /blog/2025-04-03-stop-building-ai-products-start-building-workflows
tags: ['AI', 'product strategy', 'business', 'openai', 'workflows', 'openbb']
description: The secret to building defensible AI companies isn't better AI - it's better workflows. An insider's perspective on why some AI companies thrive while others will become obsolete with each new model release.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-04-03-stop-building-ai-products-start-building-workflows.png" />
</p>

The secret to building defensible AI companies isn't better AI - it's better workflows. An insider's perspective on why some AI companies thrive while others will become obsolete with each new model release.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Lately, I've been asked several times about my opinion on how better AI models are ultimately going to impact financial companies and OpenBB.

If you're not an AI lab, then your product is a wrapper around an LLM.

In the AI space, a lot of people use the term wrapper with a negative connotation. But not all wrappers are created equal.

Being a wrapper around an LLM just means that your product is not the LLM—but the wrapper itself.

## Chatting with your internal data

If you're building a general-purpose AI model to be used on any user data, and your pitch is: our model is better at retrieval than any other AI lab.

Then you’ve already lost.

The funny thing is, the companies that fall into this trap will say:

> _"OpenAI isn't a competitor because we are better at understanding the user data"_

<br />

But then, every time a new model drops they will tell investors:

> _"Our product just got 2x better because of the latest OpenAI release"_

<br />

You see the irony right?

If you have _this_ thin of a wrapper, then in the words of Sam Altman — OpenAI will steamroll you.

I.e., while you're telling investors that your product performance improved thanks to the latest model, we both know that the value gap between using OpenAI directly and your product just got smaller.

You're fighting a fight you can't win.

## But our chatting interface is better

How is it better?

- Does it create charts and tables?
- Does it create artifacts?
- Does it highlight citations?
- Does it provide reasoning?
- Does it do web search?
- Does it do deep research?
- Does it allow you to upload documents?

I'm sorry to tell you, but OpenAI already does all these things.

Even worse - in the financial services, firms are likely already using Microsoft or Google as a cloud vendor.

And both of these have products where OpenAI and Gemini, respectively, work on top of firm's data.

So why would a firm even look at your product if this is where you fall?

## What about Perplexity?

Perplexity needs to be studied. For good reasons.

They fine-tuned an open-weight model and used it for web search.

Nothing groundbreaking here.

Except that their execution is seamless.

They did it much earlier than any of the main AI labs—and every day that passed, Perplexity was gaining market share around AI for querying the internet.

While they were gaining market share, they never let the momentum die—either through launches, partnerships, competitions...

And so today, although OpenAI and others have web search, Perplexity is considered the best product for queries that involve the web.

Ultimately, I think their moat is a combination of being first to market (on search), having a strong brand, and—more importantly—flawless execution by Aravind.

One of the things I never understood was why they didn’t push more on the Enterprise AI angle. After all, they have the best demo there is:

> _“If we can give you an answer based on a personal blog post written 17 years ago by a professor of history from Portugal, do you really think we can’t get your ‘extract the company’s last twelve months’ revenue’?”_

<br />

But they announced crossing $100M ARR, so they’re doing pretty well.

## Where does the highest value lie?

I'm seeing two dimensions here:

1. Data
2. Workflows

<br />

Let's approach each individually.

### 1. Data

When it comes to data, we are talking about:

> _Do you have your own proprietary data that firms would pay for?_

<br />

If the answer is yes—then _this_ is your moat.

Note that this has nothing to do with AI, but with the data itself.

AI is just the delivery mechanism for that data. Not an API call, not a dashboard with the data, not a notification... a box that expects natural language and returns the data.

If the answer is no, then you don’t have a moat here.

**BUT.**

If you were thinking, _“But my application connects with data from FactSet, S&P, ...”_

Then your moat is not the data itself, but the **workflow**—which takes me to the next moat discussion.

### 2. Workflows

Here, the question is: what types of workflows do you allow users to get done on your product?

The definition of a _workflow_ is: a sequence of steps or tasks that are carried out to complete a specific process or achieve a particular goal.

There’s no mention of AI anywhere in that definition. AI is a tool that can help get a workflow done, but it isn’t required.

What _is_ required is understanding users—and understanding what they want to get done.

So there's a _lot_ of value in going narrow and nailing the workflow for a specific type of user.

_"But if you go narrow in a vertical, can’t you be disrupted more easily?"_ — you ask.

Yes and no.

- **YES**, if OpenAI ultimately wanted to go after that market, it could. But OpenAI won’t care. Not necessarily because the market isn’t big, but because they’re pursuing one that’s even bigger.

- **NO**, because the more vertical and narrow you go, the fewer experts there are, the stronger the word-of-mouth is, and the lower the competition. And once you’re in—you have first-mover advantage.

## Examples

Cursor and Windsurf are amazing products because they _nail the workflow_ of developers.

It’s not just about the AI model being used—but _when_ and _how_ it's used.

It’s about being in a full IDE that users are already familiar with, and plugging in the AI at the exact moments a user needs it.

They understood the pain of developers—and used AI to alleviate that pain.

The moat is in nailing the workflow and the user experience.

**What about better models being released? How do they impact these products?**

They get better.

Because the developers behind the product understand how to use these better models to remove _even more_ friction for their users.

Another thing worth saying here—I don’t actually believe in users selecting different models.

It sounds good in theory, but in practice, it doesn’t really work.

I don’t care what model Cursor is using—I care about getting my workflow done.

As a developer, I have _zero_ loyalty to my tools. I’ll use whatever gets the job done faster and more efficiently.

I mean—how many people actually switch models manually on Cursor? I think not many, and definitely not frequently.

I, for one, use Claude because it’s the best for coding right now. But if I’m asking an implementation question, then I’ll click on the “Claude Thinking” model.

Do I _want_ to click on “Thinking model”? Not really. But Cursor doesn’t yet understand my intent to get all the “firepower” I can for this answer—so for now, this will do.

Even better—do I _really_ care that it’s Claude? Nope. If it turns out Gemini 2.5 is the best at coding, I’ll happily switch and never look back.

## OpenBB

Ok, so where do we fit?

We’re very much in the category of **Workflows** - similar to Cursor.

The difference is: we didn’t have a VSCode that we could fork and build on top of.

The best financial terminals used in the space — Bloomberg, FactSet, CapIQ — are all closed-source.

So we had to build **OpenBB Workspace** from scratch over three years to match the capability and quality that financial professionals expect.

And now, we’re adding AI where it makes sense.

Some of these workflows that can be done on OpenBB include:

1. **Public Equity**: Earnings guidance intelligence; Investor call preparation.
2. **Wealth Management**: AI-Generated investment notes; Portfolio optimization & risk management.
3. **Private Equity & Credit**: AI-enhanced due diligence; Credit data room intelligence.
4. **Crypto**: On-chain & off-chain analysis; Sentiment & community perception tracking.
5. **Commodities & Macro**: Scenario-based forecasting; Regime shift analysis.
6. **Client Advisory**: Generate draft investor letters; Client sentiment analysis.
7. **Logistics & Operations**: Bunkering intelligence; Regulatory compliance & risk monitoring.

<br />

And we’re adding more fast.

Now that we have a UI that meets industry standards, we can double down on **workflows that delight customers**.

And we’ll keep expanding how many workflows can be done on OpenBB—ultimately with the goal of making OpenBB the **central interface** used within a firm, built on top of their own data.

Here’s an example of an application built on OpenBB in just a couple of days by one of our engineers, for a workshop we’re putting together with risk managers:

<p align="center">
    <img width="900" src="/blog/2025-04-03-stop-building-ai-products-start-building-workflows_1.jpeg" />
</p>

This highlights not only what we’ve built, but also how quickly we can delight customers on top of our product.


---

---
slug: 2025-04-11-10000-followers-later-heres-where-it-all-began
title: 10,000 followers later, here’s where it all began
date: 2025-04-11
image: /blog/2025-04-11-10000-followers-later-heres-where-it-all-began
tags: ['career', 'social media', 'linkedin', 'build in public']
description: A personal reflection on my 6-year journey to 10,000 LinkedIn followers and how sharing my work publicly led to unexpected opportunities and the creation of OpenBB.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began.png" />
</p>

A personal reflection on my 6-year journey to 10,000 LinkedIn followers and how sharing my work publicly led to unexpected opportunities and the creation of OpenBB.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

I crossed 10,000 followers on LinkedIn.

But.

It took me 6 years to get here.

It's been so long, I forgot what made me start posting on LinkedIn in the first place. So in this post I'm going down that memory lane.

...

During my university years, all I did was pretty much attend classes during the day and then study and do homework once I got home. My weekends were pretty much the same too.

My main objective was to have good grades so I could pursue anything I wanted after.

It wasn't about doing something in particular; it was about having the freedom to not have to do something in particular.

The freedom to pick a path.

After university, I landed a role as a Firmware Engineer where I was working on GNSS receivers. (I wanted to go into self-driving cars, and this role allowed me to work on chips that were used for positioning by self-driving cars—close enough, eh?)

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began_1.jpg" />
    <em style={{fontSize: '0.9em'}}>Presenting my thesis at Imperial, where I selected the topic of "Energy savings from an Eco-Cooperative Adaptive Cruise Control: a BEV platoon investigation"</em>
</p>

During the day, I was working. But in the evenings and on weekends, I didn't have my work laptop, so there wasn't much to do.

In the first few weeks of the job, I was reading books about how GNSS receivers worked (this is the best one btw: **Understanding GPS principles and applications**).

**Note:** GPS technology is so underrated, in my opinion—maybe one of the most impactful inventions of the 20th century. To think that 50 years ago, there wasn't a single satellite in the sky is insane. I think that one of the reasons for this is that it taken for granted because it works seamlessly in the background.

Anyway... There are only so many books you can read on the topic of satellite positioning.

It felt odd to have this much time where there wasn’t a goal, per se, that I could easily use to tell whether I was doing the right thing or not—unlike university, where anything that doesn’t go toward getting good grades is a distraction.

Given I was interested in data, AI and self-driving cars - I decided to keep learning as I did in University, but this time there was no target that others defined for me.

This time, the target was my curiosity.

And I was curious about ML/AI.

But everywhere I looked online was recommending Python instead of MATLAB.

So I bought the **Python Data Science Handbook**, which would allow me to learn Python in a way that was practical.

After reading the first few chapters, I started side projects based on ideas I had that would let me test my skills. More importantly, they would allow me to truly learn by getting my hands dirty.

As I was reading a lot on forums and Stack Overflow (RIP 🪦), I found the community amazing. People were sharing what they were working on, solutions to the problems they had—all in the open.

I loved it.

During my university years, I experienced two very different environments:

- An open community at my Portuguese university, where everyone shared everything—but, in general, people didn’t care that much.
- A closed community at TU Delft, where no one shared anything and it was extremely competitive.

I liked the competitiveness of TU Delft, but preferred the teamwork of the Portuguese university.

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began_2.jpg" />
    <em style={{fontSize: '0.9em'}}>Picture of me in Delft, back in 2016, where I did an exchange program</em>
</p>


This DS/ML/AI community was that.

And so in that same vein, I decided to do something that I wasn't comfortable doing, I decided to start posting on LinkedIn what I was working on.

Here's that <a href="https://www.linkedin.com/posts/didier-lopes_didierrlopesjobanalysis-activity-6499793502912815104-xa7_?utm_source=share&utm_medium=member_desktop&rcm=ACoAABub6aIBaA7HieEI5VizHglQPohLA_Wptag" target="_blank" rel="noopener noreferrer">first post</a> 6 years ago.

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began_3.png" />
</p>


A bit later I <a href="https://www.linkedin.com/posts/didier-lopes_yesterday-while-being-on-the-gym-i-was-activity-6517111978396393472-aRoe?utm_source=share&utm_medium=member_desktop&rcm=ACoAABub6aIBaA7HieEI5VizHglQPohLA_Wptag" target="_blank" rel="noopener noreferrer">posted about another mini project I worked on</a>:

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began_4.png" />
</p>

Due to these posts, I got this message in my inbox from my previous Maths teacher.

<p align="center">
    <img width="600" src="/blog/2025-04-11-10000-followers-later-heres-where-it-all-began_5.png" />
</p>

That message was about challenging me to help him write the [code behind his thesis](https://github.com/DidierRLopes/UnivariateTimeSeriesForecast), which was about ***Modeling and Forecasting of Financial Time Series.***

This is what ultimately led me to the financial space—and to start [OpenBB](http://openbb.co) in my spare time.

Six years in, and the only thing I regret is not starting to post earlier.

I can’t think of a single negative to posting on socials.

So if you’re on the fence — go to LinkedIn or X and just post what you’re working on, or how you’re thinking about something.

And tell me, so I can like your post to get the ball rolling.

Sharing content is a marathon.

And no one will care—until they do. So the best you can do is be true to yourself and post something you would want to read.

At least, that’s what I do.

And what I’ll keep doing.


---

---
slug: 2025-05-01-introducing-openbb-apps-tailored-by-users-for-optimized-workflows
title: Introducing OpenBB Apps, tailored by users for optimized workflows
date: 2025-05-01
image: /blog/2025-05-01-introducing-openbb-apps-tailored-by-users-for-optimized-workflows
tags: ['fintech', 'ai', 'workflows', 'financial analysis', 'open source', 'openbb']
description: OpenBB Apps introduces a customizable platform where financial organizations can build tailored workflow solutions with dashboard templates, data widgets, and AI agents - putting firms in complete control of their data and tech stack.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-05-01-introducing-openbb-apps-tailored-by-users-for-optimized-workflows.png" />
</p>

OpenBB Apps introduces a customizable platform where financial organizations can build tailored workflow solutions with dashboard templates, data widgets, and AI agents - putting firms in complete control of their data and tech stack.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

_"Be in control. Be free"_ was something our lead investor posted a few weeks ago.

This is a great representation of the direction the financial industry is taking—to a place where firms are in control of their data and tech stack. Fully.

Without the vendor lock-in. Without being limited by their vendor's data/technology, or being stuck in siloed systems and workflows.

Paraphrasing an industry leader (CIO at $40 bn AUM Investment Firm) that I heard at a conference recently:

> _There are a lot of nuances in our workflows, and it's hard — or even impossible — for a third-party vendor to nail our workflows fully._

At OpenBB, we believe there's no one-size-fits-all and that firms should be able to own their workflows. End-to-end. From the proprietary data they own and the AI model they choose, to the way these two work together. While we provide the infrastructure and the interface layer, the goal is for financial organizations to **build custom solutions** on top of it.

## How?

By integrating their data, choosing how to display it, setting up custom dashboards, and combining all of this with their preferred AI agents. Ultimately, OpenBB enables a streamlined analysis workflow that will save your team's time and your firm's money.

And that's why, today, we are **introducing the concept of Apps** on OpenBB.

Built for specific use cases, these apps consist of a dashboard template that can include custom data widgets, AI agents, and pre-saved prompts — all carefully set up by each firm to improve their specific analysis work.

<p align="center">
    <img width="600" src="/blog/2025-05-01-introducing-openbb-apps-tailored-by-users-for-optimized-workflows_1.png" />
</p>

This future has been coming for some time, and this time has arrived.

We have been building some apps as examples and have also been helping enterprise customers and individual users build their own, and while it's still early stages, we're amazed by the results.

Here are some exciting apps (and where you can find them) that you can run on OpenBB today:

- Portfolio Risk Management and DTCC trades - built for demo purposes by our team and available [here](https://github.com/OpenBB-finance/backend-examples-for-openbb-workspace/tree/main/demo-apps/demo-risk).

- FOMC, FRED, BLS, IMF - built for demo purposes by our team and available through our [open source Platform](https://docs.openbb.co/workspace/platform-installer)

- Congressional data and Executive orders - built for demo purposes by our team and available [here](https://github.com/andrewkenreich/congress)

- Crypto - built by user Matt Maximo and available [here](https://github.com/MattMaximo/CryptoBB)

- Macro - built by user Caíque Cober and available [here](https://openbb.co/blog/from-excel-to-agents-rebuilding-the-macro-research-workflow-for-the-ai-era)

- and more highlighted [here](https://docs.openbb.co/workspace/gallery)

Remember, the best part is that you can build your own.

If you're looking to get started building an OpenBB App, don't forget to visit [our Documentation](https://docs.openbb.co/workspace).

If you'd like to discuss bringing OpenBB to your firm, ping me!


---

---
slug: 2025-05-28-openbb-is-underrated
title: OpenBB is underrated
date: 2025-05-28
image: /blog/2025-05-28-openbb-is-underrated
tags: ['fintech', 'infrastructure', 'financial-analysis', 'open-source', 'openbb', 'modularity', 'workflows', 'post-terminalism', 'extensibility']
description: OpenBB isn't just software - it's foundational infrastructure that lets firms shape their own financial workspace, moving beyond one-size-fits-all solutions toward modularity and extensibility.
hideSidebar: true

---

<p align="center">
    <img width="600" src="/blog/2025-05-28-openbb-is-underrated.jpeg" />
</p>

OpenBB isn't just software - it's foundational infrastructure that lets firms shape their own financial workspace, moving beyond one-size-fits-all solutions toward modularity and extensibility.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

Something I’ve noticed lately, many people I speak with who do know about OpenBB say the same thing, almost verbatim:

- "You guys are so underrated."

- "I was in a room with CIOs and they hadn’t yet heard about OpenBB."

- "I wonder why more people don’t use OpenBB."

<br />

They say it with a mix of **surprise and respect** - because once they’ve seen it in action, they get it.

New products take time. New ideas, especially in finance, take even longer. The industry doesn't exactly sprint towards innovation.

But we’re not waiting for permission.

We are quietly redefining what a modern financial infrastructure looks like.

It’s not about making a nicer desktop app. It’s not about putting a glossy skin on legacy workflows. We’re not trying to mimic old tools - we’re playing our own game. Executing on our own vision.

**OpenBB is foundational.**

We built it from scratch because we had no choice. Nothing existed that let us move fast, integrate deeply, and give real control to the end user. So we built it. And in doing so, we gave firms the ability to do the same.

**OpenBB isn’t just software**. It’s infrastructure. It’s a flexible, programmable foundation that lets firms **shape their own financial workspace** - aligned with their needs, integrated with their tools, and adaptable as they evolve.

That’s where we fit.

And now, with the launch of apps, users are even closer to value. Apps cut through noise. They bring workflows into focus. They get insights into hands faster. This isn’t about flashy features - it’s about practical, daily utility that compounds.

<p align="center">
    <img width="600" src="/blog/2025-05-28-openbb-is-underrated.jpeg" />
</p>

OpenBB meets users wherever they are. We empower individuals to work smarter and faster. We enable researchers to glide from raw data to actionable insight. And we give firms the building blocks to create infrastructure that reflects how they think, how they work - not how outdated systems expect them to conform.

_The Terminalist_ captured this perfectly in their <a href="https://theterminalist.substack.com?utm_source=navbar&utm_medium=web" target="_blank" rel="noreferrer">latest post</a>:

<p align="center">
    <img width="900" src="/blog/2025-05-28-openbb-is-underrated_1.jpeg" />
    <img width="900" src="/blog/2025-05-28-openbb-is-underrated_2.jpeg" />
</p>

What other company fits this description better than us?

We aren’t clinging to old paradigms. We are betting on modularity, composability, and extensibility - the principles that will define the next generation of fintech.

The Terminalist calls it the rise of post-terminalism.

We see it as **the fall of the illusion that one-size-fits-all**.

People don’t always appreciate what we’ve built - until they do. And when they see it - when they feel the control, the extensibility, the raw power, it’s hard to go back.

The infrastructure is already here.


---

---
slug: 2025-06-10-how-i-connected-figma-to-cursor-using-mcp
title: How I connected Figma to Cursor using MCP
date: 2025-06-10
image: /blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp
tags: ['figma', 'cursor', 'mcp', 'developer-tools', 'tutorial', 'integration', 'design-to-code', 'productivity', 'development-workflow']
description: A step-by-step guide on how to connect Figma to Cursor using MCP (Model-Client-Protocol), enabling seamless design-to-code workflow and improving developer productivity through direct design system integration.
hideSidebar: true

---

import CodeBlock from '@theme/CodeBlock';

<p align="center">
    <img width="600" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp.png" />
</p>

A step-by-step guide on how to connect Figma to Cursor using MCP (Model-Client-Protocol), enabling seamless design-to-code workflow and improving developer productivity through direct design system integration.

<!-- truncate -->

<div style={{borderTop: '1px solid #0088CC', margin: '1.5em 0'}} />

This weekend, I was - **again** - mind blown by technology.

As I was working on OpenBB, and needed to copy the style from the Figma mockups - I stumbled upon Figma MCP.

Here's what I said on the <a href="https://www.linkedin.com/posts/didier-lopes_i-still-cant-believe-this-i-was-deep-into-activity-7337573643431944192-f9-L?utm_source=share&utm_medium=member_desktop&rcm=ACoAABub6aIBaA7HieEI5VizHglQPohLA_Wptag" target="_blank" rel="noreferrer">LinkedIn post</a>.

<p align="center">
    <img width="600" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_1.png" />
</p>

And this is the video that I added to the post:

<div className="flex place-items-center justify-center items-center rounded-sm mx-auto">
    <iframe
        src="https://www.youtube.com/embed/UwC_pbEnN3U?si=w15gGna5j1OhgPFp"
        width="800"
        height="400"
    />
</div>

<br />

So, in this short post, I'm going to tell you how you can do the same in a couple of steps.

## Enabling MCP Server on Figma

1. Make sure you are using Figma desktop app.

2. Go into "Dev Mode" on the bottom toolbar.

<br />
<p align="center">
    <img width="400" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_2.png" />
</p>

3. Enable MCP Server.

<br />
<p align="center">
    <img width="400" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_3.png" />
</p>

## Set up MCP client (Cursor)

1. Open Cursor Settings

<br />
<p align="center">
    <img width="500" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_4.png" />
</p>

2. Add a new MCP server

<br />
<p align="center">
    <img width="600" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_5.png" />
</p>

When clicking on "Add Custom MCP", copy paste the following block of code:

<CodeBlock language="json">
{`{
  "mcpServers": {
    "Figma": {
      "url": "http://127.0.0.1:3845/sse"
    }
  }
}`}
</CodeBlock>

Then save it, like this:

<p align="center">
    <img width="400" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_6.png" />
</p>

Once you close that file, you'll see that Cursor Settings MCP tab now displays "Loading tools":

<p align="center">
    <img width="700" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_7.png" />
</p>

After a few seconds you can toggle the Figma MCP and you should be able to see a few tools.

<p align="center">
    <img width="700" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_8.png" />
</p>

## Usage

The usage is very simple.

You just need to select the layout you want to pass to Cursor on Figma, and then right click on it and select "Copy link to selection".

<p align="center">
    <img width="400" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_9.png" />
</p>

Then you paste that link to Cursor and you prompt accordingly.

<p align="center">
    <img width="400" src="/blog/2025-06-10-how-i-connected-figma-to-cursor-using-mcp_10.png" />
</p>

Note: I recommend to be explicit with the model to utilize MCP.

That's it. I hope this is helpful.

Happy hacking.
