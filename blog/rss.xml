<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Didier Lopes Blog</title>
        <link>https://didierlopes.com/blog</link>
        <description>Didier Lopes Blog</description>
        <lastBuildDate>Sat, 21 Sep 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <copyright>Copyright ¬© 2024 Didier Lopes.</copyright>
        <item>
            <title><![CDATA[ChatGPT and The Future of AI in Finance]]></title>
            <link>https://didierlopes.com/blog/chatgpt-and-the-future-of-ai-in-finance</link>
            <guid>https://didierlopes.com/blog/chatgpt-and-the-future-of-ai-in-finance</guid>
            <pubDate>Sat, 21 Sep 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT & The Future of AI in Finance.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance.jpg"></p>
<p>I took the stage at the Cornell Quant Conference alongside Yu Yu (BlackRock) Tony Berkman (Two Sigma), and Samson Qian (Citadel), to discuss ChatGPT &amp; The Future of AI in Finance.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>Last week, I participated in a panel at the Cornell Financial Engineering Manhattan Conference. The topic of the panel was ‚ÄòChatGPT &amp; The Future of AI in Finance.‚Äô</p>
<p>The other panelists were:</p>
<ul>
<li><strong>Yu Yu</strong>, Director of Data Science - BlackRock</li>
<li><strong>Tony Berkman</strong>, Managing Director - Two Sigma</li>
<li><strong>Samson Qian</strong>, Trader - Citadel</li>
</ul>
<p>After the discussion, several people reached out, mentioning it was one of their favorite panels of the day.</p>
<p>Since this wasn't recorded, I took the opportunity to write down some of the topics discussed, along with a few additional thoughts that I believe in.</p>
<p>I will organize the following sections based on the topics discussed at the event:</p>
<ol>
<li>Hallucinations</li>
<li>Agents are the future</li>
<li>When does it make sense to fine-tune?</li>
<li>Compliance and Data security</li>
</ol>
<h2 id="1-hallucinations">1. Hallucinations</h2>
<p>When talking about the topic of hallucinations, I have a <a href="https://x.com/didier_lopes/status/1675630822093918209">quote</a> that I love from Marc Andreesen:</p>
<blockquote>
<p>‚ÄúHallucination is what we call when we don't like it. Creativity is what we call it when we do like it.‚Äù</p>
</blockquote>
<h3 id="confident-hallucinations">Confident hallucinations</h3>
<p>The fundamental issue with hallucinations is the fact that the model hallucinates with confidence.</p>
<p>Imagine asking two different friends: ‚ÄúDo you know where location X is?‚Äù</p>
<p><strong>Friend A</strong>: It‚Äôs there.</p>
<p><strong>Friend B</strong>: Hmm, I‚Äôm not really sure. If I had to guess, I‚Äôd say there, but I‚Äôm not 100% certain.</p>
<p>If both gave wrong directions, you would consider <strong>Friend A</strong> a liar, but not Friend B. This is because <strong>Friend B</strong> lacked confidence in their answer, they were trying to help but highlighted that they weren‚Äôt sure about it.</p>
<p>The problem with current LLMs is that they are, for the most part, like <strong>Friend A</strong>. They say wrong things with certainty.</p>
<p>Hallucinations would be less problematic if the default behavior were more like the answer on the right, when the LLM is not 100% confident.</p>
<div class="flex justify-center items-center"><img width="350" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_1.png" style="margin-right:10px"><img width="350" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_2.png"></div>
<br>
<p>The problem with confident hallucinations is that, similar to why everyone dislikes liars, it leads to a lack of trust. So users begin to put everything that is output by an LLM under a microscope - even if what the model says is accurate.</p>
<h3 id="how-to-avoid-hallucinations">How to avoid hallucinations</h3>
<p>There are ways to address this and one of the key approaches we are extremely strong about at OpenBB is always tapping into information that is available.</p>
<p>When a user asks a question that requires financial data, the OpenBB Copilot always searches for that data on OpenBB (either through data we make available or through private data that customers bring).</p>
<p>The Copilot will only answer the question if that data exists. This allows the model to cite the data used in its response, so the user can double-check.</p>
<p>This is how it looks.</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_3.png"></p>
<p>While I've heard a few vendors promising 100% accuracy, this is simply not true.</p>
<p>We are at a stage where technology is not even yet at the ‚Äòtrust but verify‚Äô level.</p>
<p>So instead of hallucinating with confidence, when data is unavailable, we prompt the model to return that there was no real-time information accessible to answer the query.</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_4.png"></p>
<h3 id="function-calling-to-increase-accuracy">Function calling to increase accuracy</h3>
<p>One thing we found that significantly reduces hallucinations is enabling our agent, OpenBB Copilot, to have access to all the API backends that users have through OpenBB or those they've added themselves.</p>
<p>Here‚Äôs the sequence of actions that happen:</p>
<ol>
<li>The user asks the OpenBB Copilot a question.</li>
<li>The prompt is converted into embeddings.</li>
<li>We compare that embedding with all the ones that we have on an OpenBB vector store which contains widget signatures - name, description, category, subcategory and source.</li>
<li>We retrieve the widgets with the highest similarity.</li>
<li>The Copilot then decides which widget to use based on the prompt.</li>
<li>Then Copilot also decides what parameters to use when calling that API</li>
</ol>
<br>
<p>This leads to less hallucination because the LLM isn't outputting tokens based on a prompt and its internal weights. Instead, it's using its internal weights, the prompt, and a function call.</p>
<p>Assuming the function call succeeds - with correct widget retrieval and parameters - the data becomes available for the Copilot to use, which leads to higher accuracy.</p>
<p>Note: This still means that Copilot needs to use the correct widget and the correct parameter, but there's a <strong>higher likelihood of success</strong> because if it isn't, the API call will fail, prompting the LLM to try again.</p>
<p>Here's how it works behind the scenes, the OpenBB Copilot highlights its step-by-step reasoning so users can understand its thought process. Transparency is key.</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_5.png"></p>
<h3 id="workflows-to-avoid-hallucinations">Workflows to avoid hallucinations</h3>
<p>In order to reduce the number of hallucinations, there are two things that can be done.</p>
<h4 id="enable-users-to-quickly-detect-whether-a-hallucination-has-occurred">Enable users to quickly detect whether a hallucination has occurred</h4>
<p>For instance, if a user utilizes the following prompt on the OpenBB Copilot:</p>
<blockquote>
<p><em>Using&nbsp;the&nbsp;earnings&nbsp;transcript,&nbsp;create&nbsp;a&nbsp;table&nbsp;with&nbsp;columns:&nbsp;financial&nbsp;metric,&nbsp;value,&nbsp;sentence&nbsp;in&nbsp;the&nbsp;earnings&nbsp;where&nbsp;it&nbsp;was&nbsp;extracted&nbsp;from.&nbsp;Double&nbsp;check&nbsp;whether&nbsp;the&nbsp;information&nbsp;you&nbsp;are&nbsp;using&nbsp;is&nbsp;correct.</em></p>
</blockquote>
<br>
<p>They get the "<em>Sentence Extracted From</em>" column, which they can copy and paste into a search field added at the top of the Earnings Transcript widget. This enable users to quickly validate the numbers that have been found.</p>
<p>See example below,</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_6.png"></p>
<h4 id="add-deterministic-processes-to-check-for-hallucinations">Add deterministic processes to check for hallucinations</h4>
<p>For example, let‚Äôs say the user prompt involves a data retrieval task.</p>
<p>We can run a deterministic process to check whether the retrieved values exist or not. Sure this won't be 100% accurate because the numbers could be flagged by referring to another thing, BUT it's all about improving the overall accuracy of Copilot.</p>
<p>Ultimately, whatever can be done to improve the Copilot‚Äôs accuracy should be done.</p>
<h2 id="2-agents-are-the-future">2. Agents are the future</h2>
<p>When we think about how humans operate, we recognize that the brain coordinates all the actions of our body and our thought processes. This is similar to how agents work.</p>
<p>If I'm playing soccer, the muscles I use are different from those I would use if I were boxing. If I'm programming, the parts of my brain I use differ from those I would use when listening to music.</p>
<p>However, it's not as simple as "activity A requires legs". Most of your body and mind are always involved, but at different times and in different capacities. And what dictates that are external factors.</p>
<p>For instance, if I am playing soccer as a winger and my team is attacking, I will likely be using both legs to run forward and a lot of mental energy to decide where to position myself on the field.</p>
<p>And that will change a lot based on where the ball is. If the ball is on the opposite side, I'll likely run less and stay more in the middle to be ready for a counterattack. If the ball is in the middle, I'll probably be running at full speed to create space. If the ball is close to me I have to worry more about controlling it and understand what I can do with it next.</p>
<p>The environment affects my plan to carry out an action where I want to have a successful outcome.</p>
<p><strong>This is how agents work.</strong></p>
<p>Agents aren't just about a single LLM performing well, but about a full workflow that interacts with multiple language models, function calls, or any other process to carry an action.</p>
<p>At the core, the biggest advantage of an agent over a LLM is that an agent has a full feedback loop. It understands the impact of the LLM output and can use that data in the next step of the process. Whereas a single LLM API call returns its best output but won't know how that affected the external environment.</p>
<p>This is why, at OpenBB, we believe in compound AI systems.</p>
<p>And apparently, <a href="https://finance.yahoo.com/news/sequoia-sees-bigger-money-ai-203655254.html?guccounter=1">so does Sequoia</a>.</p>
<p align="center"><img width="300" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_7.png"></p>
<h3 id="the-strawberry-issue-will-be-solved">The ‚ÄúStrawberry‚Äù issue will be solved</h3>
<p>A panelist commented on stage that LLMs can‚Äôt even count how many R's are in the word "Strawberry".</p>
<p>This <a href="https://x.com/MwangoCapital/status/1828857579860095428">tweet</a> offers a good explanation of why this happens ‚Äî it turns out it's due to the tokenizer, and it can be solved. In fact, it's solved by simply ensuring that the model takes each letter as a token. See below,</p>
<div class="flex justify-center items-center"><img width="300" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_8.png" style="margin-right:10px"><img width="300" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_9.png"></div>
<br>
<p>This means that the model's output can be improved by doing extra work at the input level.</p>
<p>Data cleaning and pre-processing strikes again? üòÉ</p>
<p>Interestingly, a few days ago, <a href="https://openai.com/o1/">OpenAI announced OpenAI o1</a>. Which is basically GPT-4o with Chain-of-Thought (COT). This means that this model is a "wannabe agent".</p>
<p>It takes in a prompt from the user and decomposes it in natural steps to solve it. Then at each step, it takes the output of the model from the previous step and predicts the next token. It turns out that this improves accuracy substantially.</p>
<p>However, it still doesn‚Äôt have access to external data. And that is why I call it a "wannabe agent".</p>
<p>I love how Jeremiah put it in this <a href="https://x.com/jlowin/status/1834722014839418962">tweet</a>:</p>
<blockquote>
<p>(...) Agents are also characterized by iterative behavior. But there's a key difference: while models like o1 iterate internally to refine their reasoning, agents engage in iterative interactions with the external world. They perceive the environment, take actions, observe the outcomes (or side effects) and adjust accordingly. This recursive process enables agents to handle tasks that require adaptability and responsiveness to real-world changes. (...)</p>
</blockquote>
<br>
<p>So, o1's model isn't an agent - but it can solve this problem. The reason is that it applies its own data cleaning/pre-processing step on its own, and doesn't rely on external factors.</p>
<h3 id="small-language-models">Small Language Models</h3>
<p>Once agents work, Small Language Models (SLM) will be much more viable for very specific use cases.</p>
<p>In logical terms, a Large Language Model is a model with weights.</p>
<p>Large means that it has a lot of them. But what tends to happen is LLMs need to be very big because they want these models to be really good at everything. The problem is that if you want the exact same model to be good at discussing soccer, programming, and speaking Portuguese, its weights are updated using these drastically different datasets. Now the premise is that the more weights there are, the less each weight will be affected by data from completely different domains.</p>
<p>What a big LLM like GPT-4o is doing is trying to build a single Jarvis that knows about everything. Whereas we could have an SLM that does something extremely well and just focus on that, e.g. translating from English to Portuguese. The benefit of an SLM is that inference is likely faster, can be hosted on devices, and, in theory, it's better on a topic because it's been less "contaminated" during training by data that doesn't relate to the task at hand.</p>
<p>Imagine that a firm decides to use an SLM trained to retrieve data from SEC filings quickly and at scale. Or, we could train our own SLM to understand user intent and interact directly with the OpenBB Terminal interface.</p>
<h3 id="large-language-models-as-orchestrator">Large Language Models as orchestrator</h3>
<p>In my opinion, the best LLM in each category will win. And the second and third won't matter. It's a winner-takes-all kind of market. Unless in specific verticals such as inference time or open weights (e.g. for data security; more on this later).</p>
<p>The best example of this is OpenAI vs Anthropic.</p>
<p>I had been using OpenAI's GPT-4 for coding for several months. After trying Anthropic's Sonnet 3.5 for coding, I never went back to OpenAI.</p>
<p align="center"><img width="400" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_10.png"></p>
<p>The market share for the best LLM will be gigantic. That‚Äôs why <a href="https://www.bloomberg.com/news/articles/2024-09-11/openai-fundraising-set-to-vault-startup-s-value-to-150-billion">OpenAI is looking to raise at a $150 billion valuation</a>. While the valuation reflects the market size, the amount that will be raised represents the capital needed to reach that valuation. This is why only a few players will be able to compete at that level.</p>
<p>In an "agentic future", I believe the best LLM will serve as the core "brain" - the main LLM that routes all prompts and decides what happens next.</p>
<p>And who wouldn't want the smartest model controlling the actions with a list of models, functions and data at its disposal?</p>
<p>I know I would.</p>
<p>That's also why, when discussing OpenBB Copilot, we don‚Äôt rely on a single foundational model. Instead, we use the models that are best suited for each specific task.</p>
<p>For instance, OpenAI o1 can be the brains, but when a user uses @web it triggers the Perplexity model, and when they upload an image, we have Anthropic's Haiku. Or maybe if they want to do intraday trading, we use Llama 3.1 through Groq for fast inference.</p>
<p>You get the idea.</p>
<h2 id="3-when-does-it-make-sense-to-fine-tune">3. When does it make sense to fine-tune</h2>
<p>A good comment was made on the panel: "<em>it‚Äôs expensive to spend time fine-tuning a new model, just for that entire work to be 'eradicated' by a new model that has a higher performance in that specific domain than the model has been fine-tuned</em>".</p>
<p>In my opinion, this happens because the timing isn't right yet. We are still unlocking remarkable achievements through each new model release. Although there is a massive bump in terms of capability between these releases, I wouldn't recommend that a firm fine-tune its own models at this stage.</p>
<p>However, at some point, whether due to a lack of data to train or architecture needing to be reinvented, improvements in LLM performance won't be substantial - they may not even be noticeable. This is when the fine-tuning technique becomes relevant because at this stage you are trying to repurpose everything the model has towards a specific vertical / use-case - and at that vertical/use-case that model will be better than the following one.</p>
<p>Then after some new models come out, you may consider reapplying fine-tuning to that model, but this would likely be years later, not weeks or months. So, the ROI can be quite high. Particularly when you are trying to win in your specific market.</p>
<p>This is how I see it working in my head:</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_11.png"></p>
<h2 id="4-compliance-and-data-security">4. Compliance and Data security</h2>
<p>Another question I received was about compliance and data security.</p>
<p>Recently, during a discussion with one of the largest hedge funds in the world, we were asked about the entire workflow of the data when our AI Copilot has access to it.</p>
<p>Their main concern was ensuring that no data was being shared with third-party vendors like OpenAI. For such firms, their data is their alpha, and keeping it within their network is paramount.</p>
<p>Crypto enthusiasts often say, "Not your keys, not your coins" to emphasize the importance of storing assets in a cold wallet rather than leaving them on an exchange that might implode (looking at you, FTX). The same principle applies here: "Not your weights, not your data".</p>
<p>When you send information to a large foundation model provider like OpenAI, your data enters their ecosystem, and you have to trust they‚Äôll honor the terms of your contract.</p>
<p>A more secure approach is to host an open-source model locally within your firm, ensuring that sensitive data remains entirely within your infrastructure and network.</p>
<p>Although open-source models aren‚Äôt yet as powerful as closed-source ones, they are catching up quickly. If you think that GPT-4o can already do a lot for you, think about how at some point there will be an open-source model that is GPT-4o equivalent. Sure, at that time closed-source models will be better, but the question is: How much better?</p>
<p>Or better, the question is: <strong>"How much are you willing to sacrifice in terms of data security for performance?‚Äù</strong>.</p>
<p>At OpenBB, we take this very seriously and have taken measures to allow enterprise customers to fully control their data.</p>
<h3 id="bring-your-own-copilot">Bring your own copilot</h3>
<p>Enable firms to bring their own LLMs to access data within OpenBB. This means that we provide an interface for research, but also allow them to integrate their internal LLMs and interact directly with it from OpenBB.</p>
<div class="flex justify-center items-center"><img width="350" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_12.png" style="margin-right:10px"><img width="350" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_13.png"></div>
<br>
<p>We believe in this idea so much, that we have open-source the architecture for firms to bring their own Copilot to OpenBB. More information is available <a href="https://github.com/OpenBB-finance/copilot-for-terminal-pro/">here</a>.</p>
<h3 id="turn-off-ai-workflows">Turn off AI workflows</h3>
<p>We have incorporated workflows that make users' lives MUCH better. But they come at a cost: sharing data with an LLM provider.</p>
<p>These are the features:</p>
<ul>
<li><strong>Widget title/description suggestion from Copilot</strong>: This sends the content of the table or note output by Copilot to an LLM provider to receive suggestions of a title and description.</li>
</ul>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_14.png"></p>
<ul>
<li><strong>Widget title/description suggestion upon upload</strong>: It sends the content of the file that has been uploaded to an LLM provider to receive suggestions of title and description.</li>
</ul>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_15.png"></p>
<ul>
<li><strong>Copilot chat title generation</strong>: Upon the first user prompt, the content is sent to an LLM provider to update the chat title, reflecting the nature of the conversation.</li>
</ul>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_16.png"></p>
<ul>
<li><strong>Dashboard name generation</strong>: When renaming the dashboard, we send the title and descriptions of all widgets on that dashboard to an LLM provider, to ensure that the suggested name is relevant.</li>
</ul>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_17.png"></p>
<p>To allow firms to keep their data within their network, one of our enterprise features is the option to disable these AI workflows.</p>
<p align="center"><img width="900" src="https://didierlopes.com/blog/2024-09-21-chatgpt-and-the-future-of-ai-in-finance_18.png"></p>
<p>In the future, we could direct these AI workflows to use an LLM that our customers are running locally.</p>
<h2 id="so-in-a-nutshell-what-can-you-expect-from-openbb">So, in a nutshell, what can you expect from OpenBB?</h2>
<p>We are building an AI-powered research workspace.</p>
<p>At the core it is an AI compound system, where users can bring their own data (structured, unstructured, API, custom backend, database, data warehouse, etc..) and have our (or their own copilot) access all this data seamlessly - in an interface that is customizable, flexible and enables teams to work together.</p>
<p>If you want to learn more, e-mail me directly at <a href="mailto:didier.lopes@openbb.finance">didier.lopes@openbb.finance</a></p>]]></content:encoded>
            <category>finance</category>
            <category>ai</category>
            <category>agents</category>
            <category>chatgpt</category>
            <category>quant</category>
            <category>cornell</category>
            <category>twosigma</category>
            <category>blackrock</category>
            <category>citadel</category>
        </item>
        <item>
            <title><![CDATA[Why I love boxing]]></title>
            <link>https://didierlopes.com/blog/why-i-love-boxing</link>
            <guid>https://didierlopes.com/blog/why-i-love-boxing</guid>
            <pubDate>Mon, 09 Sep 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="300" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing.jpeg"></p>
<p>Exploring the parallels between boxing and startup life, and how both push me beyond my comfort zone to foster personal growth, resilience, and continuous learning.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>Recently, I finished reading ‚ÄúThe Art of Learning‚Äù - a really good book that I‚Äôve recommend to everyone (btw, <a href="https://x.com/didier_lopes/status/1742748040220328189?s=20">here</a> is a page of all the books I‚Äôve read in the past few years).</p>
<p>In it, the author Josh Waitzkin, reflects on his journey from chess champion to martial arts practicioner - and how anyone can master the art of learning.</p>
<p align="center"><img width="300" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_1.png"></p>
<p>It made me wonder, why at 29 years old did I decide to step into a ring with boxers who have been fighting for 10+ years? ü•ä</p>
<p>As my friend Max says, ‚ÄúYou don‚Äôt play boxing‚Äù. So why am I doing it?</p>
<p>Similar to setting up a startup, this isn‚Äôt something that‚Äôs easy to explain. The most rationale thing to do would be to go for a run outside or just go to the gym.</p>
<p>Yet, I hop in a ring to fight.</p>
<p>Why?</p>
<p>For starters, there‚Äôs something thrilling about stepping into the ring and knowing that you are going to get punched.</p>
<p>You need to get comfortable with something that - by definition - it‚Äôs uncomfortable.</p>
<h2 id="boxing-is-the-physical-to-what-startups-are-for-the-mind">Boxing is the physical to what startups are for the mind</h2>
<p>Think about it. Most activities that people do in their spare time have a ‚Äúcontrolled‚Äù level of intensity. You get progressively more tired but ‚Äúknow‚Äù it‚Äôs coming - e.g. gym, swimming, tennis, running, etc.</p>
<p>Contact sports are in general like this too, although every now and then you can get injured. Although this rate is small, and sports in general equip athletes to be protected against injuries.</p>
<p>Boxing (and martial arts) don‚Äôt work this way. You step in the ring and within the first few seconds, you may get a hook that gives you a bruise next to your eye or a uppercut that makes you stop breathing for a few seconds.</p>
<p>My point is that with boxing, you don‚Äôt know when you are going to get hurt, but you learn to be comfortable with it and over time your body gets used to that level of pain - so it will take even more to make you uncomfortable.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_2.png"></p>
<h2 id="first-sparring-session">First sparring session</h2>
<p>I still remember my first sparring session, I got hit on the nose and had tears coming out of my eyes from it. My nose hurt for 3 days in a row. It doesn‚Äôt matter how many times the coach told me to keep my hands up, nothing taught me quicker than that cross on my nose.</p>
<p>For the remainder of the fight, I was mostly protecting myself and keeping my distance. I was ‚Äúhumbled‚Äù by the other fighter, and was pushed to outside my comfort zone.</p>
<p>This is not so much different from startup life where mentally you have to be in uncomfortable places - for me this is the equivalent to speaking on a stage. For an introvert like myself, that was something that was hard to overcome. Although I am still not comfortable on a stage, I am much more comfortable than I used to be.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_3.png"></p><p style="font-size:0.8em">Presenting at CIBC a few weeks ago at New York AI meetup</p><p></p>
<h2 id="next-sparring-sessions">Next sparring sessions</h2>
<p>Currently when I step in a ring I have mixed feelings, I‚Äôm somewhat anxious but also excited about it.</p>
<p>It‚Äôs weird.</p>
<p>I mean, I know full well that I‚Äôm going against folks who‚Äôve been in a ring since they were young - and I also know full well that I‚Äôm going to get hit much more than I will hit.</p>
<p><strong>However</strong>, there‚Äôs something exciting (poetic maybe?) about knowing that each time I step into the ring again, I will be able to land more punches, avoid more hits and be better mentally.</p>
<p>Learning is the nature of the game.</p>
<p>And the only failure is to not take any lessons from each fight.</p>
<p>This is the same for startups. I like what Bezos has to say on the topic, about <a href="https://www.youtube.com/shorts/HmYj-UDT8jM">pushing Amazon to embrace failure</a>.</p>
<p align="center"><img width="300" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_4.JPG"></p><p style="font-size:0.8em">This picture was what convinced me to buy my own head gear</p><p></p>
<h2 id="so-why-do-i-love-boxing">So, why do I love boxing?</h2>
<p>I think ultimately, the reason why I love boxing is the same as why I love startups.</p>
<p>Startups push me everyday to be the best that I can be in so many different areas, there isn‚Äôt a role that - for me - is as stimulating mentally as being a startup founder.</p>
<p>There are 100 different initiatives ongoing at all times, you have a team of composed of human beings (by nature, highly complex with different backgrounds and life experiences), you have startups trying to disrupt your business, you have well established incumbents, etc..</p>
<p>Boxing is the same... but at the physical level.</p>
<p>I step in the ring and need to be the best I can in multiple verticals - it isn‚Äôt enough to be the best in one.</p>
<p>I need to have a faster reaction to avoid punches, be light on my feet to surprise an opponent, land the combos where I put most of my energy in, trade-off balance between combos and stamina, and obviously all the mental side that comes from it too - which turns out is quite a lot.</p>
<p>Ultimately, as cheesy as it sounds, being a startup founder and doing boxing make me feel alive.</p>
<p align="center"><img width="300" src="https://didierlopes.com/blog/2024-09-09-why-i-love-boxing_5.jpeg"></p><p style="font-size:0.8em">Taking my father-in-law for a class</p><p></p>]]></content:encoded>
            <category>boxing</category>
            <category>startups</category>
            <category>learning</category>
            <category>growth</category>
        </item>
        <item>
            <title><![CDATA[What I Learned in 3 Years at OpenBB]]></title>
            <link>https://didierlopes.com/blog/what-i-learned-in-3-years-at-openb</link>
            <guid>https://didierlopes.com/blog/what-i-learned-in-3-years-at-openb</guid>
            <pubDate>Tue, 20 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[The OpenBB journey started officially 3 years ago. So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-20-what-i-learned-in-3-years-at-openb.jpeg"></p>
<p>The OpenBB journey started officially 3 years ago.</p>
<p>So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>The OpenBB journey started officially 3 years ago.</p>
<p>So I want to celebrate it by sharing 36 lessons I learned over the past 36 months as a founder and CEO of a fintech company.</p>
<ol>
<li>
<p>Be curious.</p>
</li>
<li>
<p>Talk to users.</p>
</li>
<li>
<p>Protect your time.</p>
</li>
<li>
<p>Do the right thing.</p>
</li>
<li>
<p>Culture is everything.</p>
</li>
<li>
<p>Energy is contagious.</p>
</li>
<li>
<p>Hire slow and fire fast.</p>
</li>
<li>
<p>Write everything down.</p>
</li>
<li>
<p>Reward people who care.</p>
</li>
<li>
<p>Celebrate every little win.</p>
</li>
<li>
<p>Work on your storytelling.</p>
</li>
<li>
<p>Ship often and iterate fast.</p>
</li>
<li>
<p>Listen more than you speak.</p>
</li>
<li>
<p>Be comfortable with saying no.</p>
</li>
<li>
<p>When in doubt, there's no doubt.</p>
</li>
<li>
<p>Over communicate with the team.</p>
</li>
<li>
<p>Have an inherent sense of urgency.</p>
</li>
<li>
<p>Don't overthink, estimate and iterate.</p>
</li>
<li>
<p>Failing is ok, not learning from it isn't.</p>
</li>
<li>
<p>Measure success by impact, not effort.</p>
</li>
<li>
<p>Do not run away from hard conversations.</p>
</li>
<li>
<p>Having common sense is a very powerful skill.</p>
</li>
<li>
<p>How you do anything is how you do everything.</p>
</li>
<li>
<p>It's not because you can build it that you should.</p>
</li>
<li>
<p>Seeing your vision materialize gives goosebumps.</p>
</li>
<li>
<p>Be so excited in your product that users can feel it.</p>
</li>
<li>
<p>Lack of focus is likely the biggest risk you face as a company.</p>
</li>
<li>
<p>It turns out that there's a ton of data in your gut feeling.</p>
</li>
<li>
<p>Make people accountable for both successes and failures.</p>
</li>
<li>
<p>Hiring is the most important thing you will do at your company.</p>
</li>
<li>
<p>Create a culture where feedback is not only welcome but expected.</p>
</li>
<li>
<p>Work side-by-side with the team on things that are considered "boring".</p>
</li>
<li>
<p>Be there for your team when they need you, they will repay you with loyalty.</p>
</li>
<li>
<p>One of the worst things you can do is optimizing something that shouldn't exist.</p>
</li>
<li>
<p>Vast majority of decisions are 2-way door decisions. Make a decision and move on.</p>
</li>
<li>
<p>Startups are hard and fun. Working with people you like makes it less hard and more fun.</p>
</li>
</ol>
<br>
<p>In the past 3 years, we have:</p>
<ul>
<li>The <a href="https://github.com/OpenBB-finance/OpenBB">open source repo</a> has been starred over 28,000 times and 220 contributors</li>
<li>The OG OpenBB Terminal installer was downloaded over 150k times</li>
<li>Refactored that application to a platform that could be pip installable</li>
<li>Enabled users to fully <a href="https://youtu.be/cgeN3Ep2nEw?si=8e5en_xunWcBdKMM">automate their research workflow in a script</a></li>
<li>Open-sourced an <a href="https://github.com/OpenBB-finance/openbb-agents">LLM-powered financial analyst agent built on top of the OpenBB platform</a></li>
<li>Made an <a href="https://openbb.co/products/bot">OpenBB Bot</a> that run over 4M commands in 20k+ servers with 50k+ users</li>
<li>Developed an <a href="https://openbb.co/products/excel">Add-in for Excel</a></li>
<li>Grew to a team of 16</li>
<li>Built a community of over 100k people</li>
<li>And finally, we built the foundation of the <a href="https://openbb.co/products/pro">first AI-powered financial terminal</a> - more on this very very soon.</li>
</ul>
<br>
<p>Personally, during that timeline:</p>
<ul>
<li>I got a second dog</li>
<li>Visited US for the first time</li>
<li>Got married on that first visit</li>
<li>Left London to move to the Bay area a couple weeks after</li>
<li>Moved to NYC</li>
<li>Started boxing regularly</li>
</ul>
<p>We are more locked in than ever before.</p>
<p>Can‚Äôt wait for the next 3 years. ü•Ç</p>]]></content:encoded>
            <category>career development</category>
            <category>technology</category>
            <category>OpenBB</category>
            <category>learning</category>
            <category>leadership</category>
        </item>
        <item>
            <title><![CDATA[Why AI Will Replace Jobs in Finance and How You Should Prepare]]></title>
            <link>https://didierlopes.com/blog/why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare</link>
            <guid>https://didierlopes.com/blog/why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare</guid>
            <pubDate>Tue, 06 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[As AI continues to advance, many jobs in finance are at risk. Learn why this shift is happening and how to prepare for the future.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png"></p>
<p>It's not a matter of if, but a matter of when. AI will replace analysts' jobs, and we actually believe that's a good thing. In this blog post, we explain why and how you can prepare for this revolutionary change in the world of finance.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<h2 id="introduction">Introduction</h2>
<p>This is the current state of Quant/Finance/Investing conferences in 2024</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_1.png"></p>
<p>I‚Äôve heard panels defending both sides: Yes and No.</p>
<p>I think that people who say ‚ÄúNo‚Äù don‚Äôt understand how AI fundamentally works, and most people who say ‚ÄúYes‚Äù are understating the impact it will have.</p>
<p>Personally, a much better question is ‚ÄúWhen will AI replace financial analysts?‚Äù or ‚ÄúHow can I prepare for the shift?‚Äù.</p>
<h2 id="history">History</h2>
<p>If we look back at the automotive industry, 100 years ago - this is what a Ford factory looked like:</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare.png"></p>
<p>How many of these blue-collar workers would have said that their jobs would be extinct in less than 100 years? And for the most part, they are.</p>
<p>This is where we are today in terms of AI.</p>
<p>Some tooling (read: AI) can help humans do their job, but it still needs to be supervised.</p>
<p>But with enough time (for the automotive industry that was 100 years), AI will take over.</p>
<p>This is what Tesla‚Äôs Giga Berlin factory looks like today.</p>
<div class="flex place-items-center justify-center items-center rounded-sm mx-auto"><iframe src="https://www.youtube.com/embed/7-4yOx1CnXE?si=k-adJ_cOlXS6Ldlv" width="800" height="400"></iframe></div>
<h2 id="when-will-ai-replace-financial-analysts">When will AI replace financial analysts?</h2>
<p>Bill Gates famously said: ‚ÄúMost people overestimate what they can achieve in a year and underestimate what they can achieve in ten years‚Äù.</p>
<p>I‚Äôve found this to be mostly true for everything tech.</p>
<p>EXCEPT AI.</p>
<p>This is why I‚Äôm so bullish on the category as a whole.</p>
<p>I subscribe to a few newsletters that share daily AI updates, and it‚Äôs crazy that every single day there‚Äôs something big happening. Either a new model is released and open source, a new framework to do RAG or fine-tune, a new company announces they are working on foundational models, a new paper that pushes the field forward, or a new investment from a big corporation.</p>
<p>I mean, even enterprises are rushing to jump into the AI train. Either releasing AI features to millions of users before proper testing (e.g. Gemini overview on Google and the whole Reddit answers), adding AI where it isn‚Äôt really necessary (e.g. Meta AI on WhatsApp), exploring new monetization opportunities (e.g. Amazon Bedrock for fine-tuning) or risking on their values to not be left behind (e.g. Apple partnering with OpenAI ‚Äî risking the security brand they worked so hard for).</p>
<p>So, I think this will happen soon.</p>
<p>And it‚Äôs with that in mind that we have been building OpenBB.</p>
<h2 id="how-can-i-prepare-for-the-shift">How can I prepare for the shift?</h2>
<p>I think that the most important question that financial analysts should ask themselves is not ‚Äò<strong>when</strong>‚Äô but ‚Äò<strong>what can I do to prepare myself for when AI starts taking over</strong>‚Äô.</p>
<p>There‚Äôs going to be multiple stages before AI fully takes over. Here‚Äôs how I envision it playing out:</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-06-why-ai-will-replace-jobs-in-finance-and-how-you-should-prepare_2.png"></p>
<p>(For what it‚Äôs worth, I think this is equivalent to what will happen to developers in general).</p>
<h3 id="short-term">Short term</h3>
<p>We are starting to enter this timeline.</p>
<p>A timeline where analysts will use AI to augment their output.</p>
<p>A good analyst using AI will be able to perform at a better level than a great analyst who doesn‚Äôt use AI.</p>
<p>Interestingly, a mediocre analyst will be able to increase their output but nowhere as much as a good or great analyst. This is because the AI usage will supervised and still ‚Äúdriven‚Äù by the analyst (through prompts). So mediocre analysts will not benefit as much because they will either trust too much the AI (without being able to discern its validity), not use the best prompts because they don‚Äôt know what to use the AI for, or not use the output because they won‚Äôt comprehend the insights that the AI is generating.</p>
<p>During this period, the gap between mediocre and great analysts will be at an all-time high. This will expose more who is pushing their weight and who isn‚Äôt.</p>
<p>Another thing is that firms that will be hiring high-talented juniors/interns will start adding AI experience as a requirement (e.g. OpenBB experience) since they understand that they will have a higher leverage and their output will be much better. Potentially even replacing a current analyst with many years of experience that doesn‚Äôt leverage AI in the day-to-day.</p>
<p>I think there are 2 reasons for this:</p>
<ol>
<li>
<p><strong>AI will allow financial analysts to have much broader mandates</strong> as they will be able to automate the process of research and screen the best companies. Instead of analyzing 20 companies per quarter, they will do 500.</p>
</li>
<li>
<p><strong>AI will be able to extract trends and patterns that humans simply can‚Äôt due to the amount of data necessary to process</strong>. The amount of data that financial firms use to invest is constantly on the rise, that‚Äôs where they get their alpha from. Given that an analyst has a limited amount of resources, they will either have to narrow down the companies in their mandate or process less data for each.</p>
</li>
</ol>
<h3 id="long-term">Long term</h3>
<p>In the long term, AI will start taking the reigns.</p>
<p>This is the equivalent of self-driving cars becoming fully autonomous.</p>
<p>The gap between mediocre and great analysts will narrow over time because AI is doing all the heavy work.</p>
<p>At that time, it will be very hard to distinguish the competency of mediocre and great analysts ‚Äî the main indicator will be how they interpret/understand the AI model, i.e. how they can explain what led to the AI ‚Äúdeciding‚Äù to invest in companies based on hundreds of different datasets.</p>
<p>This is why we spend hours obsessing over the UX of the <a href="https://openbb.co/products/pro">OpenBB Terminal Pro</a>. We want to make sure analysts know at all times what the AI Copilot is doing and thinking. Because interpretability will be a big topic in the future.</p>
<p>It‚Äôs important to note that the best analysts will be the ones who have their jobs more secure over time. That is because provided the AI is taking the reigns, when it fully takes the reigns, the output of all analysts will be more or less the same. However, in the period before, the great analyst will have an edge because their skill is still in use and so the leverage lever is bigger.</p>
<p>I think that when AI fully takes over analysts' jobs, the best ones will move towards opening their investment firms and focus on the human part of the job: communication.</p>
<p>Communicating to their investors why they made their decisions, e.g. ‚ÄúWe have access to this dataset which others don‚Äôt, and our AI model correlated that data with x, y, and z which enabled us to invest ahead of the rest of the market‚Äù. This is the ‚Äúinterpretability‚Äù of the AI that I mentioned earlier.</p>
<h2 id="what-can-you-do">What can you do?</h2>
<p>You should still pursue a career in the space.</p>
<p>But you should do so with AI in mind.</p>
<p>Experiment with products out there that leverage AI to make you more efficient (you can try OpenBB for free at pro.openbb.co). You will soon realize that your output can compete with someone who is neglecting AI in their day-to-day.</p>
<p>Being a top financial analyst is still something you should strive for since these are going to be the last to be replaced. And when they are, you will still have an edge because your role is likely to evolve into a communication/management role that explains what the AI is doing to investors. And that would be much easier if you‚Äôre a top analyst in the first place - because you would understand the insights extracted from an AI copilot.</p>
<p>What is your opinion on this topic?</p>]]></content:encoded>
            <category>artificial intelligence</category>
            <category>finance</category>
            <category>career development</category>
            <category>technology</category>
            <category>future of work</category>
        </item>
        <item>
            <title><![CDATA[Inspired by Bia - How Her Fight Against Cancer Changed My Life]]></title>
            <link>https://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life</link>
            <guid>https://didierlopes.com/blog/inspired-by-bia-how-her-fight-against-cancer-changed-my-life</guid>
            <pubDate>Thu, 01 Aug 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG"></p>
<p>In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>This cause could not have been a personal one, but it is.</p>
<p>As a young kid from a small town in Portugal, people who die from cancer are on TV and I don't know them personally.
&nbsp;
My friends &amp; family are ‚Äúprotected‚Äù by an imaginary shield that I created in my head.</p>
<p>Until they aren‚Äôt.</p>
<p>Let me go back down memory lane and talk about Beatriz.</p>
<p>Bia was in my class in high school.</p>
<p>We started talking here and there.</p>
<p>Before I knew it, she was my best friend.</p>
<p>We would talk for hours about everything and nothing - always laughing.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life.JPG"></p>
<p>We would sit next to each other and professors would have a hard time with us because we liked to chit chat.</p>
<p>So we created a new communication medium to not get caught.</p>
<p>We would rip the side of those pages and write in very small font notes to each other.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_1.jpg"></p>
<p>We would go through multiple of these in each class.</p>
<p>It was our thing.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_2.JPG"></p>
<p>A few months later, we had a sports class and she felt weak from her wrist.</p>
<p>She didn't really like sports. So I remember making fun of her for trying to find an excuse to skip sports class.</p>
<p>That would be the last time I made fun of that.</p>
<p>She went to the hospital the day after, and to another one soon for a second opinion.</p>
<p>She had cancer. On her back.</p>
<p>Her floor was pulled from under her.</p>
<p>She was 16 and while kids her age were worrying about boys and school grades, she had to fight for her life.</p>
<p>At fucking 16.</p>
<p>The crazy part is that the attitude she had with others was the same.</p>
<p>She would not display any weakness throughout none of it.</p>
<p>She was so strong. At 16.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_3.png"></p>
<p>One day I visited her and she had no hair because of chemotherapy.</p>
<p>She was still the same beautiful and happy girl that I loved.</p>
<p>Underneath it all, I don't know where she got the strength to go through it.</p>
<p>The school adapted the classes to be livestream so that she could attend from home.</p>
<p>Not only she wasn't gonna lose this battle but she didn't want to lose 1 year of school either.</p>
<p>She was incredibly smart for her age. So losing a year wasn't an option for her.</p>
<p>At the graduation she wrote me a message. She didn't have strength in her hand to write so she used her wrist to be able to write it in an iPad.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_4.JPG"></p>
<p>The translation doesn‚Äôt make it justice, but it reads as:</p>
<blockquote><p>Didier</p><br><p>It was in the middle of laughter, in the middle of playfulness.</p><br><p>It was in the middle of tantrums and misunderstandings.</p><br><p>It was in the middle of sheets of paper fallen on the floor and of pieces of paper so efficiently utilized.</p><br><p>It was like this that our friendship grew!</p><br><p>Beatriz ‚ù§Ô∏è</p></blockquote>
<br>
<p>Saturday morning I got a call. A common friend let me know that she passed away unexpectedly.</p>
<p>I was still in bed. I cried for hours. I didn't want to wake up. Maybe some part of me never did.</p>
<p>She had her entire life ahead of her.</p>
<p>She was kind, curious and loving. She would have accomplished so much.</p>
<p>Yet she was gone.</p>
<p>No one deserves to lose their best friend at 17. Not like that. It wasn't fair.</p>
<p>But that's cancer for you.</p>
<p>Cancer doesn't care.</p>
<p>It never did.</p>
<p>From that moment onwards I changed my attitude towards life.</p>
<p>I stopped doing things for the sake of doing them and always put 120%.</p>
<p>I went from spending most of my time as a gamer and doing just enough to have good grades in high school to being the best student of my year in my BSc in Electrical and Computer Engineering, moving to London to have a distinction at Imperial College London (top 2 uni in the world) and now moving to NYC to increase chances of success for my startup.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-08-01-inspired-by-bia-how-her-fight-against-cancer-changed-my-life_5.jpeg"></p>
<p>I have a tattoo that says ‚ÄúAll her would-haves are our opportunities" (which is from Anne Frank's house in Amsterdam) to remind me that every day I have opportunities that she didn't get to experience.</p>
<p>But I hope that in some way, shape or form, she is.</p>
<p>And that I make her proud.</p>
<p>Stories like this are not as uncommon as you may think they are.</p>
<p>It took me over 10 years to talk about how cancer took my best friend‚Äôs life away.</p>
<p>Imagine the number of people who never write about how it impacted their lives.</p>
<p>If anything, my objective with this post is to highlight that cancer is real.</p>
<p>In a time when we talk about going to Mars and having AGI, cancer is still taking lives every day...</p>
<p><a href="https://haymakersforhope.org/">Haymakers for Hope</a> is fundraising to help organizations fighting for the cause.</p>
<p>Although I wasn't selected to participate in the Boxing match that happens in NYC to support the cause, I will be there.</p>
<p>Consider to either <a href="https://haymakersforhope.org/events/boxing/hope-nyc-xi-2024">donate to the fighters</a> or buying a ticket to attend.</p>
<p>And if you buy a ticket, the first drink at the event is on me.</p>
<p>See you on the 14th of November. ü•ä</p>]]></content:encoded>
            <category>cancer</category>
            <category>development</category>
            <category>disease</category>
            <category>charity</category>
            <category>personal</category>
        </item>
        <item>
            <title><![CDATA[My first-hand experience on AI impacting education through Perplexity, Cursor and ChatGPT]]></title>
            <link>https://didierlopes.com/blog/my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt</link>
            <guid>https://didierlopes.com/blog/my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt</guid>
            <pubDate>Sun, 30 Jun 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt.png"></p>
<p>AI will change education forever. Here's how I leveraged Perplexity, Cursor and ChatGPT to teach Supervised Learning and assess coursework.</p>
<p>The open source code is available <a href="https://github.com/DidierRLopes/supervised-learning">here</a>.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>Recently I was invited to teach a course in Big Data and Data Analytics at Europeia University. I gave 4 hours of classes, divided into:</p>
<ul>
<li>Supervised Learning - Theory</li>
<li>Supervised Learning - Practice</li>
</ul>
<p>And then evaluated the students coursework.</p>
<h2 id="creating-a-new-syllabus">Creating a new syllabus</h2>
<p>My past experience as a teacher happened during my BSc., back in 2016, where I was a TA for the course of Signal Theory and had to help students in their coursework through Matlab/Octave.</p>
<p>Things were different at the time because I had a syllabus to follow and most of my time was spent helping students if they were blocked coding-wise or had some questions regarding the theory.</p>
<p>And of course - there was no AI. At least not in the sense that we speak about today - i.e. there were no LLMs.</p>
<p>This time was different - I had the flexibility to choose what I was going to cover about Supervised Learning.</p>
<p>I‚Äôve never worked as a Data Scientist per se, but have been passionate about data for a while and spent a lot of time reading books and learning about the topic. In my previous company, I started playing with IMU data in my spare time which lead me to publish a paper at ICMLA where I used <a href="https://ieeexplore.ieee.org/document/9680024">Support Vector Machine (SVM) for Step Detection using Nurvv trackers</a> and even open sourced the code <a href="https://github.com/DidierRLopes/step-detection-ML/tree/main">here</a>.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_svm_paper.png"></p>
<p>I've wrote about this and how I managed to write the entire code in my spare time in a single week, and missing the yearly team event in order to pull this off. You can read more about it <a href="https://didierlopes.com/blog/how-i-wrote-a-machine-learning-paper-in-1-week-that-got-accepted-to-icmla">here</a>.</p>
<p>But so the question is:</p>
<p><em>"Where do I start?"</em></p>
<p>My first intuition was to gather some of my favorite books and courses on the topic and understand how they presented the overall subject. I wouldn‚Äôt have the same time, so I would need to touch on most topics briefly - enough for students to know about it and explore further if curious.</p>
<p>However, given my time constraints with running OpenBB, I would have had a hard time since I would need to:</p>
<ol>
<li>Consume the content of these books and courses</li>
<li>Mix and match them</li>
<li>Cut to fit the time constraints</li>
<li>Produce a final syllabus that I‚Äôm confident about</li>
</ol>
<br>
<p>This was not a trivial task, and definitely not a weekend job.</p>
<p>Except that <strong>IT WAS</strong>.</p>
<h3 id="perplexity-enters-the-chat">Perplexity enters the chat</h3>
<p>Since Perplexity‚Äôs main value proposition is being better at Google than Google - I popped the following prompt into it.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_perplexity.png"></p>
<p>BAM.üí•</p>
<p>This was exactly what I was looking for.</p>
<p>Did it give me the content end-to-end that I was expecting?</p>
<p>No.</p>
<p>Was it a perfect starting point?</p>
<p>Yes.</p>
<p>I didn‚Äôt literally copy-paste it. I took the parts I liked, re-iterated on the ones I didn't until I eventually did. Plus, use my experience to prioritize parts that I felt should be more relevant vs others.</p>
<p>Were there some hallucinations?</p>
<p>Yes, it‚Äôs not a silver bullet.</p>
<p>But it saved me DAYS of work.</p>
<p>I was dreading having to write the syllabus and like this, it was actually fun. It was fun because I felt like Perplexity was acting as my assistant and I was engaging in a conversation of what should be contained within the course and what shouldn‚Äôt.</p>
<p>After having all the content ready, I asked my wife to help me with some images to make it easier for students to understand concepts.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_assets.png"></p>
<p>I was happy with the results - but wanted a second opinion. So I asked a friend of mine who‚Äôs been a DS for over 6 years what his thoughts were on the materials I worked on - and he was impressed about the speed.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_ai_friend_message.jpeg"></p>
<p>Being a fan of open source, I have open sourced all the theory and practice of the course and you can access it here: <a href="https://github.com/DidierRLopes/supervised-learning">https://github.com/DidierRLopes/supervised-learning</a></p>
<p>For the practice exercises I made it so that users can run it with colab directly on the browser to focus on the learning and not on the installation of libraries - highly recommend doing this.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_colab.jpeg"></p>
<h2 id="assessing-students-grades">Assessing students grades</h2>
<p>After presenting the classes to the students, they had to work on a final project that involved supervised learning - and I had to grade their work on it. The grade was from 0 to 5 and I was given freedom in terms of what criteria to use.</p>
<p>So I did what someone else in my shoes would do.</p>
<h2 id="chatgpt-to-define-grading-criteria">ChatGPT to define grading criteria</h2>
<p>I typed <a href="http://chat.openai.com/">chat.openai.com</a> and had a conversation with ChatGPT about the best way to grade the coursework. I wanted it to be as fair as possible, but also evaluate students based on criteria outside of coding, such as problem formulation and documentation/clarity.</p>
<p>Note: Story for another day but with the raise of LLMs, I have a very strong opinion that documentation and clarity will be as important as the code itself.</p>
<p>This is the outcome of that conversation:</p>
<blockquote>
<p><strong>PART I - Problem Formulation</strong></p>
<ul>
<li>
<p>1.a. <strong>Clarity and Definition:</strong> Is the problem clearly defined and well-formulated? Are the project's objectives explicitly mentioned?</p>
</li>
<li>
<p>1.b. <strong>Relevance and Context:</strong> Is the relevance of the problem within the application domain explained? Does the problem justify the use of supervised learning?</p>
</li>
</ul>
</blockquote>
<br>
<blockquote>
<p><strong>PART II - Documentation and Quality</strong></p>
<ul>
<li>
<p><strong>2.a. Code Quality and Readability:</strong> Clarity and Structure: Is the code well-organized with clear and consistent formatting? Are comments used effectively to explain complex logic? Best Practices: Does the code follow standard coding practices (e.g., naming conventions, modularization)? Are functions and classes used appropriately?</p>
</li>
<li>
<p><strong>2.b. Documentation and Explanation in Comments or Notebook Markdown</strong>: Clarity: Are the results and methodology clearly documented? Is there a detailed explanation of the steps taken and the reasons behind them? Visualization: Are visual aids (e.g., graphs, plots) used to illustrate key points and results? Are these visualizations clear and informative?</p>
</li>
</ul>
</blockquote>
<br>
<blockquote>
<p><strong>PART III - Code</strong></p>
<ul>
<li>
<p><strong>3.a. Data Preprocessing and Cleaning</strong>: Completeness: Are all necessary steps for data preprocessing included (e.g., handling missing values, encoding categorical variables, scaling features)? Justification: Are the preprocessing steps justified and explained? Is there a clear reason for the choices made?</p>
</li>
<li>
<p><strong>3.b. Data Exploration</strong>: Initial Analysis: Is there an exploratory data analysis? Are descriptive statistics used to better understand the data? Visualization: Are visualizations (e.g., graphs, plots) used to illustrate data distribution, correlations, and important patterns? Are these visualizations clear and informative?</p>
</li>
<li>
<p><strong>3.c. Model Implementation and Training</strong>: Correctness: Is the model implemented correctly according to the chosen algorithm? Are appropriate libraries and functions used? Parameter Tuning: Is there evidence of parameter tuning or optimization? Are the chosen parameters explained and justified?</p>
</li>
<li>
<p><strong>3.d. Evaluation and Validation</strong>: Metrics: Are appropriate evaluation metrics chosen and calculated? Are these metrics relevant to the problem at hand? Validation Techniques: Are appropriate validation techniques used (e.g., cross-validation, train-test split)? Is there an analysis of the model's performance on both training and testing data?</p>
</li>
</ul>
</blockquote>
<br>
<p>This was it.</p>
<p>Exactly what I was looking for.</p>
<p>Now I could grade a student on each of these criteria, then select a final grade weight for each criteria (e.g. 5-15%), create a spreadsheet with such a table and call it a day.</p>
<p>However, the most time-consuming task was coming - the grading itself.</p>
<p>There were 10 groups in total. So 10 notebooks that I had to look into, exploring completely different datasets with a different ML model being used, different ways to do exploratory data analysis, different ways to assess the model, different objectives, ‚Ä¶</p>
<h3 id="cursor-helping-with-grading">Cursor helping with grading</h3>
<p>I opened <a href="https://www.cursor.com/">cursor</a> (which is basically VSCode + ChatGPT) and probably the software I‚Äôve recommended the most to developers in 2024.</p>
<p>And opened my first notebook.</p>
<p>Then I thought, what if I had GPT-4o on my side - helping me to assess this coursework.</p>
<p>It didn‚Äôt need to be perfect because I was doing it myself, but it could help me understand if there was any critical thing that I missed OR if it completely had a different grade than the one I was going to provide - which would enable me to spend more time on that criteria and iterate.</p>
<p>It gave me confidence that I was being fair to the students.</p>
<p>And made me realize how hard it is for professors when they have 100s of students and have a subjective answer to grade. It‚Äôs impossible to get it right. They try their best, but as soon as the answer is not binary (0 or 1), they are doomed to fail.</p>
<p>So how did I do it?</p>
<p>Given that I just wanted GPT-4o to quickly review each of the criterias based on the code, I created a prompt that I could use for all of notebooks that the students sent.</p>
<p>This is what my setup looked like</p>
<p align="center"><img width="1000" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor.png"></p>
<p>Having the code on the left side and the copilot on the right side that I could use to chat really enabled me to grade more confidently.</p>
<p>Here‚Äôs an example of a section of a response I got to one of the student‚Äôs notebooks</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-30-my-first-hand-experience-on-ai-impacting-education-through-perplexity-cursor-and-chatgpt_cursor_output.png"></p>
<p>One thing I did to have the copilot produce better outputs was to push it to do chain-of-thought (CoT). Meaning that I prompted the model to explain the reasoning behind a decision before providing a grade. This has been proved to yield to less hallucinations and more accurate responses - which is what I was looking for.</p>
<p><strong>What if I wanted to do this at scale?</strong></p>
<p>I would have put more effort into the prompt and focused on evaluating 1 criteria at a time. I would have done few-shot prompting where I put examples of what grades 1,2,3,4,5 look like for such criteria so the model has those references and can check for similarity of issues committed or successful tasks performed.</p>
<p>Note: the model was able to interpret comments written in Portuguese which is another benefit.</p>
<h2 id="democratizing-access-to-tutors">Democratizing access to tutors</h2>
<p>While I was working on my prompts to get some feedback from AI in terms of student‚Äôs coursework I realized that I only need $20/mo to access them.</p>
<p>But then I realized - so do the students.</p>
<p>This means that the students have no reason to NOT run their entire coursework by a LLM that can act as a critic of their work.</p>
<p>They can keep iterating until the model doesn‚Äôt find anything - hence making students feel more confident about the work they are putting forward.</p>
<p>My initial thought was: ‚Äúthis feels like cheating‚Äù (right after the - ‚ÄúI wish I had this a few years ago‚Äù).</p>
<p>But it actually isn‚Äôt.</p>
<p>Tutors have existed for a long time.</p>
<p>Students pay tutors to spend time with them to learn outside of classes - whether it‚Äôs explaining the theory or helping with coursework.</p>
<p>However, tutors are a vitamin and not a painkiller (they are a nice-to-have and not a must-have). And because they aren‚Äôt a requirement, it‚Äôs not a typical choice among lower-income families.</p>
<p>On the other hand, kids from wealthy families often have multiple tutors. Not for students who are almost failing their class, but who want to bump their grades from A- to an A+.</p>
<p>But this is about to change.</p>
<p>For the most part, GPT-3.5 is accessible for free.</p>
<p>This means that everyone can have access to a tutor that they can work with to have better grades but also produce better coursework.</p>
<p>This means that the concept of a tutor will be democratized and the playing field between students who come from different wealth backgrounds will be leveled and fair.</p>
<h2 id="a-final-thought-on-open-source">A final thought on open source</h2>
<p>Another class that I had to give to students was "Data Analytics in Financial Markets".</p>
<p>The goal here was to have a more real-life application of data analytics, particularly in financial markets - and even feature OpenBB which has partnered with this university.</p>
<p>But when I started working on the content from scratch, I wondered.</p>
<p>Can't I find a repository on GitHub that suits my needs?</p>
<p>And I did.</p>
<p>The GitHub repository I found was the GitHub repository that contains the code for the case studies in the O'Reilly book "Machine Learning and Data Science Blueprints for Finance" written by my friend <a href="https://www.linkedin.com/in/hariomtatsat/">Hariom Tatsat</a>: <a href="https://github.com/tatsath/fin-ml">https://github.com/tatsath/fin-ml</a>.</p>
<p>So why would I spend the time re-inventing the wheel when I could just walk students through a few of these case studies?</p>
<p>This is what I did.</p>
<p>Which then made me think that all of this data has been already fed into foundational models, and so even if I were to apply the same approach I did earlier with Perplexity or ChatGPT - it is likely that with a good prompt some of the main examples would have been derived from this repository.</p>
<p>But in this case, this repository already had the perfect case-study format I was looking for, and so I can more easily credit the author.</p>
<p>which made me wonder:</p>
<p><em>How will open source authors be able to get credit for their work when all of it is being translated into weights in a big neural network architecture?</em></p>]]></content:encoded>
            <category>education</category>
            <category>ai</category>
            <category>perplexity</category>
            <category>chatgpt</category>
            <category>cursor</category>
            <category>students</category>
            <category>big data</category>
            <category>analytics</category>
            <category>supervised learning</category>
            <category>machine learning</category>
        </item>
        <item>
            <title><![CDATA[Why chat-only AI Financial Assistants are not the future]]></title>
            <link>https://didierlopes.com/blog/why-chat-only-AI-Financial-Assistants-are-not-the-future</link>
            <guid>https://didierlopes.com/blog/why-chat-only-AI-Financial-Assistants-are-not-the-future</guid>
            <pubDate>Sat, 15 Jun 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future.png"></p>
<p>Financial assistants structured like ChatGPT are great for quick searches but fall short for comprehensive investment research. They are limited by their one-dimensional approach, which hinders efficient data retrieval and long-term usability. Read on to discover how OpenBB Terminal Pro addresses these issues with a three-dimensional solution.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>This is a spicy take but bear with me.</p>
<p>The more I think about ‚ÄúChatGPT for Finance‚Äù products, the more I think this is not the answer.</p>
<p>They are extremely good knowledge retrieval engines because you can ask what you want to know and get the answer immediately.</p>
<p>My problem with their approach is what happens after.</p>
<p>However, very little thought is given to the real-world investment workflow. That's why I strongly believe that a chat-only financial platform will never be successful on its own.</p>
<p>Sure, they can win in the categories of ‚Äúsearch‚Äù or ‚Äúscreening‚Äù, but they won‚Äôt be able to compete in the category of ‚Äúinvestment research platform‚Äù.</p>
<p>To do that, they would need to evolve.</p>
<p>Let me explain why and how OpenBB differs from them.</p>
<h2 id="1-dimensional-vs-n-dimensional">1-Dimensional vs N-Dimensional</h2>
<p>Financial assistants are, in general, 1-dimensional. By that, I mean that all you have on a screen is a ‚Äúdashboard‚Äù with an unlimited y-axis (1 single dimension).</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_1.png"></p>
<p>This means that whatever information they output will always be in the same position, which is great for the short term.</p>
<p>But for the long term? Not so much. If the user wants to find specific information, they will need to keep scrolling up the text to find it.</p>
<p>When financial assistants allow multiple conversations, then we start having 2 dimensions, where each conversation introduces a new axis.</p>
<p>The problem with this approach is that you can‚Äôt easily find data within one of those past conversations since the assistant focuses on answering your question and not on data retrieval from the previous outputs.</p>
<h2 id="our-3-dimensional-solution-on-terminal-pro">Our 3-dimensional solution on Terminal Pro</h2>
<p>How do we handle those issues? We have 3 dimensions.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_2.png"></p>
<p>Our Terminal Pro has a Copilot on the side, similar to other financial assistants.</p>
<p>However, its big advantage is that when you want to save Copilot‚Äôs output for later, you can convert it into a text widget. And when you do so, you can place it wherever you want in this space ‚Äî with the axis being infinite vertical scroll, tabs, dashboards, and folders.</p>
<video controls=""><source src="https://openbb-cms.directus.app/assets/ebdda68a-95f7-425b-aebe-5c98936c9189"></video>
<h2 id="storage-based-solutions-are-not-optimized-for-investment-research">Storage-based solutions are not optimized for investment research</h2>
<p>Again, financial assistants are optimized for search rather than information storage.</p>
<p>This means that, by nature, chat-only financial assistants assume that their output will not matter in the future, so they answer your queries similarly to how a text conversation works. It's literally called ChatGPT for that reason.</p>
<p>However, that‚Äôs not ideal for investment research.</p>
<p>If analysts and researchers need to access these financial assistants' output at some point in the future, they won‚Äôt be able to do it quickly. Instead, they‚Äôll have to go through a long chat history.</p>
<p>This is why, in our Terminal Pro, we allow users to create a markdown-based text widget from the Copilot‚Äôs output, as shown above, so that you can have that information quickly accessible, but also editable.</p>
<h2 id="theres-no-simple-way-to-know-where-the-data-comes-from">There‚Äôs no simple way to know where the data comes from</h2>
<p>Financial assistants are great, and they are improving every day. But if there‚Äôs something I‚Äôve learned from talking with financial firms for over three years, it's that this is a very slow-moving industry, and adopting new technologies takes time.</p>
<p>But with AI, it seems different. It‚Äôs so revolutionary that people are willing to incorporate it into their workflow faster because they immediately understand the benefits it can bring to their business.</p>
<p>However, hallucinations are still a big problem ‚Äî so it‚Äôs essential for these firms to be able to verify the raw data and sources.</p>
<p>The current level of AI is equivalent to having a smart intern that you would need to double-check their work or trust but verify.</p>
<p>This is why our Copilot always answers based on data that is readily available on the dashboard ‚Äî and (due to our ‚ÄúBring Your Own Data‚Äù technology) that data can be brought by your firm rather than being limited to what we offer out of the box.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_3.png"></p>
<h2 id="financial-chats-are-not-collaborative">Financial chats are not collaborative</h2>
<p>Financial assistants are not collaborative by default.</p>
<p>When someone opens a tool like ChatGPT, they are interested in getting an answer to their question. Can you imagine what would happen if more people had access to that conversation and asked ChatGPT a different question? That would translate into a horrible user experience.</p>
<p>The interesting thing is that investment research starts as an individual process but ends up being a collaborative effort where the findings are shared and discussed within a team.</p>
<p>So, financial assistants have a challenging task: multiple people on a team should be able to access all the conversations without being able to interact with these chats.</p>
<p>But what if you go through a colleague‚Äôs chat where they were asking questions about a company‚Äôs earnings, and you want to do a follow-up question?</p>
<p>That‚Äôs a complex problem.</p>
<p>At OpenBB, we are in a very good position to solve this for our users.</p>
<p>Since we allow them to create a widget from their conversation with the Copilot, users can effectively create the ideal dashboard to share with their team. On their turn, other team members will then be able to use the Copilot on that same dashboard to make their questions.</p>
<p>And guess what?</p>
<p>This can be considered yet another dimension that we allow users to explore.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-15-why-chat-only-AI-Financial-Assistants-are-not-the-future_4.png"></p>
<h2 id="wrap-up">Wrap up</h2>
<p>In a nutshell,</p>
<ul>
<li>
<p>Most AI financial assistant products are 1-dimensional. Great at retrieving an answer quickly but poor at the overall task of doing investment research.</p>
</li>
<li>
<p>OpenBB Terminal Pro is positioning itself as a flexible and customizable investment research platform with N-dimensions that an AI copilot can control to produce a full investment dashboard as if it were an analyst.</p>
</li>
</ul>
<p>I'm biased, but once we provide the OpenBB Copilot with the capability to interact with the interface (create widgets, dashboards and folders) we might be the company that gets closest to replace an analyst's job.</p>]]></content:encoded>
            <category>finance</category>
            <category>ai</category>
            <category>openbb</category>
            <category>chat</category>
            <category>finance assistant</category>
            <category>chatgpt</category>
            <category>perplexity</category>
            <category>investment research</category>
        </item>
        <item>
            <title><![CDATA[29 years old and sitting on the top of giants]]></title>
            <link>https://didierlopes.com/blog/29-years-old-and-sitting-on-the-top-of-giants</link>
            <guid>https://didierlopes.com/blog/29-years-old-and-sitting-on-the-top-of-giants</guid>
            <pubDate>Wed, 05 Jun 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Yesterday was my 29th birthday, and I was reflecting on my life and on how sitting on the top of giants isn‚Äôt given enough credit. My giants are my parents.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-06-05-29-years-old-and-sitting-on-the-top-of-giants.png"></p>
<p>Yesterday was my 29th birthday, and I was reflecting on my life and on how sitting on the top of giants isn‚Äôt given enough credit. My giants are my parents.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<p>Yesterday I turned 29 years old.</p>
<p>The night before, I was speaking with my dad about how grateful I am for everything he‚Äôs done for my brother and I.‚Ä®‚Ä®I always had everything - food at the table, a roof and education.</p>
<p>I‚Äôm the person I am today because of my parents.</p>
<p>But my dad didn‚Äôt have it easy.</p>
<p>And so instead of writing about how grateful I am for the life I have today, I want to share some parts of my dad‚Äôs life.</p>
<p>I don‚Äôt like to share personal information about my family, but I feel like from all the posts I read on success - sitting on the top of giants isn‚Äôt given enough credit.</p>
<p>My giants are my parents.</p>
<p>Here‚Äôs his story.</p>
<p>My dad grew up with very little in a town in the middle of nowhere in Portugal with 6 siblings.</p>
<p>He did a few years in school and after classes he would come home and watch his parents sheep until it was dark. He did his homework during that time since there was no electricity back then.</p>
<p>If a sheep ran away while he was doing his homework, his dad would punish him with whatever was at hand, a stick or a belt.</p>
<p>Times were different back then.</p>
<p>In school, if he got questions like 7x8 wrong, teachers wouldn‚Äôt just say the correct answer. They had a special ruler that was used to hit a student‚Äôs hand.</p>
<p>Again, times were different.</p>
<p>After a couple of years in school - he didn‚Äôt like it (I wonder why eh) and they didn‚Äôt have a lot of money. So he started working at the age of 11 in construction.</p>
<p>An 11 year old kid, taking 2 buckets of cement up and down the stairs to build houses.</p>
<p>At the age of 17 he moved to Geneva (Switzerland) for a better paid job, as a bricklayer but also did painting jobs and similar.</p>
<p>At 18, his mum died.  She was run over by a car near our hometown.</p>
<p>At 20, he had to come to Portugal because of his passport and he met my mum.</p>
<p>1 year later, my mum moved to Geneva to be with him. She worked in a factory making boxes for Rolex watches.</p>
<p>At 22, his dad died from a disease.</p>
<p>He kept working his ass off. 6 days a week, starting at 6 am whether it was snowing, raining or extremely hot.</p>
<p>No travelling or unnecessary expenses, except tobacco, it was his only addiction as everyone around him smoked - it was a social thing.</p>
<p>At 24 he got married with my mum. My mum‚Äôs family didn‚Äôt like his, so they didn‚Äôt attend the wedding and they had to cover it with all of their savings.</p>
<p>At 31, he had me.</p>
<p>The week before I was born would be the last he would ever smoke, since my mum said that she didn‚Äôt want smoke near us because of our health. At some point he was smoking 2 packs a day, and he stopped from one day to the other which is wild.</p>
<p>At 32 his painting shift had just finished and his boss asked him to give one more painting layer to the outside of an apartment. And he went up the ladder, and it broke. He fell from a 2-story apartment on his foot, and his foot bone got smashed into pieces. (He had actually mentioned to his boss that the ladder didn‚Äôt feel very stable earlier that day).
‚Ä®The doctor told him that he would never be able to do any physical work ever again. 24 years later, and he still struggles to walk for long periods of time.</p>
<p>At 33, he had my brother.</p>
<p>Because of the accident, he stayed at home to raise my brother and I.</p>
<p>A bit after, Portugal joined the Euro. So my dad thought that the living conditions in Portugal would improve overall like other European countries (spoiler alert: it didn‚Äôt).</p>
<p>So, he decided to start building a house on the same land where his hometown house was, in Portugal.</p>
<p>They couldn‚Äôt afford to buy a house in Geneva, but had enough savings that they could build one in his hometown.</p>
<p>They went back when he was 39 (I was 8), and that‚Äôs where I grew up.</p>
<p>My mum struggled to find a job for many years - she only got a job as a secretary at a furniture store - until they went bankrupt.</p>
<p>My dad had depression since he was stuck at home with nothing to do.</p>
<p>Growing up, I wanted to work as a bricklayer in summers to make some cash and my dad forbid me doing so.</p>
<p>He said that it was dangerous and he didn‚Äôt want me to have that life. He has seen a lot of young people dropping out of school because they start receiving salaries early and prioritise short-term outcomes over long-term ones.</p>
<p>He didn‚Äôt want me to follow that path.</p>
<p>He wanted to give me the opportunities that he didn‚Äôt have growing up. And he did.</p>
<p>One day I got home from high school, and commented that someone I knew always had expensive clothes and watches. He happened to know their family and got upset. He was upset because he knew that they owed a lot of money to a lot of people - and kept living a luxury lifestyle.
‚Ä®So he told me ‚ÄúYou may not wear all of that, but you will never hear in your life that we owe anything to anyone. Everything you have has been bought with a lot of hard work from your mother and I, and not by stealing or owing anything to anyone‚Äù.</p>
<p>I still think about this often, and how appearances are often just that.</p>
<p>A few years later after I got into university, my parents decided to move back to Switzerland.</p>
<p>My mum still didn‚Äôt have a job and we weren‚Äôt going home as much (we both studied relatively far from our hometown). It was hard on her to move away from us, but it was the right thing to do.</p>
<p>She found a job as a cleaner, which she has been doing for almost 10 years now.</p>
<p>In the meantime my dad wondered if he could leverage all the skills he had learned growing up to manage a housing project. So he bought land in Portugal, and was heavily involved in the management of the project. Meaning he worked across everything, except the physical aspects of the job.</p>
<p>It was an investment, but after having so many years in real estate - it was hard for someone to have as much knowledge breadth as he did in terms of costs of materials and staff since he had been on the other side of the coin for a long time.</p>
<p>Now he does that every now and then, which keeps him busy. But since it involves being far from my mum, this time he‚Äôs hiring an agency to be more involved at the expense of less headaches and a lower margin.</p>
<p>He has a good life now. But he came from nothing, literally.</p>
<p>Most people on his shoes, don‚Äôt make it.</p>
<p>Damn.</p>
<p>Most people with more opportunities than him don‚Äôt make it.</p>
<p>I often feel guilty because I get to live life in a way that my parents could never.</p>
<p>The best way I can think to repay them is to work hard and show them that their hard life will be the last that the future Lopes generation will have to endure.</p>
<p>That and hopefully buying them a nice car one day.</p>]]></content:encoded>
            <category>birthday</category>
            <category>dad</category>
            <category>family</category>
        </item>
        <item>
            <title><![CDATA[rabbit r1, there is hope]]></title>
            <link>https://didierlopes.com/blog/rabbit-r1-there-is-hope</link>
            <guid>https://didierlopes.com/blog/rabbit-r1-there-is-hope</guid>
            <pubDate>Sun, 28 Apr 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[I can see a future where people use rabbit r1 for very particular use cases where phone is suboptimal. For instance, when multiple people want to interact with said phone (e.g. selecting music at a party without having to give phone away) and that is not ideal due to personal information on phone, or when the phone isn't ideal because it has too many distractions and user wants to focus on doing something (e.g. practicing a presentation using recording session and then asking for feedback).]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope.png"></p>
<p>I can see a future where people use rabbit r1 for very particular use cases where phone is suboptimal. For instance, when multiple people want to interact with said phone (e.g. selecting music at a party without having to give phone away) and that is not ideal due to personal information on phone, or when the phone isn't ideal because it has too many distractions and user wants to focus on doing something (e.g. practicing a presentation using recording session and then asking for feedback).</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<h2 id="what-is-the-rabbit-r1">What is the rabbit r1</h2>
<p>Rabbit r1 was first introduced at CES 2024 as a pocket AI companion (watch the keynote <a href="https://www.rabbit.tech/rabbit-r1">here</a>).</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_1.png"></p>
<p>The main distinction over being just a "ChatGPT on-the-go" is the fact that they introduced what they call a Large Action Model (LAM), which is an agent capable of taking requests and making different function calls (e.g., translation, weather, finance, vision, taking notes, and more).</p>
<p>There are now quite a few consumer products that are trying to win this category. Here are a few:</p>
<ul>
<li>
<p><a href="https://humane.com/">AI pin</a> from Humane. MKBHD did a good <a href="https://www.youtube.com/watch?v=TitZV6k8zfA">review</a> on this product (or should I say 'bad review'?).</p>
</li>
<li>
<p><a href="https://www.limitless.ai/">pendant</a> from Limitless (previously Rewind AI).</p>
</li>
<li>
<p><a href="https://www.openinterpreter.com/">01</a> from Open Interpreter. I ordered this one because it's <a href="https://github.com/OpenInterpreter/open-interpreter">open source</a> and I can build on top.</p>
</li>
</ul>
<p>While at the surface these devices are somewhat similar, they approach the problem from a different angle. AI pin relies on users to clip their device to their clothes, the pendant is put on the collar of your top and 01 is held handheld. Rabbit r1 is also handheld, but unlike the others contains a screen to interact with - so it's closer to a phone than the others.</p>
<p>Nonetheless, according to Jesse (rabbit's CEO) they are currently the most successful AI device in terms of sales (sold over 100,000 rabbit r1 in a few weeks).</p>
<h2 id="how-i-got-my-r1">How I got my r1</h2>
<p>My wife saw me watching a few videos of rabbit r1 and decided to surprise me with one, a one-time $199 purchase without any subscription fee. I wonder why she didn‚Äôt do it when I was watching Apple Vision Pro üòÑ.</p>
<p>But they didn‚Äôt ship immediately. My batch was only meant to be shipped sometime in June. However, rabbit tweeted that there would be a Pickup Party in NYC. I added notifications on their X account and once they announced that registrations were open I was ready. I RSVPd and this week I attended the event to grab mine.</p>
<p>The event was well organized. One thing is for sure, rabbit knows how to build a community and hype with their users.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_2.png"></p>
<p>The keynote presented at the event can be found <a href="https://www.rabbit.tech/live-unboxing">here</a>. In it, rabbit's CEO unboxes a rabbit r1 and shows everything it can do on stage.</p>
<h2 id="my-experience">My experience</h2>
<p>I have been playing with rabbit r1 for a couple of days now. A few funny things I've done since:</p>
<ul>
<li>
<p>Jailbreak rabbit r1 to say <a href="https://x.com/didier_lopes/status/1783335809459859708">f*ck which falls outside the guidelines</a></p>
</li>
<li>
<p>Ask it what LLM it was using under the hood, to which it said <a href="https://x.com/didier_lopes/status/1783346493832753477">it was using a fine-tuned version of OpenAI's GPT-3</a></p>
</li>
<li>
<p>Have rabbit r1 make a <a href="https://x.com/didier_lopes/status/1784228313717776505">Deez Nuts joke</a></p>
</li>
<li>
<p>Use rabbit r1 as a <a href="https://x.com/didier_lopes/status/1784357946920505387">Not Hotdog app</a> (<a href="https://www.imdb.com/title/tt2575988/">Silicon Valley reference</a>)</p>
</li>
</ul>
<p>But now onto the serious stuff. Since I was at the Pickup Party where Jesse split the presentation based on the major features of the products, I want to address each of these individually after having time to play with them.</p>
<h3 id="search">Search</h3>
<p>For search, rabbit r1 relies on <a href="https://www.perplexity.ai/">Perplexity</a>. I'm a Perplexity fan myself and at some point I even replaced my default <a href="https://arc.net/">Arc browser</a> search engine with Perplexity. This only lasted one day because then I realized how many times I just wanted to end up on a landing page or on someone's LinkedIn/X. It made me realize why Google is, well, Google. Regardless, this is something that I do with my phone, and so I don't think it's a strong use case.</p>
<p>However, if you have a kid that is curious to understand the world. I think a rabbit r1 is well worth it to use it to ask questions that they are curious about, without having the distractions that a phone provides.</p>
<h3 id="vision">Vision</h3>
<p><strong>What is this</strong> - I just don't think this is a strong use case overall. This is not something that you do daily, weekly, or even monthly. Maybe once a year or so. The last time I did it was last year in Mexico to know the name of an animal that was nearby. I went to Google and looked for "Mexico animal that looks like a racoon" and the first answer was Coati which was what I was looking for. If that query didn't work, I would have taken a picture of the animal and then Google search - but that's my second choice because of the effort of doing so. This to say that it's not really a pain point that users will have.</p>
<p><strong>Edit spreadsheet</strong> - This is a somewhat interesting use case choice, I wonder if they picked it up because no other device showed being capable of doing this (taking a picture to a handwritten table, asking for a change and emailing the image to your email). Personally, I don't write tables that much anymore on paper, and the ones I do are small enough that if I want to transcribe it takes me seconds to do. It may be a strong use case for certain jobs, but I‚Äôm not sure about it, nor the performance it would have on large tables. The example Jesse shared at the event was a 5x3 tabl.</p>
<h3 id="terminal-mode">Terminal mode</h3>
<p>It‚Äôs like using ChatGPT but with a worse interface. The keyboard reminds me of BlackBerry but it‚Äôs gimmicky to use - personally, I didn‚Äôt like the experience. I would always pick up my phone to use ChatGPT over using the Terminal mode for instance.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_3.png"></p>
<h3 id="translation">Translation</h3>
<p>YES. Having Portuguese parents that don‚Äôt speak english, whenever they are with my wife, I need to be the translator. So having a device that allows them to translate in ‚Äúreal-time‚Äù both ways is a huge value add.</p>
<p>Yes, I know that Google already has this feature - but it's shit and if you disagree, you never actually used it. LLMs can understand expression and meaning, in a way that a model like BERT cannot. I actually did this post where I prompted ChatGPT to do exactly this - act as a device that stays in the middle of a conversation translating from one language to another based on who the speaker was (tweet <a href="https://x.com/didier_lopes/status/1740049615804846461">here</a>, it went kind of viral).</p>
<p>Sure, this could be an app, but I quite like the idea of having a device that just does this. I think that‚Äôs because the translation works both ways, so I imagine you passing the device to the other person to press the button when they want to speak. So that way, it feels more like a ‚Äúcommon‚Äù object whereas your phone is more personal.</p>
<p>Although I was excited about this, and it was the first thing I tried it failed badly. The CTO of the company <a href="https://x.com/LiaoPeiyuan/status/1783001793573843078">replied</a> to <a href="https://x.com/didier_lopes/status/1783000272278569412">my tweet</a> saying that they are working on fixing it.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_4.png"></p>
<h3 id="notes">Notes</h3>
<p>Yay, another note-taking app. NOT. I‚Äôd prefer an integration with the Apple Notes app or Notion, so I don‚Äôt need to then go into yet another website and copy-paste those notes to some other place.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_5.png"></p>
<h3 id="voice-recording">Voice Recording</h3>
<p>The voice recording feature is pretty good. If you are a content creator (e.g., writer, youtuber), I think this is very powerful. The way I see it is that rabbit offers way less distractions than your phone, so you could go on a walk and take r1 and just speak with it to brainstorm ideas. Then go to the website and analyze your ideas to transform it into content.</p>
<p>Personally, when I have ideas like this I just drop a voice note to my wife‚Äôs WhatsApp and then mark the message as unread. It‚Äôs hacky but it works and I've been doing it for a long time now. We have an inside joke where I start these audios with ‚ÄúNote to self‚Äù and she always makes fun of it.</p>
<div class="flex justify-center gap-2"><img src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_6.png" width="50%"><img src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_7.png" width="50%"></div>
<h3 id="music">Music</h3>
<p>Last year for my birthday my wife gave me a <a href="https://divoom.com/products/divoom-pro">Divoom Ditoo-Pro Retro</a> - it does a lot of things (e.g. music, radio, alarm, voice memo, games, music, planner, pixel art). Honestly, I just use it for music. It lived in my car during the entire year as a speaker since I didn't have bluetooth audio in the car. I think the advantage of rabbit r1 over it is that I can use my voice to change the music, which is handy if you are driving. On the other hand, my Divoom allows me to listen to my audibles since it acts as a bluetooth speaker whereas rabbit r1 would need an audible integration.</p>
<p>I think this can be a compelling use case as sitting in the middle of the table at a dinner or party with friends, where if someone wants to change the music they can just use the rabbit r1 to ask for something - and this way you can keep your phone/laptop on you instead of using it for everybody else to touch.</p>
<h3 id="apps">Apps</h3>
<p><strong>Doordash/Uber</strong> - I haven‚Äôt tried it yet, but I feel like the phone is so good at it already and with a rich UI/UX, that I don‚Äôt see the point in using rabbit r1.</p>
<p><strong>Generative AI</strong> - This is an interesting use case. Personally I don‚Äôt use Midjourney so I'm not the target audience. I do find it interesting that you can generate these images on the go on r1 directly without having to go through Discord (suboptimal) experience. I'm excited about the opportunities that this presents - for instance, integrating with <a href="https://openbb.co/products/bot">OpenBB Bot</a> to display financial data on rabbit r1 directly.</p>
<h3 id="teach-mode">Teach mode</h3>
<p>Jesse showed a brief preview of how teach mode works but mentioned that this feature is not yet available and they want to nail the user experience and add guardrails so users cannot use it for something malicious. I'm very excited about the teach mode prospect, since I think this falls in the category of "app creation" and allows users to use the device for very specific needs, hence opening the total addressable market.</p>
<h2 id="conclusion">Conclusion</h2>
<p>First of all, the rabbit r1 is beautiful. It's light, well made and has this bright appealing color. This isn't surprising since it was done in collaboration with <a href="https://teenage.engineering/">Teenage Engineering</a> (a company known for making products that I want without knowing what they do).</p>
<p>This may be controversial, but the thing I like the least about the hardware is the button being located on the right side. The reason why I hate that decision is that I cannot easily use the device with one hand only. If I try, it becomes very gimmicky where I do gymnastics just to press the button. I don't get why they didn't make it right under the scrolling wheel, it would resemble more a controller/phone which is something that our hands have long been accustomed to. Even if the button was located on the upper side of the device, the UX would be MUCH better.</p>
<p>That's one of my biggest complaints against the hardware itself, see image below to see what I mean. I almost need to bend my right thumb in order to reach the button which is used very often. One can argue that I can wrap my hands more around the device to give a better experiencing in clicking the button which is 100% true, HOWEVER, if I do that then I can't reach the wheel to scroll.</p>
<div class="flex justify-center gap-2"><img src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_8.png" width="50%"><img src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_9.png" width="50%"></div>
<br>
<p>Also, related with the picture from the above. The battery is pretty weak, it needs to be charged often.</p>
<p>The rabbit r1 OS has a lot of room for improvement, a few things I've experienced:</p>
<ul>
<li>Having a black screen that doesn't recover until I manually power off device;</li>
<li>Not triggering the function I want - sometimes it looks for a specific wording, e.g. "start a recording session" works but "do a voice recording" does not. I would have expected for it to be able to understand intent;</li>
<li>Sometimes I get a "The app is under maintenance. Please try again later" for functions that I know it is capable of doing;</li>
<li>Every few minutes getting "unable to connect to Rabbit OS";</li>
<li>Randomly losing the previous context - I assume this is because of the number of tokens that can fit in the context?;</li>
<li>Spotify integration broken;</li>
<li>Even though it knows my location (due to getting weather app location correct), the time is not correct and I can't update it through the settings.</li>
</ul>
<p>But this is also the first product version and LLMs are by nature non-deterministic so these type of bugs are kind of expected.</p>
<p>It's a one-time $199 price tag. There's no recurring subscription. As a consumer, I like this a lot. A one-time purchase allows users to buy the product to experiment without any strong commitment (apart from that one-time fee of course). In terms of economics, I'm not sure how Rabbit will handle a growing user base and better LLMs. During the event, they mentioned a partnership with both OpenAI and Anthropic. If they are using one of these models, someone needs to be paying for these tokens. For instance, for <a href="https://openbb.co/products/pro">OpenBB Terminal Pro</a> we decided to allow usage similarly to how the ChatGPT free tier works, which basically rate limits based on usage and allows us to keep our costs controlled.</p>
<p>Meta is attempting to commoditize LLMs, so if I were in rabbit's shoes I would consider hosting <a href="https://llama.meta.com/llama3/">Llama 3</a> locally and providing inference from this directly. Maybe even do a partnership with <a href="https://groq.com/">Groq</a> for users paying a small subscription - not so much because of the impressive 800 tokens/s inference (using Llama 3) since rabbit r1 uses voice and inference speed is less relevant, but for the cold start (i.e. the lag between user question and output). Meta's commercial license only applies to companies with over 700 Million active users, so I think Rabbit would be good for some time.</p>
<p>Personally, I wouldn‚Äôt recommend rabbit r1 as a phone alternative. Not even close. If someone says that they stopped using their phone after having their rabbit r1, I can guarantee you that they weren‚Äôt using their phone a lot anyway. I agree a lot with MKBHD in saying <a href="https://www.youtube.com/watch?v=TitZV6k8zfA">Phones are OP</a>.</p>
<p>But if you are reading this, you are probably wondering what are the use cases where I would recommend Rabbit r1. So let's do that.</p>
<h3 id="this-is-a-buy-if">This is a buy if</h3>
<ul>
<li>
<p>For kids that are curious and want to learn more about the world. Being able to have it before a phone, is very compelling. Imagine your kid being able to ask r1 what a word means and how to use it in a sentence, who person X is, how something works, to practice learning another language, as a complement when reading a book/studying. The advantage over the phone is that it doesn't have any other distractions. It would basically be Perplexity on the go, and thus the Perplexity tagline "Where knowledge begins" makes total sense.</p>
</li>
<li>
<p>As a device for two-way translation. The two-way is important, because if it‚Äôs just one-way then using the phone is preferred. But being two-way allows for both people to interact with the device, which in my opinion is less personal than a phone and more like a gadget. We aren't there yet, but I'm sure the model will keep improving and becoming better at this.</p>
</li>
<li>
<p>For content creators who want to ‚Äúzone out‚Äù and leave their phone at home and just use the record feature to record content, whether that is a blog post, a new lyrics or a podcast idea.</p>
</li>
<li>
<p>As a music device to be at the center of a table at a dinner, in the corner at a party selecting the tunes or on a roadtrip. People will enjoy interacting with it due to its unique nature, and that way you don't need to be blocked from using your phone.</p>
</li>
<li>
<p>As a virtual assistant. If the alarm feature was already implemented, I would've likely already replace my Alexa, since rabbit r1 looks much nicer. Even more with the cool standing case.</p>
</li>
</ul>
<p>... and of course, the use case is worth $200 for you. There are likely devices that can achieve the same for a cheaper cost. I like the fact that is state-of-the-art and they are trying to innovate.</p>
<p>Also, the rabbit effect going up and down waiting to be prompted and the hears going up when listening is pretty sweet - see it <a target="_blank" data-nobrokenlinkcheck="true" href="https://didierlopes.com/assets/files/2024-04-28-rabbit-r1-there-is-hope_10-7f8ddd0aa7943163b831fe104197e46a.png">here</a>.</p>
<p>In any case, there are two recurring topics in these use cases, so let's talk about each individually.</p>
<h3 id="main-use-cases">Main use cases</h3>
<ol>
<li>
<p><strong>A very targeted use case</strong> - The phone can be a double-edged sword. On the one hand, it's your door to the world and what's happening. On the other hand, it's your door to the world and what's happening. I say it this way because this can be extremely good or bad depending on the use case. Phones are optimized for users to spend time on them, apps are optimized to provide dopamine hits so users use them for longer. Notifications will interrupt you throughout the day so you remember to go back to the app, etc.. But sometimes you only want to do 1 thing, and don't want to be distracted from it. The best example are E-Books. You can read on your phone, iPad or laptop - yet people decide to buy a kindle so they can just do that. Read with no distractions. You are paying a premium for a product to remove the distractions. I believe that rabbit r1 can achieve this, particularly if they allow developers to build specific apps for specific use cases.</p>
</li>
<li>
<p><strong>Gadget to be used by multiple people</strong> (examples above: two-way translation or music device) - The phone has become a very personal device over the years. If someone gets access to your phone unlocked they have access to who you are (important emails, personal photos, chat conversations, the apps you use and how do you spend your time, the songs you listen or books you read, even confidential documents). So, there are certain scenarios where you don't want to borrow your phone to someone to do something, since that requires trust that they won't see anything that is confidential. I think Rabbit r1 can go after this category because its a shiny gadget that doesn't really hold any personal information from the user, and this way allows the user to keep their phone in their pocket while using rabbit r1 for some tasks that the phone could also do but would require for others to have access to it.</p>
</li>
</ol>
<br>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_11.png"></p>
<h2 id="excited-about">Excited about</h2>
<h3 id="developer-ecosystem">Developer Ecosystem</h3>
<p>Apple became Apple not because of their revolutionary LCD screen without a keyboard, but because of the developer ecosystem they created. The iPhone became stickier over time, because there were more apps being built on top of it that users could easily tap into. It also allowed Apple to generate revenue from the monetization of these apps.</p>
<p>I truly hope that this is the direction that Jesse and team want to take. If I were in their shoes, I would prioritize that over any other feature. Just allow developers to create apps (in this case functions) that the LAM can call to do something very specific.</p>
<p>Instead of having their team working on all these features, create the foundational marketplace that allows developers to do so. Start by only allowing free apps and see what developers are building and what users are utilizing. Then move to allow developers to monetize and take a cut from it. And allow users to decide what apps are enabled within their devices and which ones aren't - show which apps are the most downloaded and used and link it to a user profile. Make it so that the user profile needs to be a rabbit r1 holder to avoid scams..</p>
<p>A few examples: Someone building a Pokedex app for animals, you take r1 to the zoo and just take a picture of the animals with it, then you go home and look into your pokedex. Or a Pokedex for travel monuments. Or integrating OpenBB so I could do research on-the-go.</p>
<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-04-28-rabbit-r1-there-is-hope_12.png"></p>
<h3 id="native-ai-phone">Native AI-phone</h3>
<p><a href="https://us.nothing.tech/">Nothing</a> has one of the best consumer tech brands out there. If the Apple ecosystem wasn't as sticky as it is today, I would buy one. Both Nothing and Rabbit are very unique brands, and I think a partnership between them could be a game-changer.</p>
<p>I'm imagining a Native AI-phone built on Android with rabbit's LAM. So, in simple terms, it would be like Nothing Phone (2) but it would have an r1 button that you can use to interact with it through voice instead of fingers. The challenge would be combining the LAM from rabbit r1 to all the apps that Nothing Phone (2) provides - but I believe in a future where applications will be built not only thinking about how humans will utilize them but also LLMs - at least <a href="https://github.com/OpenBB-finance/openbb-agents">we are doing that at OpenBB</a> with the <a href="https://github.com/OpenBB-finance/OpenBBTerminal">OpenBB Platform</a>.</p>]]></content:encoded>
            <category>rabbit r1</category>
            <category>tech</category>
            <category>review</category>
            <category>ai</category>
            <category>gadget</category>
        </item>
        <item>
            <title><![CDATA[Goh Analyst - The AI-powered financial analyst who lives on Slack]]></title>
            <link>https://didierlopes.com/blog/goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack</link>
            <guid>https://didierlopes.com/blog/goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack</guid>
            <pubDate>Tue, 26 Mar 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[How I built a financial analyst that lives on Slack and has access to OpenBB.]]></description>
            <content:encoded><![CDATA[<p align="center"><img width="600" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_1.png"></p>
<p>How I built a financial analyst that lives on Slack and has access to OpenBB.</p>
<p>The open source code is available <a href="https://github.com/DidierRLopes/openbb-slack-agent">here</a>.</p>
<div style="border-top:1px solid #0088CC;margin:1.5em 0"></div>
<h2 id="context">Context</h2>
<p>At OpenBB, we have the tradition of hosting an internal Creaton on the penultimate week of the year.</p>
<p>The OpenBB Creaton is our creative Hackathon, where every team member picks a project to work on throughout the week and gets fully focused on it. The only rule is that it relies on OpenBB technology.</p>
<p>It‚Äôs a way for us to get further contact with our technology, but it also allows us to create proofs-of-concept of products/features that we may invest in the feature. Think of it as an R&amp;D week.</p>
<p>We do it then because our team members get the last week of the year as time off. So, if they want to present their project to the rest of the team in January, they can also use that time to wrap up.</p>
<h2 id="my-project">My Project</h2>
<p>At the Open Core Summit III, I presented a way of creating an AI-powered financial analyst capable of handling complex financial queries.</p>
<p>I wrote more about this in this <a href="https://didierlopes.com/blog/creating-an-ai-powered-financial-analyst">blog post</a>. This robust architecture can access 100+ financial datasets from OpenBB tools and reason about them. The code is open source here.</p>
<p>I shared how our AI-powered financial analyst was able to answer</p>
<blockquote>
<p>‚ÄúCheck what TSLA peers are. From those, check which one has the highest market cap. Then, for the ticker that has the highest market cap, get the most recent price target estimate from an analyst, and tell me who it was and on what date the estimate was made.‚Äù</p>
</blockquote>
<br>
<p>and</p>
<blockquote>
<p>‚ÄúPerform a fundamentals financial analysis of AMZN using the most recently available data. What do you find that‚Äôs interesting?‚Äù</p>
</blockquote>
<br>
<p>Since that was already working so well (watch the <a href="https://www.youtube.com/watch?v=A-43EKK2PhE&amp;embeds_referring_euri=https://openbb.co/blog/creating-an-ai-powered-financial-analyst&amp;source_ve_path=MjM4NTE">presentation video here</a>), I wanted to bring these capabilities to Slack, show that this could be the future, and prove it would impact every analyst job.</p>
<p>That‚Äôs when Goh Analyst was born.</p>
<p align="center"><img width="800" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_2.png"></p>
<p>Note: Goh Analyst together is GOHANalyst, which is why the image is Gohan from Dragon Ball with the OpenBB logo on his forehead.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>To get started, you can see the <a href="https://github.com/DidierRLopes/openbb-slack-agent/tree/main">open-source repository and instructions</a>.</p>
<p>First, I forked the <a href="https://github.com/OpenBB-finance/openbb-agents">open-source code of the OpenBB agents repository</a> that we have been using for R&amp;D. This repository contains all the code for the OpenBB agent and has access to 100+ financial datasets.</p>
<p>Then, I modified it to my needs:</p>
<p>Created the Slack bot interface</p>
<p>When a Slack message mentions @Gohanalyst this workflow gets triggered</p>
<p>When the Slack message contains the word ‚ÄúOpenBB‚Äù, I send that message through the OpenBB agent since the assumption is that data retrieval will be necessary. Otherwise, it goes straight through OpenAI.</p>
<p>In a nutshell, this is what the architecture looks like:</p>
<p align="center"><img width="800" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_3.png"></p>
<p>I made Goh Analyst slightly sarcastic to make it a bit more fun. This makes interacting in a public channel somewhat more human and exciting. It can handle simple financial questions, retrieve data using OpenBB tools, or even answer more complex reasoning questions.</p>
<p align="center"><img width="800" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_4.png"></p>
<p align="center"><img width="800" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_5.png"></p>
<p>Now imagine that every organization has an analyst on their Slack to help make decisions.</p>
<h2 id="whats-next">What's next</h2>
<p>As I mentioned earlier, one of the advantages we get from OpenBB Creaton is that we test our products and give feedback to the team on what went well or less well. After working on this project, this is what I shared with the team:</p>
<p align="center"><img width="800" src="https://didierlopes.com/blog/2024-03-28-goh-analyst-the-ai-powered-financial-analyst-who-lives-on-slack_6.png"></p>
<p>Exciting times we live in. If you want to leverage AI within your financial firm, we can help you ü§ù</p>]]></content:encoded>
            <category>learning</category>
            <category>experience</category>
            <category>growth</category>
            <category>moving</category>
            <category>london</category>
            <category>bay</category>
            <category>US</category>
            <category>travel</category>
            <category>startup</category>
            <category>nyc</category>
        </item>
    </channel>
</rss>